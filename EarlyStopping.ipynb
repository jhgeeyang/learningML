{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/3000\n",
      "700/700 [==============================] - 0s 291us/step - loss: 2.2576 - acc: 0.1643 - val_loss: 2.2272 - val_acc: 0.1633\n",
      "Epoch 2/3000\n",
      "700/700 [==============================] - 0s 82us/step - loss: 2.2072 - acc: 0.1657 - val_loss: 2.1908 - val_acc: 0.1800\n",
      "Epoch 3/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 2.1730 - acc: 0.1729 - val_loss: 2.1631 - val_acc: 0.1867\n",
      "Epoch 4/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 2.1441 - acc: 0.1786 - val_loss: 2.1372 - val_acc: 0.1867\n",
      "Epoch 5/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 2.1177 - acc: 0.1900 - val_loss: 2.1141 - val_acc: 0.1867\n",
      "Epoch 6/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 2.0940 - acc: 0.2029 - val_loss: 2.0931 - val_acc: 0.2033\n",
      "Epoch 7/3000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 2.0721 - acc: 0.2071 - val_loss: 2.0727 - val_acc: 0.2067\n",
      "Epoch 8/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 2.0520 - acc: 0.2129 - val_loss: 2.0564 - val_acc: 0.2067\n",
      "Epoch 9/3000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 2.0342 - acc: 0.2157 - val_loss: 2.0410 - val_acc: 0.2033\n",
      "Epoch 10/3000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 2.0190 - acc: 0.2143 - val_loss: 2.0269 - val_acc: 0.2067\n",
      "Epoch 11/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 2.0041 - acc: 0.2186 - val_loss: 2.0125 - val_acc: 0.2100\n",
      "Epoch 12/3000\n",
      "700/700 [==============================] - 0s 118us/step - loss: 1.9911 - acc: 0.2200 - val_loss: 2.0037 - val_acc: 0.2100\n",
      "Epoch 13/3000\n",
      "700/700 [==============================] - 0s 120us/step - loss: 1.9789 - acc: 0.2286 - val_loss: 1.9955 - val_acc: 0.2100\n",
      "Epoch 14/3000\n",
      "700/700 [==============================] - 0s 115us/step - loss: 1.9685 - acc: 0.2329 - val_loss: 1.9833 - val_acc: 0.2067\n",
      "Epoch 15/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.9582 - acc: 0.2214 - val_loss: 1.9753 - val_acc: 0.2100\n",
      "Epoch 16/3000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.9484 - acc: 0.2357 - val_loss: 1.9686 - val_acc: 0.2000\n",
      "Epoch 17/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.9393 - acc: 0.2343 - val_loss: 1.9612 - val_acc: 0.2033\n",
      "Epoch 18/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.9309 - acc: 0.2314 - val_loss: 1.9537 - val_acc: 0.2100\n",
      "Epoch 19/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.9232 - acc: 0.2286 - val_loss: 1.9452 - val_acc: 0.2100\n",
      "Epoch 20/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.9156 - acc: 0.2386 - val_loss: 1.9392 - val_acc: 0.2100\n",
      "Epoch 21/3000\n",
      "700/700 [==============================] - 0s 147us/step - loss: 1.9085 - acc: 0.2343 - val_loss: 1.9363 - val_acc: 0.2100\n",
      "Epoch 22/3000\n",
      "700/700 [==============================] - 0s 139us/step - loss: 1.9011 - acc: 0.2386 - val_loss: 1.9289 - val_acc: 0.2033\n",
      "Epoch 23/3000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.8954 - acc: 0.2357 - val_loss: 1.9234 - val_acc: 0.2100\n",
      "Epoch 24/3000\n",
      "700/700 [==============================] - 0s 83us/step - loss: 1.8895 - acc: 0.2314 - val_loss: 1.9201 - val_acc: 0.2067\n",
      "Epoch 25/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.8830 - acc: 0.2343 - val_loss: 1.9178 - val_acc: 0.2167\n",
      "Epoch 26/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.8769 - acc: 0.2300 - val_loss: 1.9105 - val_acc: 0.2167\n",
      "Epoch 27/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.8715 - acc: 0.2357 - val_loss: 1.9098 - val_acc: 0.2167\n",
      "Epoch 28/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.8662 - acc: 0.2400 - val_loss: 1.9094 - val_acc: 0.2000\n",
      "Epoch 29/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.8615 - acc: 0.2400 - val_loss: 1.9041 - val_acc: 0.1900\n",
      "Epoch 30/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.8565 - acc: 0.2243 - val_loss: 1.8976 - val_acc: 0.2167\n",
      "Epoch 31/3000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.8513 - acc: 0.2471 - val_loss: 1.8971 - val_acc: 0.1933\n",
      "Epoch 32/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.8463 - acc: 0.2371 - val_loss: 1.8925 - val_acc: 0.1900\n",
      "Epoch 33/3000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.8423 - acc: 0.2229 - val_loss: 1.8874 - val_acc: 0.2067\n",
      "Epoch 34/3000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 1.8382 - acc: 0.2371 - val_loss: 1.8808 - val_acc: 0.1933\n",
      "Epoch 35/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.8335 - acc: 0.2471 - val_loss: 1.8836 - val_acc: 0.1900\n",
      "Epoch 36/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.8299 - acc: 0.2343 - val_loss: 1.8756 - val_acc: 0.1967\n",
      "Epoch 37/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.8257 - acc: 0.2486 - val_loss: 1.8745 - val_acc: 0.1800\n",
      "Epoch 38/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.8220 - acc: 0.2371 - val_loss: 1.8700 - val_acc: 0.1933\n",
      "Epoch 39/3000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.8184 - acc: 0.2457 - val_loss: 1.8706 - val_acc: 0.1767\n",
      "Epoch 40/3000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.8144 - acc: 0.2314 - val_loss: 1.8677 - val_acc: 0.2000\n",
      "Epoch 41/3000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.8105 - acc: 0.2400 - val_loss: 1.8668 - val_acc: 0.1833\n",
      "Epoch 42/3000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 1.8075 - acc: 0.2471 - val_loss: 1.8635 - val_acc: 0.1800\n",
      "Epoch 43/3000\n",
      "700/700 [==============================] - 0s 81us/step - loss: 1.8046 - acc: 0.2429 - val_loss: 1.8611 - val_acc: 0.1700\n",
      "Epoch 44/3000\n",
      "700/700 [==============================] - 0s 78us/step - loss: 1.8001 - acc: 0.2371 - val_loss: 1.8566 - val_acc: 0.1967\n",
      "Epoch 45/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.7970 - acc: 0.2429 - val_loss: 1.8564 - val_acc: 0.1700\n",
      "Epoch 46/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 1.7939 - acc: 0.2271 - val_loss: 1.8528 - val_acc: 0.1933\n",
      "Epoch 47/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.7913 - acc: 0.2600 - val_loss: 1.8552 - val_acc: 0.1833\n",
      "Epoch 48/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.7886 - acc: 0.2471 - val_loss: 1.8543 - val_acc: 0.1867\n",
      "Epoch 49/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.7858 - acc: 0.2486 - val_loss: 1.8504 - val_acc: 0.1867\n",
      "Epoch 50/3000\n",
      "700/700 [==============================] - 0s 121us/step - loss: 1.7819 - acc: 0.2471 - val_loss: 1.8443 - val_acc: 0.2267\n",
      "Epoch 51/3000\n",
      "700/700 [==============================] - 0s 98us/step - loss: 1.7794 - acc: 0.2643 - val_loss: 1.8468 - val_acc: 0.1900\n",
      "Epoch 52/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.7762 - acc: 0.2486 - val_loss: 1.8411 - val_acc: 0.1933\n",
      "Epoch 53/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.7744 - acc: 0.2514 - val_loss: 1.8486 - val_acc: 0.2000\n",
      "Epoch 54/3000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 1.7716 - acc: 0.2700 - val_loss: 1.8472 - val_acc: 0.1800\n",
      "Epoch 55/3000\n",
      "700/700 [==============================] - 0s 126us/step - loss: 1.7687 - acc: 0.2500 - val_loss: 1.8364 - val_acc: 0.2033\n",
      "Epoch 56/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.7672 - acc: 0.2543 - val_loss: 1.8430 - val_acc: 0.2200\n",
      "Epoch 57/3000\n",
      "700/700 [==============================] - 0s 98us/step - loss: 1.7641 - acc: 0.2714 - val_loss: 1.8390 - val_acc: 0.2167\n",
      "Epoch 58/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.7616 - acc: 0.2557 - val_loss: 1.8347 - val_acc: 0.2267\n",
      "Epoch 59/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.7590 - acc: 0.2671 - val_loss: 1.8329 - val_acc: 0.2233\n",
      "Epoch 60/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 98us/step - loss: 1.7552 - acc: 0.2614 - val_loss: 1.8256 - val_acc: 0.2500\n",
      "Epoch 61/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.7566 - acc: 0.2814 - val_loss: 1.8336 - val_acc: 0.2400\n",
      "Epoch 62/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.7531 - acc: 0.2729 - val_loss: 1.8312 - val_acc: 0.2267\n",
      "Epoch 63/3000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 1.7505 - acc: 0.2857 - val_loss: 1.8299 - val_acc: 0.2000\n",
      "Epoch 64/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.7484 - acc: 0.2800 - val_loss: 1.8268 - val_acc: 0.2200\n",
      "Epoch 65/3000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.7457 - acc: 0.2814 - val_loss: 1.8298 - val_acc: 0.2033\n",
      "Epoch 66/3000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.7439 - acc: 0.2786 - val_loss: 1.8296 - val_acc: 0.2067\n",
      "Epoch 67/3000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 1.7419 - acc: 0.2700 - val_loss: 1.8299 - val_acc: 0.2067\n",
      "Epoch 68/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.7405 - acc: 0.2729 - val_loss: 1.8238 - val_acc: 0.2000\n",
      "Epoch 69/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.7376 - acc: 0.2814 - val_loss: 1.8298 - val_acc: 0.2167\n",
      "Epoch 70/3000\n",
      "700/700 [==============================] - 0s 108us/step - loss: 1.7356 - acc: 0.2857 - val_loss: 1.8269 - val_acc: 0.2433\n",
      "Epoch 71/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.7345 - acc: 0.2800 - val_loss: 1.8214 - val_acc: 0.2167\n",
      "Epoch 72/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.7328 - acc: 0.2857 - val_loss: 1.8226 - val_acc: 0.2133\n",
      "Epoch 73/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.7298 - acc: 0.2800 - val_loss: 1.8252 - val_acc: 0.2467\n",
      "Epoch 74/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.7283 - acc: 0.2857 - val_loss: 1.8257 - val_acc: 0.1967\n",
      "Epoch 75/3000\n",
      "700/700 [==============================] - 0s 88us/step - loss: 1.7268 - acc: 0.2786 - val_loss: 1.8190 - val_acc: 0.2267\n",
      "Epoch 76/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.7255 - acc: 0.2857 - val_loss: 1.8196 - val_acc: 0.2233\n",
      "Epoch 77/3000\n",
      "700/700 [==============================] - 0s 81us/step - loss: 1.7228 - acc: 0.3057 - val_loss: 1.8232 - val_acc: 0.2033\n",
      "Epoch 78/3000\n",
      "700/700 [==============================] - 0s 82us/step - loss: 1.7212 - acc: 0.2857 - val_loss: 1.8187 - val_acc: 0.1933\n",
      "Epoch 79/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.7199 - acc: 0.2829 - val_loss: 1.8203 - val_acc: 0.2433\n",
      "Epoch 80/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.7188 - acc: 0.2929 - val_loss: 1.8197 - val_acc: 0.2067\n",
      "Epoch 81/3000\n",
      "700/700 [==============================] - 0s 78us/step - loss: 1.7165 - acc: 0.2843 - val_loss: 1.8256 - val_acc: 0.2067\n",
      "Epoch 82/3000\n",
      "700/700 [==============================] - 0s 79us/step - loss: 1.7142 - acc: 0.2829 - val_loss: 1.8144 - val_acc: 0.2667\n",
      "Epoch 83/3000\n",
      "700/700 [==============================] - 0s 85us/step - loss: 1.7132 - acc: 0.2857 - val_loss: 1.8190 - val_acc: 0.2400\n",
      "Epoch 84/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.7127 - acc: 0.2986 - val_loss: 1.8220 - val_acc: 0.2167\n",
      "Epoch 85/3000\n",
      "700/700 [==============================] - 0s 122us/step - loss: 1.7097 - acc: 0.2971 - val_loss: 1.8159 - val_acc: 0.2267\n",
      "Epoch 86/3000\n",
      "700/700 [==============================] - 0s 86us/step - loss: 1.7082 - acc: 0.2800 - val_loss: 1.8136 - val_acc: 0.2633\n",
      "Epoch 87/3000\n",
      "700/700 [==============================] - 0s 84us/step - loss: 1.7051 - acc: 0.3100 - val_loss: 1.8191 - val_acc: 0.2733\n",
      "Epoch 88/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.7062 - acc: 0.3043 - val_loss: 1.8125 - val_acc: 0.2433\n",
      "Epoch 89/3000\n",
      "700/700 [==============================] - 0s 81us/step - loss: 1.7043 - acc: 0.3043 - val_loss: 1.8167 - val_acc: 0.2167\n",
      "Epoch 90/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 1.7027 - acc: 0.2843 - val_loss: 1.8151 - val_acc: 0.2233\n",
      "Epoch 91/3000\n",
      "700/700 [==============================] - 0s 98us/step - loss: 1.7017 - acc: 0.3086 - val_loss: 1.8185 - val_acc: 0.2167\n",
      "Epoch 92/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.6987 - acc: 0.3129 - val_loss: 1.8215 - val_acc: 0.2067\n",
      "Epoch 93/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.6980 - acc: 0.3071 - val_loss: 1.8173 - val_acc: 0.2767\n",
      "Epoch 94/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.6970 - acc: 0.3157 - val_loss: 1.8176 - val_acc: 0.2100\n",
      "Epoch 95/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.6943 - acc: 0.2986 - val_loss: 1.8194 - val_acc: 0.2833\n",
      "Epoch 96/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.6948 - acc: 0.3014 - val_loss: 1.8095 - val_acc: 0.2233\n",
      "Epoch 97/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.6930 - acc: 0.3057 - val_loss: 1.8228 - val_acc: 0.2300\n",
      "Epoch 98/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.6921 - acc: 0.3043 - val_loss: 1.8117 - val_acc: 0.2200\n",
      "Epoch 99/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.6901 - acc: 0.3129 - val_loss: 1.8252 - val_acc: 0.2233\n",
      "Epoch 100/3000\n",
      "700/700 [==============================] - 0s 108us/step - loss: 1.6890 - acc: 0.3129 - val_loss: 1.8210 - val_acc: 0.2267\n",
      "Epoch 101/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.6878 - acc: 0.3143 - val_loss: 1.8190 - val_acc: 0.2200\n",
      "Epoch 102/3000\n",
      "700/700 [==============================] - 0s 98us/step - loss: 1.6877 - acc: 0.3014 - val_loss: 1.8219 - val_acc: 0.2300\n",
      "Epoch 103/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.6843 - acc: 0.3000 - val_loss: 1.8102 - val_acc: 0.2500\n",
      "Epoch 104/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.6842 - acc: 0.3200 - val_loss: 1.8122 - val_acc: 0.2200\n",
      "Epoch 105/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.6821 - acc: 0.3071 - val_loss: 1.8063 - val_acc: 0.2067\n",
      "Epoch 106/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.6814 - acc: 0.3114 - val_loss: 1.8173 - val_acc: 0.2200\n",
      "Epoch 107/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.6805 - acc: 0.3071 - val_loss: 1.8228 - val_acc: 0.2367\n",
      "Epoch 108/3000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.6784 - acc: 0.3071 - val_loss: 1.8167 - val_acc: 0.2767\n",
      "Epoch 109/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.6782 - acc: 0.3143 - val_loss: 1.8178 - val_acc: 0.2300\n",
      "Epoch 110/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.6775 - acc: 0.3171 - val_loss: 1.8147 - val_acc: 0.2133\n",
      "Epoch 111/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.6775 - acc: 0.3043 - val_loss: 1.8173 - val_acc: 0.2233\n",
      "Epoch 112/3000\n",
      "700/700 [==============================] - 0s 92us/step - loss: 1.6745 - acc: 0.3129 - val_loss: 1.8193 - val_acc: 0.2267\n",
      "Epoch 113/3000\n",
      "700/700 [==============================] - 0s 83us/step - loss: 1.6737 - acc: 0.3100 - val_loss: 1.8196 - val_acc: 0.2300\n",
      "Epoch 114/3000\n",
      "700/700 [==============================] - 0s 83us/step - loss: 1.6724 - acc: 0.3014 - val_loss: 1.8221 - val_acc: 0.2300\n",
      "Epoch 115/3000\n",
      "700/700 [==============================] - 0s 98us/step - loss: 1.6711 - acc: 0.3071 - val_loss: 1.8128 - val_acc: 0.2333\n",
      "Epoch 116/3000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.6703 - acc: 0.3157 - val_loss: 1.8255 - val_acc: 0.2300\n",
      "Epoch 117/3000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.6694 - acc: 0.3100 - val_loss: 1.8228 - val_acc: 0.2333\n",
      "Epoch 118/3000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.6682 - acc: 0.3114 - val_loss: 1.8262 - val_acc: 0.2333\n",
      "Epoch 119/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.6670 - acc: 0.3257 - val_loss: 1.8216 - val_acc: 0.2200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 120/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.6661 - acc: 0.3129 - val_loss: 1.8219 - val_acc: 0.2200\n",
      "Epoch 121/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.6646 - acc: 0.3071 - val_loss: 1.8132 - val_acc: 0.2233\n",
      "Epoch 122/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.6637 - acc: 0.3229 - val_loss: 1.8194 - val_acc: 0.2200\n",
      "Epoch 123/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.6629 - acc: 0.3100 - val_loss: 1.8139 - val_acc: 0.2200\n",
      "Epoch 124/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.6619 - acc: 0.3143 - val_loss: 1.8187 - val_acc: 0.2267\n",
      "Epoch 125/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.6606 - acc: 0.3257 - val_loss: 1.8212 - val_acc: 0.2333\n",
      "Epoch 126/3000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.6592 - acc: 0.3143 - val_loss: 1.8245 - val_acc: 0.2233\n",
      "Epoch 127/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.6583 - acc: 0.3129 - val_loss: 1.8147 - val_acc: 0.2333\n",
      "Epoch 128/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.6565 - acc: 0.3300 - val_loss: 1.8280 - val_acc: 0.2300\n",
      "Epoch 129/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.6570 - acc: 0.3143 - val_loss: 1.8193 - val_acc: 0.2200\n",
      "Epoch 130/3000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.6548 - acc: 0.3214 - val_loss: 1.8124 - val_acc: 0.2533\n",
      "Epoch 131/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.6547 - acc: 0.3229 - val_loss: 1.8202 - val_acc: 0.2500\n",
      "Epoch 132/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.6545 - acc: 0.3200 - val_loss: 1.8133 - val_acc: 0.2267\n",
      "Epoch 133/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.6524 - acc: 0.3143 - val_loss: 1.8317 - val_acc: 0.2400\n",
      "Epoch 134/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.6514 - acc: 0.3214 - val_loss: 1.8226 - val_acc: 0.2733\n",
      "Epoch 135/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.6512 - acc: 0.3314 - val_loss: 1.8233 - val_acc: 0.2267\n",
      "Epoch 136/3000\n",
      "700/700 [==============================] - 0s 82us/step - loss: 1.6493 - acc: 0.3186 - val_loss: 1.8168 - val_acc: 0.2200\n",
      "Epoch 137/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.6483 - acc: 0.3214 - val_loss: 1.8191 - val_acc: 0.2200\n",
      "Epoch 138/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.6488 - acc: 0.3257 - val_loss: 1.8199 - val_acc: 0.2167\n",
      "Epoch 139/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.6466 - acc: 0.3257 - val_loss: 1.8512 - val_acc: 0.2433\n",
      "Epoch 140/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.6465 - acc: 0.3214 - val_loss: 1.8168 - val_acc: 0.2200\n",
      "Epoch 141/3000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.6446 - acc: 0.3229 - val_loss: 1.8284 - val_acc: 0.2267\n",
      "Epoch 142/3000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.6437 - acc: 0.3243 - val_loss: 1.8154 - val_acc: 0.2633\n",
      "Epoch 143/3000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.6437 - acc: 0.3329 - val_loss: 1.8292 - val_acc: 0.2433\n",
      "Epoch 144/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.6431 - acc: 0.3329 - val_loss: 1.8273 - val_acc: 0.2300\n",
      "Epoch 145/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.6419 - acc: 0.3271 - val_loss: 1.8197 - val_acc: 0.2200\n",
      "Epoch 146/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.6392 - acc: 0.3343 - val_loss: 1.8324 - val_acc: 0.2233\n",
      "Epoch 147/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.6412 - acc: 0.3100 - val_loss: 1.8328 - val_acc: 0.2333\n",
      "Epoch 148/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.6390 - acc: 0.3243 - val_loss: 1.8306 - val_acc: 0.2500\n",
      "Epoch 149/3000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 1.6375 - acc: 0.3271 - val_loss: 1.8189 - val_acc: 0.2133\n",
      "Epoch 150/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.6367 - acc: 0.3229 - val_loss: 1.8276 - val_acc: 0.2233\n",
      "Epoch 151/3000\n",
      "700/700 [==============================] - 0s 112us/step - loss: 1.6364 - acc: 0.3257 - val_loss: 1.8245 - val_acc: 0.2267\n",
      "Epoch 152/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.6350 - acc: 0.3214 - val_loss: 1.8290 - val_acc: 0.2233\n",
      "Epoch 153/3000\n",
      "700/700 [==============================] - 0s 108us/step - loss: 1.6340 - acc: 0.3400 - val_loss: 1.8270 - val_acc: 0.2300\n",
      "Epoch 154/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.6319 - acc: 0.3457 - val_loss: 1.8343 - val_acc: 0.2233\n",
      "Epoch 155/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.6316 - acc: 0.3243 - val_loss: 1.8183 - val_acc: 0.2367\n",
      "Epoch 156/3000\n",
      "700/700 [==============================] - 0s 108us/step - loss: 1.6326 - acc: 0.3329 - val_loss: 1.8309 - val_acc: 0.2200\n",
      "Epoch 157/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.6308 - acc: 0.3300 - val_loss: 1.8241 - val_acc: 0.2200\n",
      "Epoch 158/3000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.6308 - acc: 0.3343 - val_loss: 1.8329 - val_acc: 0.2300\n",
      "Epoch 159/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.6285 - acc: 0.3257 - val_loss: 1.8336 - val_acc: 0.2433\n",
      "Epoch 160/3000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.6278 - acc: 0.3300 - val_loss: 1.8304 - val_acc: 0.2233\n",
      "Epoch 161/3000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.6271 - acc: 0.3257 - val_loss: 1.8406 - val_acc: 0.2300\n",
      "Epoch 162/3000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.6265 - acc: 0.3271 - val_loss: 1.8350 - val_acc: 0.2267\n",
      "Epoch 163/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.6254 - acc: 0.3371 - val_loss: 1.8365 - val_acc: 0.2300\n",
      "Epoch 164/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.6239 - acc: 0.3314 - val_loss: 1.8264 - val_acc: 0.2100\n",
      "Epoch 165/3000\n",
      "700/700 [==============================] - 0s 98us/step - loss: 1.6236 - acc: 0.3200 - val_loss: 1.8396 - val_acc: 0.2367\n",
      "Epoch 166/3000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.6230 - acc: 0.3286 - val_loss: 1.8344 - val_acc: 0.2233\n",
      "Epoch 167/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.6221 - acc: 0.3314 - val_loss: 1.8389 - val_acc: 0.2633\n",
      "Epoch 168/3000\n",
      "700/700 [==============================] - 0s 108us/step - loss: 1.6208 - acc: 0.3386 - val_loss: 1.8444 - val_acc: 0.2200\n",
      "Epoch 169/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.6198 - acc: 0.3386 - val_loss: 1.8525 - val_acc: 0.2233\n",
      "Epoch 170/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.6191 - acc: 0.3371 - val_loss: 1.8369 - val_acc: 0.2233\n",
      "Epoch 171/3000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.6170 - acc: 0.3271 - val_loss: 1.8517 - val_acc: 0.2600\n",
      "Epoch 172/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.6164 - acc: 0.3386 - val_loss: 1.8397 - val_acc: 0.2133\n",
      "Epoch 173/3000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.6182 - acc: 0.3386 - val_loss: 1.8392 - val_acc: 0.2367\n",
      "Epoch 174/3000\n",
      "700/700 [==============================] - 0s 108us/step - loss: 1.6167 - acc: 0.3300 - val_loss: 1.8420 - val_acc: 0.2200\n",
      "Epoch 175/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.6166 - acc: 0.3357 - val_loss: 1.8406 - val_acc: 0.2200\n",
      "Epoch 176/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.6143 - acc: 0.3229 - val_loss: 1.8437 - val_acc: 0.2600\n",
      "Epoch 177/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.6134 - acc: 0.3371 - val_loss: 1.8384 - val_acc: 0.2167\n",
      "Epoch 178/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.6139 - acc: 0.3371 - val_loss: 1.8446 - val_acc: 0.2267\n",
      "Epoch 179/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 91us/step - loss: 1.6134 - acc: 0.3400 - val_loss: 1.8376 - val_acc: 0.2233\n",
      "Epoch 180/3000\n",
      "700/700 [==============================] - 0s 88us/step - loss: 1.6110 - acc: 0.3371 - val_loss: 1.8415 - val_acc: 0.2667\n",
      "Epoch 181/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.6115 - acc: 0.3457 - val_loss: 1.8339 - val_acc: 0.2567\n",
      "Epoch 182/3000\n",
      "700/700 [==============================] - 0s 134us/step - loss: 1.6106 - acc: 0.3471 - val_loss: 1.8366 - val_acc: 0.2167\n",
      "Epoch 183/3000\n",
      "700/700 [==============================] - 0s 147us/step - loss: 1.6115 - acc: 0.3300 - val_loss: 1.8411 - val_acc: 0.2333\n",
      "Epoch 184/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.6093 - acc: 0.3471 - val_loss: 1.8453 - val_acc: 0.2267\n",
      "Epoch 185/3000\n",
      "700/700 [==============================] - 0s 87us/step - loss: 1.6076 - acc: 0.3386 - val_loss: 1.8641 - val_acc: 0.2200\n",
      "Epoch 186/3000\n",
      "700/700 [==============================] - 0s 87us/step - loss: 1.6086 - acc: 0.3443 - val_loss: 1.8449 - val_acc: 0.2233\n",
      "Epoch 187/3000\n",
      "700/700 [==============================] - 0s 85us/step - loss: 1.6065 - acc: 0.3543 - val_loss: 1.8442 - val_acc: 0.2167\n",
      "Epoch 188/3000\n",
      "700/700 [==============================] - 0s 83us/step - loss: 1.6075 - acc: 0.3386 - val_loss: 1.8412 - val_acc: 0.2133\n",
      "Epoch 189/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 1.6045 - acc: 0.3529 - val_loss: 1.8517 - val_acc: 0.2233\n",
      "Epoch 190/3000\n",
      "700/700 [==============================] - 0s 117us/step - loss: 1.6065 - acc: 0.3314 - val_loss: 1.8401 - val_acc: 0.2300\n",
      "Epoch 191/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.6042 - acc: 0.3529 - val_loss: 1.8564 - val_acc: 0.2233\n",
      "Epoch 192/3000\n",
      "700/700 [==============================] - 0s 124us/step - loss: 1.6044 - acc: 0.3500 - val_loss: 1.8503 - val_acc: 0.2200\n",
      "Epoch 193/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.6029 - acc: 0.3357 - val_loss: 1.8539 - val_acc: 0.2267\n",
      "Epoch 194/3000\n",
      "700/700 [==============================] - 0s 116us/step - loss: 1.6025 - acc: 0.3414 - val_loss: 1.8470 - val_acc: 0.2267\n",
      "Epoch 195/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.6019 - acc: 0.3457 - val_loss: 1.8453 - val_acc: 0.2467\n",
      "Epoch 196/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.6016 - acc: 0.3514 - val_loss: 1.8472 - val_acc: 0.2167\n",
      "Epoch 197/3000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 1.6002 - acc: 0.3443 - val_loss: 1.8488 - val_acc: 0.2300\n",
      "Epoch 198/3000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 1.6005 - acc: 0.3386 - val_loss: 1.8591 - val_acc: 0.2200\n",
      "Epoch 199/3000\n",
      "700/700 [==============================] - 0s 117us/step - loss: 1.6003 - acc: 0.3429 - val_loss: 1.8558 - val_acc: 0.2200\n",
      "Epoch 200/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.5975 - acc: 0.3457 - val_loss: 1.8604 - val_acc: 0.2633\n",
      "Epoch 201/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.5986 - acc: 0.3457 - val_loss: 1.8469 - val_acc: 0.2167\n",
      "Epoch 202/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.5979 - acc: 0.3414 - val_loss: 1.8478 - val_acc: 0.2100\n",
      "Epoch 203/3000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 1.5965 - acc: 0.3343 - val_loss: 1.8562 - val_acc: 0.2267\n",
      "Epoch 204/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.5953 - acc: 0.3557 - val_loss: 1.8461 - val_acc: 0.2067\n",
      "Epoch 205/3000\n",
      "700/700 [==============================] - 0s 115us/step - loss: 1.5953 - acc: 0.3429 - val_loss: 1.8508 - val_acc: 0.2200\n",
      "Epoch 206/3000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.5946 - acc: 0.3500 - val_loss: 1.8463 - val_acc: 0.2133\n",
      "Epoch 207/3000\n",
      "700/700 [==============================] - 0s 115us/step - loss: 1.5947 - acc: 0.3543 - val_loss: 1.8537 - val_acc: 0.2233\n",
      "Epoch 208/3000\n",
      "700/700 [==============================] - 0s 116us/step - loss: 1.5920 - acc: 0.3414 - val_loss: 1.8557 - val_acc: 0.2233\n",
      "Epoch 209/3000\n",
      "700/700 [==============================] - 0s 116us/step - loss: 1.5919 - acc: 0.3514 - val_loss: 1.8521 - val_acc: 0.2300\n",
      "Epoch 210/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.5915 - acc: 0.3443 - val_loss: 1.8523 - val_acc: 0.2267\n",
      "Epoch 211/3000\n",
      "700/700 [==============================] - 0s 118us/step - loss: 1.5903 - acc: 0.3371 - val_loss: 1.8456 - val_acc: 0.2567\n",
      "Epoch 212/3000\n",
      "700/700 [==============================] - 0s 124us/step - loss: 1.5913 - acc: 0.3471 - val_loss: 1.8593 - val_acc: 0.2200\n",
      "Epoch 213/3000\n",
      "700/700 [==============================] - 0s 122us/step - loss: 1.5894 - acc: 0.3500 - val_loss: 1.8519 - val_acc: 0.2233\n",
      "Epoch 214/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.5905 - acc: 0.3457 - val_loss: 1.8541 - val_acc: 0.2267\n",
      "Epoch 215/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.5886 - acc: 0.3514 - val_loss: 1.8602 - val_acc: 0.2667\n",
      "Epoch 216/3000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.5895 - acc: 0.3486 - val_loss: 1.8624 - val_acc: 0.2267\n",
      "Epoch 217/3000\n",
      "700/700 [==============================] - 0s 112us/step - loss: 1.5881 - acc: 0.3471 - val_loss: 1.8638 - val_acc: 0.2300\n",
      "Epoch 218/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.5876 - acc: 0.3486 - val_loss: 1.8600 - val_acc: 0.2300\n",
      "Epoch 219/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.5865 - acc: 0.3500 - val_loss: 1.8659 - val_acc: 0.2267\n",
      "Epoch 220/3000\n",
      "700/700 [==============================] - 0s 108us/step - loss: 1.5855 - acc: 0.3514 - val_loss: 1.8581 - val_acc: 0.2267\n",
      "Epoch 221/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.5855 - acc: 0.3471 - val_loss: 1.8621 - val_acc: 0.2267\n",
      "Epoch 222/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.5845 - acc: 0.3514 - val_loss: 1.8751 - val_acc: 0.2500\n",
      "Epoch 223/3000\n",
      "700/700 [==============================] - 0s 80us/step - loss: 1.5844 - acc: 0.3443 - val_loss: 1.8615 - val_acc: 0.2600\n",
      "Epoch 224/3000\n",
      "700/700 [==============================] - 0s 85us/step - loss: 1.5845 - acc: 0.3529 - val_loss: 1.8766 - val_acc: 0.2467\n",
      "Epoch 225/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.5833 - acc: 0.3457 - val_loss: 1.8572 - val_acc: 0.2167\n",
      "Epoch 226/3000\n",
      "700/700 [==============================] - 0s 112us/step - loss: 1.5835 - acc: 0.3486 - val_loss: 1.8686 - val_acc: 0.2233\n",
      "Epoch 227/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.5825 - acc: 0.3486 - val_loss: 1.8611 - val_acc: 0.2133\n",
      "Epoch 228/3000\n",
      "700/700 [==============================] - 0s 116us/step - loss: 1.5825 - acc: 0.3443 - val_loss: 1.8693 - val_acc: 0.2267\n",
      "Epoch 229/3000\n",
      "700/700 [==============================] - 0s 112us/step - loss: 1.5801 - acc: 0.3471 - val_loss: 1.8688 - val_acc: 0.2233\n",
      "Epoch 230/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.5818 - acc: 0.3471 - val_loss: 1.8635 - val_acc: 0.2133\n",
      "Epoch 231/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.5797 - acc: 0.3529 - val_loss: 1.8606 - val_acc: 0.2200\n",
      "Epoch 232/3000\n",
      "700/700 [==============================] - 0s 108us/step - loss: 1.5809 - acc: 0.3514 - val_loss: 1.8731 - val_acc: 0.2133\n",
      "Epoch 233/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.5796 - acc: 0.3486 - val_loss: 1.8781 - val_acc: 0.2200\n",
      "Epoch 234/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.5791 - acc: 0.3457 - val_loss: 1.8666 - val_acc: 0.2133\n",
      "Epoch 235/3000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 1.5777 - acc: 0.3571 - val_loss: 1.8693 - val_acc: 0.2100\n",
      "Epoch 236/3000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 1.5778 - acc: 0.3443 - val_loss: 1.8664 - val_acc: 0.2133\n",
      "Epoch 237/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.5770 - acc: 0.3429 - val_loss: 1.8718 - val_acc: 0.2300\n",
      "Epoch 238/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 110us/step - loss: 1.5774 - acc: 0.3471 - val_loss: 1.8613 - val_acc: 0.2200\n",
      "Epoch 239/3000\n",
      "700/700 [==============================] - 0s 112us/step - loss: 1.5770 - acc: 0.3571 - val_loss: 1.8682 - val_acc: 0.2267\n",
      "Epoch 240/3000\n",
      "700/700 [==============================] - 0s 112us/step - loss: 1.5749 - acc: 0.3571 - val_loss: 1.8719 - val_acc: 0.2500\n",
      "Epoch 241/3000\n",
      "700/700 [==============================] - 0s 119us/step - loss: 1.5749 - acc: 0.3571 - val_loss: 1.8738 - val_acc: 0.2433\n",
      "Epoch 242/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.5743 - acc: 0.3514 - val_loss: 1.8733 - val_acc: 0.2100\n",
      "Epoch 243/3000\n",
      "700/700 [==============================] - 0s 112us/step - loss: 1.5743 - acc: 0.3629 - val_loss: 1.8806 - val_acc: 0.2200\n",
      "Epoch 244/3000\n",
      "700/700 [==============================] - 0s 124us/step - loss: 1.5713 - acc: 0.3557 - val_loss: 1.8724 - val_acc: 0.2200\n",
      "Epoch 245/3000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.5715 - acc: 0.3586 - val_loss: 1.8839 - val_acc: 0.2233\n",
      "Epoch 246/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.5712 - acc: 0.3543 - val_loss: 1.8710 - val_acc: 0.2533\n",
      "Epoch 247/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.5722 - acc: 0.3557 - val_loss: 1.8631 - val_acc: 0.2167\n",
      "Epoch 248/3000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.5716 - acc: 0.3557 - val_loss: 1.8700 - val_acc: 0.2233\n",
      "Epoch 249/3000\n",
      "700/700 [==============================] - 0s 124us/step - loss: 1.5712 - acc: 0.3471 - val_loss: 1.8840 - val_acc: 0.2233\n",
      "Epoch 250/3000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 1.5680 - acc: 0.3657 - val_loss: 1.8981 - val_acc: 0.2167\n",
      "Epoch 251/3000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 1.5704 - acc: 0.3486 - val_loss: 1.8793 - val_acc: 0.2400\n",
      "Epoch 252/3000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.5682 - acc: 0.3643 - val_loss: 1.8744 - val_acc: 0.2200\n",
      "Epoch 253/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.5689 - acc: 0.3600 - val_loss: 1.8820 - val_acc: 0.2133\n",
      "Epoch 254/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.5677 - acc: 0.3571 - val_loss: 1.8835 - val_acc: 0.2267\n",
      "Epoch 255/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.5681 - acc: 0.3457 - val_loss: 1.8713 - val_acc: 0.2267\n",
      "Epoch 256/3000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 1.5657 - acc: 0.3571 - val_loss: 1.8761 - val_acc: 0.2533\n",
      "Epoch 257/3000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.5667 - acc: 0.3514 - val_loss: 1.8912 - val_acc: 0.2467\n",
      "Epoch 258/3000\n",
      "700/700 [==============================] - 0s 121us/step - loss: 1.5649 - acc: 0.3614 - val_loss: 1.8946 - val_acc: 0.2567\n",
      "Epoch 259/3000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.5648 - acc: 0.3643 - val_loss: 1.8911 - val_acc: 0.2167\n",
      "Epoch 260/3000\n",
      "700/700 [==============================] - 0s 108us/step - loss: 1.5657 - acc: 0.3600 - val_loss: 1.8989 - val_acc: 0.2200\n",
      "Epoch 261/3000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.5637 - acc: 0.3571 - val_loss: 1.8751 - val_acc: 0.2167\n",
      "Epoch 262/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.5638 - acc: 0.3614 - val_loss: 1.8836 - val_acc: 0.2100\n",
      "Epoch 263/3000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.5631 - acc: 0.3629 - val_loss: 1.8858 - val_acc: 0.2100\n",
      "Epoch 264/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.5640 - acc: 0.3571 - val_loss: 1.8812 - val_acc: 0.2133\n",
      "Epoch 265/3000\n",
      "700/700 [==============================] - 0s 117us/step - loss: 1.5638 - acc: 0.3686 - val_loss: 1.8902 - val_acc: 0.2200\n",
      "Epoch 266/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.5614 - acc: 0.3614 - val_loss: 1.8968 - val_acc: 0.2500\n",
      "Epoch 267/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.5612 - acc: 0.3629 - val_loss: 1.8918 - val_acc: 0.2300\n",
      "Epoch 268/3000\n",
      "700/700 [==============================] - 0s 108us/step - loss: 1.5613 - acc: 0.3614 - val_loss: 1.8757 - val_acc: 0.2100\n",
      "Epoch 269/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.5601 - acc: 0.3643 - val_loss: 1.8854 - val_acc: 0.2133\n",
      "Epoch 270/3000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 1.5594 - acc: 0.3671 - val_loss: 1.8674 - val_acc: 0.2333\n",
      "Epoch 271/3000\n",
      "700/700 [==============================] - 0s 122us/step - loss: 1.5610 - acc: 0.3657 - val_loss: 1.8914 - val_acc: 0.2333\n",
      "Epoch 272/3000\n",
      "700/700 [==============================] - 0s 115us/step - loss: 1.5595 - acc: 0.3600 - val_loss: 1.9030 - val_acc: 0.2267\n",
      "Epoch 273/3000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.5591 - acc: 0.3571 - val_loss: 1.8964 - val_acc: 0.2200\n",
      "Epoch 274/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.5589 - acc: 0.3457 - val_loss: 1.8841 - val_acc: 0.2233\n",
      "Epoch 275/3000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.5589 - acc: 0.3629 - val_loss: 1.8914 - val_acc: 0.2200\n",
      "Epoch 276/3000\n",
      "700/700 [==============================] - 0s 108us/step - loss: 1.5579 - acc: 0.3529 - val_loss: 1.8967 - val_acc: 0.2533\n",
      "Epoch 277/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.5581 - acc: 0.3714 - val_loss: 1.8909 - val_acc: 0.2167\n",
      "Epoch 278/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.5578 - acc: 0.3600 - val_loss: 1.9032 - val_acc: 0.2300\n",
      "Epoch 279/3000\n",
      "700/700 [==============================] - 0s 126us/step - loss: 1.5559 - acc: 0.3571 - val_loss: 1.8859 - val_acc: 0.2167\n",
      "Epoch 280/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.5559 - acc: 0.3700 - val_loss: 1.8876 - val_acc: 0.2167\n",
      "Epoch 281/3000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.5541 - acc: 0.3586 - val_loss: 1.8906 - val_acc: 0.2333\n",
      "Epoch 282/3000\n",
      "700/700 [==============================] - 0s 108us/step - loss: 1.5553 - acc: 0.3671 - val_loss: 1.8840 - val_acc: 0.2133\n",
      "Epoch 283/3000\n",
      "700/700 [==============================] - 0s 112us/step - loss: 1.5543 - acc: 0.3557 - val_loss: 1.8927 - val_acc: 0.2167\n",
      "Epoch 284/3000\n",
      "700/700 [==============================] - 0s 127us/step - loss: 1.5542 - acc: 0.3614 - val_loss: 1.8936 - val_acc: 0.2567\n",
      "Epoch 285/3000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.5535 - acc: 0.3557 - val_loss: 1.8887 - val_acc: 0.2200\n",
      "Epoch 286/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.5536 - acc: 0.3586 - val_loss: 1.8989 - val_acc: 0.2233\n",
      "Epoch 287/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.5527 - acc: 0.3686 - val_loss: 1.9019 - val_acc: 0.2133\n",
      "Epoch 288/3000\n",
      "700/700 [==============================] - 0s 117us/step - loss: 1.5525 - acc: 0.3600 - val_loss: 1.8930 - val_acc: 0.2133\n",
      "Epoch 289/3000\n",
      "700/700 [==============================] - 0s 117us/step - loss: 1.5519 - acc: 0.3600 - val_loss: 1.9014 - val_acc: 0.2167\n",
      "Epoch 290/3000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.5514 - acc: 0.3657 - val_loss: 1.9032 - val_acc: 0.2200\n",
      "Epoch 291/3000\n",
      "700/700 [==============================] - 0s 119us/step - loss: 1.5513 - acc: 0.3586 - val_loss: 1.9037 - val_acc: 0.2167\n",
      "Epoch 292/3000\n",
      "700/700 [==============================] - 0s 116us/step - loss: 1.5509 - acc: 0.3543 - val_loss: 1.8995 - val_acc: 0.2433\n",
      "Epoch 293/3000\n",
      "700/700 [==============================] - 0s 115us/step - loss: 1.5507 - acc: 0.3543 - val_loss: 1.9011 - val_acc: 0.2300\n",
      "Epoch 294/3000\n",
      "700/700 [==============================] - 0s 115us/step - loss: 1.5497 - acc: 0.3543 - val_loss: 1.9002 - val_acc: 0.2567\n",
      "Epoch 295/3000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.5499 - acc: 0.3657 - val_loss: 1.9120 - val_acc: 0.2200\n",
      "Epoch 296/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.5495 - acc: 0.3571 - val_loss: 1.9104 - val_acc: 0.2133\n",
      "Epoch 297/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 110us/step - loss: 1.5479 - acc: 0.3571 - val_loss: 1.9128 - val_acc: 0.2167\n",
      "Epoch 298/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.5477 - acc: 0.3486 - val_loss: 1.8958 - val_acc: 0.2267\n",
      "Epoch 299/3000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.5485 - acc: 0.3686 - val_loss: 1.9145 - val_acc: 0.2267\n",
      "Epoch 300/3000\n",
      "700/700 [==============================] - 0s 112us/step - loss: 1.5472 - acc: 0.3629 - val_loss: 1.9031 - val_acc: 0.2300\n",
      "Epoch 301/3000\n",
      "700/700 [==============================] - 0s 122us/step - loss: 1.5470 - acc: 0.3629 - val_loss: 1.8934 - val_acc: 0.2200\n",
      "Epoch 302/3000\n",
      "700/700 [==============================] - 0s 118us/step - loss: 1.5479 - acc: 0.3657 - val_loss: 1.9081 - val_acc: 0.2167\n",
      "Epoch 303/3000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.5465 - acc: 0.3529 - val_loss: 1.9016 - val_acc: 0.2333\n",
      "Epoch 304/3000\n",
      "700/700 [==============================] - 0s 112us/step - loss: 1.5452 - acc: 0.3671 - val_loss: 1.9066 - val_acc: 0.2200\n",
      "Epoch 305/3000\n",
      "700/700 [==============================] - 0s 116us/step - loss: 1.5432 - acc: 0.3643 - val_loss: 1.9140 - val_acc: 0.2267\n",
      "Epoch 306/3000\n",
      "700/700 [==============================] - 0s 79us/step - loss: 1.5458 - acc: 0.3600 - val_loss: 1.9100 - val_acc: 0.2267\n",
      "Epoch 307/3000\n",
      "700/700 [==============================] - 0s 82us/step - loss: 1.5436 - acc: 0.3671 - val_loss: 1.9064 - val_acc: 0.2267\n",
      "Epoch 308/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.5453 - acc: 0.3600 - val_loss: 1.9129 - val_acc: 0.2333\n",
      "Epoch 309/3000\n",
      "700/700 [==============================] - 0s 116us/step - loss: 1.5435 - acc: 0.3643 - val_loss: 1.9120 - val_acc: 0.2367\n",
      "Epoch 310/3000\n",
      "700/700 [==============================] - 0s 119us/step - loss: 1.5448 - acc: 0.3671 - val_loss: 1.9110 - val_acc: 0.2167\n",
      "Epoch 311/3000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.5426 - acc: 0.3586 - val_loss: 1.9058 - val_acc: 0.2300\n",
      "Epoch 312/3000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.5423 - acc: 0.3729 - val_loss: 1.9273 - val_acc: 0.2367\n",
      "Epoch 313/3000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.5387 - acc: 0.3657 - val_loss: 1.9056 - val_acc: 0.2633\n",
      "Epoch 314/3000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.5433 - acc: 0.3686 - val_loss: 1.9131 - val_acc: 0.2300\n",
      "Epoch 315/3000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.5406 - acc: 0.3657 - val_loss: 1.9118 - val_acc: 0.2233\n",
      "Epoch 316/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.5404 - acc: 0.3614 - val_loss: 1.9141 - val_acc: 0.2233\n",
      "Epoch 317/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.5412 - acc: 0.3614 - val_loss: 1.9213 - val_acc: 0.2333\n",
      "Epoch 318/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.5408 - acc: 0.3614 - val_loss: 1.9096 - val_acc: 0.2300\n",
      "Epoch 319/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.5390 - acc: 0.3614 - val_loss: 1.9092 - val_acc: 0.2300\n",
      "Epoch 320/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.5392 - acc: 0.3629 - val_loss: 1.9278 - val_acc: 0.2233\n",
      "Epoch 321/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.5392 - acc: 0.3686 - val_loss: 1.9258 - val_acc: 0.2300\n",
      "Epoch 322/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.5375 - acc: 0.3671 - val_loss: 1.9181 - val_acc: 0.2533\n",
      "Epoch 323/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 1.5383 - acc: 0.3714 - val_loss: 1.9197 - val_acc: 0.2300\n",
      "Epoch 324/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.5373 - acc: 0.3657 - val_loss: 1.9227 - val_acc: 0.2200\n",
      "Epoch 325/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.5387 - acc: 0.3600 - val_loss: 1.9178 - val_acc: 0.2133\n",
      "Epoch 326/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.5365 - acc: 0.3614 - val_loss: 1.9227 - val_acc: 0.2200\n",
      "Epoch 327/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.5359 - acc: 0.3743 - val_loss: 1.9378 - val_acc: 0.2333\n",
      "Epoch 328/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.5366 - acc: 0.3657 - val_loss: 1.9307 - val_acc: 0.2233\n",
      "Epoch 329/3000\n",
      "700/700 [==============================] - 0s 98us/step - loss: 1.5354 - acc: 0.3714 - val_loss: 1.9147 - val_acc: 0.2300\n",
      "Epoch 330/3000\n",
      "700/700 [==============================] - 0s 108us/step - loss: 1.5351 - acc: 0.3600 - val_loss: 1.9222 - val_acc: 0.2333\n",
      "Epoch 331/3000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.5338 - acc: 0.3714 - val_loss: 1.9155 - val_acc: 0.2200\n",
      "Epoch 332/3000\n",
      "700/700 [==============================] - 0s 118us/step - loss: 1.5346 - acc: 0.3571 - val_loss: 1.9340 - val_acc: 0.2500\n",
      "Epoch 333/3000\n",
      "700/700 [==============================] - 0s 120us/step - loss: 1.5358 - acc: 0.3671 - val_loss: 1.9235 - val_acc: 0.2233\n",
      "Epoch 334/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.5349 - acc: 0.3629 - val_loss: 1.9289 - val_acc: 0.2233\n",
      "Epoch 335/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.5327 - acc: 0.3757 - val_loss: 1.9246 - val_acc: 0.2567\n",
      "Epoch 336/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.5335 - acc: 0.3800 - val_loss: 1.9185 - val_acc: 0.2300\n",
      "Epoch 337/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.5330 - acc: 0.3757 - val_loss: 1.9324 - val_acc: 0.2300\n",
      "Epoch 338/3000\n",
      "700/700 [==============================] - 0s 115us/step - loss: 1.5320 - acc: 0.3743 - val_loss: 1.9238 - val_acc: 0.2133\n",
      "Epoch 339/3000\n",
      "700/700 [==============================] - 0s 112us/step - loss: 1.5314 - acc: 0.3700 - val_loss: 1.9158 - val_acc: 0.2167\n",
      "Epoch 340/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.5328 - acc: 0.3729 - val_loss: 1.9403 - val_acc: 0.2267\n",
      "Epoch 341/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.5317 - acc: 0.3757 - val_loss: 1.9258 - val_acc: 0.2267\n",
      "Epoch 342/3000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.5313 - acc: 0.3600 - val_loss: 1.9441 - val_acc: 0.2167\n",
      "Epoch 343/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.5310 - acc: 0.3686 - val_loss: 1.9333 - val_acc: 0.2267\n",
      "Epoch 344/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.5308 - acc: 0.3671 - val_loss: 1.9431 - val_acc: 0.2300\n",
      "Epoch 345/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.5291 - acc: 0.3686 - val_loss: 1.9443 - val_acc: 0.2567\n",
      "Epoch 346/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.5301 - acc: 0.3700 - val_loss: 1.9314 - val_acc: 0.2267\n",
      "Epoch 347/3000\n",
      "700/700 [==============================] - 0s 132us/step - loss: 1.5278 - acc: 0.3800 - val_loss: 1.9199 - val_acc: 0.2200\n",
      "Epoch 348/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.5284 - acc: 0.3643 - val_loss: 1.9294 - val_acc: 0.2167\n",
      "Epoch 349/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.5281 - acc: 0.3700 - val_loss: 1.9273 - val_acc: 0.2133\n",
      "Epoch 350/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.5282 - acc: 0.3657 - val_loss: 1.9312 - val_acc: 0.2300\n",
      "Epoch 351/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.5264 - acc: 0.3757 - val_loss: 1.9309 - val_acc: 0.2333\n",
      "Epoch 352/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.5283 - acc: 0.3729 - val_loss: 1.9282 - val_acc: 0.2300\n",
      "Epoch 353/3000\n",
      "700/700 [==============================] - 0s 84us/step - loss: 1.5256 - acc: 0.3657 - val_loss: 1.9422 - val_acc: 0.2300\n",
      "Epoch 354/3000\n",
      "700/700 [==============================] - 0s 83us/step - loss: 1.5279 - acc: 0.3700 - val_loss: 1.9350 - val_acc: 0.2167\n",
      "Epoch 355/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 1.5261 - acc: 0.3600 - val_loss: 1.9553 - val_acc: 0.2267\n",
      "Epoch 356/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 85us/step - loss: 1.5260 - acc: 0.3700 - val_loss: 1.9442 - val_acc: 0.2433\n",
      "Epoch 357/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.5259 - acc: 0.3743 - val_loss: 1.9355 - val_acc: 0.2267\n",
      "Epoch 358/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.5251 - acc: 0.3729 - val_loss: 1.9494 - val_acc: 0.2233\n",
      "Epoch 359/3000\n",
      "700/700 [==============================] - 0s 98us/step - loss: 1.5251 - acc: 0.3729 - val_loss: 1.9451 - val_acc: 0.2133\n",
      "Epoch 360/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.5232 - acc: 0.3743 - val_loss: 1.9454 - val_acc: 0.2233\n",
      "Epoch 361/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.5232 - acc: 0.3686 - val_loss: 1.9485 - val_acc: 0.2300\n",
      "Epoch 362/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.5240 - acc: 0.3643 - val_loss: 1.9508 - val_acc: 0.2267\n",
      "Epoch 363/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.5215 - acc: 0.3757 - val_loss: 1.9527 - val_acc: 0.2333\n",
      "Epoch 364/3000\n",
      "700/700 [==============================] - 0s 86us/step - loss: 1.5230 - acc: 0.3643 - val_loss: 1.9381 - val_acc: 0.2300\n",
      "Epoch 365/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.5224 - acc: 0.3771 - val_loss: 1.9524 - val_acc: 0.2267\n",
      "Epoch 366/3000\n",
      "700/700 [==============================] - 0s 87us/step - loss: 1.5222 - acc: 0.3686 - val_loss: 1.9407 - val_acc: 0.2133\n",
      "Epoch 367/3000\n",
      "700/700 [==============================] - 0s 88us/step - loss: 1.5222 - acc: 0.3757 - val_loss: 1.9567 - val_acc: 0.2300\n",
      "Epoch 368/3000\n",
      "700/700 [==============================] - 0s 84us/step - loss: 1.5206 - acc: 0.3786 - val_loss: 1.9552 - val_acc: 0.2367\n",
      "Epoch 369/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.5207 - acc: 0.3629 - val_loss: 1.9321 - val_acc: 0.2367\n",
      "Epoch 370/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.5200 - acc: 0.3757 - val_loss: 1.9534 - val_acc: 0.2400\n",
      "Epoch 371/3000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.5209 - acc: 0.3671 - val_loss: 1.9508 - val_acc: 0.2233\n",
      "Epoch 372/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.5195 - acc: 0.3729 - val_loss: 1.9590 - val_acc: 0.2333\n",
      "Epoch 373/3000\n",
      "700/700 [==============================] - 0s 98us/step - loss: 1.5205 - acc: 0.3757 - val_loss: 1.9453 - val_acc: 0.2133\n",
      "Epoch 374/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.5197 - acc: 0.3686 - val_loss: 1.9514 - val_acc: 0.2267\n",
      "Epoch 375/3000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.5181 - acc: 0.3843 - val_loss: 1.9386 - val_acc: 0.2267\n",
      "Epoch 376/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.5182 - acc: 0.3800 - val_loss: 1.9488 - val_acc: 0.2167\n",
      "Epoch 377/3000\n",
      "700/700 [==============================] - 0s 98us/step - loss: 1.5170 - acc: 0.3743 - val_loss: 1.9760 - val_acc: 0.2267\n",
      "Epoch 378/3000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.5182 - acc: 0.3743 - val_loss: 1.9761 - val_acc: 0.2367\n",
      "Epoch 379/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.5188 - acc: 0.3700 - val_loss: 1.9517 - val_acc: 0.2367\n",
      "Epoch 380/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.5166 - acc: 0.3671 - val_loss: 1.9602 - val_acc: 0.2567\n",
      "Epoch 381/3000\n",
      "700/700 [==============================] - 0s 86us/step - loss: 1.5180 - acc: 0.3786 - val_loss: 1.9711 - val_acc: 0.2167\n",
      "Epoch 382/3000\n",
      "700/700 [==============================] - 0s 98us/step - loss: 1.5161 - acc: 0.3743 - val_loss: 1.9585 - val_acc: 0.2267\n",
      "Epoch 383/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.5155 - acc: 0.3700 - val_loss: 1.9714 - val_acc: 0.2433\n",
      "Epoch 384/3000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.5164 - acc: 0.3771 - val_loss: 1.9509 - val_acc: 0.2233\n",
      "Epoch 385/3000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.5163 - acc: 0.3743 - val_loss: 1.9579 - val_acc: 0.2267\n",
      "Epoch 386/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.5156 - acc: 0.3714 - val_loss: 1.9502 - val_acc: 0.2333\n",
      "Epoch 387/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.5153 - acc: 0.3743 - val_loss: 1.9578 - val_acc: 0.2300\n",
      "Epoch 388/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.5143 - acc: 0.3714 - val_loss: 1.9668 - val_acc: 0.2467\n",
      "Epoch 389/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.5158 - acc: 0.3800 - val_loss: 1.9490 - val_acc: 0.2267\n",
      "Epoch 390/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.5125 - acc: 0.3671 - val_loss: 1.9572 - val_acc: 0.2400\n",
      "Epoch 391/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.5132 - acc: 0.3757 - val_loss: 1.9539 - val_acc: 0.2367\n",
      "Epoch 392/3000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.5137 - acc: 0.3714 - val_loss: 1.9599 - val_acc: 0.2233\n",
      "Epoch 393/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.5137 - acc: 0.3757 - val_loss: 1.9730 - val_acc: 0.2233\n",
      "Epoch 394/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.5136 - acc: 0.3757 - val_loss: 1.9565 - val_acc: 0.2267\n",
      "Epoch 395/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.5132 - acc: 0.3771 - val_loss: 1.9565 - val_acc: 0.2167\n",
      "Epoch 396/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.5124 - acc: 0.3771 - val_loss: 1.9619 - val_acc: 0.2167\n",
      "Epoch 397/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.5111 - acc: 0.3857 - val_loss: 1.9755 - val_acc: 0.2367\n",
      "Epoch 398/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.5124 - acc: 0.3643 - val_loss: 1.9588 - val_acc: 0.2200\n",
      "Epoch 399/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.5107 - acc: 0.3743 - val_loss: 1.9873 - val_acc: 0.2333\n",
      "Epoch 400/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.5113 - acc: 0.3643 - val_loss: 1.9599 - val_acc: 0.2167\n",
      "Epoch 401/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.5109 - acc: 0.3657 - val_loss: 1.9595 - val_acc: 0.2267\n",
      "Epoch 402/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.5086 - acc: 0.3771 - val_loss: 1.9650 - val_acc: 0.2233\n",
      "Epoch 403/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.5068 - acc: 0.3843 - val_loss: 1.9930 - val_acc: 0.2200\n",
      "Epoch 404/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.5085 - acc: 0.3743 - val_loss: 1.9678 - val_acc: 0.2333\n",
      "Epoch 405/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.5074 - acc: 0.3800 - val_loss: 1.9811 - val_acc: 0.2300\n",
      "Epoch 406/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.5085 - acc: 0.3771 - val_loss: 1.9745 - val_acc: 0.2200\n",
      "Epoch 407/3000\n",
      "700/700 [==============================] - 0s 116us/step - loss: 1.5080 - acc: 0.3714 - val_loss: 1.9792 - val_acc: 0.2267\n",
      "Epoch 408/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.5077 - acc: 0.3757 - val_loss: 1.9706 - val_acc: 0.2267\n",
      "Epoch 409/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.5040 - acc: 0.3700 - val_loss: 1.9783 - val_acc: 0.2367\n",
      "Epoch 410/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.5058 - acc: 0.3771 - val_loss: 1.9611 - val_acc: 0.2267\n",
      "Epoch 411/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.5056 - acc: 0.3714 - val_loss: 1.9817 - val_acc: 0.2300\n",
      "Epoch 412/3000\n",
      "700/700 [==============================] - 0s 108us/step - loss: 1.5048 - acc: 0.3843 - val_loss: 1.9719 - val_acc: 0.2233\n",
      "Epoch 413/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.5033 - acc: 0.3771 - val_loss: 1.9761 - val_acc: 0.2333\n",
      "Epoch 414/3000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.5043 - acc: 0.3800 - val_loss: 1.9843 - val_acc: 0.2333\n",
      "Epoch 415/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.5015 - acc: 0.3786 - val_loss: 1.9779 - val_acc: 0.2333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 416/3000\n",
      "700/700 [==============================] - 0s 133us/step - loss: 1.5031 - acc: 0.3843 - val_loss: 1.9889 - val_acc: 0.2267\n",
      "Epoch 417/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.5032 - acc: 0.3786 - val_loss: 1.9804 - val_acc: 0.2200\n",
      "Epoch 418/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.5016 - acc: 0.3871 - val_loss: 1.9744 - val_acc: 0.2333\n",
      "Epoch 419/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.5019 - acc: 0.3786 - val_loss: 1.9663 - val_acc: 0.2200\n",
      "Epoch 420/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.5015 - acc: 0.3800 - val_loss: 1.9877 - val_acc: 0.2300\n",
      "Epoch 421/3000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.5011 - acc: 0.3829 - val_loss: 1.9692 - val_acc: 0.2433\n",
      "Epoch 422/3000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.5004 - acc: 0.3743 - val_loss: 1.9747 - val_acc: 0.2433\n",
      "Epoch 423/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.5003 - acc: 0.3814 - val_loss: 1.9792 - val_acc: 0.2333\n",
      "Epoch 424/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.5001 - acc: 0.3757 - val_loss: 1.9678 - val_acc: 0.2200\n",
      "Epoch 425/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.4991 - acc: 0.3886 - val_loss: 1.9619 - val_acc: 0.2400\n",
      "Epoch 426/3000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.4984 - acc: 0.3914 - val_loss: 1.9792 - val_acc: 0.2167\n",
      "Epoch 427/3000\n",
      "700/700 [==============================] - 0s 98us/step - loss: 1.4983 - acc: 0.3814 - val_loss: 1.9833 - val_acc: 0.2533\n",
      "Epoch 428/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.4984 - acc: 0.3843 - val_loss: 2.0046 - val_acc: 0.2300\n",
      "Epoch 429/3000\n",
      "700/700 [==============================] - 0s 98us/step - loss: 1.4982 - acc: 0.3771 - val_loss: 1.9696 - val_acc: 0.2300\n",
      "Epoch 430/3000\n",
      "700/700 [==============================] - 0s 84us/step - loss: 1.4977 - acc: 0.3814 - val_loss: 1.9811 - val_acc: 0.2467\n",
      "Epoch 431/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.4990 - acc: 0.3786 - val_loss: 1.9880 - val_acc: 0.2333\n",
      "Epoch 432/3000\n",
      "700/700 [==============================] - 0s 119us/step - loss: 1.4974 - acc: 0.3843 - val_loss: 1.9760 - val_acc: 0.2233\n",
      "Epoch 433/3000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.4967 - acc: 0.3814 - val_loss: 1.9850 - val_acc: 0.2367\n",
      "Epoch 434/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.4976 - acc: 0.3743 - val_loss: 1.9881 - val_acc: 0.2233\n",
      "Epoch 435/3000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 1.4957 - acc: 0.3900 - val_loss: 1.9819 - val_acc: 0.2267\n",
      "Epoch 436/3000\n",
      "700/700 [==============================] - 0s 115us/step - loss: 1.4975 - acc: 0.3843 - val_loss: 1.9691 - val_acc: 0.2233\n",
      "Epoch 437/3000\n",
      "700/700 [==============================] - 0s 115us/step - loss: 1.4957 - acc: 0.3943 - val_loss: 1.9951 - val_acc: 0.2200\n",
      "Epoch 438/3000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 1.4948 - acc: 0.3857 - val_loss: 1.9635 - val_acc: 0.2300\n",
      "Epoch 439/3000\n",
      "700/700 [==============================] - 0s 115us/step - loss: 1.4946 - acc: 0.3771 - val_loss: 1.9782 - val_acc: 0.2233\n",
      "Epoch 440/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.4960 - acc: 0.3800 - val_loss: 1.9796 - val_acc: 0.2300\n",
      "Epoch 441/3000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 1.4951 - acc: 0.3886 - val_loss: 1.9825 - val_acc: 0.2300\n",
      "Epoch 442/3000\n",
      "700/700 [==============================] - 0s 108us/step - loss: 1.4944 - acc: 0.3829 - val_loss: 1.9940 - val_acc: 0.2233\n",
      "Epoch 443/3000\n",
      "700/700 [==============================] - 0s 116us/step - loss: 1.4937 - acc: 0.3857 - val_loss: 1.9899 - val_acc: 0.2400\n",
      "Epoch 444/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.4946 - acc: 0.3829 - val_loss: 1.9926 - val_acc: 0.2233\n",
      "Epoch 445/3000\n",
      "700/700 [==============================] - 0s 116us/step - loss: 1.4942 - acc: 0.3829 - val_loss: 1.9955 - val_acc: 0.2300\n",
      "Epoch 446/3000\n",
      "700/700 [==============================] - 0s 112us/step - loss: 1.4931 - acc: 0.3886 - val_loss: 2.0029 - val_acc: 0.2267\n",
      "Epoch 447/3000\n",
      "700/700 [==============================] - 0s 123us/step - loss: 1.4926 - acc: 0.3800 - val_loss: 2.0142 - val_acc: 0.2300\n",
      "Epoch 448/3000\n",
      "700/700 [==============================] - 0s 116us/step - loss: 1.4927 - acc: 0.3843 - val_loss: 1.9924 - val_acc: 0.2267\n",
      "Epoch 449/3000\n",
      "700/700 [==============================] - 0s 108us/step - loss: 1.4918 - acc: 0.3886 - val_loss: 2.0006 - val_acc: 0.2333\n",
      "Epoch 450/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.4929 - acc: 0.3843 - val_loss: 1.9930 - val_acc: 0.2233\n",
      "Epoch 451/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.4919 - acc: 0.3843 - val_loss: 1.9986 - val_acc: 0.2233\n",
      "Epoch 452/3000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 1.4908 - acc: 0.3857 - val_loss: 1.9947 - val_acc: 0.2300\n",
      "Epoch 453/3000\n",
      "700/700 [==============================] - 0s 117us/step - loss: 1.4910 - acc: 0.3871 - val_loss: 1.9899 - val_acc: 0.2333\n",
      "Epoch 454/3000\n",
      "700/700 [==============================] - 0s 116us/step - loss: 1.4908 - acc: 0.3871 - val_loss: 1.9967 - val_acc: 0.2333\n",
      "Epoch 455/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.4907 - acc: 0.3843 - val_loss: 1.9881 - val_acc: 0.2233\n",
      "Epoch 456/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.4898 - acc: 0.3786 - val_loss: 1.9915 - val_acc: 0.2467\n",
      "Epoch 457/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.4899 - acc: 0.3871 - val_loss: 1.9972 - val_acc: 0.2333\n",
      "Epoch 458/3000\n",
      "700/700 [==============================] - 0s 108us/step - loss: 1.4902 - acc: 0.3857 - val_loss: 1.9926 - val_acc: 0.2267\n",
      "Epoch 459/3000\n",
      "700/700 [==============================] - 0s 112us/step - loss: 1.4881 - acc: 0.3943 - val_loss: 1.9909 - val_acc: 0.2433\n",
      "Epoch 460/3000\n",
      "700/700 [==============================] - 0s 117us/step - loss: 1.4900 - acc: 0.3886 - val_loss: 2.0007 - val_acc: 0.2300\n",
      "Epoch 461/3000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.4883 - acc: 0.3957 - val_loss: 2.0034 - val_acc: 0.2300\n",
      "Epoch 462/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.4883 - acc: 0.3900 - val_loss: 1.9937 - val_acc: 0.2267\n",
      "Epoch 463/3000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 1.4872 - acc: 0.3857 - val_loss: 2.0002 - val_acc: 0.2467\n",
      "Epoch 464/3000\n",
      "700/700 [==============================] - 0s 84us/step - loss: 1.4871 - acc: 0.3871 - val_loss: 1.9888 - val_acc: 0.2333\n",
      "Epoch 465/3000\n",
      "700/700 [==============================] - 0s 79us/step - loss: 1.4877 - acc: 0.3900 - val_loss: 1.9972 - val_acc: 0.2233\n",
      "Epoch 466/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.4871 - acc: 0.3757 - val_loss: 2.0004 - val_acc: 0.2267\n",
      "Epoch 467/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.4873 - acc: 0.3871 - val_loss: 2.0061 - val_acc: 0.2300\n",
      "Epoch 468/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.4865 - acc: 0.3829 - val_loss: 1.9905 - val_acc: 0.2267\n",
      "Epoch 469/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.4859 - acc: 0.3871 - val_loss: 2.0314 - val_acc: 0.2333\n",
      "Epoch 470/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.4871 - acc: 0.3871 - val_loss: 2.0096 - val_acc: 0.2233\n",
      "Epoch 471/3000\n",
      "700/700 [==============================] - 0s 118us/step - loss: 1.4859 - acc: 0.3957 - val_loss: 2.0055 - val_acc: 0.2267\n",
      "Epoch 472/3000\n",
      "700/700 [==============================] - 0s 117us/step - loss: 1.4845 - acc: 0.3971 - val_loss: 2.0080 - val_acc: 0.2367\n",
      "Epoch 473/3000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 1.4850 - acc: 0.3914 - val_loss: 2.0121 - val_acc: 0.2367\n",
      "Epoch 474/3000\n",
      "700/700 [==============================] - 0s 108us/step - loss: 1.4838 - acc: 0.3900 - val_loss: 1.9976 - val_acc: 0.2267\n",
      "Epoch 475/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 126us/step - loss: 1.4842 - acc: 0.3900 - val_loss: 2.0047 - val_acc: 0.2233\n",
      "Epoch 476/3000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.4835 - acc: 0.3900 - val_loss: 2.0057 - val_acc: 0.2267\n",
      "Epoch 477/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.4839 - acc: 0.3900 - val_loss: 2.0095 - val_acc: 0.2267\n",
      "Epoch 478/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.4838 - acc: 0.3929 - val_loss: 2.0056 - val_acc: 0.2333\n",
      "Epoch 479/3000\n",
      "700/700 [==============================] - 0s 126us/step - loss: 1.4833 - acc: 0.3900 - val_loss: 2.0015 - val_acc: 0.2300\n",
      "Epoch 480/3000\n",
      "700/700 [==============================] - 0s 128us/step - loss: 1.4824 - acc: 0.3957 - val_loss: 2.0102 - val_acc: 0.2367\n",
      "Epoch 481/3000\n",
      "700/700 [==============================] - 0s 117us/step - loss: 1.4821 - acc: 0.3871 - val_loss: 2.0187 - val_acc: 0.2400\n",
      "Epoch 482/3000\n",
      "700/700 [==============================] - 0s 112us/step - loss: 1.4810 - acc: 0.3986 - val_loss: 2.0164 - val_acc: 0.2300\n",
      "Epoch 483/3000\n",
      "700/700 [==============================] - 0s 108us/step - loss: 1.4821 - acc: 0.4000 - val_loss: 2.0144 - val_acc: 0.2367\n",
      "Epoch 484/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.4815 - acc: 0.3986 - val_loss: 2.0162 - val_acc: 0.2400\n",
      "Epoch 485/3000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 1.4811 - acc: 0.4029 - val_loss: 2.0154 - val_acc: 0.2300\n",
      "Epoch 486/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.4808 - acc: 0.3857 - val_loss: 2.0074 - val_acc: 0.2467\n",
      "Epoch 487/3000\n",
      "700/700 [==============================] - 0s 80us/step - loss: 1.4811 - acc: 0.3957 - val_loss: 2.0076 - val_acc: 0.2500\n",
      "Epoch 488/3000\n",
      "700/700 [==============================] - 0s 92us/step - loss: 1.4808 - acc: 0.3914 - val_loss: 2.0157 - val_acc: 0.2500\n",
      "Epoch 489/3000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 1.4804 - acc: 0.3886 - val_loss: 2.0031 - val_acc: 0.2267\n",
      "Epoch 490/3000\n",
      "700/700 [==============================] - 0s 118us/step - loss: 1.4809 - acc: 0.3900 - val_loss: 2.0000 - val_acc: 0.2333\n",
      "Epoch 491/3000\n",
      "700/700 [==============================] - 0s 117us/step - loss: 1.4808 - acc: 0.3871 - val_loss: 2.0215 - val_acc: 0.2300\n",
      "Epoch 492/3000\n",
      "700/700 [==============================] - 0s 98us/step - loss: 1.4800 - acc: 0.3914 - val_loss: 2.0007 - val_acc: 0.2267\n",
      "Epoch 493/3000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 1.4799 - acc: 0.4014 - val_loss: 2.0076 - val_acc: 0.2333\n",
      "Epoch 494/3000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 1.4802 - acc: 0.3900 - val_loss: 2.0072 - val_acc: 0.2233\n",
      "Epoch 495/3000\n",
      "700/700 [==============================] - 0s 117us/step - loss: 1.4792 - acc: 0.4029 - val_loss: 2.0260 - val_acc: 0.2333\n",
      "Epoch 496/3000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.4786 - acc: 0.3857 - val_loss: 2.0112 - val_acc: 0.2433\n",
      "Epoch 497/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.4773 - acc: 0.3929 - val_loss: 2.0122 - val_acc: 0.2467\n",
      "Epoch 498/3000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 1.4763 - acc: 0.3886 - val_loss: 2.0468 - val_acc: 0.2367\n",
      "Epoch 499/3000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 1.4775 - acc: 0.4014 - val_loss: 2.0281 - val_acc: 0.2367\n",
      "Epoch 500/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.4780 - acc: 0.3929 - val_loss: 2.0262 - val_acc: 0.2367\n",
      "Epoch 501/3000\n",
      "700/700 [==============================] - 0s 117us/step - loss: 1.4782 - acc: 0.4000 - val_loss: 2.0258 - val_acc: 0.2300\n",
      "Epoch 502/3000\n",
      "700/700 [==============================] - 0s 118us/step - loss: 1.4760 - acc: 0.3943 - val_loss: 2.0261 - val_acc: 0.2267\n",
      "Epoch 503/3000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 1.4766 - acc: 0.3957 - val_loss: 2.0202 - val_acc: 0.2267\n",
      "Epoch 504/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.4757 - acc: 0.3971 - val_loss: 2.0240 - val_acc: 0.2267\n",
      "Epoch 505/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.4754 - acc: 0.3957 - val_loss: 2.0196 - val_acc: 0.2400\n",
      "Epoch 506/3000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.4754 - acc: 0.3986 - val_loss: 2.0154 - val_acc: 0.2300\n",
      "Epoch 507/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.4769 - acc: 0.3986 - val_loss: 2.0225 - val_acc: 0.2233\n",
      "Epoch 508/3000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.4750 - acc: 0.3900 - val_loss: 2.0240 - val_acc: 0.2267\n",
      "Epoch 509/3000\n",
      "700/700 [==============================] - 0s 115us/step - loss: 1.4744 - acc: 0.3943 - val_loss: 2.0373 - val_acc: 0.2333\n",
      "Epoch 510/3000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 1.4745 - acc: 0.3914 - val_loss: 2.0230 - val_acc: 0.2233\n",
      "Epoch 511/3000\n",
      "700/700 [==============================] - 0s 115us/step - loss: 1.4737 - acc: 0.4029 - val_loss: 2.0154 - val_acc: 0.2267\n",
      "Epoch 512/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.4739 - acc: 0.3971 - val_loss: 2.0106 - val_acc: 0.2467\n",
      "Epoch 513/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.4732 - acc: 0.3986 - val_loss: 2.0137 - val_acc: 0.2433\n",
      "Epoch 514/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.4727 - acc: 0.4000 - val_loss: 2.0269 - val_acc: 0.2267\n",
      "Epoch 515/3000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 1.4734 - acc: 0.4014 - val_loss: 2.0250 - val_acc: 0.2300\n",
      "Epoch 516/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.4741 - acc: 0.3957 - val_loss: 2.0273 - val_acc: 0.2267\n",
      "Epoch 517/3000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.4706 - acc: 0.3929 - val_loss: 2.0338 - val_acc: 0.2500\n",
      "Epoch 518/3000\n",
      "700/700 [==============================] - 0s 115us/step - loss: 1.4740 - acc: 0.4000 - val_loss: 2.0343 - val_acc: 0.2267\n",
      "Epoch 519/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.4727 - acc: 0.4043 - val_loss: 2.0238 - val_acc: 0.2300\n",
      "Epoch 520/3000\n",
      "700/700 [==============================] - 0s 116us/step - loss: 1.4718 - acc: 0.3957 - val_loss: 2.0308 - val_acc: 0.2400\n",
      "Epoch 521/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.4713 - acc: 0.4129 - val_loss: 2.0126 - val_acc: 0.2333\n",
      "Epoch 522/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.4725 - acc: 0.3986 - val_loss: 2.0341 - val_acc: 0.2267\n",
      "Epoch 523/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.4721 - acc: 0.3929 - val_loss: 2.0293 - val_acc: 0.2267\n",
      "Epoch 524/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.4711 - acc: 0.3986 - val_loss: 2.0231 - val_acc: 0.2333\n",
      "Epoch 525/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.4696 - acc: 0.4000 - val_loss: 2.0285 - val_acc: 0.2467\n",
      "Epoch 526/3000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.4711 - acc: 0.4029 - val_loss: 2.0247 - val_acc: 0.2267\n",
      "Epoch 527/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.4702 - acc: 0.3929 - val_loss: 2.0259 - val_acc: 0.2300\n",
      "Epoch 528/3000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.4694 - acc: 0.4029 - val_loss: 2.0291 - val_acc: 0.2267\n",
      "Epoch 529/3000\n",
      "700/700 [==============================] - 0s 98us/step - loss: 1.4681 - acc: 0.3943 - val_loss: 2.0337 - val_acc: 0.2267\n",
      "Epoch 530/3000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 1.4686 - acc: 0.4000 - val_loss: 2.0412 - val_acc: 0.2267\n",
      "Epoch 531/3000\n",
      "700/700 [==============================] - 0s 115us/step - loss: 1.4689 - acc: 0.3957 - val_loss: 2.0247 - val_acc: 0.2433\n",
      "Epoch 532/3000\n",
      "700/700 [==============================] - 0s 120us/step - loss: 1.4690 - acc: 0.4014 - val_loss: 2.0352 - val_acc: 0.2433\n",
      "Epoch 533/3000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.4685 - acc: 0.4000 - val_loss: 2.0312 - val_acc: 0.2300\n",
      "Epoch 534/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 107us/step - loss: 1.4688 - acc: 0.3971 - val_loss: 2.0267 - val_acc: 0.2300\n",
      "Epoch 535/3000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.4673 - acc: 0.4043 - val_loss: 2.0500 - val_acc: 0.2433\n",
      "Epoch 536/3000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.4671 - acc: 0.4043 - val_loss: 2.0468 - val_acc: 0.2267\n",
      "Epoch 537/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.4676 - acc: 0.4029 - val_loss: 2.0293 - val_acc: 0.2300\n",
      "Epoch 538/3000\n",
      "700/700 [==============================] - 0s 108us/step - loss: 1.4672 - acc: 0.3957 - val_loss: 2.0361 - val_acc: 0.2367\n",
      "Epoch 539/3000\n",
      "700/700 [==============================] - 0s 115us/step - loss: 1.4691 - acc: 0.3943 - val_loss: 2.0314 - val_acc: 0.2267\n",
      "Epoch 540/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.4678 - acc: 0.4014 - val_loss: 2.0397 - val_acc: 0.2267\n",
      "Epoch 541/3000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 1.4667 - acc: 0.4014 - val_loss: 2.0372 - val_acc: 0.2267\n",
      "Epoch 542/3000\n",
      "700/700 [==============================] - 0s 108us/step - loss: 1.4665 - acc: 0.4057 - val_loss: 2.0430 - val_acc: 0.2433\n",
      "Epoch 543/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.4670 - acc: 0.4000 - val_loss: 2.0292 - val_acc: 0.2333\n",
      "Epoch 544/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.4657 - acc: 0.3943 - val_loss: 2.0243 - val_acc: 0.2367\n",
      "Epoch 545/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.4665 - acc: 0.4014 - val_loss: 2.0327 - val_acc: 0.2300\n",
      "Epoch 546/3000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.4635 - acc: 0.4000 - val_loss: 2.0464 - val_acc: 0.2533\n",
      "Epoch 547/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.4657 - acc: 0.4000 - val_loss: 2.0518 - val_acc: 0.2400\n",
      "Epoch 548/3000\n",
      "700/700 [==============================] - 0s 81us/step - loss: 1.4643 - acc: 0.3971 - val_loss: 2.0295 - val_acc: 0.2300\n",
      "Epoch 549/3000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.4647 - acc: 0.4043 - val_loss: 2.0262 - val_acc: 0.2333\n",
      "Epoch 550/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.4638 - acc: 0.4000 - val_loss: 2.0388 - val_acc: 0.2300\n",
      "Epoch 551/3000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.4647 - acc: 0.4000 - val_loss: 2.0365 - val_acc: 0.2300\n",
      "Epoch 552/3000\n",
      "700/700 [==============================] - 0s 108us/step - loss: 1.4632 - acc: 0.4086 - val_loss: 2.0365 - val_acc: 0.2333\n",
      "Epoch 553/3000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.4654 - acc: 0.4000 - val_loss: 2.0342 - val_acc: 0.2300\n",
      "Epoch 554/3000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 1.4630 - acc: 0.3986 - val_loss: 2.0435 - val_acc: 0.2300\n",
      "Epoch 555/3000\n",
      "700/700 [==============================] - 0s 119us/step - loss: 1.4637 - acc: 0.4057 - val_loss: 2.0446 - val_acc: 0.2400\n",
      "Epoch 556/3000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 1.4621 - acc: 0.4000 - val_loss: 2.0385 - val_acc: 0.2467\n",
      "Epoch 557/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.4614 - acc: 0.4114 - val_loss: 2.0554 - val_acc: 0.2500\n",
      "Epoch 558/3000\n",
      "700/700 [==============================] - 0s 119us/step - loss: 1.4631 - acc: 0.4029 - val_loss: 2.0380 - val_acc: 0.2333\n",
      "Epoch 559/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.4614 - acc: 0.4029 - val_loss: 2.0413 - val_acc: 0.2533\n",
      "Epoch 560/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.4612 - acc: 0.4014 - val_loss: 2.0447 - val_acc: 0.2567\n",
      "Epoch 561/3000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.4623 - acc: 0.4100 - val_loss: 2.0394 - val_acc: 0.2267\n",
      "Epoch 562/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.4619 - acc: 0.4029 - val_loss: 2.0325 - val_acc: 0.2300\n",
      "Epoch 563/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.4613 - acc: 0.4000 - val_loss: 2.0365 - val_acc: 0.2267\n",
      "Epoch 564/3000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.4611 - acc: 0.4071 - val_loss: 2.0515 - val_acc: 0.2300\n",
      "Epoch 565/3000\n",
      "700/700 [==============================] - 0s 116us/step - loss: 1.4603 - acc: 0.4043 - val_loss: 2.0375 - val_acc: 0.2333\n",
      "Epoch 566/3000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.4620 - acc: 0.4100 - val_loss: 2.0473 - val_acc: 0.2300\n",
      "Epoch 567/3000\n",
      "700/700 [==============================] - 0s 120us/step - loss: 1.4599 - acc: 0.4171 - val_loss: 2.0504 - val_acc: 0.2300\n",
      "Epoch 568/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.4598 - acc: 0.4057 - val_loss: 2.0487 - val_acc: 0.2433\n",
      "Epoch 569/3000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.4594 - acc: 0.4057 - val_loss: 2.0432 - val_acc: 0.2533\n",
      "Epoch 570/3000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.4586 - acc: 0.4114 - val_loss: 2.0507 - val_acc: 0.2333\n",
      "Epoch 571/3000\n",
      "700/700 [==============================] - 0s 118us/step - loss: 1.4588 - acc: 0.4043 - val_loss: 2.0480 - val_acc: 0.2300\n",
      "Epoch 572/3000\n",
      "700/700 [==============================] - 0s 126us/step - loss: 1.4580 - acc: 0.4014 - val_loss: 2.0397 - val_acc: 0.2333\n",
      "Epoch 573/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.4573 - acc: 0.4114 - val_loss: 2.0551 - val_acc: 0.2533\n",
      "Epoch 574/3000\n",
      "700/700 [==============================] - 0s 79us/step - loss: 1.4597 - acc: 0.4043 - val_loss: 2.0408 - val_acc: 0.2500\n",
      "Epoch 575/3000\n",
      "700/700 [==============================] - 0s 75us/step - loss: 1.4597 - acc: 0.4114 - val_loss: 2.0449 - val_acc: 0.2267\n",
      "Epoch 576/3000\n",
      "700/700 [==============================] - 0s 108us/step - loss: 1.4586 - acc: 0.3957 - val_loss: 2.0468 - val_acc: 0.2300\n",
      "Epoch 577/3000\n",
      "700/700 [==============================] - 0s 117us/step - loss: 1.4583 - acc: 0.4014 - val_loss: 2.0449 - val_acc: 0.2300\n",
      "Epoch 578/3000\n",
      "700/700 [==============================] - 0s 115us/step - loss: 1.4577 - acc: 0.4071 - val_loss: 2.0453 - val_acc: 0.2367\n",
      "Epoch 579/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.4584 - acc: 0.4057 - val_loss: 2.0428 - val_acc: 0.2267\n",
      "Epoch 580/3000\n",
      "700/700 [==============================] - 0s 82us/step - loss: 1.4574 - acc: 0.4086 - val_loss: 2.0531 - val_acc: 0.2367\n",
      "Epoch 581/3000\n",
      "700/700 [==============================] - 0s 81us/step - loss: 1.4570 - acc: 0.4071 - val_loss: 2.0488 - val_acc: 0.2567\n",
      "Epoch 582/3000\n",
      "700/700 [==============================] - 0s 80us/step - loss: 1.4569 - acc: 0.4071 - val_loss: 2.0514 - val_acc: 0.2267\n",
      "Epoch 583/3000\n",
      "700/700 [==============================] - 0s 83us/step - loss: 1.4563 - acc: 0.4014 - val_loss: 2.0529 - val_acc: 0.2267\n",
      "Epoch 584/3000\n",
      "700/700 [==============================] - 0s 82us/step - loss: 1.4571 - acc: 0.4071 - val_loss: 2.0504 - val_acc: 0.2267\n",
      "Epoch 585/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.4558 - acc: 0.4100 - val_loss: 2.0556 - val_acc: 0.2300\n",
      "Epoch 586/3000\n",
      "700/700 [==============================] - 0s 86us/step - loss: 1.4550 - acc: 0.4043 - val_loss: 2.0556 - val_acc: 0.2500\n",
      "Epoch 587/3000\n",
      "700/700 [==============================] - 0s 84us/step - loss: 1.4573 - acc: 0.4114 - val_loss: 2.0557 - val_acc: 0.2333\n",
      "Epoch 588/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.4560 - acc: 0.4043 - val_loss: 2.0581 - val_acc: 0.2300\n",
      "Epoch 589/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.4553 - acc: 0.4057 - val_loss: 2.0576 - val_acc: 0.2267\n",
      "Epoch 590/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.4553 - acc: 0.4014 - val_loss: 2.0520 - val_acc: 0.2300\n",
      "Epoch 591/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.4554 - acc: 0.4086 - val_loss: 2.0605 - val_acc: 0.2267\n",
      "Epoch 592/3000\n",
      "700/700 [==============================] - 0s 98us/step - loss: 1.4544 - acc: 0.4086 - val_loss: 2.0558 - val_acc: 0.2333\n",
      "Epoch 593/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 122us/step - loss: 1.4546 - acc: 0.4057 - val_loss: 2.0498 - val_acc: 0.2267\n",
      "Epoch 594/3000\n",
      "700/700 [==============================] - 0s 98us/step - loss: 1.4540 - acc: 0.4129 - val_loss: 2.0513 - val_acc: 0.2333\n",
      "Epoch 595/3000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 1.4543 - acc: 0.4057 - val_loss: 2.0569 - val_acc: 0.2433\n",
      "Epoch 596/3000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.4537 - acc: 0.4129 - val_loss: 2.0472 - val_acc: 0.2300\n",
      "Epoch 597/3000\n",
      "700/700 [==============================] - 0s 121us/step - loss: 1.4525 - acc: 0.4143 - val_loss: 2.0491 - val_acc: 0.2500\n",
      "Epoch 598/3000\n",
      "700/700 [==============================] - 0s 108us/step - loss: 1.4537 - acc: 0.3986 - val_loss: 2.0563 - val_acc: 0.2267\n",
      "Epoch 599/3000\n",
      "700/700 [==============================] - 0s 116us/step - loss: 1.4541 - acc: 0.4043 - val_loss: 2.0478 - val_acc: 0.2333\n",
      "Epoch 600/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.4525 - acc: 0.4143 - val_loss: 2.0625 - val_acc: 0.2300\n",
      "Epoch 601/3000\n",
      "700/700 [==============================] - 0s 112us/step - loss: 1.4523 - acc: 0.4129 - val_loss: 2.0623 - val_acc: 0.2433\n",
      "Epoch 602/3000\n",
      "700/700 [==============================] - 0s 122us/step - loss: 1.4526 - acc: 0.4029 - val_loss: 2.0586 - val_acc: 0.2333\n",
      "Epoch 603/3000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 1.4527 - acc: 0.4114 - val_loss: 2.0504 - val_acc: 0.2400\n",
      "Epoch 604/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.4525 - acc: 0.4029 - val_loss: 2.0489 - val_acc: 0.2433\n",
      "Epoch 605/3000\n",
      "700/700 [==============================] - 0s 121us/step - loss: 1.4516 - acc: 0.4057 - val_loss: 2.0553 - val_acc: 0.2367\n",
      "Epoch 606/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.4517 - acc: 0.4100 - val_loss: 2.0474 - val_acc: 0.2333\n",
      "Epoch 607/3000\n",
      "700/700 [==============================] - 0s 122us/step - loss: 1.4518 - acc: 0.4100 - val_loss: 2.0580 - val_acc: 0.2300\n",
      "Epoch 608/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.4515 - acc: 0.4071 - val_loss: 2.0504 - val_acc: 0.2367\n",
      "Epoch 609/3000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.4500 - acc: 0.4157 - val_loss: 2.0635 - val_acc: 0.2567\n",
      "Epoch 610/3000\n",
      "700/700 [==============================] - 0s 116us/step - loss: 1.4507 - acc: 0.4129 - val_loss: 2.0636 - val_acc: 0.2333\n",
      "Epoch 611/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.4508 - acc: 0.4129 - val_loss: 2.0608 - val_acc: 0.2367\n",
      "Epoch 612/3000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 1.4506 - acc: 0.4086 - val_loss: 2.0591 - val_acc: 0.2433\n",
      "Epoch 613/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.4505 - acc: 0.4086 - val_loss: 2.0601 - val_acc: 0.2300\n",
      "Epoch 614/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.4496 - acc: 0.4129 - val_loss: 2.0687 - val_acc: 0.2500\n",
      "Epoch 615/3000\n",
      "700/700 [==============================] - 0s 108us/step - loss: 1.4502 - acc: 0.4129 - val_loss: 2.0535 - val_acc: 0.2533\n",
      "Epoch 616/3000\n",
      "700/700 [==============================] - 0s 108us/step - loss: 1.4495 - acc: 0.4129 - val_loss: 2.0732 - val_acc: 0.2333\n",
      "Epoch 617/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.4480 - acc: 0.4157 - val_loss: 2.0653 - val_acc: 0.2533\n",
      "Epoch 618/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.4491 - acc: 0.4014 - val_loss: 2.0597 - val_acc: 0.2400\n",
      "Epoch 619/3000\n",
      "700/700 [==============================] - 0s 117us/step - loss: 1.4479 - acc: 0.4114 - val_loss: 2.0671 - val_acc: 0.2333\n",
      "Epoch 620/3000\n",
      "700/700 [==============================] - 0s 122us/step - loss: 1.4488 - acc: 0.4171 - val_loss: 2.0564 - val_acc: 0.2300\n",
      "Epoch 621/3000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 1.4487 - acc: 0.4129 - val_loss: 2.0741 - val_acc: 0.2333\n",
      "Epoch 622/3000\n",
      "700/700 [==============================] - 0s 85us/step - loss: 1.4476 - acc: 0.4114 - val_loss: 2.0741 - val_acc: 0.2367\n",
      "Epoch 623/3000\n",
      "700/700 [==============================] - 0s 117us/step - loss: 1.4471 - acc: 0.4186 - val_loss: 2.0690 - val_acc: 0.2267\n",
      "Epoch 624/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.4480 - acc: 0.4171 - val_loss: 2.0689 - val_acc: 0.2367\n",
      "Epoch 625/3000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.4479 - acc: 0.4029 - val_loss: 2.0724 - val_acc: 0.2367\n",
      "Epoch 626/3000\n",
      "700/700 [==============================] - 0s 120us/step - loss: 1.4471 - acc: 0.4086 - val_loss: 2.0535 - val_acc: 0.2367\n",
      "Epoch 627/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.4478 - acc: 0.4257 - val_loss: 2.0632 - val_acc: 0.2333\n",
      "Epoch 628/3000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 1.4459 - acc: 0.4157 - val_loss: 2.0503 - val_acc: 0.2400\n",
      "Epoch 629/3000\n",
      "700/700 [==============================] - 0s 116us/step - loss: 1.4475 - acc: 0.4100 - val_loss: 2.0616 - val_acc: 0.2333\n",
      "Epoch 630/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.4460 - acc: 0.4114 - val_loss: 2.0542 - val_acc: 0.2333\n",
      "Epoch 631/3000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 1.4468 - acc: 0.4114 - val_loss: 2.0818 - val_acc: 0.2400\n",
      "Epoch 632/3000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.4467 - acc: 0.4086 - val_loss: 2.0750 - val_acc: 0.2400\n",
      "Epoch 633/3000\n",
      "700/700 [==============================] - 0s 77us/step - loss: 1.4455 - acc: 0.4143 - val_loss: 2.0829 - val_acc: 0.2367\n",
      "Epoch 634/3000\n",
      "700/700 [==============================] - 0s 87us/step - loss: 1.4457 - acc: 0.4129 - val_loss: 2.0715 - val_acc: 0.2333\n",
      "Epoch 635/3000\n",
      "700/700 [==============================] - 0s 117us/step - loss: 1.4444 - acc: 0.4071 - val_loss: 2.0653 - val_acc: 0.2567\n",
      "Epoch 636/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.4463 - acc: 0.4129 - val_loss: 2.0670 - val_acc: 0.2333\n",
      "Epoch 637/3000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 1.4451 - acc: 0.4114 - val_loss: 2.0764 - val_acc: 0.2367\n",
      "Epoch 638/3000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 1.4452 - acc: 0.4114 - val_loss: 2.0816 - val_acc: 0.2300\n",
      "Epoch 639/3000\n",
      "700/700 [==============================] - 0s 118us/step - loss: 1.4449 - acc: 0.4086 - val_loss: 2.0820 - val_acc: 0.2233\n",
      "Epoch 640/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.4441 - acc: 0.4157 - val_loss: 2.0581 - val_acc: 0.2367\n",
      "Epoch 641/3000\n",
      "700/700 [==============================] - 0s 121us/step - loss: 1.4437 - acc: 0.4143 - val_loss: 2.0742 - val_acc: 0.2467\n",
      "Epoch 642/3000\n",
      "700/700 [==============================] - 0s 117us/step - loss: 1.4448 - acc: 0.4100 - val_loss: 2.0819 - val_acc: 0.2433\n",
      "Epoch 643/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.4439 - acc: 0.4129 - val_loss: 2.0856 - val_acc: 0.2300\n",
      "Epoch 644/3000\n",
      "700/700 [==============================] - 0s 112us/step - loss: 1.4440 - acc: 0.4129 - val_loss: 2.0722 - val_acc: 0.2367\n",
      "Epoch 645/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.4432 - acc: 0.4186 - val_loss: 2.0797 - val_acc: 0.2333\n",
      "Epoch 646/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.4414 - acc: 0.4114 - val_loss: 2.0734 - val_acc: 0.2567\n",
      "Epoch 647/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.4423 - acc: 0.4114 - val_loss: 2.0704 - val_acc: 0.2367\n",
      "Epoch 648/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.4431 - acc: 0.4100 - val_loss: 2.0860 - val_acc: 0.2333\n",
      "Epoch 649/3000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.4415 - acc: 0.4057 - val_loss: 2.0823 - val_acc: 0.2333\n",
      "Epoch 650/3000\n",
      "700/700 [==============================] - 0s 119us/step - loss: 1.4432 - acc: 0.4143 - val_loss: 2.0725 - val_acc: 0.2333\n",
      "Epoch 651/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.4419 - acc: 0.4157 - val_loss: 2.0891 - val_acc: 0.2400\n",
      "Epoch 652/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 106us/step - loss: 1.4430 - acc: 0.4114 - val_loss: 2.0737 - val_acc: 0.2333\n",
      "Epoch 653/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.4415 - acc: 0.4171 - val_loss: 2.0781 - val_acc: 0.2433\n",
      "Epoch 654/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.4414 - acc: 0.4143 - val_loss: 2.0641 - val_acc: 0.2467\n",
      "Epoch 655/3000\n",
      "700/700 [==============================] - 0s 118us/step - loss: 1.4406 - acc: 0.4100 - val_loss: 2.0746 - val_acc: 0.2533\n",
      "Epoch 656/3000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.4426 - acc: 0.4086 - val_loss: 2.0850 - val_acc: 0.2433\n",
      "Epoch 657/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.4409 - acc: 0.4186 - val_loss: 2.0809 - val_acc: 0.2300\n",
      "Epoch 658/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.4409 - acc: 0.4143 - val_loss: 2.0781 - val_acc: 0.2367\n",
      "Epoch 659/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.4404 - acc: 0.4186 - val_loss: 2.0800 - val_acc: 0.2467\n",
      "Epoch 660/3000\n",
      "700/700 [==============================] - 0s 85us/step - loss: 1.4409 - acc: 0.4100 - val_loss: 2.0796 - val_acc: 0.2367\n",
      "Epoch 661/3000\n",
      "700/700 [==============================] - 0s 86us/step - loss: 1.4418 - acc: 0.4086 - val_loss: 2.0753 - val_acc: 0.2367\n",
      "Epoch 662/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.4410 - acc: 0.4000 - val_loss: 2.0794 - val_acc: 0.2367\n",
      "Epoch 663/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.4402 - acc: 0.4157 - val_loss: 2.0953 - val_acc: 0.2400\n",
      "Epoch 664/3000\n",
      "700/700 [==============================] - 0s 129us/step - loss: 1.4394 - acc: 0.4186 - val_loss: 2.0829 - val_acc: 0.2400\n",
      "Epoch 665/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.4396 - acc: 0.4114 - val_loss: 2.0887 - val_acc: 0.2333\n",
      "Epoch 666/3000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.4390 - acc: 0.4200 - val_loss: 2.0808 - val_acc: 0.2533\n",
      "Epoch 667/3000\n",
      "700/700 [==============================] - 0s 108us/step - loss: 1.4406 - acc: 0.4114 - val_loss: 2.0751 - val_acc: 0.2367\n",
      "Epoch 668/3000\n",
      "700/700 [==============================] - 0s 85us/step - loss: 1.4375 - acc: 0.4157 - val_loss: 2.0902 - val_acc: 0.2567\n",
      "Epoch 669/3000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.4382 - acc: 0.4157 - val_loss: 2.0931 - val_acc: 0.2333\n",
      "Epoch 670/3000\n",
      "700/700 [==============================] - 0s 118us/step - loss: 1.4393 - acc: 0.4171 - val_loss: 2.0815 - val_acc: 0.2333\n",
      "Epoch 671/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.4377 - acc: 0.4157 - val_loss: 2.0801 - val_acc: 0.2533\n",
      "Epoch 672/3000\n",
      "700/700 [==============================] - 0s 87us/step - loss: 1.4382 - acc: 0.4100 - val_loss: 2.0893 - val_acc: 0.2367\n",
      "Epoch 673/3000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.4384 - acc: 0.4171 - val_loss: 2.0821 - val_acc: 0.2400\n",
      "Epoch 674/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.4374 - acc: 0.4086 - val_loss: 2.1027 - val_acc: 0.2433\n",
      "Epoch 675/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.4366 - acc: 0.4214 - val_loss: 2.1019 - val_acc: 0.2533\n",
      "Epoch 676/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.4370 - acc: 0.4186 - val_loss: 2.0800 - val_acc: 0.2567\n",
      "Epoch 677/3000\n",
      "700/700 [==============================] - 0s 82us/step - loss: 1.4360 - acc: 0.4143 - val_loss: 2.0972 - val_acc: 0.2300\n",
      "Epoch 678/3000\n",
      "700/700 [==============================] - 0s 85us/step - loss: 1.4355 - acc: 0.4200 - val_loss: 2.0724 - val_acc: 0.2333\n",
      "Epoch 679/3000\n",
      "700/700 [==============================] - 0s 78us/step - loss: 1.4369 - acc: 0.4257 - val_loss: 2.0890 - val_acc: 0.2367\n",
      "Epoch 680/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.4377 - acc: 0.4157 - val_loss: 2.0891 - val_acc: 0.2400\n",
      "Epoch 681/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.4370 - acc: 0.4186 - val_loss: 2.0805 - val_acc: 0.2400\n",
      "Epoch 682/3000\n",
      "700/700 [==============================] - 0s 115us/step - loss: 1.4360 - acc: 0.4214 - val_loss: 2.0854 - val_acc: 0.2567\n",
      "Epoch 683/3000\n",
      "700/700 [==============================] - 0s 92us/step - loss: 1.4356 - acc: 0.4129 - val_loss: 2.0779 - val_acc: 0.2500\n",
      "Epoch 684/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 1.4330 - acc: 0.4143 - val_loss: 2.0887 - val_acc: 0.2600\n",
      "Epoch 685/3000\n",
      "700/700 [==============================] - 0s 84us/step - loss: 1.4356 - acc: 0.4143 - val_loss: 2.0846 - val_acc: 0.2567\n",
      "Epoch 686/3000\n",
      "700/700 [==============================] - 0s 87us/step - loss: 1.4352 - acc: 0.4200 - val_loss: 2.1067 - val_acc: 0.2533\n",
      "Epoch 687/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.4354 - acc: 0.4143 - val_loss: 2.0772 - val_acc: 0.2367\n",
      "Epoch 688/3000\n",
      "700/700 [==============================] - 0s 87us/step - loss: 1.4355 - acc: 0.4157 - val_loss: 2.0829 - val_acc: 0.2400\n",
      "Epoch 689/3000\n",
      "700/700 [==============================] - 0s 85us/step - loss: 1.4348 - acc: 0.4200 - val_loss: 2.0925 - val_acc: 0.2367\n",
      "Epoch 690/3000\n",
      "700/700 [==============================] - 0s 80us/step - loss: 1.4345 - acc: 0.4143 - val_loss: 2.0995 - val_acc: 0.2333\n",
      "Epoch 691/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.4337 - acc: 0.4229 - val_loss: 2.0944 - val_acc: 0.2333\n",
      "Epoch 692/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.4339 - acc: 0.4186 - val_loss: 2.0823 - val_acc: 0.2400\n",
      "Epoch 693/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.4345 - acc: 0.4171 - val_loss: 2.0821 - val_acc: 0.2400\n",
      "Epoch 694/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 1.4335 - acc: 0.4186 - val_loss: 2.1068 - val_acc: 0.2467\n",
      "Epoch 695/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.4348 - acc: 0.4171 - val_loss: 2.0871 - val_acc: 0.2567\n",
      "Epoch 696/3000\n",
      "700/700 [==============================] - 0s 88us/step - loss: 1.4324 - acc: 0.4214 - val_loss: 2.0991 - val_acc: 0.2333\n",
      "Epoch 697/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.4337 - acc: 0.4171 - val_loss: 2.1062 - val_acc: 0.2467\n",
      "Epoch 698/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.4333 - acc: 0.4243 - val_loss: 2.0948 - val_acc: 0.2433\n",
      "Epoch 699/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.4328 - acc: 0.4214 - val_loss: 2.0955 - val_acc: 0.2400\n",
      "Epoch 700/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.4329 - acc: 0.4200 - val_loss: 2.0952 - val_acc: 0.2467\n",
      "Epoch 701/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.4317 - acc: 0.4171 - val_loss: 2.0920 - val_acc: 0.2433\n",
      "Epoch 702/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.4327 - acc: 0.4129 - val_loss: 2.0981 - val_acc: 0.2367\n",
      "Epoch 703/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.4316 - acc: 0.4229 - val_loss: 2.1139 - val_acc: 0.2300\n",
      "Epoch 704/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.4326 - acc: 0.4200 - val_loss: 2.0936 - val_acc: 0.2433\n",
      "Epoch 705/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.4320 - acc: 0.4157 - val_loss: 2.0878 - val_acc: 0.2400\n",
      "Epoch 706/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.4321 - acc: 0.4229 - val_loss: 2.0808 - val_acc: 0.2400\n",
      "Epoch 707/3000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.4315 - acc: 0.4243 - val_loss: 2.0931 - val_acc: 0.2367\n",
      "Epoch 708/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.4316 - acc: 0.4229 - val_loss: 2.0919 - val_acc: 0.2333\n",
      "Epoch 709/3000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.4295 - acc: 0.4200 - val_loss: 2.1159 - val_acc: 0.2533\n",
      "Epoch 710/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.4314 - acc: 0.4229 - val_loss: 2.0956 - val_acc: 0.2467\n",
      "Epoch 711/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.4304 - acc: 0.4171 - val_loss: 2.0959 - val_acc: 0.2367\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 712/3000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.4300 - acc: 0.4229 - val_loss: 2.1033 - val_acc: 0.2533\n",
      "Epoch 713/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.4311 - acc: 0.4186 - val_loss: 2.0831 - val_acc: 0.2400\n",
      "Epoch 714/3000\n",
      "700/700 [==============================] - 0s 98us/step - loss: 1.4303 - acc: 0.4243 - val_loss: 2.0992 - val_acc: 0.2367\n",
      "Epoch 715/3000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 1.4282 - acc: 0.4257 - val_loss: 2.0858 - val_acc: 0.2600\n",
      "Epoch 716/3000\n",
      "700/700 [==============================] - 0s 98us/step - loss: 1.4305 - acc: 0.4171 - val_loss: 2.0989 - val_acc: 0.2367\n",
      "Epoch 717/3000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.4297 - acc: 0.4157 - val_loss: 2.1004 - val_acc: 0.2367\n",
      "Epoch 718/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.4290 - acc: 0.4200 - val_loss: 2.1239 - val_acc: 0.2533\n",
      "Epoch 719/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.4301 - acc: 0.4143 - val_loss: 2.1158 - val_acc: 0.2400\n",
      "Epoch 720/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.4297 - acc: 0.4200 - val_loss: 2.1034 - val_acc: 0.2367\n",
      "Epoch 721/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.4290 - acc: 0.4200 - val_loss: 2.1025 - val_acc: 0.2433\n",
      "Epoch 722/3000\n",
      "700/700 [==============================] - 0s 108us/step - loss: 1.4287 - acc: 0.4214 - val_loss: 2.1022 - val_acc: 0.2367\n",
      "Epoch 723/3000\n",
      "700/700 [==============================] - 0s 79us/step - loss: 1.4283 - acc: 0.4214 - val_loss: 2.0942 - val_acc: 0.2400\n",
      "Epoch 724/3000\n",
      "700/700 [==============================] - 0s 81us/step - loss: 1.4282 - acc: 0.4243 - val_loss: 2.1100 - val_acc: 0.2367\n",
      "Epoch 725/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.4278 - acc: 0.4243 - val_loss: 2.1164 - val_acc: 0.2433\n",
      "Epoch 726/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.4277 - acc: 0.4271 - val_loss: 2.0986 - val_acc: 0.2367\n",
      "Epoch 727/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.4274 - acc: 0.4229 - val_loss: 2.1274 - val_acc: 0.2333\n",
      "Epoch 728/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.4276 - acc: 0.4243 - val_loss: 2.0950 - val_acc: 0.2400\n",
      "Epoch 729/3000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.4270 - acc: 0.4186 - val_loss: 2.1200 - val_acc: 0.2467\n",
      "Epoch 730/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.4269 - acc: 0.4243 - val_loss: 2.1230 - val_acc: 0.2367\n",
      "Epoch 731/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.4276 - acc: 0.4143 - val_loss: 2.1100 - val_acc: 0.2367\n",
      "Epoch 732/3000\n",
      "700/700 [==============================] - 0s 98us/step - loss: 1.4260 - acc: 0.4257 - val_loss: 2.1122 - val_acc: 0.2400\n",
      "Epoch 733/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.4264 - acc: 0.4286 - val_loss: 2.1089 - val_acc: 0.2333\n",
      "Epoch 734/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 1.4273 - acc: 0.4200 - val_loss: 2.1142 - val_acc: 0.2400\n",
      "Epoch 735/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 1.4260 - acc: 0.4300 - val_loss: 2.1090 - val_acc: 0.2367\n",
      "Epoch 736/3000\n",
      "700/700 [==============================] - 0s 82us/step - loss: 1.4249 - acc: 0.4286 - val_loss: 2.1022 - val_acc: 0.2400\n",
      "Epoch 737/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.4265 - acc: 0.4214 - val_loss: 2.1187 - val_acc: 0.2433\n",
      "Epoch 738/3000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.4265 - acc: 0.4214 - val_loss: 2.1078 - val_acc: 0.2467\n",
      "Epoch 739/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.4251 - acc: 0.4286 - val_loss: 2.1169 - val_acc: 0.2367\n",
      "Epoch 740/3000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.4250 - acc: 0.4286 - val_loss: 2.1058 - val_acc: 0.2400\n",
      "Epoch 741/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.4249 - acc: 0.4200 - val_loss: 2.1190 - val_acc: 0.2567\n",
      "Epoch 742/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.4253 - acc: 0.4157 - val_loss: 2.1008 - val_acc: 0.2533\n",
      "Epoch 743/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.4240 - acc: 0.4286 - val_loss: 2.1059 - val_acc: 0.2533\n",
      "Epoch 744/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.4257 - acc: 0.4186 - val_loss: 2.1053 - val_acc: 0.2433\n",
      "Epoch 745/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.4220 - acc: 0.4329 - val_loss: 2.1165 - val_acc: 0.2533\n",
      "Epoch 746/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.4254 - acc: 0.4300 - val_loss: 2.1039 - val_acc: 0.2400\n",
      "Epoch 747/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.4251 - acc: 0.4186 - val_loss: 2.1129 - val_acc: 0.2433\n",
      "Epoch 748/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.4233 - acc: 0.4257 - val_loss: 2.1292 - val_acc: 0.2600\n",
      "Epoch 749/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.4222 - acc: 0.4271 - val_loss: 2.0963 - val_acc: 0.2333\n",
      "Epoch 750/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.4239 - acc: 0.4314 - val_loss: 2.1021 - val_acc: 0.2333\n",
      "Epoch 751/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.4225 - acc: 0.4157 - val_loss: 2.1131 - val_acc: 0.2400\n",
      "Epoch 752/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.4235 - acc: 0.4257 - val_loss: 2.1180 - val_acc: 0.2367\n",
      "Epoch 753/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.4222 - acc: 0.4243 - val_loss: 2.1361 - val_acc: 0.2333\n",
      "Epoch 754/3000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.4238 - acc: 0.4271 - val_loss: 2.1209 - val_acc: 0.2367\n",
      "Epoch 755/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.4222 - acc: 0.4400 - val_loss: 2.1211 - val_acc: 0.2467\n",
      "Epoch 756/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.4221 - acc: 0.4114 - val_loss: 2.1149 - val_acc: 0.2400\n",
      "Epoch 757/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.4231 - acc: 0.4200 - val_loss: 2.1240 - val_acc: 0.2433\n",
      "Epoch 758/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.4219 - acc: 0.4286 - val_loss: 2.1194 - val_acc: 0.2433\n",
      "Epoch 759/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.4223 - acc: 0.4243 - val_loss: 2.1156 - val_acc: 0.2400\n",
      "Epoch 760/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.4218 - acc: 0.4357 - val_loss: 2.1137 - val_acc: 0.2400\n",
      "Epoch 761/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.4216 - acc: 0.4243 - val_loss: 2.1349 - val_acc: 0.2500\n",
      "Epoch 762/3000\n",
      "700/700 [==============================] - 0s 92us/step - loss: 1.4224 - acc: 0.4257 - val_loss: 2.1265 - val_acc: 0.2400\n",
      "Epoch 763/3000\n",
      "700/700 [==============================] - 0s 88us/step - loss: 1.4216 - acc: 0.4200 - val_loss: 2.1124 - val_acc: 0.2400\n",
      "Epoch 764/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.4224 - acc: 0.4314 - val_loss: 2.1313 - val_acc: 0.2433\n",
      "Epoch 765/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.4203 - acc: 0.4186 - val_loss: 2.1418 - val_acc: 0.2333\n",
      "Epoch 766/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.4217 - acc: 0.4243 - val_loss: 2.1152 - val_acc: 0.2400\n",
      "Epoch 767/3000\n",
      "700/700 [==============================] - 0s 98us/step - loss: 1.4217 - acc: 0.4257 - val_loss: 2.1161 - val_acc: 0.2367\n",
      "Epoch 768/3000\n",
      "700/700 [==============================] - 0s 92us/step - loss: 1.4205 - acc: 0.4257 - val_loss: 2.1064 - val_acc: 0.2400\n",
      "Epoch 769/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.4206 - acc: 0.4214 - val_loss: 2.1189 - val_acc: 0.2367\n",
      "Epoch 770/3000\n",
      "700/700 [==============================] - 0s 98us/step - loss: 1.4201 - acc: 0.4243 - val_loss: 2.1090 - val_acc: 0.2333\n",
      "Epoch 771/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 103us/step - loss: 1.4196 - acc: 0.4229 - val_loss: 2.1239 - val_acc: 0.2367\n",
      "Epoch 772/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.4201 - acc: 0.4243 - val_loss: 2.1278 - val_acc: 0.2433\n",
      "Epoch 773/3000\n",
      "700/700 [==============================] - 0s 92us/step - loss: 1.4200 - acc: 0.4229 - val_loss: 2.1336 - val_acc: 0.2500\n",
      "Epoch 774/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.4192 - acc: 0.4214 - val_loss: 2.1300 - val_acc: 0.2400\n",
      "Epoch 775/3000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.4182 - acc: 0.4300 - val_loss: 2.1276 - val_acc: 0.2533\n",
      "Epoch 776/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.4191 - acc: 0.4286 - val_loss: 2.1263 - val_acc: 0.2467\n",
      "Epoch 777/3000\n",
      "700/700 [==============================] - 0s 108us/step - loss: 1.4179 - acc: 0.4271 - val_loss: 2.1359 - val_acc: 0.2333\n",
      "Epoch 778/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.4190 - acc: 0.4229 - val_loss: 2.1250 - val_acc: 0.2367\n",
      "Epoch 779/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.4193 - acc: 0.4286 - val_loss: 2.1246 - val_acc: 0.2333\n",
      "Epoch 780/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.4190 - acc: 0.4243 - val_loss: 2.1178 - val_acc: 0.2400\n",
      "Epoch 781/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.4197 - acc: 0.4214 - val_loss: 2.1243 - val_acc: 0.2467\n",
      "Epoch 782/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.4184 - acc: 0.4200 - val_loss: 2.1093 - val_acc: 0.2433\n",
      "Epoch 783/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.4186 - acc: 0.4314 - val_loss: 2.1294 - val_acc: 0.2433\n",
      "Epoch 784/3000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.4182 - acc: 0.4329 - val_loss: 2.1340 - val_acc: 0.2400\n",
      "Epoch 785/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.4181 - acc: 0.4286 - val_loss: 2.1413 - val_acc: 0.2367\n",
      "Epoch 786/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.4180 - acc: 0.4257 - val_loss: 2.1248 - val_acc: 0.2467\n",
      "Epoch 787/3000\n",
      "700/700 [==============================] - 0s 98us/step - loss: 1.4184 - acc: 0.4200 - val_loss: 2.1167 - val_acc: 0.2500\n",
      "Epoch 788/3000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.4177 - acc: 0.4271 - val_loss: 2.1244 - val_acc: 0.2433\n",
      "Epoch 789/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.4173 - acc: 0.4229 - val_loss: 2.1260 - val_acc: 0.2400\n",
      "Epoch 790/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.4174 - acc: 0.4314 - val_loss: 2.1285 - val_acc: 0.2400\n",
      "Epoch 791/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.4165 - acc: 0.4286 - val_loss: 2.1298 - val_acc: 0.2500\n",
      "Epoch 792/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.4171 - acc: 0.4214 - val_loss: 2.1204 - val_acc: 0.2367\n",
      "Epoch 793/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.4165 - acc: 0.4257 - val_loss: 2.1363 - val_acc: 0.2500\n",
      "Epoch 794/3000\n",
      "700/700 [==============================] - 0s 98us/step - loss: 1.4169 - acc: 0.4257 - val_loss: 2.1304 - val_acc: 0.2367\n",
      "Epoch 795/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.4164 - acc: 0.4329 - val_loss: 2.1282 - val_acc: 0.2400\n",
      "Epoch 796/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.4160 - acc: 0.4314 - val_loss: 2.1292 - val_acc: 0.2367\n",
      "Epoch 797/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.4164 - acc: 0.4200 - val_loss: 2.1351 - val_acc: 0.2367\n",
      "Epoch 798/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.4162 - acc: 0.4371 - val_loss: 2.1358 - val_acc: 0.2400\n",
      "Epoch 799/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.4152 - acc: 0.4329 - val_loss: 2.1290 - val_acc: 0.2567\n",
      "Epoch 800/3000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.4158 - acc: 0.4200 - val_loss: 2.1393 - val_acc: 0.2333\n",
      "Epoch 801/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 1.4159 - acc: 0.4329 - val_loss: 2.1352 - val_acc: 0.2333\n",
      "Epoch 802/3000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.4158 - acc: 0.4329 - val_loss: 2.1720 - val_acc: 0.2400\n",
      "Epoch 803/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.4147 - acc: 0.4271 - val_loss: 2.1339 - val_acc: 0.2600\n",
      "Epoch 804/3000\n",
      "700/700 [==============================] - 0s 98us/step - loss: 1.4148 - acc: 0.4243 - val_loss: 2.1274 - val_acc: 0.2433\n",
      "Epoch 805/3000\n",
      "700/700 [==============================] - 0s 98us/step - loss: 1.4143 - acc: 0.4329 - val_loss: 2.1286 - val_acc: 0.2467\n",
      "Epoch 806/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.4148 - acc: 0.4343 - val_loss: 2.1283 - val_acc: 0.2400\n",
      "Epoch 807/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.4148 - acc: 0.4371 - val_loss: 2.1298 - val_acc: 0.2400\n",
      "Epoch 808/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.4143 - acc: 0.4329 - val_loss: 2.1350 - val_acc: 0.2400\n",
      "Epoch 809/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.4150 - acc: 0.4229 - val_loss: 2.1407 - val_acc: 0.2467\n",
      "Epoch 810/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.4139 - acc: 0.4343 - val_loss: 2.1367 - val_acc: 0.2367\n",
      "Epoch 811/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.4142 - acc: 0.4314 - val_loss: 2.1361 - val_acc: 0.2433\n",
      "Epoch 812/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.4142 - acc: 0.4257 - val_loss: 2.1266 - val_acc: 0.2400\n",
      "Epoch 813/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.4139 - acc: 0.4329 - val_loss: 2.1435 - val_acc: 0.2400\n",
      "Epoch 814/3000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.4131 - acc: 0.4286 - val_loss: 2.1360 - val_acc: 0.2567\n",
      "Epoch 815/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.4139 - acc: 0.4286 - val_loss: 2.1408 - val_acc: 0.2467\n",
      "Epoch 816/3000\n",
      "700/700 [==============================] - 0s 82us/step - loss: 1.4135 - acc: 0.4286 - val_loss: 2.1300 - val_acc: 0.2367\n",
      "Epoch 817/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.4118 - acc: 0.4300 - val_loss: 2.1349 - val_acc: 0.2367\n",
      "Epoch 818/3000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.4123 - acc: 0.4286 - val_loss: 2.1436 - val_acc: 0.2367\n",
      "Epoch 819/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.4110 - acc: 0.4371 - val_loss: 2.1507 - val_acc: 0.2600\n",
      "Epoch 820/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.4130 - acc: 0.4329 - val_loss: 2.1396 - val_acc: 0.2633\n",
      "Epoch 821/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.4129 - acc: 0.4300 - val_loss: 2.1475 - val_acc: 0.2467\n",
      "Epoch 822/3000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.4130 - acc: 0.4329 - val_loss: 2.1390 - val_acc: 0.2367\n",
      "Epoch 823/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.4115 - acc: 0.4229 - val_loss: 2.1447 - val_acc: 0.2433\n",
      "Epoch 824/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.4109 - acc: 0.4286 - val_loss: 2.1447 - val_acc: 0.2433\n",
      "Epoch 825/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.4112 - acc: 0.4314 - val_loss: 2.1568 - val_acc: 0.2467\n",
      "Epoch 826/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.4120 - acc: 0.4229 - val_loss: 2.1501 - val_acc: 0.2467\n",
      "Epoch 827/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.4113 - acc: 0.4300 - val_loss: 2.1475 - val_acc: 0.2400\n",
      "Epoch 828/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.4117 - acc: 0.4343 - val_loss: 2.1373 - val_acc: 0.2367\n",
      "Epoch 829/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.4111 - acc: 0.4357 - val_loss: 2.1402 - val_acc: 0.2433\n",
      "Epoch 830/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 96us/step - loss: 1.4106 - acc: 0.4257 - val_loss: 2.1451 - val_acc: 0.2400\n",
      "Epoch 831/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.4105 - acc: 0.4457 - val_loss: 2.1588 - val_acc: 0.2467\n",
      "Epoch 832/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.4111 - acc: 0.4314 - val_loss: 2.1617 - val_acc: 0.2500\n",
      "Epoch 833/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.4110 - acc: 0.4257 - val_loss: 2.1648 - val_acc: 0.2467\n",
      "Epoch 834/3000\n",
      "700/700 [==============================] - 0s 82us/step - loss: 1.4106 - acc: 0.4329 - val_loss: 2.1737 - val_acc: 0.2433\n",
      "Epoch 835/3000\n",
      "700/700 [==============================] - 0s 80us/step - loss: 1.4095 - acc: 0.4300 - val_loss: 2.1431 - val_acc: 0.2367\n",
      "Epoch 836/3000\n",
      "700/700 [==============================] - 0s 80us/step - loss: 1.4098 - acc: 0.4286 - val_loss: 2.1513 - val_acc: 0.2500\n",
      "Epoch 837/3000\n",
      "700/700 [==============================] - 0s 82us/step - loss: 1.4102 - acc: 0.4300 - val_loss: 2.1377 - val_acc: 0.2433\n",
      "Epoch 838/3000\n",
      "700/700 [==============================] - 0s 85us/step - loss: 1.4107 - acc: 0.4329 - val_loss: 2.1497 - val_acc: 0.2367\n",
      "Epoch 839/3000\n",
      "700/700 [==============================] - 0s 84us/step - loss: 1.4088 - acc: 0.4300 - val_loss: 2.1490 - val_acc: 0.2367\n",
      "Epoch 840/3000\n",
      "700/700 [==============================] - 0s 87us/step - loss: 1.4081 - acc: 0.4357 - val_loss: 2.1407 - val_acc: 0.2433\n",
      "Epoch 841/3000\n",
      "700/700 [==============================] - 0s 83us/step - loss: 1.4092 - acc: 0.4371 - val_loss: 2.1472 - val_acc: 0.2367\n",
      "Epoch 842/3000\n",
      "700/700 [==============================] - 0s 86us/step - loss: 1.4099 - acc: 0.4286 - val_loss: 2.1589 - val_acc: 0.2467\n",
      "Epoch 843/3000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.4089 - acc: 0.4300 - val_loss: 2.1513 - val_acc: 0.2367\n",
      "Epoch 844/3000\n",
      "700/700 [==============================] - 0s 129us/step - loss: 1.4079 - acc: 0.4300 - val_loss: 2.1619 - val_acc: 0.2400\n",
      "Epoch 845/3000\n",
      "700/700 [==============================] - 0s 151us/step - loss: 1.4086 - acc: 0.4314 - val_loss: 2.1374 - val_acc: 0.2367\n",
      "Epoch 846/3000\n",
      "700/700 [==============================] - 0s 86us/step - loss: 1.4091 - acc: 0.4357 - val_loss: 2.1492 - val_acc: 0.2400\n",
      "Epoch 847/3000\n",
      "700/700 [==============================] - 0s 84us/step - loss: 1.4075 - acc: 0.4229 - val_loss: 2.1594 - val_acc: 0.2433\n",
      "Epoch 848/3000\n",
      "700/700 [==============================] - 0s 87us/step - loss: 1.4080 - acc: 0.4371 - val_loss: 2.1538 - val_acc: 0.2533\n",
      "Epoch 849/3000\n",
      "700/700 [==============================] - 0s 88us/step - loss: 1.4086 - acc: 0.4300 - val_loss: 2.1555 - val_acc: 0.2433\n",
      "Epoch 850/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.4072 - acc: 0.4314 - val_loss: 2.1449 - val_acc: 0.2367\n",
      "Epoch 851/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.4070 - acc: 0.4243 - val_loss: 2.1549 - val_acc: 0.2333\n",
      "Epoch 852/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.4084 - acc: 0.4371 - val_loss: 2.1509 - val_acc: 0.2433\n",
      "Epoch 853/3000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.4066 - acc: 0.4314 - val_loss: 2.1500 - val_acc: 0.2367\n",
      "Epoch 854/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.4047 - acc: 0.4329 - val_loss: 2.1738 - val_acc: 0.2600\n",
      "Epoch 855/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.4074 - acc: 0.4271 - val_loss: 2.1511 - val_acc: 0.2333\n",
      "Epoch 856/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.4074 - acc: 0.4357 - val_loss: 2.1665 - val_acc: 0.2467\n",
      "Epoch 857/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.4067 - acc: 0.4300 - val_loss: 2.1639 - val_acc: 0.2467\n",
      "Epoch 858/3000\n",
      "700/700 [==============================] - 0s 83us/step - loss: 1.4070 - acc: 0.4329 - val_loss: 2.1544 - val_acc: 0.2367\n",
      "Epoch 859/3000\n",
      "700/700 [==============================] - 0s 77us/step - loss: 1.4050 - acc: 0.4371 - val_loss: 2.1551 - val_acc: 0.2367\n",
      "Epoch 860/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.4058 - acc: 0.4357 - val_loss: 2.1795 - val_acc: 0.2533\n",
      "Epoch 861/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.4064 - acc: 0.4357 - val_loss: 2.1621 - val_acc: 0.2433\n",
      "Epoch 862/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.4071 - acc: 0.4286 - val_loss: 2.1695 - val_acc: 0.2533\n",
      "Epoch 863/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.4057 - acc: 0.4329 - val_loss: 2.1651 - val_acc: 0.2500\n",
      "Epoch 864/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.4054 - acc: 0.4343 - val_loss: 2.1622 - val_acc: 0.2533\n",
      "Epoch 865/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.4044 - acc: 0.4371 - val_loss: 2.1701 - val_acc: 0.2633\n",
      "Epoch 866/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.4049 - acc: 0.4357 - val_loss: 2.1378 - val_acc: 0.2433\n",
      "Epoch 867/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.4052 - acc: 0.4357 - val_loss: 2.1690 - val_acc: 0.2433\n",
      "Epoch 868/3000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.4055 - acc: 0.4357 - val_loss: 2.1619 - val_acc: 0.2467\n",
      "Epoch 869/3000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.4050 - acc: 0.4371 - val_loss: 2.1594 - val_acc: 0.2400\n",
      "Epoch 870/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.4035 - acc: 0.4357 - val_loss: 2.1714 - val_acc: 0.2467\n",
      "Epoch 871/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.4048 - acc: 0.4286 - val_loss: 2.1743 - val_acc: 0.2467\n",
      "Epoch 872/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.4037 - acc: 0.4357 - val_loss: 2.1607 - val_acc: 0.2533\n",
      "Epoch 873/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.4043 - acc: 0.4329 - val_loss: 2.1411 - val_acc: 0.2367\n",
      "Epoch 874/3000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.4048 - acc: 0.4329 - val_loss: 2.1524 - val_acc: 0.2367\n",
      "Epoch 875/3000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.4039 - acc: 0.4343 - val_loss: 2.1699 - val_acc: 0.2500\n",
      "Epoch 876/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.4036 - acc: 0.4314 - val_loss: 2.1523 - val_acc: 0.2433\n",
      "Epoch 877/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.4035 - acc: 0.4257 - val_loss: 2.1738 - val_acc: 0.2333\n",
      "Epoch 878/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.4043 - acc: 0.4314 - val_loss: 2.1690 - val_acc: 0.2400\n",
      "Epoch 879/3000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.4013 - acc: 0.4343 - val_loss: 2.1699 - val_acc: 0.2367\n",
      "Epoch 880/3000\n",
      "700/700 [==============================] - 0s 88us/step - loss: 1.4052 - acc: 0.4329 - val_loss: 2.1563 - val_acc: 0.2400\n",
      "Epoch 881/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.4032 - acc: 0.4414 - val_loss: 2.1837 - val_acc: 0.2500\n",
      "Epoch 882/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.4035 - acc: 0.4371 - val_loss: 2.1727 - val_acc: 0.2400\n",
      "Epoch 883/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.4043 - acc: 0.4300 - val_loss: 2.1504 - val_acc: 0.2433\n",
      "Epoch 884/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.4027 - acc: 0.4329 - val_loss: 2.1788 - val_acc: 0.2533\n",
      "Epoch 885/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.4031 - acc: 0.4314 - val_loss: 2.1451 - val_acc: 0.2433\n",
      "Epoch 886/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.4036 - acc: 0.4371 - val_loss: 2.1687 - val_acc: 0.2433\n",
      "Epoch 887/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.4026 - acc: 0.4371 - val_loss: 2.1613 - val_acc: 0.2400\n",
      "Epoch 888/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.4025 - acc: 0.4343 - val_loss: 2.1661 - val_acc: 0.2400\n",
      "Epoch 889/3000\n",
      "700/700 [==============================] - 0s 108us/step - loss: 1.4009 - acc: 0.4429 - val_loss: 2.1793 - val_acc: 0.2600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 890/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.4027 - acc: 0.4386 - val_loss: 2.1646 - val_acc: 0.2567\n",
      "Epoch 891/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.4025 - acc: 0.4271 - val_loss: 2.1701 - val_acc: 0.2433\n",
      "Epoch 892/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.4023 - acc: 0.4386 - val_loss: 2.1744 - val_acc: 0.2433\n",
      "Epoch 893/3000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.4017 - acc: 0.4371 - val_loss: 2.1793 - val_acc: 0.2433\n",
      "Epoch 894/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.4021 - acc: 0.4414 - val_loss: 2.1674 - val_acc: 0.2400\n",
      "Epoch 895/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.4011 - acc: 0.4329 - val_loss: 2.1722 - val_acc: 0.2467\n",
      "Epoch 896/3000\n",
      "700/700 [==============================] - 0s 108us/step - loss: 1.4014 - acc: 0.4343 - val_loss: 2.1742 - val_acc: 0.2600\n",
      "Epoch 897/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.4016 - acc: 0.4357 - val_loss: 2.1774 - val_acc: 0.2567\n",
      "Epoch 898/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.4011 - acc: 0.4371 - val_loss: 2.1871 - val_acc: 0.2467\n",
      "Epoch 899/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.4015 - acc: 0.4343 - val_loss: 2.1625 - val_acc: 0.2467\n",
      "Epoch 900/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.4001 - acc: 0.4471 - val_loss: 2.1650 - val_acc: 0.2467\n",
      "Epoch 901/3000\n",
      "700/700 [==============================] - 0s 108us/step - loss: 1.3999 - acc: 0.4400 - val_loss: 2.1776 - val_acc: 0.2533\n",
      "Epoch 902/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.4002 - acc: 0.4343 - val_loss: 2.1679 - val_acc: 0.2467\n",
      "Epoch 903/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.3993 - acc: 0.4400 - val_loss: 2.1855 - val_acc: 0.2633\n",
      "Epoch 904/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.3989 - acc: 0.4386 - val_loss: 2.1641 - val_acc: 0.2400\n",
      "Epoch 905/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.4009 - acc: 0.4414 - val_loss: 2.1605 - val_acc: 0.2367\n",
      "Epoch 906/3000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.3998 - acc: 0.4357 - val_loss: 2.1572 - val_acc: 0.2367\n",
      "Epoch 907/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.4004 - acc: 0.4371 - val_loss: 2.1813 - val_acc: 0.2467\n",
      "Epoch 908/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3997 - acc: 0.4371 - val_loss: 2.1766 - val_acc: 0.2433\n",
      "Epoch 909/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.3994 - acc: 0.4357 - val_loss: 2.1811 - val_acc: 0.2467\n",
      "Epoch 910/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.4002 - acc: 0.4357 - val_loss: 2.1620 - val_acc: 0.2400\n",
      "Epoch 911/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.3991 - acc: 0.4386 - val_loss: 2.1801 - val_acc: 0.2367\n",
      "Epoch 912/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.3995 - acc: 0.4414 - val_loss: 2.1687 - val_acc: 0.2367\n",
      "Epoch 913/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.4000 - acc: 0.4386 - val_loss: 2.1885 - val_acc: 0.2433\n",
      "Epoch 914/3000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 1.3983 - acc: 0.4386 - val_loss: 2.1845 - val_acc: 0.2567\n",
      "Epoch 915/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.3990 - acc: 0.4343 - val_loss: 2.1741 - val_acc: 0.2467\n",
      "Epoch 916/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.3988 - acc: 0.4386 - val_loss: 2.1833 - val_acc: 0.2433\n",
      "Epoch 917/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.3977 - acc: 0.4400 - val_loss: 2.1743 - val_acc: 0.2333\n",
      "Epoch 918/3000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.3972 - acc: 0.4386 - val_loss: 2.1798 - val_acc: 0.2533\n",
      "Epoch 919/3000\n",
      "700/700 [==============================] - 0s 92us/step - loss: 1.3985 - acc: 0.4300 - val_loss: 2.1881 - val_acc: 0.2433\n",
      "Epoch 920/3000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.3988 - acc: 0.4329 - val_loss: 2.1703 - val_acc: 0.2500\n",
      "Epoch 921/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.3984 - acc: 0.4371 - val_loss: 2.1712 - val_acc: 0.2400\n",
      "Epoch 922/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.3967 - acc: 0.4429 - val_loss: 2.1864 - val_acc: 0.2500\n",
      "Epoch 923/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.3966 - acc: 0.4414 - val_loss: 2.1707 - val_acc: 0.2567\n",
      "Epoch 924/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.3988 - acc: 0.4414 - val_loss: 2.1769 - val_acc: 0.2467\n",
      "Epoch 925/3000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.3970 - acc: 0.4357 - val_loss: 2.1820 - val_acc: 0.2367\n",
      "Epoch 926/3000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.3973 - acc: 0.4443 - val_loss: 2.1759 - val_acc: 0.2467\n",
      "Epoch 927/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.3975 - acc: 0.4357 - val_loss: 2.1873 - val_acc: 0.2433\n",
      "Epoch 928/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.3972 - acc: 0.4371 - val_loss: 2.1906 - val_acc: 0.2433\n",
      "Epoch 929/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.3971 - acc: 0.4414 - val_loss: 2.1908 - val_acc: 0.2400\n",
      "Epoch 930/3000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.3971 - acc: 0.4357 - val_loss: 2.1859 - val_acc: 0.2500\n",
      "Epoch 931/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.3968 - acc: 0.4357 - val_loss: 2.1799 - val_acc: 0.2433\n",
      "Epoch 932/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.3962 - acc: 0.4400 - val_loss: 2.1711 - val_acc: 0.2500\n",
      "Epoch 933/3000\n",
      "700/700 [==============================] - 0s 98us/step - loss: 1.3967 - acc: 0.4314 - val_loss: 2.1820 - val_acc: 0.2467\n",
      "Epoch 934/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.3956 - acc: 0.4414 - val_loss: 2.1875 - val_acc: 0.2500\n",
      "Epoch 935/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.3969 - acc: 0.4443 - val_loss: 2.1837 - val_acc: 0.2467\n",
      "Epoch 936/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3964 - acc: 0.4429 - val_loss: 2.1925 - val_acc: 0.2500\n",
      "Epoch 937/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.3960 - acc: 0.4429 - val_loss: 2.1816 - val_acc: 0.2367\n",
      "Epoch 938/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 1.3954 - acc: 0.4471 - val_loss: 2.1929 - val_acc: 0.2500\n",
      "Epoch 939/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.3953 - acc: 0.4357 - val_loss: 2.1962 - val_acc: 0.2500\n",
      "Epoch 940/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 1.3960 - acc: 0.4343 - val_loss: 2.1778 - val_acc: 0.2367\n",
      "Epoch 941/3000\n",
      "700/700 [==============================] - 0s 86us/step - loss: 1.3957 - acc: 0.4343 - val_loss: 2.1835 - val_acc: 0.2400\n",
      "Epoch 942/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.3947 - acc: 0.4357 - val_loss: 2.1688 - val_acc: 0.2333\n",
      "Epoch 943/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.3954 - acc: 0.4429 - val_loss: 2.1907 - val_acc: 0.2433\n",
      "Epoch 944/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3943 - acc: 0.4357 - val_loss: 2.1946 - val_acc: 0.2467\n",
      "Epoch 945/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.3948 - acc: 0.4329 - val_loss: 2.1893 - val_acc: 0.2500\n",
      "Epoch 946/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.3945 - acc: 0.4329 - val_loss: 2.1830 - val_acc: 0.2467\n",
      "Epoch 947/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.3938 - acc: 0.4386 - val_loss: 2.1930 - val_acc: 0.2533\n",
      "Epoch 948/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.3941 - acc: 0.4286 - val_loss: 2.1749 - val_acc: 0.2367\n",
      "Epoch 949/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 95us/step - loss: 1.3938 - acc: 0.4457 - val_loss: 2.1840 - val_acc: 0.2400\n",
      "Epoch 950/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.3930 - acc: 0.4400 - val_loss: 2.1803 - val_acc: 0.2333\n",
      "Epoch 951/3000\n",
      "700/700 [==============================] - 0s 78us/step - loss: 1.3940 - acc: 0.4443 - val_loss: 2.1888 - val_acc: 0.2500\n",
      "Epoch 952/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.3938 - acc: 0.4414 - val_loss: 2.1891 - val_acc: 0.2433\n",
      "Epoch 953/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.3937 - acc: 0.4371 - val_loss: 2.1975 - val_acc: 0.2533\n",
      "Epoch 954/3000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.3940 - acc: 0.4443 - val_loss: 2.1865 - val_acc: 0.2567\n",
      "Epoch 955/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.3937 - acc: 0.4443 - val_loss: 2.1960 - val_acc: 0.2500\n",
      "Epoch 956/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.3929 - acc: 0.4386 - val_loss: 2.2015 - val_acc: 0.2433\n",
      "Epoch 957/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.3925 - acc: 0.4414 - val_loss: 2.1841 - val_acc: 0.2400\n",
      "Epoch 958/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.3938 - acc: 0.4343 - val_loss: 2.2125 - val_acc: 0.2467\n",
      "Epoch 959/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.3936 - acc: 0.4371 - val_loss: 2.1821 - val_acc: 0.2467\n",
      "Epoch 960/3000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.3927 - acc: 0.4386 - val_loss: 2.1951 - val_acc: 0.2433\n",
      "Epoch 961/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.3924 - acc: 0.4429 - val_loss: 2.1687 - val_acc: 0.2467\n",
      "Epoch 962/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.3931 - acc: 0.4371 - val_loss: 2.1889 - val_acc: 0.2467\n",
      "Epoch 963/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.3924 - acc: 0.4400 - val_loss: 2.1850 - val_acc: 0.2500\n",
      "Epoch 964/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.3920 - acc: 0.4371 - val_loss: 2.1778 - val_acc: 0.2433\n",
      "Epoch 965/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.3913 - acc: 0.4414 - val_loss: 2.1850 - val_acc: 0.2533\n",
      "Epoch 966/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.3924 - acc: 0.4414 - val_loss: 2.2029 - val_acc: 0.2533\n",
      "Epoch 967/3000\n",
      "700/700 [==============================] - 0s 98us/step - loss: 1.3924 - acc: 0.4386 - val_loss: 2.1945 - val_acc: 0.2467\n",
      "Epoch 968/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.3913 - acc: 0.4400 - val_loss: 2.1865 - val_acc: 0.2433\n",
      "Epoch 969/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.3918 - acc: 0.4400 - val_loss: 2.1908 - val_acc: 0.2433\n",
      "Epoch 970/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.3915 - acc: 0.4386 - val_loss: 2.2008 - val_acc: 0.2400\n",
      "Epoch 971/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.3916 - acc: 0.4414 - val_loss: 2.1865 - val_acc: 0.2467\n",
      "Epoch 972/3000\n",
      "700/700 [==============================] - 0s 92us/step - loss: 1.3913 - acc: 0.4386 - val_loss: 2.2012 - val_acc: 0.2333\n",
      "Epoch 973/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.3902 - acc: 0.4414 - val_loss: 2.1886 - val_acc: 0.2500\n",
      "Epoch 974/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.3909 - acc: 0.4357 - val_loss: 2.1963 - val_acc: 0.2500\n",
      "Epoch 975/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3908 - acc: 0.4429 - val_loss: 2.2044 - val_acc: 0.2500\n",
      "Epoch 976/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.3905 - acc: 0.4429 - val_loss: 2.1917 - val_acc: 0.2533\n",
      "Epoch 977/3000\n",
      "700/700 [==============================] - 0s 98us/step - loss: 1.3907 - acc: 0.4343 - val_loss: 2.1894 - val_acc: 0.2400\n",
      "Epoch 978/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.3900 - acc: 0.4486 - val_loss: 2.1950 - val_acc: 0.2533\n",
      "Epoch 979/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.3906 - acc: 0.4443 - val_loss: 2.1926 - val_acc: 0.2467\n",
      "Epoch 980/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.3905 - acc: 0.4429 - val_loss: 2.2049 - val_acc: 0.2500\n",
      "Epoch 981/3000\n",
      "700/700 [==============================] - 0s 82us/step - loss: 1.3895 - acc: 0.4400 - val_loss: 2.2123 - val_acc: 0.2500\n",
      "Epoch 982/3000\n",
      "700/700 [==============================] - 0s 88us/step - loss: 1.3903 - acc: 0.4400 - val_loss: 2.1963 - val_acc: 0.2533\n",
      "Epoch 983/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.3899 - acc: 0.4357 - val_loss: 2.2014 - val_acc: 0.2500\n",
      "Epoch 984/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.3898 - acc: 0.4414 - val_loss: 2.1942 - val_acc: 0.2500\n",
      "Epoch 985/3000\n",
      "700/700 [==============================] - 0s 98us/step - loss: 1.3892 - acc: 0.4429 - val_loss: 2.2077 - val_acc: 0.2367\n",
      "Epoch 986/3000\n",
      "700/700 [==============================] - 0s 98us/step - loss: 1.3893 - acc: 0.4414 - val_loss: 2.2002 - val_acc: 0.2500\n",
      "Epoch 987/3000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.3888 - acc: 0.4429 - val_loss: 2.1919 - val_acc: 0.2367\n",
      "Epoch 988/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.3888 - acc: 0.4443 - val_loss: 2.2148 - val_acc: 0.2633\n",
      "Epoch 989/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.3902 - acc: 0.4357 - val_loss: 2.2111 - val_acc: 0.2567\n",
      "Epoch 990/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.3887 - acc: 0.4443 - val_loss: 2.2174 - val_acc: 0.2533\n",
      "Epoch 991/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.3889 - acc: 0.4471 - val_loss: 2.1936 - val_acc: 0.2433\n",
      "Epoch 992/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.3888 - acc: 0.4371 - val_loss: 2.2050 - val_acc: 0.2400\n",
      "Epoch 993/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.3885 - acc: 0.4443 - val_loss: 2.2004 - val_acc: 0.2533\n",
      "Epoch 994/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.3881 - acc: 0.4371 - val_loss: 2.1853 - val_acc: 0.2333\n",
      "Epoch 995/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.3891 - acc: 0.4471 - val_loss: 2.2011 - val_acc: 0.2500\n",
      "Epoch 996/3000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.3879 - acc: 0.4457 - val_loss: 2.2043 - val_acc: 0.2500\n",
      "Epoch 997/3000\n",
      "700/700 [==============================] - 0s 86us/step - loss: 1.3880 - acc: 0.4429 - val_loss: 2.2012 - val_acc: 0.2500\n",
      "Epoch 998/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.3886 - acc: 0.4386 - val_loss: 2.2122 - val_acc: 0.2500\n",
      "Epoch 999/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.3881 - acc: 0.4386 - val_loss: 2.2007 - val_acc: 0.2500\n",
      "Epoch 1000/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.3880 - acc: 0.4400 - val_loss: 2.2126 - val_acc: 0.2500\n",
      "Epoch 1001/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 1.3864 - acc: 0.4414 - val_loss: 2.2071 - val_acc: 0.2600\n",
      "Epoch 1002/3000\n",
      "700/700 [==============================] - 0s 98us/step - loss: 1.3883 - acc: 0.4371 - val_loss: 2.2011 - val_acc: 0.2533\n",
      "Epoch 1003/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.3864 - acc: 0.4443 - val_loss: 2.2102 - val_acc: 0.2567\n",
      "Epoch 1004/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.3885 - acc: 0.4429 - val_loss: 2.2188 - val_acc: 0.2500\n",
      "Epoch 1005/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.3875 - acc: 0.4371 - val_loss: 2.2037 - val_acc: 0.2533\n",
      "Epoch 1006/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.3869 - acc: 0.4371 - val_loss: 2.2213 - val_acc: 0.2533\n",
      "Epoch 1007/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.3864 - acc: 0.4414 - val_loss: 2.2156 - val_acc: 0.2567\n",
      "Epoch 1008/3000\n",
      "700/700 [==============================] - 0s 98us/step - loss: 1.3870 - acc: 0.4386 - val_loss: 2.1962 - val_acc: 0.2500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1009/3000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.3864 - acc: 0.4443 - val_loss: 2.2205 - val_acc: 0.2500\n",
      "Epoch 1010/3000\n",
      "700/700 [==============================] - 0s 108us/step - loss: 1.3866 - acc: 0.4457 - val_loss: 2.2001 - val_acc: 0.2500\n",
      "Epoch 1011/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.3858 - acc: 0.4429 - val_loss: 2.2108 - val_acc: 0.2533\n",
      "Epoch 1012/3000\n",
      "700/700 [==============================] - 0s 98us/step - loss: 1.3850 - acc: 0.4443 - val_loss: 2.2257 - val_acc: 0.2567\n",
      "Epoch 1013/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.3851 - acc: 0.4443 - val_loss: 2.2018 - val_acc: 0.2400\n",
      "Epoch 1014/3000\n",
      "700/700 [==============================] - 0s 98us/step - loss: 1.3854 - acc: 0.4429 - val_loss: 2.1999 - val_acc: 0.2567\n",
      "Epoch 1015/3000\n",
      "700/700 [==============================] - 0s 98us/step - loss: 1.3842 - acc: 0.4429 - val_loss: 2.2062 - val_acc: 0.2400\n",
      "Epoch 1016/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.3867 - acc: 0.4429 - val_loss: 2.2060 - val_acc: 0.2500\n",
      "Epoch 1017/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.3862 - acc: 0.4343 - val_loss: 2.2076 - val_acc: 0.2500\n",
      "Epoch 1018/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.3860 - acc: 0.4486 - val_loss: 2.2147 - val_acc: 0.2500\n",
      "Epoch 1019/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.3850 - acc: 0.4386 - val_loss: 2.2059 - val_acc: 0.2467\n",
      "Epoch 1020/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.3846 - acc: 0.4529 - val_loss: 2.2039 - val_acc: 0.2500\n",
      "Epoch 1021/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.3854 - acc: 0.4457 - val_loss: 2.2053 - val_acc: 0.2500\n",
      "Epoch 1022/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.3843 - acc: 0.4514 - val_loss: 2.2097 - val_acc: 0.2400\n",
      "Epoch 1023/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.3853 - acc: 0.4429 - val_loss: 2.2018 - val_acc: 0.2467\n",
      "Epoch 1024/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.3850 - acc: 0.4529 - val_loss: 2.2003 - val_acc: 0.2400\n",
      "Epoch 1025/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.3844 - acc: 0.4429 - val_loss: 2.2070 - val_acc: 0.2533\n",
      "Epoch 1026/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.3848 - acc: 0.4471 - val_loss: 2.1899 - val_acc: 0.2433\n",
      "Epoch 1027/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.3841 - acc: 0.4457 - val_loss: 2.2121 - val_acc: 0.2500\n",
      "Epoch 1028/3000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.3844 - acc: 0.4386 - val_loss: 2.2028 - val_acc: 0.2433\n",
      "Epoch 1029/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.3842 - acc: 0.4429 - val_loss: 2.2037 - val_acc: 0.2467\n",
      "Epoch 1030/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.3836 - acc: 0.4486 - val_loss: 2.2142 - val_acc: 0.2500\n",
      "Epoch 1031/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.3836 - acc: 0.4457 - val_loss: 2.2162 - val_acc: 0.2567\n",
      "Epoch 1032/3000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.3845 - acc: 0.4443 - val_loss: 2.2142 - val_acc: 0.2433\n",
      "Epoch 1033/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.3843 - acc: 0.4429 - val_loss: 2.2275 - val_acc: 0.2467\n",
      "Epoch 1034/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.3821 - acc: 0.4443 - val_loss: 2.2094 - val_acc: 0.2300\n",
      "Epoch 1035/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.3843 - acc: 0.4457 - val_loss: 2.2128 - val_acc: 0.2533\n",
      "Epoch 1036/3000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.3837 - acc: 0.4471 - val_loss: 2.2099 - val_acc: 0.2500\n",
      "Epoch 1037/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.3830 - acc: 0.4429 - val_loss: 2.2097 - val_acc: 0.2400\n",
      "Epoch 1038/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.3838 - acc: 0.4443 - val_loss: 2.2313 - val_acc: 0.2567\n",
      "Epoch 1039/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.3834 - acc: 0.4457 - val_loss: 2.2173 - val_acc: 0.2500\n",
      "Epoch 1040/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.3832 - acc: 0.4400 - val_loss: 2.2159 - val_acc: 0.2467\n",
      "Epoch 1041/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.3825 - acc: 0.4429 - val_loss: 2.2265 - val_acc: 0.2500\n",
      "Epoch 1042/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.3814 - acc: 0.4414 - val_loss: 2.2031 - val_acc: 0.2467\n",
      "Epoch 1043/3000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.3833 - acc: 0.4400 - val_loss: 2.2242 - val_acc: 0.2567\n",
      "Epoch 1044/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.3825 - acc: 0.4429 - val_loss: 2.2152 - val_acc: 0.2467\n",
      "Epoch 1045/3000\n",
      "700/700 [==============================] - 0s 98us/step - loss: 1.3800 - acc: 0.4429 - val_loss: 2.2106 - val_acc: 0.2300\n",
      "Epoch 1046/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.3831 - acc: 0.4514 - val_loss: 2.2172 - val_acc: 0.2433\n",
      "Epoch 1047/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.3808 - acc: 0.4471 - val_loss: 2.2105 - val_acc: 0.2367\n",
      "Epoch 1048/3000\n",
      "700/700 [==============================] - 0s 92us/step - loss: 1.3824 - acc: 0.4400 - val_loss: 2.2062 - val_acc: 0.2433\n",
      "Epoch 1049/3000\n",
      "700/700 [==============================] - 0s 81us/step - loss: 1.3817 - acc: 0.4429 - val_loss: 2.2119 - val_acc: 0.2500\n",
      "Epoch 1050/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.3809 - acc: 0.4471 - val_loss: 2.2227 - val_acc: 0.2433\n",
      "Epoch 1051/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.3821 - acc: 0.4443 - val_loss: 2.2110 - val_acc: 0.2500\n",
      "Epoch 1052/3000\n",
      "700/700 [==============================] - 0s 98us/step - loss: 1.3811 - acc: 0.4386 - val_loss: 2.2243 - val_acc: 0.2433\n",
      "Epoch 1053/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.3814 - acc: 0.4429 - val_loss: 2.2188 - val_acc: 0.2467\n",
      "Epoch 1054/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3808 - acc: 0.4486 - val_loss: 2.2118 - val_acc: 0.2500\n",
      "Epoch 1055/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.3806 - acc: 0.4471 - val_loss: 2.2057 - val_acc: 0.2433\n",
      "Epoch 1056/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.3807 - acc: 0.4400 - val_loss: 2.2251 - val_acc: 0.2500\n",
      "Epoch 1057/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.3799 - acc: 0.4343 - val_loss: 2.2335 - val_acc: 0.2433\n",
      "Epoch 1058/3000\n",
      "700/700 [==============================] - 0s 88us/step - loss: 1.3813 - acc: 0.4429 - val_loss: 2.2227 - val_acc: 0.2533\n",
      "Epoch 1059/3000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.3798 - acc: 0.4486 - val_loss: 2.2240 - val_acc: 0.2500\n",
      "Epoch 1060/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.3801 - acc: 0.4429 - val_loss: 2.2176 - val_acc: 0.2533\n",
      "Epoch 1061/3000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.3806 - acc: 0.4457 - val_loss: 2.2294 - val_acc: 0.2567\n",
      "Epoch 1062/3000\n",
      "700/700 [==============================] - 0s 98us/step - loss: 1.3810 - acc: 0.4400 - val_loss: 2.2116 - val_acc: 0.2533\n",
      "Epoch 1063/3000\n",
      "700/700 [==============================] - 0s 98us/step - loss: 1.3795 - acc: 0.4414 - val_loss: 2.2136 - val_acc: 0.2500\n",
      "Epoch 1064/3000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.3800 - acc: 0.4443 - val_loss: 2.2248 - val_acc: 0.2500\n",
      "Epoch 1065/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.3800 - acc: 0.4386 - val_loss: 2.2149 - val_acc: 0.2467\n",
      "Epoch 1066/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.3800 - acc: 0.4414 - val_loss: 2.2180 - val_acc: 0.2400\n",
      "Epoch 1067/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.3799 - acc: 0.4514 - val_loss: 2.2362 - val_acc: 0.2567\n",
      "Epoch 1068/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 83us/step - loss: 1.3792 - acc: 0.4414 - val_loss: 2.2353 - val_acc: 0.2467\n",
      "Epoch 1069/3000\n",
      "700/700 [==============================] - 0s 83us/step - loss: 1.3796 - acc: 0.4400 - val_loss: 2.2314 - val_acc: 0.2500\n",
      "Epoch 1070/3000\n",
      "700/700 [==============================] - 0s 84us/step - loss: 1.3786 - acc: 0.4457 - val_loss: 2.2214 - val_acc: 0.2367\n",
      "Epoch 1071/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.3782 - acc: 0.4471 - val_loss: 2.2401 - val_acc: 0.2267\n",
      "Epoch 1072/3000\n",
      "700/700 [==============================] - 0s 85us/step - loss: 1.3791 - acc: 0.4543 - val_loss: 2.2239 - val_acc: 0.2533\n",
      "Epoch 1073/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3784 - acc: 0.4443 - val_loss: 2.2127 - val_acc: 0.2500\n",
      "Epoch 1074/3000\n",
      "700/700 [==============================] - 0s 83us/step - loss: 1.3788 - acc: 0.4529 - val_loss: 2.2089 - val_acc: 0.2500\n",
      "Epoch 1075/3000\n",
      "700/700 [==============================] - 0s 85us/step - loss: 1.3787 - acc: 0.4529 - val_loss: 2.2174 - val_acc: 0.2400\n",
      "Epoch 1076/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 1.3789 - acc: 0.4443 - val_loss: 2.2170 - val_acc: 0.2533\n",
      "Epoch 1077/3000\n",
      "700/700 [==============================] - 0s 80us/step - loss: 1.3786 - acc: 0.4457 - val_loss: 2.2210 - val_acc: 0.2367\n",
      "Epoch 1078/3000\n",
      "700/700 [==============================] - 0s 79us/step - loss: 1.3784 - acc: 0.4457 - val_loss: 2.2261 - val_acc: 0.2433\n",
      "Epoch 1079/3000\n",
      "700/700 [==============================] - 0s 79us/step - loss: 1.3779 - acc: 0.4443 - val_loss: 2.2231 - val_acc: 0.2400\n",
      "Epoch 1080/3000\n",
      "700/700 [==============================] - 0s 79us/step - loss: 1.3781 - acc: 0.4414 - val_loss: 2.2206 - val_acc: 0.2533\n",
      "Epoch 1081/3000\n",
      "700/700 [==============================] - 0s 80us/step - loss: 1.3782 - acc: 0.4457 - val_loss: 2.2212 - val_acc: 0.2400\n",
      "Epoch 1082/3000\n",
      "700/700 [==============================] - 0s 79us/step - loss: 1.3770 - acc: 0.4500 - val_loss: 2.2325 - val_acc: 0.2533\n",
      "Epoch 1083/3000\n",
      "700/700 [==============================] - 0s 84us/step - loss: 1.3784 - acc: 0.4429 - val_loss: 2.2295 - val_acc: 0.2400\n",
      "Epoch 1084/3000\n",
      "700/700 [==============================] - 0s 80us/step - loss: 1.3783 - acc: 0.4457 - val_loss: 2.2367 - val_acc: 0.2433\n",
      "Epoch 1085/3000\n",
      "700/700 [==============================] - 0s 78us/step - loss: 1.3772 - acc: 0.4414 - val_loss: 2.2271 - val_acc: 0.2533\n",
      "Epoch 1086/3000\n",
      "700/700 [==============================] - 0s 92us/step - loss: 1.3778 - acc: 0.4500 - val_loss: 2.2372 - val_acc: 0.2400\n",
      "Epoch 1087/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.3768 - acc: 0.4529 - val_loss: 2.2247 - val_acc: 0.2333\n",
      "Epoch 1088/3000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.3769 - acc: 0.4543 - val_loss: 2.2206 - val_acc: 0.2500\n",
      "Epoch 1089/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.3780 - acc: 0.4471 - val_loss: 2.2241 - val_acc: 0.2500\n",
      "Epoch 1090/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.3766 - acc: 0.4486 - val_loss: 2.2329 - val_acc: 0.2533\n",
      "Epoch 1091/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.3766 - acc: 0.4486 - val_loss: 2.2213 - val_acc: 0.2400\n",
      "Epoch 1092/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.3767 - acc: 0.4557 - val_loss: 2.2318 - val_acc: 0.2500\n",
      "Epoch 1093/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.3769 - acc: 0.4457 - val_loss: 2.2303 - val_acc: 0.2467\n",
      "Epoch 1094/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.3752 - acc: 0.4571 - val_loss: 2.2192 - val_acc: 0.2467\n",
      "Epoch 1095/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.3778 - acc: 0.4443 - val_loss: 2.2288 - val_acc: 0.2533\n",
      "Epoch 1096/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.3760 - acc: 0.4457 - val_loss: 2.2282 - val_acc: 0.2367\n",
      "Epoch 1097/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.3763 - acc: 0.4557 - val_loss: 2.2281 - val_acc: 0.2533\n",
      "Epoch 1098/3000\n",
      "700/700 [==============================] - 0s 98us/step - loss: 1.3766 - acc: 0.4414 - val_loss: 2.2403 - val_acc: 0.2467\n",
      "Epoch 1099/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.3767 - acc: 0.4486 - val_loss: 2.2500 - val_acc: 0.2467\n",
      "Epoch 1100/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.3763 - acc: 0.4471 - val_loss: 2.2328 - val_acc: 0.2467\n",
      "Epoch 1101/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.3757 - acc: 0.4486 - val_loss: 2.2314 - val_acc: 0.2500\n",
      "Epoch 1102/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3748 - acc: 0.4414 - val_loss: 2.2346 - val_acc: 0.2367\n",
      "Epoch 1103/3000\n",
      "700/700 [==============================] - 0s 98us/step - loss: 1.3754 - acc: 0.4429 - val_loss: 2.2391 - val_acc: 0.2533\n",
      "Epoch 1104/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.3759 - acc: 0.4414 - val_loss: 2.2228 - val_acc: 0.2533\n",
      "Epoch 1105/3000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.3752 - acc: 0.4500 - val_loss: 2.2246 - val_acc: 0.2533\n",
      "Epoch 1106/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.3747 - acc: 0.4486 - val_loss: 2.2383 - val_acc: 0.2533\n",
      "Epoch 1107/3000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.3760 - acc: 0.4471 - val_loss: 2.2126 - val_acc: 0.2500\n",
      "Epoch 1108/3000\n",
      "700/700 [==============================] - 0s 98us/step - loss: 1.3755 - acc: 0.4500 - val_loss: 2.2382 - val_acc: 0.2467\n",
      "Epoch 1109/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.3758 - acc: 0.4486 - val_loss: 2.2459 - val_acc: 0.2467\n",
      "Epoch 1110/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.3745 - acc: 0.4429 - val_loss: 2.2134 - val_acc: 0.2433\n",
      "Epoch 1111/3000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.3742 - acc: 0.4557 - val_loss: 2.2365 - val_acc: 0.2500\n",
      "Epoch 1112/3000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.3742 - acc: 0.4471 - val_loss: 2.2383 - val_acc: 0.2400\n",
      "Epoch 1113/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.3738 - acc: 0.4429 - val_loss: 2.2471 - val_acc: 0.2500\n",
      "Epoch 1114/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.3745 - acc: 0.4500 - val_loss: 2.2335 - val_acc: 0.2533\n",
      "Epoch 1115/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.3755 - acc: 0.4457 - val_loss: 2.2281 - val_acc: 0.2533\n",
      "Epoch 1116/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.3736 - acc: 0.4486 - val_loss: 2.2393 - val_acc: 0.2500\n",
      "Epoch 1117/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3736 - acc: 0.4500 - val_loss: 2.2373 - val_acc: 0.2467\n",
      "Epoch 1118/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.3740 - acc: 0.4529 - val_loss: 2.2365 - val_acc: 0.2467\n",
      "Epoch 1119/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.3731 - acc: 0.4400 - val_loss: 2.2320 - val_acc: 0.2333\n",
      "Epoch 1120/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.3733 - acc: 0.4543 - val_loss: 2.2523 - val_acc: 0.2500\n",
      "Epoch 1121/3000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.3743 - acc: 0.4471 - val_loss: 2.2250 - val_acc: 0.2433\n",
      "Epoch 1122/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3737 - acc: 0.4500 - val_loss: 2.2400 - val_acc: 0.2533\n",
      "Epoch 1123/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.3729 - acc: 0.4514 - val_loss: 2.2367 - val_acc: 0.2467\n",
      "Epoch 1124/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.3740 - acc: 0.4500 - val_loss: 2.2329 - val_acc: 0.2400\n",
      "Epoch 1125/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.3736 - acc: 0.4486 - val_loss: 2.2294 - val_acc: 0.2500\n",
      "Epoch 1126/3000\n",
      "700/700 [==============================] - 0s 98us/step - loss: 1.3723 - acc: 0.4529 - val_loss: 2.2359 - val_acc: 0.2467\n",
      "Epoch 1127/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 101us/step - loss: 1.3730 - acc: 0.4586 - val_loss: 2.2396 - val_acc: 0.2533\n",
      "Epoch 1128/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.3737 - acc: 0.4457 - val_loss: 2.2595 - val_acc: 0.2500\n",
      "Epoch 1129/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.3721 - acc: 0.4457 - val_loss: 2.2432 - val_acc: 0.2333\n",
      "Epoch 1130/3000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.3726 - acc: 0.4429 - val_loss: 2.2388 - val_acc: 0.2433\n",
      "Epoch 1131/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.3711 - acc: 0.4443 - val_loss: 2.2511 - val_acc: 0.2533\n",
      "Epoch 1132/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.3738 - acc: 0.4486 - val_loss: 2.2412 - val_acc: 0.2467\n",
      "Epoch 1133/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.3715 - acc: 0.4529 - val_loss: 2.2491 - val_acc: 0.2467\n",
      "Epoch 1134/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.3717 - acc: 0.4457 - val_loss: 2.2414 - val_acc: 0.2333\n",
      "Epoch 1135/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.3727 - acc: 0.4514 - val_loss: 2.2390 - val_acc: 0.2500\n",
      "Epoch 1136/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.3717 - acc: 0.4486 - val_loss: 2.2340 - val_acc: 0.2467\n",
      "Epoch 1137/3000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 1.3726 - acc: 0.4500 - val_loss: 2.2374 - val_acc: 0.2500\n",
      "Epoch 1138/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.3717 - acc: 0.4514 - val_loss: 2.2386 - val_acc: 0.2433\n",
      "Epoch 1139/3000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.3720 - acc: 0.4514 - val_loss: 2.2317 - val_acc: 0.2500\n",
      "Epoch 1140/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.3702 - acc: 0.4557 - val_loss: 2.2341 - val_acc: 0.2333\n",
      "Epoch 1141/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.3714 - acc: 0.4514 - val_loss: 2.2570 - val_acc: 0.2500\n",
      "Epoch 1142/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.3717 - acc: 0.4571 - val_loss: 2.2533 - val_acc: 0.2500\n",
      "Epoch 1143/3000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.3707 - acc: 0.4443 - val_loss: 2.2487 - val_acc: 0.2433\n",
      "Epoch 1144/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.3687 - acc: 0.4457 - val_loss: 2.2591 - val_acc: 0.2367\n",
      "Epoch 1145/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.3717 - acc: 0.4543 - val_loss: 2.2454 - val_acc: 0.2467\n",
      "Epoch 1146/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.3706 - acc: 0.4529 - val_loss: 2.2483 - val_acc: 0.2333\n",
      "Epoch 1147/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.3702 - acc: 0.4557 - val_loss: 2.2359 - val_acc: 0.2333\n",
      "Epoch 1148/3000\n",
      "700/700 [==============================] - 0s 86us/step - loss: 1.3714 - acc: 0.4543 - val_loss: 2.2555 - val_acc: 0.2467\n",
      "Epoch 1149/3000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.3711 - acc: 0.4443 - val_loss: 2.2480 - val_acc: 0.2367\n",
      "Epoch 1150/3000\n",
      "700/700 [==============================] - 0s 80us/step - loss: 1.3714 - acc: 0.4500 - val_loss: 2.2261 - val_acc: 0.2400\n",
      "Epoch 1151/3000\n",
      "700/700 [==============================] - 0s 83us/step - loss: 1.3712 - acc: 0.4514 - val_loss: 2.2324 - val_acc: 0.2433\n",
      "Epoch 1152/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.3698 - acc: 0.4543 - val_loss: 2.2410 - val_acc: 0.2467\n",
      "Epoch 1153/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.3712 - acc: 0.4471 - val_loss: 2.2486 - val_acc: 0.2467\n",
      "Epoch 1154/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.3698 - acc: 0.4514 - val_loss: 2.2220 - val_acc: 0.2367\n",
      "Epoch 1155/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.3696 - acc: 0.4514 - val_loss: 2.2447 - val_acc: 0.2433\n",
      "Epoch 1156/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.3707 - acc: 0.4429 - val_loss: 2.2371 - val_acc: 0.2300\n",
      "Epoch 1157/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.3707 - acc: 0.4514 - val_loss: 2.2438 - val_acc: 0.2433\n",
      "Epoch 1158/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.3695 - acc: 0.4543 - val_loss: 2.2634 - val_acc: 0.2533\n",
      "Epoch 1159/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.3698 - acc: 0.4443 - val_loss: 2.2454 - val_acc: 0.2467\n",
      "Epoch 1160/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.3708 - acc: 0.4543 - val_loss: 2.2526 - val_acc: 0.2333\n",
      "Epoch 1161/3000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.3694 - acc: 0.4557 - val_loss: 2.2496 - val_acc: 0.2500\n",
      "Epoch 1162/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.3693 - acc: 0.4586 - val_loss: 2.2522 - val_acc: 0.2467\n",
      "Epoch 1163/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.3692 - acc: 0.4514 - val_loss: 2.2501 - val_acc: 0.2500\n",
      "Epoch 1164/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.3688 - acc: 0.4557 - val_loss: 2.2500 - val_acc: 0.2333\n",
      "Epoch 1165/3000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.3701 - acc: 0.4529 - val_loss: 2.2261 - val_acc: 0.2367\n",
      "Epoch 1166/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.3689 - acc: 0.4543 - val_loss: 2.2374 - val_acc: 0.2433\n",
      "Epoch 1167/3000\n",
      "700/700 [==============================] - 0s 88us/step - loss: 1.3687 - acc: 0.4557 - val_loss: 2.2464 - val_acc: 0.2433\n",
      "Epoch 1168/3000\n",
      "700/700 [==============================] - 0s 85us/step - loss: 1.3689 - acc: 0.4500 - val_loss: 2.2422 - val_acc: 0.2333\n",
      "Epoch 1169/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.3682 - acc: 0.4514 - val_loss: 2.2499 - val_acc: 0.2467\n",
      "Epoch 1170/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.3681 - acc: 0.4529 - val_loss: 2.2423 - val_acc: 0.2467\n",
      "Epoch 1171/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.3676 - acc: 0.4514 - val_loss: 2.2402 - val_acc: 0.2433\n",
      "Epoch 1172/3000\n",
      "700/700 [==============================] - 0s 135us/step - loss: 1.3681 - acc: 0.4543 - val_loss: 2.2577 - val_acc: 0.2433\n",
      "Epoch 1173/3000\n",
      "700/700 [==============================] - 0s 118us/step - loss: 1.3678 - acc: 0.4514 - val_loss: 2.2482 - val_acc: 0.2300\n",
      "Epoch 1174/3000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.3687 - acc: 0.4500 - val_loss: 2.2422 - val_acc: 0.2400\n",
      "Epoch 1175/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.3672 - acc: 0.4543 - val_loss: 2.2465 - val_acc: 0.2400\n",
      "Epoch 1176/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.3680 - acc: 0.4543 - val_loss: 2.2522 - val_acc: 0.2433\n",
      "Epoch 1177/3000\n",
      "700/700 [==============================] - 0s 116us/step - loss: 1.3681 - acc: 0.4529 - val_loss: 2.2520 - val_acc: 0.2433\n",
      "Epoch 1178/3000\n",
      "700/700 [==============================] - 0s 108us/step - loss: 1.3674 - acc: 0.4457 - val_loss: 2.2514 - val_acc: 0.2267\n",
      "Epoch 1179/3000\n",
      "700/700 [==============================] - 0s 98us/step - loss: 1.3677 - acc: 0.4571 - val_loss: 2.2514 - val_acc: 0.2300\n",
      "Epoch 1180/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.3679 - acc: 0.4500 - val_loss: 2.2564 - val_acc: 0.2400\n",
      "Epoch 1181/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.3670 - acc: 0.4586 - val_loss: 2.2635 - val_acc: 0.2500\n",
      "Epoch 1182/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.3680 - acc: 0.4543 - val_loss: 2.2468 - val_acc: 0.2400\n",
      "Epoch 1183/3000\n",
      "700/700 [==============================] - 0s 81us/step - loss: 1.3674 - acc: 0.4514 - val_loss: 2.2484 - val_acc: 0.2433\n",
      "Epoch 1184/3000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 1.3661 - acc: 0.4557 - val_loss: 2.2426 - val_acc: 0.2467\n",
      "Epoch 1185/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.3673 - acc: 0.4557 - val_loss: 2.2458 - val_acc: 0.2400\n",
      "Epoch 1186/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 102us/step - loss: 1.3671 - acc: 0.4500 - val_loss: 2.2618 - val_acc: 0.2467\n",
      "Epoch 1187/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.3666 - acc: 0.4500 - val_loss: 2.2537 - val_acc: 0.2333\n",
      "Epoch 1188/3000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.3666 - acc: 0.4543 - val_loss: 2.2618 - val_acc: 0.2467\n",
      "Epoch 1189/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.3656 - acc: 0.4600 - val_loss: 2.2532 - val_acc: 0.2467\n",
      "Epoch 1190/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.3664 - acc: 0.4514 - val_loss: 2.2673 - val_acc: 0.2533\n",
      "Epoch 1191/3000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.3667 - acc: 0.4500 - val_loss: 2.2576 - val_acc: 0.2333\n",
      "Epoch 1192/3000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.3666 - acc: 0.4571 - val_loss: 2.2416 - val_acc: 0.2433\n",
      "Epoch 1193/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3667 - acc: 0.4557 - val_loss: 2.2561 - val_acc: 0.2433\n",
      "Epoch 1194/3000\n",
      "700/700 [==============================] - 0s 82us/step - loss: 1.3660 - acc: 0.4514 - val_loss: 2.2493 - val_acc: 0.2300\n",
      "Epoch 1195/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.3667 - acc: 0.4543 - val_loss: 2.2426 - val_acc: 0.2300\n",
      "Epoch 1196/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.3656 - acc: 0.4614 - val_loss: 2.2566 - val_acc: 0.2433\n",
      "Epoch 1197/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 1.3657 - acc: 0.4529 - val_loss: 2.2526 - val_acc: 0.2400\n",
      "Epoch 1198/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.3653 - acc: 0.4557 - val_loss: 2.2529 - val_acc: 0.2500\n",
      "Epoch 1199/3000\n",
      "700/700 [==============================] - 0s 79us/step - loss: 1.3653 - acc: 0.4514 - val_loss: 2.2505 - val_acc: 0.2367\n",
      "Epoch 1200/3000\n",
      "700/700 [==============================] - 0s 81us/step - loss: 1.3662 - acc: 0.4514 - val_loss: 2.2561 - val_acc: 0.2400\n",
      "Epoch 1201/3000\n",
      "700/700 [==============================] - 0s 83us/step - loss: 1.3651 - acc: 0.4586 - val_loss: 2.2577 - val_acc: 0.2467\n",
      "Epoch 1202/3000\n",
      "700/700 [==============================] - 0s 85us/step - loss: 1.3661 - acc: 0.4514 - val_loss: 2.2640 - val_acc: 0.2433\n",
      "Epoch 1203/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 1.3651 - acc: 0.4586 - val_loss: 2.2389 - val_acc: 0.2433\n",
      "Epoch 1204/3000\n",
      "700/700 [==============================] - 0s 79us/step - loss: 1.3653 - acc: 0.4629 - val_loss: 2.2416 - val_acc: 0.2467\n",
      "Epoch 1205/3000\n",
      "700/700 [==============================] - 0s 85us/step - loss: 1.3640 - acc: 0.4629 - val_loss: 2.2482 - val_acc: 0.2467\n",
      "Epoch 1206/3000\n",
      "700/700 [==============================] - 0s 79us/step - loss: 1.3650 - acc: 0.4586 - val_loss: 2.2554 - val_acc: 0.2433\n",
      "Epoch 1207/3000\n",
      "700/700 [==============================] - 0s 77us/step - loss: 1.3639 - acc: 0.4571 - val_loss: 2.2591 - val_acc: 0.2233\n",
      "Epoch 1208/3000\n",
      "700/700 [==============================] - 0s 83us/step - loss: 1.3633 - acc: 0.4529 - val_loss: 2.2561 - val_acc: 0.2267\n",
      "Epoch 1209/3000\n",
      "700/700 [==============================] - 0s 76us/step - loss: 1.3630 - acc: 0.4571 - val_loss: 2.2521 - val_acc: 0.2433\n",
      "Epoch 1210/3000\n",
      "700/700 [==============================] - 0s 87us/step - loss: 1.3650 - acc: 0.4543 - val_loss: 2.2545 - val_acc: 0.2433\n",
      "Epoch 1211/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.3645 - acc: 0.4586 - val_loss: 2.2636 - val_acc: 0.2433\n",
      "Epoch 1212/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.3631 - acc: 0.4514 - val_loss: 2.2718 - val_acc: 0.2500\n",
      "Epoch 1213/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.3654 - acc: 0.4571 - val_loss: 2.2528 - val_acc: 0.2433\n",
      "Epoch 1214/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.3632 - acc: 0.4557 - val_loss: 2.2664 - val_acc: 0.2467\n",
      "Epoch 1215/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3633 - acc: 0.4529 - val_loss: 2.2588 - val_acc: 0.2467\n",
      "Epoch 1216/3000\n",
      "700/700 [==============================] - 0s 98us/step - loss: 1.3636 - acc: 0.4600 - val_loss: 2.2540 - val_acc: 0.2433\n",
      "Epoch 1217/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.3637 - acc: 0.4514 - val_loss: 2.2624 - val_acc: 0.2433\n",
      "Epoch 1218/3000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.3634 - acc: 0.4586 - val_loss: 2.2592 - val_acc: 0.2433\n",
      "Epoch 1219/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.3631 - acc: 0.4543 - val_loss: 2.2624 - val_acc: 0.2433\n",
      "Epoch 1220/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 1.3641 - acc: 0.4557 - val_loss: 2.2456 - val_acc: 0.2433\n",
      "Epoch 1221/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.3632 - acc: 0.4614 - val_loss: 2.2632 - val_acc: 0.2300\n",
      "Epoch 1222/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.3633 - acc: 0.4600 - val_loss: 2.2695 - val_acc: 0.2433\n",
      "Epoch 1223/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3632 - acc: 0.4571 - val_loss: 2.2611 - val_acc: 0.2467\n",
      "Epoch 1224/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.3625 - acc: 0.4571 - val_loss: 2.2677 - val_acc: 0.2467\n",
      "Epoch 1225/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.3621 - acc: 0.4529 - val_loss: 2.2626 - val_acc: 0.2333\n",
      "Epoch 1226/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.3635 - acc: 0.4629 - val_loss: 2.2581 - val_acc: 0.2467\n",
      "Epoch 1227/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.3609 - acc: 0.4586 - val_loss: 2.2657 - val_acc: 0.2500\n",
      "Epoch 1228/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.3627 - acc: 0.4614 - val_loss: 2.2669 - val_acc: 0.2433\n",
      "Epoch 1229/3000\n",
      "700/700 [==============================] - 0s 83us/step - loss: 1.3628 - acc: 0.4571 - val_loss: 2.2593 - val_acc: 0.2433\n",
      "Epoch 1230/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.3623 - acc: 0.4571 - val_loss: 2.2553 - val_acc: 0.2467\n",
      "Epoch 1231/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.3629 - acc: 0.4557 - val_loss: 2.2417 - val_acc: 0.2333\n",
      "Epoch 1232/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.3628 - acc: 0.4543 - val_loss: 2.2696 - val_acc: 0.2500\n",
      "Epoch 1233/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.3629 - acc: 0.4614 - val_loss: 2.2508 - val_acc: 0.2433\n",
      "Epoch 1234/3000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.3617 - acc: 0.4686 - val_loss: 2.2470 - val_acc: 0.2467\n",
      "Epoch 1235/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3618 - acc: 0.4557 - val_loss: 2.2512 - val_acc: 0.2400\n",
      "Epoch 1236/3000\n",
      "700/700 [==============================] - 0s 108us/step - loss: 1.3621 - acc: 0.4571 - val_loss: 2.2513 - val_acc: 0.2400\n",
      "Epoch 1237/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.3621 - acc: 0.4486 - val_loss: 2.2367 - val_acc: 0.2500\n",
      "Epoch 1238/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.3610 - acc: 0.4586 - val_loss: 2.2668 - val_acc: 0.2500\n",
      "Epoch 1239/3000\n",
      "700/700 [==============================] - 0s 92us/step - loss: 1.3618 - acc: 0.4500 - val_loss: 2.2611 - val_acc: 0.2500\n",
      "Epoch 1240/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.3615 - acc: 0.4571 - val_loss: 2.2527 - val_acc: 0.2467\n",
      "Epoch 1241/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.3615 - acc: 0.4571 - val_loss: 2.2614 - val_acc: 0.2400\n",
      "Epoch 1242/3000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.3609 - acc: 0.4514 - val_loss: 2.2584 - val_acc: 0.2433\n",
      "Epoch 1243/3000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.3612 - acc: 0.4614 - val_loss: 2.2728 - val_acc: 0.2467\n",
      "Epoch 1244/3000\n",
      "700/700 [==============================] - 0s 119us/step - loss: 1.3612 - acc: 0.4543 - val_loss: 2.2481 - val_acc: 0.2500\n",
      "Epoch 1245/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 134us/step - loss: 1.3608 - acc: 0.4643 - val_loss: 2.2558 - val_acc: 0.2433\n",
      "Epoch 1246/3000\n",
      "700/700 [==============================] - 0s 92us/step - loss: 1.3601 - acc: 0.4571 - val_loss: 2.2741 - val_acc: 0.2433\n",
      "Epoch 1247/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.3602 - acc: 0.4629 - val_loss: 2.2648 - val_acc: 0.2433\n",
      "Epoch 1248/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.3608 - acc: 0.4557 - val_loss: 2.2674 - val_acc: 0.2433\n",
      "Epoch 1249/3000\n",
      "700/700 [==============================] - 0s 98us/step - loss: 1.3612 - acc: 0.4557 - val_loss: 2.2606 - val_acc: 0.2400\n",
      "Epoch 1250/3000\n",
      "700/700 [==============================] - 0s 98us/step - loss: 1.3597 - acc: 0.4571 - val_loss: 2.2876 - val_acc: 0.2300\n",
      "Epoch 1251/3000\n",
      "700/700 [==============================] - 0s 98us/step - loss: 1.3608 - acc: 0.4614 - val_loss: 2.2648 - val_acc: 0.2400\n",
      "Epoch 1252/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.3598 - acc: 0.4629 - val_loss: 2.2728 - val_acc: 0.2400\n",
      "Epoch 1253/3000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.3609 - acc: 0.4543 - val_loss: 2.2612 - val_acc: 0.2400\n",
      "Epoch 1254/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.3600 - acc: 0.4600 - val_loss: 2.2555 - val_acc: 0.2433\n",
      "Epoch 1255/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.3603 - acc: 0.4571 - val_loss: 2.2583 - val_acc: 0.2433\n",
      "Epoch 1256/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.3591 - acc: 0.4586 - val_loss: 2.2739 - val_acc: 0.2400\n",
      "Epoch 1257/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.3600 - acc: 0.4586 - val_loss: 2.2782 - val_acc: 0.2467\n",
      "Epoch 1258/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.3598 - acc: 0.4686 - val_loss: 2.2635 - val_acc: 0.2467\n",
      "Epoch 1259/3000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.3597 - acc: 0.4586 - val_loss: 2.2529 - val_acc: 0.2433\n",
      "Epoch 1260/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.3590 - acc: 0.4643 - val_loss: 2.2724 - val_acc: 0.2467\n",
      "Epoch 1261/3000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.3600 - acc: 0.4629 - val_loss: 2.2619 - val_acc: 0.2433\n",
      "Epoch 1262/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.3597 - acc: 0.4543 - val_loss: 2.2671 - val_acc: 0.2400\n",
      "Epoch 1263/3000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.3591 - acc: 0.4686 - val_loss: 2.2645 - val_acc: 0.2400\n",
      "Epoch 1264/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.3593 - acc: 0.4600 - val_loss: 2.2587 - val_acc: 0.2333\n",
      "Epoch 1265/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.3593 - acc: 0.4643 - val_loss: 2.2639 - val_acc: 0.2400\n",
      "Epoch 1266/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.3591 - acc: 0.4571 - val_loss: 2.2524 - val_acc: 0.2467\n",
      "Epoch 1267/3000\n",
      "700/700 [==============================] - 0s 108us/step - loss: 1.3586 - acc: 0.4586 - val_loss: 2.2577 - val_acc: 0.2400\n",
      "Epoch 1268/3000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.3596 - acc: 0.4643 - val_loss: 2.2681 - val_acc: 0.2433\n",
      "Epoch 1269/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.3587 - acc: 0.4657 - val_loss: 2.2797 - val_acc: 0.2467\n",
      "Epoch 1270/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.3584 - acc: 0.4614 - val_loss: 2.2683 - val_acc: 0.2433\n",
      "Epoch 1271/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.3589 - acc: 0.4571 - val_loss: 2.2603 - val_acc: 0.2400\n",
      "Epoch 1272/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.3581 - acc: 0.4629 - val_loss: 2.2663 - val_acc: 0.2433\n",
      "Epoch 1273/3000\n",
      "700/700 [==============================] - 0s 108us/step - loss: 1.3583 - acc: 0.4557 - val_loss: 2.2676 - val_acc: 0.2433\n",
      "Epoch 1274/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.3584 - acc: 0.4614 - val_loss: 2.2627 - val_acc: 0.2433\n",
      "Epoch 1275/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.3576 - acc: 0.4614 - val_loss: 2.2715 - val_acc: 0.2433\n",
      "Epoch 1276/3000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 1.3588 - acc: 0.4571 - val_loss: 2.2727 - val_acc: 0.2400\n",
      "Epoch 1277/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.3580 - acc: 0.4557 - val_loss: 2.2722 - val_acc: 0.2467\n",
      "Epoch 1278/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.3576 - acc: 0.4600 - val_loss: 2.2789 - val_acc: 0.2467\n",
      "Epoch 1279/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.3578 - acc: 0.4529 - val_loss: 2.2654 - val_acc: 0.2433\n",
      "Epoch 1280/3000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.3574 - acc: 0.4614 - val_loss: 2.2768 - val_acc: 0.2433\n",
      "Epoch 1281/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.3572 - acc: 0.4514 - val_loss: 2.2552 - val_acc: 0.2433\n",
      "Epoch 1282/3000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.3576 - acc: 0.4586 - val_loss: 2.2749 - val_acc: 0.2433\n",
      "Epoch 1283/3000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.3571 - acc: 0.4643 - val_loss: 2.2908 - val_acc: 0.2500\n",
      "Epoch 1284/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.3575 - acc: 0.4629 - val_loss: 2.2884 - val_acc: 0.2533\n",
      "Epoch 1285/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.3548 - acc: 0.4571 - val_loss: 2.2605 - val_acc: 0.2333\n",
      "Epoch 1286/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.3547 - acc: 0.4600 - val_loss: 2.2798 - val_acc: 0.2500\n",
      "Epoch 1287/3000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.3573 - acc: 0.4614 - val_loss: 2.2838 - val_acc: 0.2500\n",
      "Epoch 1288/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.3566 - acc: 0.4571 - val_loss: 2.2772 - val_acc: 0.2500\n",
      "Epoch 1289/3000\n",
      "700/700 [==============================] - 0s 108us/step - loss: 1.3568 - acc: 0.4657 - val_loss: 2.2724 - val_acc: 0.2467\n",
      "Epoch 1290/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.3569 - acc: 0.4643 - val_loss: 2.2707 - val_acc: 0.2433\n",
      "Epoch 1291/3000\n",
      "700/700 [==============================] - 0s 92us/step - loss: 1.3569 - acc: 0.4643 - val_loss: 2.2821 - val_acc: 0.2400\n",
      "Epoch 1292/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3565 - acc: 0.4629 - val_loss: 2.2863 - val_acc: 0.2533\n",
      "Epoch 1293/3000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.3562 - acc: 0.4600 - val_loss: 2.2808 - val_acc: 0.2400\n",
      "Epoch 1294/3000\n",
      "700/700 [==============================] - 0s 88us/step - loss: 1.3570 - acc: 0.4586 - val_loss: 2.2800 - val_acc: 0.2400\n",
      "Epoch 1295/3000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.3557 - acc: 0.4657 - val_loss: 2.2678 - val_acc: 0.2433\n",
      "Epoch 1296/3000\n",
      "700/700 [==============================] - 0s 98us/step - loss: 1.3567 - acc: 0.4671 - val_loss: 2.2758 - val_acc: 0.2433\n",
      "Epoch 1297/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.3560 - acc: 0.4700 - val_loss: 2.2668 - val_acc: 0.2433\n",
      "Epoch 1298/3000\n",
      "700/700 [==============================] - 0s 108us/step - loss: 1.3564 - acc: 0.4643 - val_loss: 2.2695 - val_acc: 0.2400\n",
      "Epoch 1299/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.3550 - acc: 0.4671 - val_loss: 2.2845 - val_acc: 0.2400\n",
      "Epoch 1300/3000\n",
      "700/700 [==============================] - 0s 98us/step - loss: 1.3547 - acc: 0.4671 - val_loss: 2.2654 - val_acc: 0.2300\n",
      "Epoch 1301/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.3543 - acc: 0.4529 - val_loss: 2.2603 - val_acc: 0.2433\n",
      "Epoch 1302/3000\n",
      "700/700 [==============================] - 0s 117us/step - loss: 1.3559 - acc: 0.4671 - val_loss: 2.2766 - val_acc: 0.2467\n",
      "Epoch 1303/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.3559 - acc: 0.4643 - val_loss: 2.2770 - val_acc: 0.2433\n",
      "Epoch 1304/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 98us/step - loss: 1.3555 - acc: 0.4743 - val_loss: 2.2820 - val_acc: 0.2433\n",
      "Epoch 1305/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.3548 - acc: 0.4643 - val_loss: 2.2851 - val_acc: 0.2467\n",
      "Epoch 1306/3000\n",
      "700/700 [==============================] - 0s 98us/step - loss: 1.3549 - acc: 0.4600 - val_loss: 2.2742 - val_acc: 0.2433\n",
      "Epoch 1307/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.3556 - acc: 0.4614 - val_loss: 2.2713 - val_acc: 0.2433\n",
      "Epoch 1308/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.3540 - acc: 0.4614 - val_loss: 2.2640 - val_acc: 0.2467\n",
      "Epoch 1309/3000\n",
      "700/700 [==============================] - 0s 133us/step - loss: 1.3539 - acc: 0.4643 - val_loss: 2.2772 - val_acc: 0.2300\n",
      "Epoch 1310/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.3550 - acc: 0.4629 - val_loss: 2.2827 - val_acc: 0.2467\n",
      "Epoch 1311/3000\n",
      "700/700 [==============================] - 0s 98us/step - loss: 1.3555 - acc: 0.4671 - val_loss: 2.2783 - val_acc: 0.2433\n",
      "Epoch 1312/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.3547 - acc: 0.4586 - val_loss: 2.2747 - val_acc: 0.2467\n",
      "Epoch 1313/3000\n",
      "700/700 [==============================] - 0s 98us/step - loss: 1.3544 - acc: 0.4600 - val_loss: 2.2676 - val_acc: 0.2400\n",
      "Epoch 1314/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.3540 - acc: 0.4557 - val_loss: 2.2840 - val_acc: 0.2400\n",
      "Epoch 1315/3000\n",
      "700/700 [==============================] - 0s 85us/step - loss: 1.3535 - acc: 0.4671 - val_loss: 2.2684 - val_acc: 0.2433\n",
      "Epoch 1316/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.3545 - acc: 0.4643 - val_loss: 2.2886 - val_acc: 0.2500\n",
      "Epoch 1317/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.3537 - acc: 0.4614 - val_loss: 2.2716 - val_acc: 0.2300\n",
      "Epoch 1318/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 1.3546 - acc: 0.4643 - val_loss: 2.2660 - val_acc: 0.2433\n",
      "Epoch 1319/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.3545 - acc: 0.4700 - val_loss: 2.2864 - val_acc: 0.2533\n",
      "Epoch 1320/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.3540 - acc: 0.4600 - val_loss: 2.2712 - val_acc: 0.2433\n",
      "Epoch 1321/3000\n",
      "700/700 [==============================] - 0s 108us/step - loss: 1.3534 - acc: 0.4686 - val_loss: 2.2708 - val_acc: 0.2433\n",
      "Epoch 1322/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.3535 - acc: 0.4657 - val_loss: 2.2711 - val_acc: 0.2400\n",
      "Epoch 1323/3000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.3535 - acc: 0.4614 - val_loss: 2.3079 - val_acc: 0.2467\n",
      "Epoch 1324/3000\n",
      "700/700 [==============================] - 0s 125us/step - loss: 1.3538 - acc: 0.4643 - val_loss: 2.2775 - val_acc: 0.2433\n",
      "Epoch 1325/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.3524 - acc: 0.4643 - val_loss: 2.2927 - val_acc: 0.2367\n",
      "Epoch 1326/3000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.3540 - acc: 0.4643 - val_loss: 2.2791 - val_acc: 0.2400\n",
      "Epoch 1327/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.3532 - acc: 0.4671 - val_loss: 2.2720 - val_acc: 0.2400\n",
      "Epoch 1328/3000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 1.3527 - acc: 0.4643 - val_loss: 2.3007 - val_acc: 0.2467\n",
      "Epoch 1329/3000\n",
      "700/700 [==============================] - 0s 108us/step - loss: 1.3532 - acc: 0.4643 - val_loss: 2.2788 - val_acc: 0.2500\n",
      "Epoch 1330/3000\n",
      "700/700 [==============================] - 0s 152us/step - loss: 1.3533 - acc: 0.4643 - val_loss: 2.2966 - val_acc: 0.2400\n",
      "Epoch 1331/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.3532 - acc: 0.4657 - val_loss: 2.2884 - val_acc: 0.2533\n",
      "Epoch 1332/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.3528 - acc: 0.4671 - val_loss: 2.2845 - val_acc: 0.2433\n",
      "Epoch 1333/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.3521 - acc: 0.4671 - val_loss: 2.2729 - val_acc: 0.2433\n",
      "Epoch 1334/3000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.3521 - acc: 0.4671 - val_loss: 2.2992 - val_acc: 0.2500\n",
      "Epoch 1335/3000\n",
      "700/700 [==============================] - 0s 98us/step - loss: 1.3530 - acc: 0.4586 - val_loss: 2.2702 - val_acc: 0.2400\n",
      "Epoch 1336/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.3530 - acc: 0.4686 - val_loss: 2.2901 - val_acc: 0.2433\n",
      "Epoch 1337/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3525 - acc: 0.4614 - val_loss: 2.2790 - val_acc: 0.2433\n",
      "Epoch 1338/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.3522 - acc: 0.4614 - val_loss: 2.2791 - val_acc: 0.2400\n",
      "Epoch 1339/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.3519 - acc: 0.4671 - val_loss: 2.3117 - val_acc: 0.2467\n",
      "Epoch 1340/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.3527 - acc: 0.4643 - val_loss: 2.2760 - val_acc: 0.2433\n",
      "Epoch 1341/3000\n",
      "700/700 [==============================] - 0s 98us/step - loss: 1.3523 - acc: 0.4700 - val_loss: 2.2898 - val_acc: 0.2467\n",
      "Epoch 1342/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3523 - acc: 0.4714 - val_loss: 2.2825 - val_acc: 0.2433\n",
      "Epoch 1343/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.3514 - acc: 0.4671 - val_loss: 2.2861 - val_acc: 0.2467\n",
      "Epoch 1344/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.3516 - acc: 0.4629 - val_loss: 2.2949 - val_acc: 0.2500\n",
      "Epoch 1345/3000\n",
      "700/700 [==============================] - 0s 81us/step - loss: 1.3512 - acc: 0.4714 - val_loss: 2.3033 - val_acc: 0.2500\n",
      "Epoch 1346/3000\n",
      "700/700 [==============================] - 0s 80us/step - loss: 1.3514 - acc: 0.4614 - val_loss: 2.2694 - val_acc: 0.2400\n",
      "Epoch 1347/3000\n",
      "700/700 [==============================] - 0s 122us/step - loss: 1.3521 - acc: 0.4700 - val_loss: 2.2893 - val_acc: 0.2467\n",
      "Epoch 1348/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.3505 - acc: 0.4657 - val_loss: 2.2835 - val_acc: 0.2433\n",
      "Epoch 1349/3000\n",
      "700/700 [==============================] - 0s 115us/step - loss: 1.3509 - acc: 0.4629 - val_loss: 2.2919 - val_acc: 0.2467\n",
      "Epoch 1350/3000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.3514 - acc: 0.4643 - val_loss: 2.2931 - val_acc: 0.2433\n",
      "Epoch 1351/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3512 - acc: 0.4686 - val_loss: 2.2938 - val_acc: 0.2500\n",
      "Epoch 1352/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.3514 - acc: 0.4671 - val_loss: 2.2751 - val_acc: 0.2433\n",
      "Epoch 1353/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.3507 - acc: 0.4700 - val_loss: 2.2915 - val_acc: 0.2433\n",
      "Epoch 1354/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.3513 - acc: 0.4643 - val_loss: 2.2833 - val_acc: 0.2400\n",
      "Epoch 1355/3000\n",
      "700/700 [==============================] - 0s 84us/step - loss: 1.3499 - acc: 0.4700 - val_loss: 2.2895 - val_acc: 0.2433\n",
      "Epoch 1356/3000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.3512 - acc: 0.4643 - val_loss: 2.2900 - val_acc: 0.2400\n",
      "Epoch 1357/3000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.3514 - acc: 0.4714 - val_loss: 2.2970 - val_acc: 0.2433\n",
      "Epoch 1358/3000\n",
      "700/700 [==============================] - 0s 88us/step - loss: 1.3505 - acc: 0.4614 - val_loss: 2.2822 - val_acc: 0.2433\n",
      "Epoch 1359/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.3498 - acc: 0.4686 - val_loss: 2.2918 - val_acc: 0.2400\n",
      "Epoch 1360/3000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.3506 - acc: 0.4657 - val_loss: 2.2892 - val_acc: 0.2467\n",
      "Epoch 1361/3000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.3508 - acc: 0.4629 - val_loss: 2.2956 - val_acc: 0.2467\n",
      "Epoch 1362/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.3497 - acc: 0.4643 - val_loss: 2.2765 - val_acc: 0.2467\n",
      "Epoch 1363/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 103us/step - loss: 1.3506 - acc: 0.4714 - val_loss: 2.2913 - val_acc: 0.2433\n",
      "Epoch 1364/3000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 1.3498 - acc: 0.4643 - val_loss: 2.2973 - val_acc: 0.2467\n",
      "Epoch 1365/3000\n",
      "700/700 [==============================] - 0s 172us/step - loss: 1.3503 - acc: 0.4714 - val_loss: 2.2740 - val_acc: 0.2400\n",
      "Epoch 1366/3000\n",
      "700/700 [==============================] - 0s 128us/step - loss: 1.3500 - acc: 0.4657 - val_loss: 2.2875 - val_acc: 0.2467\n",
      "Epoch 1367/3000\n",
      "700/700 [==============================] - 0s 87us/step - loss: 1.3498 - acc: 0.4743 - val_loss: 2.2773 - val_acc: 0.2433\n",
      "Epoch 1368/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.3504 - acc: 0.4671 - val_loss: 2.2966 - val_acc: 0.2467\n",
      "Epoch 1369/3000\n",
      "700/700 [==============================] - 0s 119us/step - loss: 1.3505 - acc: 0.4700 - val_loss: 2.3066 - val_acc: 0.2467\n",
      "Epoch 1370/3000\n",
      "700/700 [==============================] - 0s 120us/step - loss: 1.3491 - acc: 0.4657 - val_loss: 2.3127 - val_acc: 0.2467\n",
      "Epoch 1371/3000\n",
      "700/700 [==============================] - 0s 98us/step - loss: 1.3502 - acc: 0.4686 - val_loss: 2.2951 - val_acc: 0.2400\n",
      "Epoch 1372/3000\n",
      "700/700 [==============================] - 0s 98us/step - loss: 1.3495 - acc: 0.4700 - val_loss: 2.2962 - val_acc: 0.2433\n",
      "Epoch 1373/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.3493 - acc: 0.4771 - val_loss: 2.2956 - val_acc: 0.2533\n",
      "Epoch 1374/3000\n",
      "700/700 [==============================] - 0s 118us/step - loss: 1.3495 - acc: 0.4643 - val_loss: 2.2992 - val_acc: 0.2500\n",
      "Epoch 1375/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.3494 - acc: 0.4743 - val_loss: 2.2853 - val_acc: 0.2433\n",
      "Epoch 1376/3000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.3489 - acc: 0.4714 - val_loss: 2.2856 - val_acc: 0.2500\n",
      "Epoch 1377/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.3495 - acc: 0.4657 - val_loss: 2.2741 - val_acc: 0.2433\n",
      "Epoch 1378/3000\n",
      "700/700 [==============================] - 0s 112us/step - loss: 1.3489 - acc: 0.4700 - val_loss: 2.3018 - val_acc: 0.2533\n",
      "Epoch 1379/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.3486 - acc: 0.4614 - val_loss: 2.3061 - val_acc: 0.2467\n",
      "Epoch 1380/3000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 1.3478 - acc: 0.4671 - val_loss: 2.3032 - val_acc: 0.2467\n",
      "Epoch 1381/3000\n",
      "700/700 [==============================] - 0s 116us/step - loss: 1.3488 - acc: 0.4686 - val_loss: 2.3012 - val_acc: 0.2433\n",
      "Epoch 1382/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.3472 - acc: 0.4714 - val_loss: 2.3042 - val_acc: 0.2467\n",
      "Epoch 1383/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.3483 - acc: 0.4657 - val_loss: 2.3004 - val_acc: 0.2433\n",
      "Epoch 1384/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.3485 - acc: 0.4700 - val_loss: 2.2911 - val_acc: 0.2433\n",
      "Epoch 1385/3000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 1.3476 - acc: 0.4671 - val_loss: 2.3008 - val_acc: 0.2467\n",
      "Epoch 1386/3000\n",
      "700/700 [==============================] - 0s 112us/step - loss: 1.3479 - acc: 0.4629 - val_loss: 2.2995 - val_acc: 0.2333\n",
      "Epoch 1387/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.3479 - acc: 0.4671 - val_loss: 2.3052 - val_acc: 0.2300\n",
      "Epoch 1388/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.3479 - acc: 0.4657 - val_loss: 2.3037 - val_acc: 0.2400\n",
      "Epoch 1389/3000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 1.3470 - acc: 0.4671 - val_loss: 2.3055 - val_acc: 0.2467\n",
      "Epoch 1390/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.3485 - acc: 0.4657 - val_loss: 2.2828 - val_acc: 0.2400\n",
      "Epoch 1391/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3483 - acc: 0.4686 - val_loss: 2.3009 - val_acc: 0.2467\n",
      "Epoch 1392/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 1.3485 - acc: 0.4657 - val_loss: 2.3069 - val_acc: 0.2400\n",
      "Epoch 1393/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.3475 - acc: 0.4714 - val_loss: 2.3097 - val_acc: 0.2433\n",
      "Epoch 1394/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.3463 - acc: 0.4614 - val_loss: 2.3005 - val_acc: 0.2267\n",
      "Epoch 1395/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.3474 - acc: 0.4671 - val_loss: 2.3091 - val_acc: 0.2300\n",
      "Epoch 1396/3000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 1.3484 - acc: 0.4629 - val_loss: 2.2928 - val_acc: 0.2500\n",
      "Epoch 1397/3000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.3463 - acc: 0.4671 - val_loss: 2.3013 - val_acc: 0.2467\n",
      "Epoch 1398/3000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.3474 - acc: 0.4629 - val_loss: 2.3129 - val_acc: 0.2500\n",
      "Epoch 1399/3000\n",
      "700/700 [==============================] - 0s 124us/step - loss: 1.3465 - acc: 0.4714 - val_loss: 2.3319 - val_acc: 0.2500\n",
      "Epoch 1400/3000\n",
      "700/700 [==============================] - 0s 117us/step - loss: 1.3463 - acc: 0.4686 - val_loss: 2.3307 - val_acc: 0.2467\n",
      "Epoch 1401/3000\n",
      "700/700 [==============================] - 0s 126us/step - loss: 1.3470 - acc: 0.4729 - val_loss: 2.3056 - val_acc: 0.2500\n",
      "Epoch 1402/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.3464 - acc: 0.4714 - val_loss: 2.3070 - val_acc: 0.2433\n",
      "Epoch 1403/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.3449 - acc: 0.4671 - val_loss: 2.2946 - val_acc: 0.2500\n",
      "Epoch 1404/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.3465 - acc: 0.4629 - val_loss: 2.3206 - val_acc: 0.2467\n",
      "Epoch 1405/3000\n",
      "700/700 [==============================] - 0s 87us/step - loss: 1.3464 - acc: 0.4614 - val_loss: 2.3031 - val_acc: 0.2433\n",
      "Epoch 1406/3000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.3467 - acc: 0.4657 - val_loss: 2.2939 - val_acc: 0.2400\n",
      "Epoch 1407/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.3464 - acc: 0.4729 - val_loss: 2.2874 - val_acc: 0.2467\n",
      "Epoch 1408/3000\n",
      "700/700 [==============================] - 0s 115us/step - loss: 1.3459 - acc: 0.4671 - val_loss: 2.3003 - val_acc: 0.2500\n",
      "Epoch 1409/3000\n",
      "700/700 [==============================] - 0s 126us/step - loss: 1.3456 - acc: 0.4657 - val_loss: 2.2894 - val_acc: 0.2467\n",
      "Epoch 1410/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.3463 - acc: 0.4686 - val_loss: 2.2862 - val_acc: 0.2467\n",
      "Epoch 1411/3000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.3458 - acc: 0.4714 - val_loss: 2.3231 - val_acc: 0.2467\n",
      "Epoch 1412/3000\n",
      "700/700 [==============================] - 0s 119us/step - loss: 1.3463 - acc: 0.4686 - val_loss: 2.3012 - val_acc: 0.2467\n",
      "Epoch 1413/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.3461 - acc: 0.4657 - val_loss: 2.3184 - val_acc: 0.2400\n",
      "Epoch 1414/3000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.3466 - acc: 0.4671 - val_loss: 2.2919 - val_acc: 0.2467\n",
      "Epoch 1415/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.3457 - acc: 0.4743 - val_loss: 2.3047 - val_acc: 0.2500\n",
      "Epoch 1416/3000\n",
      "700/700 [==============================] - 0s 117us/step - loss: 1.3456 - acc: 0.4671 - val_loss: 2.3044 - val_acc: 0.2467\n",
      "Epoch 1417/3000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.3465 - acc: 0.4700 - val_loss: 2.2975 - val_acc: 0.2500\n",
      "Epoch 1418/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.3449 - acc: 0.4629 - val_loss: 2.2974 - val_acc: 0.2467\n",
      "Epoch 1419/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.3457 - acc: 0.4657 - val_loss: 2.2938 - val_acc: 0.2533\n",
      "Epoch 1420/3000\n",
      "700/700 [==============================] - 0s 112us/step - loss: 1.3454 - acc: 0.4700 - val_loss: 2.3193 - val_acc: 0.2467\n",
      "Epoch 1421/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.3457 - acc: 0.4657 - val_loss: 2.3040 - val_acc: 0.2433\n",
      "Epoch 1422/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 109us/step - loss: 1.3438 - acc: 0.4686 - val_loss: 2.2998 - val_acc: 0.2467\n",
      "Epoch 1423/3000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.3448 - acc: 0.4643 - val_loss: 2.3083 - val_acc: 0.2433\n",
      "Epoch 1424/3000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 1.3456 - acc: 0.4686 - val_loss: 2.3076 - val_acc: 0.2433\n",
      "Epoch 1425/3000\n",
      "700/700 [==============================] - 0s 120us/step - loss: 1.3438 - acc: 0.4629 - val_loss: 2.3114 - val_acc: 0.2333\n",
      "Epoch 1426/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.3447 - acc: 0.4700 - val_loss: 2.3110 - val_acc: 0.2467\n",
      "Epoch 1427/3000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.3441 - acc: 0.4686 - val_loss: 2.3238 - val_acc: 0.2467\n",
      "Epoch 1428/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.3446 - acc: 0.4743 - val_loss: 2.3043 - val_acc: 0.2467\n",
      "Epoch 1429/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.3445 - acc: 0.4657 - val_loss: 2.2882 - val_acc: 0.2433\n",
      "Epoch 1430/3000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.3446 - acc: 0.4671 - val_loss: 2.3207 - val_acc: 0.2467\n",
      "Epoch 1431/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.3435 - acc: 0.4743 - val_loss: 2.2900 - val_acc: 0.2400\n",
      "Epoch 1432/3000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.3444 - acc: 0.4714 - val_loss: 2.3153 - val_acc: 0.2433\n",
      "Epoch 1433/3000\n",
      "700/700 [==============================] - 0s 108us/step - loss: 1.3449 - acc: 0.4686 - val_loss: 2.3076 - val_acc: 0.2467\n",
      "Epoch 1434/3000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 1.3449 - acc: 0.4671 - val_loss: 2.3018 - val_acc: 0.2467\n",
      "Epoch 1435/3000\n",
      "700/700 [==============================] - 0s 119us/step - loss: 1.3447 - acc: 0.4671 - val_loss: 2.3072 - val_acc: 0.2400\n",
      "Epoch 1436/3000\n",
      "700/700 [==============================] - 0s 108us/step - loss: 1.3424 - acc: 0.4686 - val_loss: 2.3252 - val_acc: 0.2467\n",
      "Epoch 1437/3000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 1.3445 - acc: 0.4714 - val_loss: 2.3119 - val_acc: 0.2467\n",
      "Epoch 1438/3000\n",
      "700/700 [==============================] - 0s 116us/step - loss: 1.3445 - acc: 0.4643 - val_loss: 2.2977 - val_acc: 0.2433\n",
      "Epoch 1439/3000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 1.3437 - acc: 0.4757 - val_loss: 2.3121 - val_acc: 0.2467\n",
      "Epoch 1440/3000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.3440 - acc: 0.4700 - val_loss: 2.3102 - val_acc: 0.2500\n",
      "Epoch 1441/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.3437 - acc: 0.4714 - val_loss: 2.3086 - val_acc: 0.2400\n",
      "Epoch 1442/3000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.3441 - acc: 0.4714 - val_loss: 2.3189 - val_acc: 0.2433\n",
      "Epoch 1443/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.3434 - acc: 0.4714 - val_loss: 2.3125 - val_acc: 0.2467\n",
      "Epoch 1444/3000\n",
      "700/700 [==============================] - 0s 116us/step - loss: 1.3438 - acc: 0.4686 - val_loss: 2.3073 - val_acc: 0.2500\n",
      "Epoch 1445/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.3427 - acc: 0.4586 - val_loss: 2.3061 - val_acc: 0.2333\n",
      "Epoch 1446/3000\n",
      "700/700 [==============================] - 0s 98us/step - loss: 1.3430 - acc: 0.4700 - val_loss: 2.3255 - val_acc: 0.2500\n",
      "Epoch 1447/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.3437 - acc: 0.4657 - val_loss: 2.3117 - val_acc: 0.2433\n",
      "Epoch 1448/3000\n",
      "700/700 [==============================] - 0s 112us/step - loss: 1.3421 - acc: 0.4686 - val_loss: 2.3109 - val_acc: 0.2367\n",
      "Epoch 1449/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.3424 - acc: 0.4700 - val_loss: 2.2877 - val_acc: 0.2433\n",
      "Epoch 1450/3000\n",
      "700/700 [==============================] - 0s 112us/step - loss: 1.3433 - acc: 0.4814 - val_loss: 2.2929 - val_acc: 0.2433\n",
      "Epoch 1451/3000\n",
      "700/700 [==============================] - 0s 119us/step - loss: 1.3425 - acc: 0.4729 - val_loss: 2.3154 - val_acc: 0.2500\n",
      "Epoch 1452/3000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.3428 - acc: 0.4657 - val_loss: 2.3074 - val_acc: 0.2400\n",
      "Epoch 1453/3000\n",
      "700/700 [==============================] - 0s 108us/step - loss: 1.3423 - acc: 0.4629 - val_loss: 2.3040 - val_acc: 0.2433\n",
      "Epoch 1454/3000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.3428 - acc: 0.4743 - val_loss: 2.3024 - val_acc: 0.2433\n",
      "Epoch 1455/3000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 1.3427 - acc: 0.4757 - val_loss: 2.3195 - val_acc: 0.2467\n",
      "Epoch 1456/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.3430 - acc: 0.4771 - val_loss: 2.3111 - val_acc: 0.2400\n",
      "Epoch 1457/3000\n",
      "700/700 [==============================] - 0s 108us/step - loss: 1.3424 - acc: 0.4643 - val_loss: 2.3209 - val_acc: 0.2500\n",
      "Epoch 1458/3000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.3427 - acc: 0.4643 - val_loss: 2.3074 - val_acc: 0.2433\n",
      "Epoch 1459/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.3423 - acc: 0.4700 - val_loss: 2.3051 - val_acc: 0.2500\n",
      "Epoch 1460/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.3417 - acc: 0.4714 - val_loss: 2.3069 - val_acc: 0.2367\n",
      "Epoch 1461/3000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.3410 - acc: 0.4671 - val_loss: 2.3028 - val_acc: 0.2533\n",
      "Epoch 1462/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.3418 - acc: 0.4757 - val_loss: 2.3350 - val_acc: 0.2467\n",
      "Epoch 1463/3000\n",
      "700/700 [==============================] - 0s 122us/step - loss: 1.3424 - acc: 0.4643 - val_loss: 2.3144 - val_acc: 0.2400\n",
      "Epoch 1464/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.3418 - acc: 0.4657 - val_loss: 2.3176 - val_acc: 0.2467\n",
      "Epoch 1465/3000\n",
      "700/700 [==============================] - 0s 108us/step - loss: 1.3419 - acc: 0.4700 - val_loss: 2.3296 - val_acc: 0.2433\n",
      "Epoch 1466/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.3416 - acc: 0.4700 - val_loss: 2.3160 - val_acc: 0.2400\n",
      "Epoch 1467/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.3396 - acc: 0.4743 - val_loss: 2.3130 - val_acc: 0.2433\n",
      "Epoch 1468/3000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 1.3430 - acc: 0.4729 - val_loss: 2.3174 - val_acc: 0.2467\n",
      "Epoch 1469/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.3420 - acc: 0.4700 - val_loss: 2.3200 - val_acc: 0.2433\n",
      "Epoch 1470/3000\n",
      "700/700 [==============================] - 0s 98us/step - loss: 1.3413 - acc: 0.4757 - val_loss: 2.3164 - val_acc: 0.2467\n",
      "Epoch 1471/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3405 - acc: 0.4686 - val_loss: 2.3195 - val_acc: 0.2500\n",
      "Epoch 1472/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.3414 - acc: 0.4643 - val_loss: 2.3152 - val_acc: 0.2367\n",
      "Epoch 1473/3000\n",
      "700/700 [==============================] - 0s 108us/step - loss: 1.3406 - acc: 0.4686 - val_loss: 2.3043 - val_acc: 0.2467\n",
      "Epoch 1474/3000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.3405 - acc: 0.4714 - val_loss: 2.3044 - val_acc: 0.2500\n",
      "Epoch 1475/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.3403 - acc: 0.4714 - val_loss: 2.3234 - val_acc: 0.2433\n",
      "Epoch 1476/3000\n",
      "700/700 [==============================] - 0s 92us/step - loss: 1.3413 - acc: 0.4686 - val_loss: 2.3239 - val_acc: 0.2467\n",
      "Epoch 1477/3000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.3410 - acc: 0.4657 - val_loss: 2.3169 - val_acc: 0.2433\n",
      "Epoch 1478/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 1.3403 - acc: 0.4729 - val_loss: 2.2998 - val_acc: 0.2500\n",
      "Epoch 1479/3000\n",
      "700/700 [==============================] - 0s 84us/step - loss: 1.3402 - acc: 0.4600 - val_loss: 2.3120 - val_acc: 0.2433\n",
      "Epoch 1480/3000\n",
      "700/700 [==============================] - 0s 77us/step - loss: 1.3408 - acc: 0.4700 - val_loss: 2.3186 - val_acc: 0.2400\n",
      "Epoch 1481/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 77us/step - loss: 1.3400 - acc: 0.4686 - val_loss: 2.3188 - val_acc: 0.2367\n",
      "Epoch 1482/3000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.3400 - acc: 0.4714 - val_loss: 2.3392 - val_acc: 0.2500\n",
      "Epoch 1483/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.3410 - acc: 0.4729 - val_loss: 2.3225 - val_acc: 0.2433\n",
      "Epoch 1484/3000\n",
      "700/700 [==============================] - 0s 134us/step - loss: 1.3397 - acc: 0.4671 - val_loss: 2.3197 - val_acc: 0.2333\n",
      "Epoch 1485/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 1.3397 - acc: 0.4686 - val_loss: 2.3283 - val_acc: 0.2333\n",
      "Epoch 1486/3000\n",
      "700/700 [==============================] - 0s 92us/step - loss: 1.3402 - acc: 0.4700 - val_loss: 2.3124 - val_acc: 0.2500\n",
      "Epoch 1487/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3396 - acc: 0.4686 - val_loss: 2.3279 - val_acc: 0.2433\n",
      "Epoch 1488/3000\n",
      "700/700 [==============================] - 0s 82us/step - loss: 1.3391 - acc: 0.4600 - val_loss: 2.2924 - val_acc: 0.2367\n",
      "Epoch 1489/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 1.3400 - acc: 0.4700 - val_loss: 2.3326 - val_acc: 0.2367\n",
      "Epoch 1490/3000\n",
      "700/700 [==============================] - 0s 84us/step - loss: 1.3390 - acc: 0.4700 - val_loss: 2.3367 - val_acc: 0.2467\n",
      "Epoch 1491/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3394 - acc: 0.4729 - val_loss: 2.3332 - val_acc: 0.2433\n",
      "Epoch 1492/3000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.3377 - acc: 0.4700 - val_loss: 2.3287 - val_acc: 0.2367\n",
      "Epoch 1493/3000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.3412 - acc: 0.4614 - val_loss: 2.3205 - val_acc: 0.2500\n",
      "Epoch 1494/3000\n",
      "700/700 [==============================] - 0s 108us/step - loss: 1.3398 - acc: 0.4743 - val_loss: 2.3205 - val_acc: 0.2500\n",
      "Epoch 1495/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.3384 - acc: 0.4700 - val_loss: 2.3176 - val_acc: 0.2433\n",
      "Epoch 1496/3000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.3393 - acc: 0.4729 - val_loss: 2.3179 - val_acc: 0.2467\n",
      "Epoch 1497/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.3383 - acc: 0.4643 - val_loss: 2.3266 - val_acc: 0.2467\n",
      "Epoch 1498/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.3389 - acc: 0.4743 - val_loss: 2.3432 - val_acc: 0.2500\n",
      "Epoch 1499/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.3394 - acc: 0.4686 - val_loss: 2.3217 - val_acc: 0.2467\n",
      "Epoch 1500/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.3388 - acc: 0.4757 - val_loss: 2.3200 - val_acc: 0.2400\n",
      "Epoch 1501/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.3389 - acc: 0.4757 - val_loss: 2.3227 - val_acc: 0.2467\n",
      "Epoch 1502/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.3388 - acc: 0.4743 - val_loss: 2.3419 - val_acc: 0.2467\n",
      "Epoch 1503/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.3394 - acc: 0.4657 - val_loss: 2.3233 - val_acc: 0.2433\n",
      "Epoch 1504/3000\n",
      "700/700 [==============================] - 0s 98us/step - loss: 1.3382 - acc: 0.4757 - val_loss: 2.3333 - val_acc: 0.2433\n",
      "Epoch 1505/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.3385 - acc: 0.4671 - val_loss: 2.3233 - val_acc: 0.2433\n",
      "Epoch 1506/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.3391 - acc: 0.4786 - val_loss: 2.3171 - val_acc: 0.2433\n",
      "Epoch 1507/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.3383 - acc: 0.4671 - val_loss: 2.3241 - val_acc: 0.2367\n",
      "Epoch 1508/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.3385 - acc: 0.4686 - val_loss: 2.3364 - val_acc: 0.2467\n",
      "Epoch 1509/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.3382 - acc: 0.4743 - val_loss: 2.3200 - val_acc: 0.2433\n",
      "Epoch 1510/3000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.3385 - acc: 0.4743 - val_loss: 2.3386 - val_acc: 0.2467\n",
      "Epoch 1511/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.3380 - acc: 0.4743 - val_loss: 2.3497 - val_acc: 0.2500\n",
      "Epoch 1512/3000\n",
      "700/700 [==============================] - 0s 108us/step - loss: 1.3369 - acc: 0.4729 - val_loss: 2.3148 - val_acc: 0.2433\n",
      "Epoch 1513/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.3383 - acc: 0.4671 - val_loss: 2.3088 - val_acc: 0.2433\n",
      "Epoch 1514/3000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.3382 - acc: 0.4700 - val_loss: 2.3281 - val_acc: 0.2433\n",
      "Epoch 1515/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.3376 - acc: 0.4743 - val_loss: 2.3457 - val_acc: 0.2467\n",
      "Epoch 1516/3000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.3395 - acc: 0.4729 - val_loss: 2.3355 - val_acc: 0.2433\n",
      "Epoch 1517/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.3371 - acc: 0.4786 - val_loss: 2.3190 - val_acc: 0.2467\n",
      "Epoch 1518/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.3372 - acc: 0.4743 - val_loss: 2.3126 - val_acc: 0.2533\n",
      "Epoch 1519/3000\n",
      "700/700 [==============================] - 0s 82us/step - loss: 1.3371 - acc: 0.4771 - val_loss: 2.3143 - val_acc: 0.2367\n",
      "Epoch 1520/3000\n",
      "700/700 [==============================] - 0s 92us/step - loss: 1.3375 - acc: 0.4700 - val_loss: 2.3339 - val_acc: 0.2433\n",
      "Epoch 1521/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3369 - acc: 0.4800 - val_loss: 2.3089 - val_acc: 0.2433\n",
      "Epoch 1522/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3377 - acc: 0.4743 - val_loss: 2.3286 - val_acc: 0.2467\n",
      "Epoch 1523/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.3372 - acc: 0.4743 - val_loss: 2.3185 - val_acc: 0.2467\n",
      "Epoch 1524/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.3375 - acc: 0.4757 - val_loss: 2.3372 - val_acc: 0.2467\n",
      "Epoch 1525/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.3367 - acc: 0.4743 - val_loss: 2.3384 - val_acc: 0.2433\n",
      "Epoch 1526/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3369 - acc: 0.4729 - val_loss: 2.3490 - val_acc: 0.2467\n",
      "Epoch 1527/3000\n",
      "700/700 [==============================] - 0s 98us/step - loss: 1.3353 - acc: 0.4743 - val_loss: 2.3232 - val_acc: 0.2333\n",
      "Epoch 1528/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.3373 - acc: 0.4771 - val_loss: 2.3289 - val_acc: 0.2433\n",
      "Epoch 1529/3000\n",
      "700/700 [==============================] - 0s 98us/step - loss: 1.3375 - acc: 0.4671 - val_loss: 2.3347 - val_acc: 0.2467\n",
      "Epoch 1530/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.3368 - acc: 0.4614 - val_loss: 2.3253 - val_acc: 0.2433\n",
      "Epoch 1531/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.3366 - acc: 0.4743 - val_loss: 2.3330 - val_acc: 0.2367\n",
      "Epoch 1532/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.3365 - acc: 0.4771 - val_loss: 2.3159 - val_acc: 0.2500\n",
      "Epoch 1533/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.3363 - acc: 0.4743 - val_loss: 2.3306 - val_acc: 0.2400\n",
      "Epoch 1534/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3372 - acc: 0.4700 - val_loss: 2.3179 - val_acc: 0.2500\n",
      "Epoch 1535/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3370 - acc: 0.4757 - val_loss: 2.3397 - val_acc: 0.2400\n",
      "Epoch 1536/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.3359 - acc: 0.4714 - val_loss: 2.3294 - val_acc: 0.2400\n",
      "Epoch 1537/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3359 - acc: 0.4757 - val_loss: 2.3324 - val_acc: 0.2467\n",
      "Epoch 1538/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.3354 - acc: 0.4757 - val_loss: 2.3217 - val_acc: 0.2433\n",
      "Epoch 1539/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.3355 - acc: 0.4714 - val_loss: 2.3116 - val_acc: 0.2500\n",
      "Epoch 1540/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 97us/step - loss: 1.3357 - acc: 0.4743 - val_loss: 2.3146 - val_acc: 0.2467\n",
      "Epoch 1541/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.3362 - acc: 0.4714 - val_loss: 2.3323 - val_acc: 0.2433\n",
      "Epoch 1542/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.3357 - acc: 0.4729 - val_loss: 2.3326 - val_acc: 0.2367\n",
      "Epoch 1543/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.3358 - acc: 0.4757 - val_loss: 2.3257 - val_acc: 0.2433\n",
      "Epoch 1544/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.3361 - acc: 0.4800 - val_loss: 2.3325 - val_acc: 0.2433\n",
      "Epoch 1545/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.3351 - acc: 0.4714 - val_loss: 2.3140 - val_acc: 0.2433\n",
      "Epoch 1546/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.3357 - acc: 0.4800 - val_loss: 2.3318 - val_acc: 0.2367\n",
      "Epoch 1547/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.3356 - acc: 0.4771 - val_loss: 2.3449 - val_acc: 0.2433\n",
      "Epoch 1548/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.3359 - acc: 0.4757 - val_loss: 2.3351 - val_acc: 0.2500\n",
      "Epoch 1549/3000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.3343 - acc: 0.4729 - val_loss: 2.3474 - val_acc: 0.2467\n",
      "Epoch 1550/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.3351 - acc: 0.4757 - val_loss: 2.3496 - val_acc: 0.2433\n",
      "Epoch 1551/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.3352 - acc: 0.4743 - val_loss: 2.3245 - val_acc: 0.2367\n",
      "Epoch 1552/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.3347 - acc: 0.4729 - val_loss: 2.3438 - val_acc: 0.2500\n",
      "Epoch 1553/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.3344 - acc: 0.4743 - val_loss: 2.3341 - val_acc: 0.2367\n",
      "Epoch 1554/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.3353 - acc: 0.4700 - val_loss: 2.3336 - val_acc: 0.2367\n",
      "Epoch 1555/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.3350 - acc: 0.4686 - val_loss: 2.3363 - val_acc: 0.2400\n",
      "Epoch 1556/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.3340 - acc: 0.4700 - val_loss: 2.3305 - val_acc: 0.2467\n",
      "Epoch 1557/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.3341 - acc: 0.4757 - val_loss: 2.3339 - val_acc: 0.2433\n",
      "Epoch 1558/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3343 - acc: 0.4757 - val_loss: 2.3130 - val_acc: 0.2533\n",
      "Epoch 1559/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.3344 - acc: 0.4757 - val_loss: 2.3435 - val_acc: 0.2467\n",
      "Epoch 1560/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.3348 - acc: 0.4714 - val_loss: 2.3319 - val_acc: 0.2433\n",
      "Epoch 1561/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.3334 - acc: 0.4686 - val_loss: 2.3405 - val_acc: 0.2467\n",
      "Epoch 1562/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.3346 - acc: 0.4671 - val_loss: 2.3614 - val_acc: 0.2467\n",
      "Epoch 1563/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.3349 - acc: 0.4729 - val_loss: 2.3383 - val_acc: 0.2467\n",
      "Epoch 1564/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 1.3329 - acc: 0.4743 - val_loss: 2.3326 - val_acc: 0.2400\n",
      "Epoch 1565/3000\n",
      "700/700 [==============================] - 0s 98us/step - loss: 1.3350 - acc: 0.4757 - val_loss: 2.3284 - val_acc: 0.2467\n",
      "Epoch 1566/3000\n",
      "700/700 [==============================] - 0s 98us/step - loss: 1.3336 - acc: 0.4743 - val_loss: 2.3312 - val_acc: 0.2367\n",
      "Epoch 1567/3000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.3342 - acc: 0.4743 - val_loss: 2.3365 - val_acc: 0.2433\n",
      "Epoch 1568/3000\n",
      "700/700 [==============================] - 0s 98us/step - loss: 1.3336 - acc: 0.4714 - val_loss: 2.3347 - val_acc: 0.2433\n",
      "Epoch 1569/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.3343 - acc: 0.4800 - val_loss: 2.3557 - val_acc: 0.2467\n",
      "Epoch 1570/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.3330 - acc: 0.4814 - val_loss: 2.3602 - val_acc: 0.2467\n",
      "Epoch 1571/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.3349 - acc: 0.4729 - val_loss: 2.3450 - val_acc: 0.2433\n",
      "Epoch 1572/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.3335 - acc: 0.4771 - val_loss: 2.3261 - val_acc: 0.2400\n",
      "Epoch 1573/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.3335 - acc: 0.4800 - val_loss: 2.3639 - val_acc: 0.2433\n",
      "Epoch 1574/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.3339 - acc: 0.4686 - val_loss: 2.3425 - val_acc: 0.2433\n",
      "Epoch 1575/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.3328 - acc: 0.4729 - val_loss: 2.3347 - val_acc: 0.2433\n",
      "Epoch 1576/3000\n",
      "700/700 [==============================] - 0s 87us/step - loss: 1.3331 - acc: 0.4700 - val_loss: 2.3542 - val_acc: 0.2467\n",
      "Epoch 1577/3000\n",
      "700/700 [==============================] - 0s 98us/step - loss: 1.3338 - acc: 0.4700 - val_loss: 2.3344 - val_acc: 0.2400\n",
      "Epoch 1578/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.3321 - acc: 0.4771 - val_loss: 2.3410 - val_acc: 0.2467\n",
      "Epoch 1579/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3332 - acc: 0.4714 - val_loss: 2.3401 - val_acc: 0.2467\n",
      "Epoch 1580/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.3321 - acc: 0.4814 - val_loss: 2.3487 - val_acc: 0.2467\n",
      "Epoch 1581/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 1.3334 - acc: 0.4700 - val_loss: 2.3506 - val_acc: 0.2400\n",
      "Epoch 1582/3000\n",
      "700/700 [==============================] - 0s 83us/step - loss: 1.3332 - acc: 0.4757 - val_loss: 2.3349 - val_acc: 0.2433\n",
      "Epoch 1583/3000\n",
      "700/700 [==============================] - 0s 98us/step - loss: 1.3321 - acc: 0.4714 - val_loss: 2.3423 - val_acc: 0.2433\n",
      "Epoch 1584/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 1.3334 - acc: 0.4743 - val_loss: 2.3553 - val_acc: 0.2433\n",
      "Epoch 1585/3000\n",
      "700/700 [==============================] - 0s 86us/step - loss: 1.3329 - acc: 0.4714 - val_loss: 2.3427 - val_acc: 0.2467\n",
      "Epoch 1586/3000\n",
      "700/700 [==============================] - 0s 124us/step - loss: 1.3315 - acc: 0.4714 - val_loss: 2.3542 - val_acc: 0.2367\n",
      "Epoch 1587/3000\n",
      "700/700 [==============================] - 0s 92us/step - loss: 1.3319 - acc: 0.4729 - val_loss: 2.3581 - val_acc: 0.2400\n",
      "Epoch 1588/3000\n",
      "700/700 [==============================] - 0s 85us/step - loss: 1.3323 - acc: 0.4771 - val_loss: 2.3356 - val_acc: 0.2500\n",
      "Epoch 1589/3000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.3323 - acc: 0.4786 - val_loss: 2.3540 - val_acc: 0.2400\n",
      "Epoch 1590/3000\n",
      "700/700 [==============================] - 0s 149us/step - loss: 1.3318 - acc: 0.4757 - val_loss: 2.3300 - val_acc: 0.2500\n",
      "Epoch 1591/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.3325 - acc: 0.4800 - val_loss: 2.3386 - val_acc: 0.2467\n",
      "Epoch 1592/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3318 - acc: 0.4729 - val_loss: 2.3497 - val_acc: 0.2467\n",
      "Epoch 1593/3000\n",
      "700/700 [==============================] - 0s 92us/step - loss: 1.3311 - acc: 0.4671 - val_loss: 2.3585 - val_acc: 0.2433\n",
      "Epoch 1594/3000\n",
      "700/700 [==============================] - 0s 130us/step - loss: 1.3322 - acc: 0.4729 - val_loss: 2.3475 - val_acc: 0.2433\n",
      "Epoch 1595/3000\n",
      "700/700 [==============================] - 0s 84us/step - loss: 1.3311 - acc: 0.4757 - val_loss: 2.3464 - val_acc: 0.2433\n",
      "Epoch 1596/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.3316 - acc: 0.4714 - val_loss: 2.3384 - val_acc: 0.2467\n",
      "Epoch 1597/3000\n",
      "700/700 [==============================] - 0s 122us/step - loss: 1.3316 - acc: 0.4729 - val_loss: 2.3494 - val_acc: 0.2467\n",
      "Epoch 1598/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.3321 - acc: 0.4786 - val_loss: 2.3469 - val_acc: 0.2433\n",
      "Epoch 1599/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 94us/step - loss: 1.3312 - acc: 0.4729 - val_loss: 2.3420 - val_acc: 0.2367\n",
      "Epoch 1600/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3314 - acc: 0.4714 - val_loss: 2.3531 - val_acc: 0.2333\n",
      "Epoch 1601/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.3318 - acc: 0.4771 - val_loss: 2.3367 - val_acc: 0.2500\n",
      "Epoch 1602/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.3307 - acc: 0.4729 - val_loss: 2.3601 - val_acc: 0.2467\n",
      "Epoch 1603/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.3312 - acc: 0.4743 - val_loss: 2.3576 - val_acc: 0.2500\n",
      "Epoch 1604/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.3310 - acc: 0.4743 - val_loss: 2.3532 - val_acc: 0.2433\n",
      "Epoch 1605/3000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.3313 - acc: 0.4814 - val_loss: 2.3638 - val_acc: 0.2467\n",
      "Epoch 1606/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.3309 - acc: 0.4743 - val_loss: 2.3422 - val_acc: 0.2333\n",
      "Epoch 1607/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.3322 - acc: 0.4786 - val_loss: 2.3415 - val_acc: 0.2433\n",
      "Epoch 1608/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.3294 - acc: 0.4757 - val_loss: 2.3490 - val_acc: 0.2467\n",
      "Epoch 1609/3000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.3312 - acc: 0.4786 - val_loss: 2.3647 - val_acc: 0.2500\n",
      "Epoch 1610/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.3312 - acc: 0.4729 - val_loss: 2.3467 - val_acc: 0.2433\n",
      "Epoch 1611/3000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.3301 - acc: 0.4757 - val_loss: 2.3629 - val_acc: 0.2467\n",
      "Epoch 1612/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.3307 - acc: 0.4743 - val_loss: 2.3506 - val_acc: 0.2400\n",
      "Epoch 1613/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3300 - acc: 0.4743 - val_loss: 2.3559 - val_acc: 0.2333\n",
      "Epoch 1614/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.3304 - acc: 0.4700 - val_loss: 2.3531 - val_acc: 0.2467\n",
      "Epoch 1615/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.3307 - acc: 0.4786 - val_loss: 2.3703 - val_acc: 0.2467\n",
      "Epoch 1616/3000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.3305 - acc: 0.4757 - val_loss: 2.3562 - val_acc: 0.2433\n",
      "Epoch 1617/3000\n",
      "700/700 [==============================] - 0s 123us/step - loss: 1.3293 - acc: 0.4800 - val_loss: 2.3348 - val_acc: 0.2467\n",
      "Epoch 1618/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.3312 - acc: 0.4743 - val_loss: 2.3495 - val_acc: 0.2367\n",
      "Epoch 1619/3000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.3299 - acc: 0.4729 - val_loss: 2.3565 - val_acc: 0.2467\n",
      "Epoch 1620/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.3295 - acc: 0.4700 - val_loss: 2.3672 - val_acc: 0.2467\n",
      "Epoch 1621/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.3298 - acc: 0.4757 - val_loss: 2.3743 - val_acc: 0.2467\n",
      "Epoch 1622/3000\n",
      "700/700 [==============================] - 0s 112us/step - loss: 1.3298 - acc: 0.4743 - val_loss: 2.3341 - val_acc: 0.2467\n",
      "Epoch 1623/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.3291 - acc: 0.4700 - val_loss: 2.3545 - val_acc: 0.2400\n",
      "Epoch 1624/3000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 1.3282 - acc: 0.4771 - val_loss: 2.3576 - val_acc: 0.2467\n",
      "Epoch 1625/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.3299 - acc: 0.4729 - val_loss: 2.3595 - val_acc: 0.2400\n",
      "Epoch 1626/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.3296 - acc: 0.4671 - val_loss: 2.3673 - val_acc: 0.2433\n",
      "Epoch 1627/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.3298 - acc: 0.4771 - val_loss: 2.3784 - val_acc: 0.2500\n",
      "Epoch 1628/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.3294 - acc: 0.4786 - val_loss: 2.3618 - val_acc: 0.2433\n",
      "Epoch 1629/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.3294 - acc: 0.4771 - val_loss: 2.3557 - val_acc: 0.2433\n",
      "Epoch 1630/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.3294 - acc: 0.4714 - val_loss: 2.3589 - val_acc: 0.2467\n",
      "Epoch 1631/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.3303 - acc: 0.4757 - val_loss: 2.3592 - val_acc: 0.2433\n",
      "Epoch 1632/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.3290 - acc: 0.4743 - val_loss: 2.3775 - val_acc: 0.2467\n",
      "Epoch 1633/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.3299 - acc: 0.4686 - val_loss: 2.3537 - val_acc: 0.2433\n",
      "Epoch 1634/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.3289 - acc: 0.4743 - val_loss: 2.3693 - val_acc: 0.2500\n",
      "Epoch 1635/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.3285 - acc: 0.4686 - val_loss: 2.3564 - val_acc: 0.2400\n",
      "Epoch 1636/3000\n",
      "700/700 [==============================] - 0s 112us/step - loss: 1.3294 - acc: 0.4786 - val_loss: 2.3719 - val_acc: 0.2500\n",
      "Epoch 1637/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.3267 - acc: 0.4743 - val_loss: 2.3741 - val_acc: 0.2467\n",
      "Epoch 1638/3000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.3286 - acc: 0.4771 - val_loss: 2.3734 - val_acc: 0.2467\n",
      "Epoch 1639/3000\n",
      "700/700 [==============================] - 0s 117us/step - loss: 1.3282 - acc: 0.4686 - val_loss: 2.3713 - val_acc: 0.2400\n",
      "Epoch 1640/3000\n",
      "700/700 [==============================] - 0s 92us/step - loss: 1.3279 - acc: 0.4743 - val_loss: 2.3822 - val_acc: 0.2500\n",
      "Epoch 1641/3000\n",
      "700/700 [==============================] - 0s 98us/step - loss: 1.3287 - acc: 0.4814 - val_loss: 2.3637 - val_acc: 0.2367\n",
      "Epoch 1642/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.3282 - acc: 0.4786 - val_loss: 2.3732 - val_acc: 0.2433\n",
      "Epoch 1643/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.3279 - acc: 0.4814 - val_loss: 2.3754 - val_acc: 0.2467\n",
      "Epoch 1644/3000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 1.3276 - acc: 0.4757 - val_loss: 2.3699 - val_acc: 0.2433\n",
      "Epoch 1645/3000\n",
      "700/700 [==============================] - 0s 119us/step - loss: 1.3260 - acc: 0.4843 - val_loss: 2.3670 - val_acc: 0.2433\n",
      "Epoch 1646/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.3264 - acc: 0.4671 - val_loss: 2.3509 - val_acc: 0.2333\n",
      "Epoch 1647/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.3270 - acc: 0.4843 - val_loss: 2.3820 - val_acc: 0.2467\n",
      "Epoch 1648/3000\n",
      "700/700 [==============================] - 0s 121us/step - loss: 1.3274 - acc: 0.4786 - val_loss: 2.3750 - val_acc: 0.2400\n",
      "Epoch 1649/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.3267 - acc: 0.4743 - val_loss: 2.3729 - val_acc: 0.2400\n",
      "Epoch 1650/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.3264 - acc: 0.4857 - val_loss: 2.3597 - val_acc: 0.2433\n",
      "Epoch 1651/3000\n",
      "700/700 [==============================] - 0s 85us/step - loss: 1.3280 - acc: 0.4729 - val_loss: 2.3535 - val_acc: 0.2433\n",
      "Epoch 1652/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.3267 - acc: 0.4757 - val_loss: 2.3664 - val_acc: 0.2400\n",
      "Epoch 1653/3000\n",
      "700/700 [==============================] - 0s 108us/step - loss: 1.3263 - acc: 0.4729 - val_loss: 2.3803 - val_acc: 0.2500\n",
      "Epoch 1654/3000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 1.3281 - acc: 0.4729 - val_loss: 2.3624 - val_acc: 0.2433\n",
      "Epoch 1655/3000\n",
      "700/700 [==============================] - 0s 112us/step - loss: 1.3258 - acc: 0.4743 - val_loss: 2.3660 - val_acc: 0.2433\n",
      "Epoch 1656/3000\n",
      "700/700 [==============================] - 0s 115us/step - loss: 1.3276 - acc: 0.4771 - val_loss: 2.3682 - val_acc: 0.2400\n",
      "Epoch 1657/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.3270 - acc: 0.4814 - val_loss: 2.3621 - val_acc: 0.2467\n",
      "Epoch 1658/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 111us/step - loss: 1.3265 - acc: 0.4771 - val_loss: 2.3745 - val_acc: 0.2433\n",
      "Epoch 1659/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.3266 - acc: 0.4843 - val_loss: 2.3600 - val_acc: 0.2400\n",
      "Epoch 1660/3000\n",
      "700/700 [==============================] - 0s 84us/step - loss: 1.3264 - acc: 0.4771 - val_loss: 2.3736 - val_acc: 0.2400\n",
      "Epoch 1661/3000\n",
      "700/700 [==============================] - 0s 83us/step - loss: 1.3259 - acc: 0.4786 - val_loss: 2.3614 - val_acc: 0.2400\n",
      "Epoch 1662/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 1.3262 - acc: 0.4771 - val_loss: 2.3644 - val_acc: 0.2433\n",
      "Epoch 1663/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3264 - acc: 0.4843 - val_loss: 2.3746 - val_acc: 0.2433\n",
      "Epoch 1664/3000\n",
      "700/700 [==============================] - 0s 87us/step - loss: 1.3265 - acc: 0.4786 - val_loss: 2.3677 - val_acc: 0.2433\n",
      "Epoch 1665/3000\n",
      "700/700 [==============================] - 0s 85us/step - loss: 1.3257 - acc: 0.4643 - val_loss: 2.3641 - val_acc: 0.2467\n",
      "Epoch 1666/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.3257 - acc: 0.4771 - val_loss: 2.3677 - val_acc: 0.2467\n",
      "Epoch 1667/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.3255 - acc: 0.4829 - val_loss: 2.3630 - val_acc: 0.2433\n",
      "Epoch 1668/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.3258 - acc: 0.4771 - val_loss: 2.3644 - val_acc: 0.2433\n",
      "Epoch 1669/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.3259 - acc: 0.4743 - val_loss: 2.3688 - val_acc: 0.2400\n",
      "Epoch 1670/3000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.3248 - acc: 0.4843 - val_loss: 2.3854 - val_acc: 0.2433\n",
      "Epoch 1671/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.3257 - acc: 0.4743 - val_loss: 2.3821 - val_acc: 0.2433\n",
      "Epoch 1672/3000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.3252 - acc: 0.4829 - val_loss: 2.3695 - val_acc: 0.2400\n",
      "Epoch 1673/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.3248 - acc: 0.4771 - val_loss: 2.3992 - val_acc: 0.2533\n",
      "Epoch 1674/3000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.3241 - acc: 0.4871 - val_loss: 2.3882 - val_acc: 0.2467\n",
      "Epoch 1675/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.3252 - acc: 0.4771 - val_loss: 2.3652 - val_acc: 0.2400\n",
      "Epoch 1676/3000\n",
      "700/700 [==============================] - 0s 116us/step - loss: 1.3256 - acc: 0.4757 - val_loss: 2.3785 - val_acc: 0.2433\n",
      "Epoch 1677/3000\n",
      "700/700 [==============================] - 0s 123us/step - loss: 1.3238 - acc: 0.4786 - val_loss: 2.3630 - val_acc: 0.2467\n",
      "Epoch 1678/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.3250 - acc: 0.4757 - val_loss: 2.3734 - val_acc: 0.2400\n",
      "Epoch 1679/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.3245 - acc: 0.4743 - val_loss: 2.3617 - val_acc: 0.2400\n",
      "Epoch 1680/3000\n",
      "700/700 [==============================] - 0s 120us/step - loss: 1.3248 - acc: 0.4786 - val_loss: 2.3713 - val_acc: 0.2433\n",
      "Epoch 1681/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.3248 - acc: 0.4814 - val_loss: 2.3786 - val_acc: 0.2400\n",
      "Epoch 1682/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.3249 - acc: 0.4786 - val_loss: 2.3729 - val_acc: 0.2433\n",
      "Epoch 1683/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.3247 - acc: 0.4814 - val_loss: 2.3764 - val_acc: 0.2400\n",
      "Epoch 1684/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.3236 - acc: 0.4857 - val_loss: 2.3957 - val_acc: 0.2433\n",
      "Epoch 1685/3000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.3250 - acc: 0.4814 - val_loss: 2.3720 - val_acc: 0.2400\n",
      "Epoch 1686/3000\n",
      "700/700 [==============================] - 0s 108us/step - loss: 1.3238 - acc: 0.4729 - val_loss: 2.4024 - val_acc: 0.2500\n",
      "Epoch 1687/3000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.3246 - acc: 0.4843 - val_loss: 2.3808 - val_acc: 0.2400\n",
      "Epoch 1688/3000\n",
      "700/700 [==============================] - 0s 116us/step - loss: 1.3244 - acc: 0.4900 - val_loss: 2.3720 - val_acc: 0.2400\n",
      "Epoch 1689/3000\n",
      "700/700 [==============================] - 0s 133us/step - loss: 1.3250 - acc: 0.4757 - val_loss: 2.3796 - val_acc: 0.2467\n",
      "Epoch 1690/3000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.3248 - acc: 0.4786 - val_loss: 2.3723 - val_acc: 0.2367\n",
      "Epoch 1691/3000\n",
      "700/700 [==============================] - 0s 122us/step - loss: 1.3234 - acc: 0.4814 - val_loss: 2.3742 - val_acc: 0.2433\n",
      "Epoch 1692/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.3241 - acc: 0.4829 - val_loss: 2.3769 - val_acc: 0.2433\n",
      "Epoch 1693/3000\n",
      "700/700 [==============================] - 0s 119us/step - loss: 1.3239 - acc: 0.4771 - val_loss: 2.3927 - val_acc: 0.2400\n",
      "Epoch 1694/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.3242 - acc: 0.4814 - val_loss: 2.3918 - val_acc: 0.2467\n",
      "Epoch 1695/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.3241 - acc: 0.4771 - val_loss: 2.3773 - val_acc: 0.2400\n",
      "Epoch 1696/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.3232 - acc: 0.4771 - val_loss: 2.3533 - val_acc: 0.2467\n",
      "Epoch 1697/3000\n",
      "700/700 [==============================] - 0s 108us/step - loss: 1.3235 - acc: 0.4857 - val_loss: 2.3764 - val_acc: 0.2433\n",
      "Epoch 1698/3000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.3234 - acc: 0.4829 - val_loss: 2.3871 - val_acc: 0.2400\n",
      "Epoch 1699/3000\n",
      "700/700 [==============================] - 0s 116us/step - loss: 1.3239 - acc: 0.4771 - val_loss: 2.3926 - val_acc: 0.2467\n",
      "Epoch 1700/3000\n",
      "700/700 [==============================] - 0s 98us/step - loss: 1.3230 - acc: 0.4786 - val_loss: 2.3907 - val_acc: 0.2500\n",
      "Epoch 1701/3000\n",
      "700/700 [==============================] - 0s 77us/step - loss: 1.3227 - acc: 0.4757 - val_loss: 2.3835 - val_acc: 0.2433\n",
      "Epoch 1702/3000\n",
      "700/700 [==============================] - 0s 81us/step - loss: 1.3235 - acc: 0.4729 - val_loss: 2.3741 - val_acc: 0.2433\n",
      "Epoch 1703/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.3229 - acc: 0.4771 - val_loss: 2.3786 - val_acc: 0.2400\n",
      "Epoch 1704/3000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.3224 - acc: 0.4786 - val_loss: 2.3819 - val_acc: 0.2400\n",
      "Epoch 1705/3000\n",
      "700/700 [==============================] - 0s 115us/step - loss: 1.3232 - acc: 0.4786 - val_loss: 2.3954 - val_acc: 0.2467\n",
      "Epoch 1706/3000\n",
      "700/700 [==============================] - 0s 117us/step - loss: 1.3226 - acc: 0.4829 - val_loss: 2.3687 - val_acc: 0.2467\n",
      "Epoch 1707/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.3232 - acc: 0.4829 - val_loss: 2.3819 - val_acc: 0.2433\n",
      "Epoch 1708/3000\n",
      "700/700 [==============================] - 0s 108us/step - loss: 1.3218 - acc: 0.4771 - val_loss: 2.3762 - val_acc: 0.2433\n",
      "Epoch 1709/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.3217 - acc: 0.4800 - val_loss: 2.3787 - val_acc: 0.2500\n",
      "Epoch 1710/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.3224 - acc: 0.4800 - val_loss: 2.3671 - val_acc: 0.2433\n",
      "Epoch 1711/3000\n",
      "700/700 [==============================] - 0s 117us/step - loss: 1.3220 - acc: 0.4814 - val_loss: 2.3777 - val_acc: 0.2433\n",
      "Epoch 1712/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.3233 - acc: 0.4800 - val_loss: 2.3827 - val_acc: 0.2467\n",
      "Epoch 1713/3000\n",
      "700/700 [==============================] - 0s 112us/step - loss: 1.3220 - acc: 0.4771 - val_loss: 2.3983 - val_acc: 0.2500\n",
      "Epoch 1714/3000\n",
      "700/700 [==============================] - 0s 123us/step - loss: 1.3231 - acc: 0.4857 - val_loss: 2.3625 - val_acc: 0.2433\n",
      "Epoch 1715/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.3225 - acc: 0.4843 - val_loss: 2.3985 - val_acc: 0.2533\n",
      "Epoch 1716/3000\n",
      "700/700 [==============================] - 0s 112us/step - loss: 1.3223 - acc: 0.4814 - val_loss: 2.3982 - val_acc: 0.2533\n",
      "Epoch 1717/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 105us/step - loss: 1.3219 - acc: 0.4771 - val_loss: 2.3687 - val_acc: 0.2433\n",
      "Epoch 1718/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.3227 - acc: 0.4857 - val_loss: 2.3889 - val_acc: 0.2467\n",
      "Epoch 1719/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.3225 - acc: 0.4829 - val_loss: 2.3513 - val_acc: 0.2433\n",
      "Epoch 1720/3000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.3212 - acc: 0.4814 - val_loss: 2.3805 - val_acc: 0.2433\n",
      "Epoch 1721/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.3221 - acc: 0.4771 - val_loss: 2.3683 - val_acc: 0.2433\n",
      "Epoch 1722/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.3227 - acc: 0.4757 - val_loss: 2.3658 - val_acc: 0.2400\n",
      "Epoch 1723/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.3220 - acc: 0.4800 - val_loss: 2.3654 - val_acc: 0.2367\n",
      "Epoch 1724/3000\n",
      "700/700 [==============================] - 0s 98us/step - loss: 1.3210 - acc: 0.4843 - val_loss: 2.3804 - val_acc: 0.2367\n",
      "Epoch 1725/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.3215 - acc: 0.4829 - val_loss: 2.3908 - val_acc: 0.2433\n",
      "Epoch 1726/3000\n",
      "700/700 [==============================] - 0s 108us/step - loss: 1.3215 - acc: 0.4843 - val_loss: 2.3878 - val_acc: 0.2467\n",
      "Epoch 1727/3000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.3222 - acc: 0.4843 - val_loss: 2.3878 - val_acc: 0.2500\n",
      "Epoch 1728/3000\n",
      "700/700 [==============================] - 0s 120us/step - loss: 1.3214 - acc: 0.4714 - val_loss: 2.3878 - val_acc: 0.2433\n",
      "Epoch 1729/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.3221 - acc: 0.4786 - val_loss: 2.3824 - val_acc: 0.2400\n",
      "Epoch 1730/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.3211 - acc: 0.4786 - val_loss: 2.3709 - val_acc: 0.2400\n",
      "Epoch 1731/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.3211 - acc: 0.4829 - val_loss: 2.3979 - val_acc: 0.2500\n",
      "Epoch 1732/3000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.3210 - acc: 0.4843 - val_loss: 2.3902 - val_acc: 0.2467\n",
      "Epoch 1733/3000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.3201 - acc: 0.4786 - val_loss: 2.3992 - val_acc: 0.2467\n",
      "Epoch 1734/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.3211 - acc: 0.4786 - val_loss: 2.3896 - val_acc: 0.2433\n",
      "Epoch 1735/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.3216 - acc: 0.4800 - val_loss: 2.3838 - val_acc: 0.2433\n",
      "Epoch 1736/3000\n",
      "700/700 [==============================] - 0s 147us/step - loss: 1.3207 - acc: 0.4829 - val_loss: 2.3920 - val_acc: 0.2433\n",
      "Epoch 1737/3000\n",
      "700/700 [==============================] - 0s 127us/step - loss: 1.3194 - acc: 0.4857 - val_loss: 2.3926 - val_acc: 0.2433\n",
      "Epoch 1738/3000\n",
      "700/700 [==============================] - 0s 83us/step - loss: 1.3210 - acc: 0.4843 - val_loss: 2.4025 - val_acc: 0.2500\n",
      "Epoch 1739/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3208 - acc: 0.4786 - val_loss: 2.3816 - val_acc: 0.2400\n",
      "Epoch 1740/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.3206 - acc: 0.4829 - val_loss: 2.4041 - val_acc: 0.2500\n",
      "Epoch 1741/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.3205 - acc: 0.4857 - val_loss: 2.3603 - val_acc: 0.2400\n",
      "Epoch 1742/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.3201 - acc: 0.4829 - val_loss: 2.3961 - val_acc: 0.2500\n",
      "Epoch 1743/3000\n",
      "700/700 [==============================] - 0s 117us/step - loss: 1.3208 - acc: 0.4800 - val_loss: 2.4027 - val_acc: 0.2467\n",
      "Epoch 1744/3000\n",
      "700/700 [==============================] - 0s 108us/step - loss: 1.3205 - acc: 0.4743 - val_loss: 2.3927 - val_acc: 0.2433\n",
      "Epoch 1745/3000\n",
      "700/700 [==============================] - 0s 92us/step - loss: 1.3202 - acc: 0.4843 - val_loss: 2.3810 - val_acc: 0.2400\n",
      "Epoch 1746/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.3206 - acc: 0.4800 - val_loss: 2.4052 - val_acc: 0.2500\n",
      "Epoch 1747/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3201 - acc: 0.4786 - val_loss: 2.3967 - val_acc: 0.2400\n",
      "Epoch 1748/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.3198 - acc: 0.4743 - val_loss: 2.3834 - val_acc: 0.2400\n",
      "Epoch 1749/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3198 - acc: 0.4829 - val_loss: 2.3969 - val_acc: 0.2467\n",
      "Epoch 1750/3000\n",
      "700/700 [==============================] - 0s 79us/step - loss: 1.3194 - acc: 0.4800 - val_loss: 2.3661 - val_acc: 0.2467\n",
      "Epoch 1751/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3201 - acc: 0.4871 - val_loss: 2.3665 - val_acc: 0.2433\n",
      "Epoch 1752/3000\n",
      "700/700 [==============================] - 0s 85us/step - loss: 1.3188 - acc: 0.4829 - val_loss: 2.3746 - val_acc: 0.2467\n",
      "Epoch 1753/3000\n",
      "700/700 [==============================] - 0s 82us/step - loss: 1.3200 - acc: 0.4800 - val_loss: 2.4006 - val_acc: 0.2433\n",
      "Epoch 1754/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.3198 - acc: 0.4871 - val_loss: 2.4047 - val_acc: 0.2433\n",
      "Epoch 1755/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 1.3186 - acc: 0.4857 - val_loss: 2.4020 - val_acc: 0.2467\n",
      "Epoch 1756/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.3197 - acc: 0.4829 - val_loss: 2.3743 - val_acc: 0.2433\n",
      "Epoch 1757/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.3193 - acc: 0.4843 - val_loss: 2.4091 - val_acc: 0.2467\n",
      "Epoch 1758/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.3194 - acc: 0.4843 - val_loss: 2.3828 - val_acc: 0.2433\n",
      "Epoch 1759/3000\n",
      "700/700 [==============================] - 0s 98us/step - loss: 1.3189 - acc: 0.4800 - val_loss: 2.4330 - val_acc: 0.2500\n",
      "Epoch 1760/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.3199 - acc: 0.4814 - val_loss: 2.3872 - val_acc: 0.2433\n",
      "Epoch 1761/3000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.3201 - acc: 0.4886 - val_loss: 2.3843 - val_acc: 0.2433\n",
      "Epoch 1762/3000\n",
      "700/700 [==============================] - 0s 82us/step - loss: 1.3190 - acc: 0.4800 - val_loss: 2.4092 - val_acc: 0.2500\n",
      "Epoch 1763/3000\n",
      "700/700 [==============================] - 0s 92us/step - loss: 1.3190 - acc: 0.4800 - val_loss: 2.3876 - val_acc: 0.2400\n",
      "Epoch 1764/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.3180 - acc: 0.4871 - val_loss: 2.3885 - val_acc: 0.2433\n",
      "Epoch 1765/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.3196 - acc: 0.4800 - val_loss: 2.3879 - val_acc: 0.2467\n",
      "Epoch 1766/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.3187 - acc: 0.4800 - val_loss: 2.3787 - val_acc: 0.2433\n",
      "Epoch 1767/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3189 - acc: 0.4829 - val_loss: 2.3833 - val_acc: 0.2433\n",
      "Epoch 1768/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.3189 - acc: 0.4843 - val_loss: 2.3913 - val_acc: 0.2433\n",
      "Epoch 1769/3000\n",
      "700/700 [==============================] - 0s 98us/step - loss: 1.3184 - acc: 0.4843 - val_loss: 2.3919 - val_acc: 0.2467\n",
      "Epoch 1770/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.3191 - acc: 0.4971 - val_loss: 2.4014 - val_acc: 0.2467\n",
      "Epoch 1771/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.3190 - acc: 0.4814 - val_loss: 2.3813 - val_acc: 0.2433\n",
      "Epoch 1772/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3186 - acc: 0.4771 - val_loss: 2.4008 - val_acc: 0.2500\n",
      "Epoch 1773/3000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.3184 - acc: 0.4857 - val_loss: 2.3954 - val_acc: 0.2500\n",
      "Epoch 1774/3000\n",
      "700/700 [==============================] - 0s 86us/step - loss: 1.3188 - acc: 0.4900 - val_loss: 2.3916 - val_acc: 0.2433\n",
      "Epoch 1775/3000\n",
      "700/700 [==============================] - 0s 108us/step - loss: 1.3183 - acc: 0.4829 - val_loss: 2.4103 - val_acc: 0.2533\n",
      "Epoch 1776/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 95us/step - loss: 1.3194 - acc: 0.4843 - val_loss: 2.3734 - val_acc: 0.2433\n",
      "Epoch 1777/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.3178 - acc: 0.4814 - val_loss: 2.3968 - val_acc: 0.2400\n",
      "Epoch 1778/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 1.3182 - acc: 0.4786 - val_loss: 2.3790 - val_acc: 0.2400\n",
      "Epoch 1779/3000\n",
      "700/700 [==============================] - 0s 80us/step - loss: 1.3184 - acc: 0.4886 - val_loss: 2.3933 - val_acc: 0.2400\n",
      "Epoch 1780/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 1.3184 - acc: 0.4786 - val_loss: 2.4111 - val_acc: 0.2467\n",
      "Epoch 1781/3000\n",
      "700/700 [==============================] - 0s 98us/step - loss: 1.3176 - acc: 0.4843 - val_loss: 2.4119 - val_acc: 0.2467\n",
      "Epoch 1782/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.3183 - acc: 0.4829 - val_loss: 2.3708 - val_acc: 0.2467\n",
      "Epoch 1783/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.3180 - acc: 0.4886 - val_loss: 2.4015 - val_acc: 0.2467\n",
      "Epoch 1784/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.3172 - acc: 0.4814 - val_loss: 2.3866 - val_acc: 0.2367\n",
      "Epoch 1785/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.3177 - acc: 0.4829 - val_loss: 2.3988 - val_acc: 0.2467\n",
      "Epoch 1786/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.3183 - acc: 0.4914 - val_loss: 2.3944 - val_acc: 0.2467\n",
      "Epoch 1787/3000\n",
      "700/700 [==============================] - 0s 98us/step - loss: 1.3175 - acc: 0.4914 - val_loss: 2.3869 - val_acc: 0.2400\n",
      "Epoch 1788/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.3180 - acc: 0.4843 - val_loss: 2.3901 - val_acc: 0.2400\n",
      "Epoch 1789/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.3178 - acc: 0.4843 - val_loss: 2.3749 - val_acc: 0.2367\n",
      "Epoch 1790/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.3174 - acc: 0.4871 - val_loss: 2.3711 - val_acc: 0.2400\n",
      "Epoch 1791/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.3179 - acc: 0.4800 - val_loss: 2.3893 - val_acc: 0.2400\n",
      "Epoch 1792/3000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.3168 - acc: 0.4800 - val_loss: 2.4146 - val_acc: 0.2467\n",
      "Epoch 1793/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3173 - acc: 0.4814 - val_loss: 2.4029 - val_acc: 0.2467\n",
      "Epoch 1794/3000\n",
      "700/700 [==============================] - 0s 98us/step - loss: 1.3168 - acc: 0.4843 - val_loss: 2.3970 - val_acc: 0.2467\n",
      "Epoch 1795/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.3176 - acc: 0.4829 - val_loss: 2.3992 - val_acc: 0.2467\n",
      "Epoch 1796/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.3167 - acc: 0.4843 - val_loss: 2.4206 - val_acc: 0.2533\n",
      "Epoch 1797/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.3163 - acc: 0.4800 - val_loss: 2.4033 - val_acc: 0.2400\n",
      "Epoch 1798/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.3176 - acc: 0.4843 - val_loss: 2.3914 - val_acc: 0.2433\n",
      "Epoch 1799/3000\n",
      "700/700 [==============================] - 0s 108us/step - loss: 1.3171 - acc: 0.4829 - val_loss: 2.4238 - val_acc: 0.2467\n",
      "Epoch 1800/3000\n",
      "700/700 [==============================] - 0s 108us/step - loss: 1.3170 - acc: 0.4829 - val_loss: 2.4107 - val_acc: 0.2467\n",
      "Epoch 1801/3000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 1.3163 - acc: 0.4900 - val_loss: 2.3858 - val_acc: 0.2400\n",
      "Epoch 1802/3000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.3164 - acc: 0.4843 - val_loss: 2.4091 - val_acc: 0.2467\n",
      "Epoch 1803/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.3163 - acc: 0.4857 - val_loss: 2.3956 - val_acc: 0.2467\n",
      "Epoch 1804/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.3168 - acc: 0.4886 - val_loss: 2.3896 - val_acc: 0.2433\n",
      "Epoch 1805/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.3167 - acc: 0.4829 - val_loss: 2.4091 - val_acc: 0.2467\n",
      "Epoch 1806/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.3166 - acc: 0.4814 - val_loss: 2.3916 - val_acc: 0.2400\n",
      "Epoch 1807/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.3161 - acc: 0.4800 - val_loss: 2.4098 - val_acc: 0.2500\n",
      "Epoch 1808/3000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.3158 - acc: 0.4814 - val_loss: 2.4058 - val_acc: 0.2500\n",
      "Epoch 1809/3000\n",
      "700/700 [==============================] - 0s 116us/step - loss: 1.3162 - acc: 0.4857 - val_loss: 2.3809 - val_acc: 0.2367\n",
      "Epoch 1810/3000\n",
      "700/700 [==============================] - 0s 117us/step - loss: 1.3163 - acc: 0.4829 - val_loss: 2.3936 - val_acc: 0.2400\n",
      "Epoch 1811/3000\n",
      "700/700 [==============================] - 0s 112us/step - loss: 1.3155 - acc: 0.4871 - val_loss: 2.3925 - val_acc: 0.2433\n",
      "Epoch 1812/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3154 - acc: 0.4857 - val_loss: 2.4142 - val_acc: 0.2500\n",
      "Epoch 1813/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.3163 - acc: 0.4800 - val_loss: 2.3938 - val_acc: 0.2400\n",
      "Epoch 1814/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.3163 - acc: 0.4771 - val_loss: 2.3994 - val_acc: 0.2467\n",
      "Epoch 1815/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.3155 - acc: 0.4900 - val_loss: 2.4154 - val_acc: 0.2433\n",
      "Epoch 1816/3000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.3152 - acc: 0.4886 - val_loss: 2.3907 - val_acc: 0.2433\n",
      "Epoch 1817/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.3151 - acc: 0.4871 - val_loss: 2.3909 - val_acc: 0.2400\n",
      "Epoch 1818/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.3168 - acc: 0.4800 - val_loss: 2.3940 - val_acc: 0.2467\n",
      "Epoch 1819/3000\n",
      "700/700 [==============================] - 0s 98us/step - loss: 1.3163 - acc: 0.4900 - val_loss: 2.4032 - val_acc: 0.2433\n",
      "Epoch 1820/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.3166 - acc: 0.4814 - val_loss: 2.3904 - val_acc: 0.2400\n",
      "Epoch 1821/3000\n",
      "700/700 [==============================] - 0s 121us/step - loss: 1.3151 - acc: 0.4800 - val_loss: 2.4299 - val_acc: 0.2467\n",
      "Epoch 1822/3000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 1.3153 - acc: 0.4914 - val_loss: 2.4040 - val_acc: 0.2467\n",
      "Epoch 1823/3000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.3146 - acc: 0.4814 - val_loss: 2.4296 - val_acc: 0.2467\n",
      "Epoch 1824/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.3158 - acc: 0.4814 - val_loss: 2.4033 - val_acc: 0.2500\n",
      "Epoch 1825/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.3152 - acc: 0.4843 - val_loss: 2.4164 - val_acc: 0.2467\n",
      "Epoch 1826/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.3152 - acc: 0.4814 - val_loss: 2.3840 - val_acc: 0.2400\n",
      "Epoch 1827/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3154 - acc: 0.4829 - val_loss: 2.4125 - val_acc: 0.2500\n",
      "Epoch 1828/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.3136 - acc: 0.4814 - val_loss: 2.3931 - val_acc: 0.2400\n",
      "Epoch 1829/3000\n",
      "700/700 [==============================] - 0s 108us/step - loss: 1.3161 - acc: 0.4786 - val_loss: 2.3973 - val_acc: 0.2400\n",
      "Epoch 1830/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.3144 - acc: 0.4871 - val_loss: 2.4081 - val_acc: 0.2400\n",
      "Epoch 1831/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.3147 - acc: 0.4914 - val_loss: 2.4016 - val_acc: 0.2433\n",
      "Epoch 1832/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.3146 - acc: 0.4843 - val_loss: 2.4111 - val_acc: 0.2433\n",
      "Epoch 1833/3000\n",
      "700/700 [==============================] - 0s 108us/step - loss: 1.3147 - acc: 0.4843 - val_loss: 2.4191 - val_acc: 0.2467\n",
      "Epoch 1834/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.3142 - acc: 0.4814 - val_loss: 2.4205 - val_acc: 0.2500\n",
      "Epoch 1835/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 103us/step - loss: 1.3144 - acc: 0.4886 - val_loss: 2.4117 - val_acc: 0.2433\n",
      "Epoch 1836/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.3149 - acc: 0.4871 - val_loss: 2.3977 - val_acc: 0.2433\n",
      "Epoch 1837/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.3143 - acc: 0.4857 - val_loss: 2.3980 - val_acc: 0.2467\n",
      "Epoch 1838/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.3139 - acc: 0.4857 - val_loss: 2.3960 - val_acc: 0.2433\n",
      "Epoch 1839/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.3132 - acc: 0.4871 - val_loss: 2.4220 - val_acc: 0.2533\n",
      "Epoch 1840/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.3145 - acc: 0.4900 - val_loss: 2.4064 - val_acc: 0.2433\n",
      "Epoch 1841/3000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.3128 - acc: 0.4886 - val_loss: 2.3915 - val_acc: 0.2433\n",
      "Epoch 1842/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 1.3139 - acc: 0.4871 - val_loss: 2.4198 - val_acc: 0.2467\n",
      "Epoch 1843/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3138 - acc: 0.4871 - val_loss: 2.4042 - val_acc: 0.2433\n",
      "Epoch 1844/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.3140 - acc: 0.4814 - val_loss: 2.4177 - val_acc: 0.2500\n",
      "Epoch 1845/3000\n",
      "700/700 [==============================] - 0s 82us/step - loss: 1.3134 - acc: 0.4871 - val_loss: 2.3881 - val_acc: 0.2433\n",
      "Epoch 1846/3000\n",
      "700/700 [==============================] - 0s 92us/step - loss: 1.3139 - acc: 0.4871 - val_loss: 2.4032 - val_acc: 0.2467\n",
      "Epoch 1847/3000\n",
      "700/700 [==============================] - 0s 85us/step - loss: 1.3150 - acc: 0.4857 - val_loss: 2.3747 - val_acc: 0.2467\n",
      "Epoch 1848/3000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.3146 - acc: 0.4843 - val_loss: 2.4096 - val_acc: 0.2467\n",
      "Epoch 1849/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3139 - acc: 0.4871 - val_loss: 2.4035 - val_acc: 0.2400\n",
      "Epoch 1850/3000\n",
      "700/700 [==============================] - 0s 92us/step - loss: 1.3132 - acc: 0.4800 - val_loss: 2.4156 - val_acc: 0.2467\n",
      "Epoch 1851/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3135 - acc: 0.4814 - val_loss: 2.4128 - val_acc: 0.2433\n",
      "Epoch 1852/3000\n",
      "700/700 [==============================] - 0s 92us/step - loss: 1.3133 - acc: 0.4843 - val_loss: 2.4234 - val_acc: 0.2433\n",
      "Epoch 1853/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.3131 - acc: 0.4843 - val_loss: 2.3969 - val_acc: 0.2400\n",
      "Epoch 1854/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.3129 - acc: 0.4886 - val_loss: 2.4072 - val_acc: 0.2400\n",
      "Epoch 1855/3000\n",
      "700/700 [==============================] - 0s 98us/step - loss: 1.3131 - acc: 0.4829 - val_loss: 2.4064 - val_acc: 0.2433\n",
      "Epoch 1856/3000\n",
      "700/700 [==============================] - 0s 98us/step - loss: 1.3115 - acc: 0.4829 - val_loss: 2.4003 - val_acc: 0.2433\n",
      "Epoch 1857/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.3131 - acc: 0.4843 - val_loss: 2.4012 - val_acc: 0.2367\n",
      "Epoch 1858/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.3130 - acc: 0.4857 - val_loss: 2.4183 - val_acc: 0.2467\n",
      "Epoch 1859/3000\n",
      "700/700 [==============================] - 0s 108us/step - loss: 1.3118 - acc: 0.4857 - val_loss: 2.3962 - val_acc: 0.2367\n",
      "Epoch 1860/3000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.3121 - acc: 0.4771 - val_loss: 2.4208 - val_acc: 0.2467\n",
      "Epoch 1861/3000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.3122 - acc: 0.4914 - val_loss: 2.4210 - val_acc: 0.2433\n",
      "Epoch 1862/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.3128 - acc: 0.4929 - val_loss: 2.4074 - val_acc: 0.2433\n",
      "Epoch 1863/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.3123 - acc: 0.4886 - val_loss: 2.4119 - val_acc: 0.2433\n",
      "Epoch 1864/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.3115 - acc: 0.4900 - val_loss: 2.4098 - val_acc: 0.2467\n",
      "Epoch 1865/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.3113 - acc: 0.4900 - val_loss: 2.4280 - val_acc: 0.2467\n",
      "Epoch 1866/3000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.3120 - acc: 0.4886 - val_loss: 2.4223 - val_acc: 0.2467\n",
      "Epoch 1867/3000\n",
      "700/700 [==============================] - 0s 98us/step - loss: 1.3118 - acc: 0.4900 - val_loss: 2.4151 - val_acc: 0.2400\n",
      "Epoch 1868/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.3120 - acc: 0.4900 - val_loss: 2.4161 - val_acc: 0.2333\n",
      "Epoch 1869/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.3112 - acc: 0.4886 - val_loss: 2.4308 - val_acc: 0.2500\n",
      "Epoch 1870/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.3119 - acc: 0.4829 - val_loss: 2.3962 - val_acc: 0.2400\n",
      "Epoch 1871/3000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.3115 - acc: 0.4843 - val_loss: 2.4017 - val_acc: 0.2400\n",
      "Epoch 1872/3000\n",
      "700/700 [==============================] - 0s 88us/step - loss: 1.3117 - acc: 0.4814 - val_loss: 2.4008 - val_acc: 0.2400\n",
      "Epoch 1873/3000\n",
      "700/700 [==============================] - 0s 98us/step - loss: 1.3112 - acc: 0.4886 - val_loss: 2.4363 - val_acc: 0.2467\n",
      "Epoch 1874/3000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.3111 - acc: 0.4914 - val_loss: 2.4240 - val_acc: 0.2467\n",
      "Epoch 1875/3000\n",
      "700/700 [==============================] - 0s 92us/step - loss: 1.3111 - acc: 0.4986 - val_loss: 2.4317 - val_acc: 0.2467\n",
      "Epoch 1876/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3110 - acc: 0.4800 - val_loss: 2.3957 - val_acc: 0.2400\n",
      "Epoch 1877/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.3115 - acc: 0.4814 - val_loss: 2.4075 - val_acc: 0.2467\n",
      "Epoch 1878/3000\n",
      "700/700 [==============================] - 0s 98us/step - loss: 1.3110 - acc: 0.4886 - val_loss: 2.4246 - val_acc: 0.2500\n",
      "Epoch 1879/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.3107 - acc: 0.4900 - val_loss: 2.4233 - val_acc: 0.2433\n",
      "Epoch 1880/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.3105 - acc: 0.4914 - val_loss: 2.4227 - val_acc: 0.2400\n",
      "Epoch 1881/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.3107 - acc: 0.4871 - val_loss: 2.4374 - val_acc: 0.2467\n",
      "Epoch 1882/3000\n",
      "700/700 [==============================] - 0s 92us/step - loss: 1.3107 - acc: 0.4800 - val_loss: 2.3999 - val_acc: 0.2400\n",
      "Epoch 1883/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.3110 - acc: 0.4843 - val_loss: 2.4181 - val_acc: 0.2433\n",
      "Epoch 1884/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.3105 - acc: 0.4886 - val_loss: 2.4078 - val_acc: 0.2400\n",
      "Epoch 1885/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.3100 - acc: 0.4843 - val_loss: 2.4092 - val_acc: 0.2433\n",
      "Epoch 1886/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3111 - acc: 0.4857 - val_loss: 2.4032 - val_acc: 0.2467\n",
      "Epoch 1887/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3104 - acc: 0.4843 - val_loss: 2.4163 - val_acc: 0.2400\n",
      "Epoch 1888/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3093 - acc: 0.4914 - val_loss: 2.4231 - val_acc: 0.2433\n",
      "Epoch 1889/3000\n",
      "700/700 [==============================] - 0s 98us/step - loss: 1.3107 - acc: 0.4886 - val_loss: 2.4046 - val_acc: 0.2433\n",
      "Epoch 1890/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.3101 - acc: 0.4900 - val_loss: 2.4126 - val_acc: 0.2433\n",
      "Epoch 1891/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.3103 - acc: 0.4900 - val_loss: 2.4160 - val_acc: 0.2433\n",
      "Epoch 1892/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.3100 - acc: 0.4871 - val_loss: 2.4098 - val_acc: 0.2367\n",
      "Epoch 1893/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.3097 - acc: 0.4843 - val_loss: 2.4279 - val_acc: 0.2467\n",
      "Epoch 1894/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 96us/step - loss: 1.3095 - acc: 0.4929 - val_loss: 2.4099 - val_acc: 0.2433\n",
      "Epoch 1895/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.3103 - acc: 0.4886 - val_loss: 2.4043 - val_acc: 0.2433\n",
      "Epoch 1896/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.3098 - acc: 0.4843 - val_loss: 2.4374 - val_acc: 0.2467\n",
      "Epoch 1897/3000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.3096 - acc: 0.4871 - val_loss: 2.4035 - val_acc: 0.2467\n",
      "Epoch 1898/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.3098 - acc: 0.4871 - val_loss: 2.3956 - val_acc: 0.2433\n",
      "Epoch 1899/3000\n",
      "700/700 [==============================] - 0s 117us/step - loss: 1.3096 - acc: 0.4843 - val_loss: 2.4153 - val_acc: 0.2467\n",
      "Epoch 1900/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.3094 - acc: 0.4914 - val_loss: 2.4146 - val_acc: 0.2400\n",
      "Epoch 1901/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.3098 - acc: 0.4843 - val_loss: 2.4055 - val_acc: 0.2433\n",
      "Epoch 1902/3000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.3094 - acc: 0.4843 - val_loss: 2.4347 - val_acc: 0.2433\n",
      "Epoch 1903/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.3084 - acc: 0.4857 - val_loss: 2.4099 - val_acc: 0.2433\n",
      "Epoch 1904/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.3091 - acc: 0.4943 - val_loss: 2.4342 - val_acc: 0.2467\n",
      "Epoch 1905/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.3096 - acc: 0.4871 - val_loss: 2.4348 - val_acc: 0.2467\n",
      "Epoch 1906/3000\n",
      "700/700 [==============================] - 0s 98us/step - loss: 1.3103 - acc: 0.4871 - val_loss: 2.4231 - val_acc: 0.2467\n",
      "Epoch 1907/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.3086 - acc: 0.4871 - val_loss: 2.4233 - val_acc: 0.2467\n",
      "Epoch 1908/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.3103 - acc: 0.4843 - val_loss: 2.4329 - val_acc: 0.2467\n",
      "Epoch 1909/3000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.3087 - acc: 0.4829 - val_loss: 2.4207 - val_acc: 0.2433\n",
      "Epoch 1910/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.3090 - acc: 0.4900 - val_loss: 2.4211 - val_acc: 0.2400\n",
      "Epoch 1911/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.3085 - acc: 0.4971 - val_loss: 2.4120 - val_acc: 0.2367\n",
      "Epoch 1912/3000\n",
      "700/700 [==============================] - 0s 152us/step - loss: 1.3086 - acc: 0.4886 - val_loss: 2.4163 - val_acc: 0.2500\n",
      "Epoch 1913/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.3085 - acc: 0.4871 - val_loss: 2.4254 - val_acc: 0.2433\n",
      "Epoch 1914/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.3073 - acc: 0.4857 - val_loss: 2.4305 - val_acc: 0.2500\n",
      "Epoch 1915/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.3084 - acc: 0.4843 - val_loss: 2.4372 - val_acc: 0.2467\n",
      "Epoch 1916/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.3083 - acc: 0.4871 - val_loss: 2.4052 - val_acc: 0.2467\n",
      "Epoch 1917/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3089 - acc: 0.4857 - val_loss: 2.4177 - val_acc: 0.2500\n",
      "Epoch 1918/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.3081 - acc: 0.4929 - val_loss: 2.4247 - val_acc: 0.2400\n",
      "Epoch 1919/3000\n",
      "700/700 [==============================] - 0s 125us/step - loss: 1.3082 - acc: 0.4900 - val_loss: 2.4210 - val_acc: 0.2367\n",
      "Epoch 1920/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.3091 - acc: 0.4886 - val_loss: 2.4232 - val_acc: 0.2467\n",
      "Epoch 1921/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.3080 - acc: 0.4914 - val_loss: 2.4200 - val_acc: 0.2467\n",
      "Epoch 1922/3000\n",
      "700/700 [==============================] - 0s 117us/step - loss: 1.3073 - acc: 0.4871 - val_loss: 2.4129 - val_acc: 0.2433\n",
      "Epoch 1923/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.3084 - acc: 0.4971 - val_loss: 2.4267 - val_acc: 0.2467\n",
      "Epoch 1924/3000\n",
      "700/700 [==============================] - 0s 92us/step - loss: 1.3078 - acc: 0.4843 - val_loss: 2.3982 - val_acc: 0.2433\n",
      "Epoch 1925/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.3075 - acc: 0.4900 - val_loss: 2.4373 - val_acc: 0.2400\n",
      "Epoch 1926/3000\n",
      "700/700 [==============================] - 0s 120us/step - loss: 1.3074 - acc: 0.4900 - val_loss: 2.4179 - val_acc: 0.2433\n",
      "Epoch 1927/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.3077 - acc: 0.4857 - val_loss: 2.4156 - val_acc: 0.2433\n",
      "Epoch 1928/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.3070 - acc: 0.4900 - val_loss: 2.4243 - val_acc: 0.2400\n",
      "Epoch 1929/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.3079 - acc: 0.4900 - val_loss: 2.4365 - val_acc: 0.2467\n",
      "Epoch 1930/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.3081 - acc: 0.4814 - val_loss: 2.4246 - val_acc: 0.2400\n",
      "Epoch 1931/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.3077 - acc: 0.4929 - val_loss: 2.4172 - val_acc: 0.2433\n",
      "Epoch 1932/3000\n",
      "700/700 [==============================] - 0s 143us/step - loss: 1.3073 - acc: 0.4886 - val_loss: 2.4317 - val_acc: 0.2467\n",
      "Epoch 1933/3000\n",
      "700/700 [==============================] - 0s 112us/step - loss: 1.3071 - acc: 0.4900 - val_loss: 2.4406 - val_acc: 0.2467\n",
      "Epoch 1934/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.3077 - acc: 0.4829 - val_loss: 2.4223 - val_acc: 0.2500\n",
      "Epoch 1935/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.3070 - acc: 0.4914 - val_loss: 2.4201 - val_acc: 0.2467\n",
      "Epoch 1936/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3073 - acc: 0.4886 - val_loss: 2.4456 - val_acc: 0.2467\n",
      "Epoch 1937/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3067 - acc: 0.4929 - val_loss: 2.4271 - val_acc: 0.2467\n",
      "Epoch 1938/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.3070 - acc: 0.4886 - val_loss: 2.4384 - val_acc: 0.2467\n",
      "Epoch 1939/3000\n",
      "700/700 [==============================] - 0s 116us/step - loss: 1.3072 - acc: 0.4929 - val_loss: 2.4312 - val_acc: 0.2467\n",
      "Epoch 1940/3000\n",
      "700/700 [==============================] - 0s 108us/step - loss: 1.3072 - acc: 0.4914 - val_loss: 2.4310 - val_acc: 0.2467\n",
      "Epoch 1941/3000\n",
      "700/700 [==============================] - 0s 123us/step - loss: 1.3068 - acc: 0.4843 - val_loss: 2.4157 - val_acc: 0.2467\n",
      "Epoch 1942/3000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 1.3067 - acc: 0.4929 - val_loss: 2.4383 - val_acc: 0.2467\n",
      "Epoch 1943/3000\n",
      "700/700 [==============================] - 0s 112us/step - loss: 1.3065 - acc: 0.4886 - val_loss: 2.4412 - val_acc: 0.2500\n",
      "Epoch 1944/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.3067 - acc: 0.4929 - val_loss: 2.4394 - val_acc: 0.2467\n",
      "Epoch 1945/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.3062 - acc: 0.4900 - val_loss: 2.4202 - val_acc: 0.2400\n",
      "Epoch 1946/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.3067 - acc: 0.4871 - val_loss: 2.4341 - val_acc: 0.2500\n",
      "Epoch 1947/3000\n",
      "700/700 [==============================] - 0s 98us/step - loss: 1.3070 - acc: 0.4843 - val_loss: 2.4148 - val_acc: 0.2400\n",
      "Epoch 1948/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3058 - acc: 0.4929 - val_loss: 2.4334 - val_acc: 0.2467\n",
      "Epoch 1949/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.3074 - acc: 0.4929 - val_loss: 2.4358 - val_acc: 0.2433\n",
      "Epoch 1950/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.3074 - acc: 0.4900 - val_loss: 2.4236 - val_acc: 0.2400\n",
      "Epoch 1951/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.3062 - acc: 0.4857 - val_loss: 2.4311 - val_acc: 0.2467\n",
      "Epoch 1952/3000\n",
      "700/700 [==============================] - 0s 112us/step - loss: 1.3066 - acc: 0.4871 - val_loss: 2.4509 - val_acc: 0.2467\n",
      "Epoch 1953/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 126us/step - loss: 1.3058 - acc: 0.4871 - val_loss: 2.4213 - val_acc: 0.2467\n",
      "Epoch 1954/3000\n",
      "700/700 [==============================] - 0s 142us/step - loss: 1.3060 - acc: 0.4914 - val_loss: 2.4233 - val_acc: 0.2467\n",
      "Epoch 1955/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.3062 - acc: 0.4871 - val_loss: 2.4327 - val_acc: 0.2467\n",
      "Epoch 1956/3000\n",
      "700/700 [==============================] - 0s 112us/step - loss: 1.3058 - acc: 0.4929 - val_loss: 2.4377 - val_acc: 0.2467\n",
      "Epoch 1957/3000\n",
      "700/700 [==============================] - 0s 194us/step - loss: 1.3058 - acc: 0.4900 - val_loss: 2.4066 - val_acc: 0.2433\n",
      "Epoch 1958/3000\n",
      "700/700 [==============================] - 0s 158us/step - loss: 1.3063 - acc: 0.4871 - val_loss: 2.4146 - val_acc: 0.2433\n",
      "Epoch 1959/3000\n",
      "700/700 [==============================] - 0s 131us/step - loss: 1.3056 - acc: 0.4929 - val_loss: 2.4186 - val_acc: 0.2467\n",
      "Epoch 1960/3000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.3061 - acc: 0.4914 - val_loss: 2.4311 - val_acc: 0.2433\n",
      "Epoch 1961/3000\n",
      "700/700 [==============================] - 0s 122us/step - loss: 1.3057 - acc: 0.4886 - val_loss: 2.4492 - val_acc: 0.2467\n",
      "Epoch 1962/3000\n",
      "700/700 [==============================] - 0s 131us/step - loss: 1.3055 - acc: 0.4943 - val_loss: 2.4392 - val_acc: 0.2433\n",
      "Epoch 1963/3000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.3051 - acc: 0.4900 - val_loss: 2.4361 - val_acc: 0.2467\n",
      "Epoch 1964/3000\n",
      "700/700 [==============================] - ETA: 0s - loss: 1.2866 - acc: 0.512 - 0s 127us/step - loss: 1.3053 - acc: 0.4886 - val_loss: 2.4309 - val_acc: 0.2400\n",
      "Epoch 1965/3000\n",
      "700/700 [==============================] - 0s 115us/step - loss: 1.3054 - acc: 0.4871 - val_loss: 2.4380 - val_acc: 0.2467\n",
      "Epoch 1966/3000\n",
      "700/700 [==============================] - 0s 122us/step - loss: 1.3055 - acc: 0.4914 - val_loss: 2.4372 - val_acc: 0.2433\n",
      "Epoch 1967/3000\n",
      "700/700 [==============================] - 0s 121us/step - loss: 1.3054 - acc: 0.4929 - val_loss: 2.4313 - val_acc: 0.2433\n",
      "Epoch 1968/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.3048 - acc: 0.4886 - val_loss: 2.4456 - val_acc: 0.2500\n",
      "Epoch 1969/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.3059 - acc: 0.4943 - val_loss: 2.4471 - val_acc: 0.2467\n",
      "Epoch 1970/3000\n",
      "700/700 [==============================] - 0s 139us/step - loss: 1.3051 - acc: 0.4857 - val_loss: 2.4418 - val_acc: 0.2467\n",
      "Epoch 1971/3000\n",
      "700/700 [==============================] - 0s 116us/step - loss: 1.3050 - acc: 0.4886 - val_loss: 2.4395 - val_acc: 0.2433\n",
      "Epoch 1972/3000\n",
      "700/700 [==============================] - 0s 129us/step - loss: 1.3037 - acc: 0.4914 - val_loss: 2.4340 - val_acc: 0.2433\n",
      "Epoch 1973/3000\n",
      "700/700 [==============================] - 0s 137us/step - loss: 1.3055 - acc: 0.4957 - val_loss: 2.4432 - val_acc: 0.2467\n",
      "Epoch 1974/3000\n",
      "700/700 [==============================] - 0s 139us/step - loss: 1.3047 - acc: 0.4900 - val_loss: 2.4182 - val_acc: 0.2433\n",
      "Epoch 1975/3000\n",
      "700/700 [==============================] - 0s 141us/step - loss: 1.3050 - acc: 0.4900 - val_loss: 2.4307 - val_acc: 0.2500\n",
      "Epoch 1976/3000\n",
      "700/700 [==============================] - 0s 147us/step - loss: 1.3052 - acc: 0.4843 - val_loss: 2.4415 - val_acc: 0.2467\n",
      "Epoch 1977/3000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 1.3048 - acc: 0.4914 - val_loss: 2.4178 - val_acc: 0.2467\n",
      "Epoch 1978/3000\n",
      "700/700 [==============================] - 0s 131us/step - loss: 1.3053 - acc: 0.4943 - val_loss: 2.4349 - val_acc: 0.2433\n",
      "Epoch 1979/3000\n",
      "700/700 [==============================] - 0s 148us/step - loss: 1.3041 - acc: 0.4871 - val_loss: 2.4538 - val_acc: 0.2467\n",
      "Epoch 1980/3000\n",
      "700/700 [==============================] - 0s 130us/step - loss: 1.3032 - acc: 0.4900 - val_loss: 2.4258 - val_acc: 0.2433\n",
      "Epoch 1981/3000\n",
      "700/700 [==============================] - 0s 199us/step - loss: 1.3044 - acc: 0.4871 - val_loss: 2.4284 - val_acc: 0.2433\n",
      "Epoch 1982/3000\n",
      "700/700 [==============================] - 0s 137us/step - loss: 1.3043 - acc: 0.4929 - val_loss: 2.4374 - val_acc: 0.2500\n",
      "Epoch 1983/3000\n",
      "700/700 [==============================] - 0s 133us/step - loss: 1.3043 - acc: 0.4886 - val_loss: 2.4305 - val_acc: 0.2433\n",
      "Epoch 1984/3000\n",
      "700/700 [==============================] - 0s 129us/step - loss: 1.3046 - acc: 0.4929 - val_loss: 2.4338 - val_acc: 0.2433\n",
      "Epoch 1985/3000\n",
      "700/700 [==============================] - 0s 198us/step - loss: 1.3039 - acc: 0.4957 - val_loss: 2.4500 - val_acc: 0.2500\n",
      "Epoch 1986/3000\n",
      "700/700 [==============================] - 0s 119us/step - loss: 1.3050 - acc: 0.4886 - val_loss: 2.4420 - val_acc: 0.2433\n",
      "Epoch 1987/3000\n",
      "700/700 [==============================] - 0s 122us/step - loss: 1.3042 - acc: 0.4929 - val_loss: 2.4254 - val_acc: 0.2500\n",
      "Epoch 1988/3000\n",
      "700/700 [==============================] - 0s 118us/step - loss: 1.3054 - acc: 0.4857 - val_loss: 2.4581 - val_acc: 0.2467\n",
      "Epoch 1989/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.3043 - acc: 0.4986 - val_loss: 2.4382 - val_acc: 0.2433\n",
      "Epoch 1990/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.3037 - acc: 0.4857 - val_loss: 2.4328 - val_acc: 0.2433\n",
      "Epoch 1991/3000\n",
      "700/700 [==============================] - 0s 130us/step - loss: 1.3036 - acc: 0.4957 - val_loss: 2.4367 - val_acc: 0.2467\n",
      "Epoch 1992/3000\n",
      "700/700 [==============================] - 0s 140us/step - loss: 1.3035 - acc: 0.4886 - val_loss: 2.4605 - val_acc: 0.2500\n",
      "Epoch 1993/3000\n",
      "700/700 [==============================] - 0s 143us/step - loss: 1.3039 - acc: 0.4900 - val_loss: 2.4101 - val_acc: 0.2467\n",
      "Epoch 1994/3000\n",
      "700/700 [==============================] - 0s 122us/step - loss: 1.3044 - acc: 0.4943 - val_loss: 2.4379 - val_acc: 0.2467\n",
      "Epoch 1995/3000\n",
      "700/700 [==============================] - 0s 145us/step - loss: 1.3035 - acc: 0.4886 - val_loss: 2.4504 - val_acc: 0.2467\n",
      "Epoch 1996/3000\n",
      "700/700 [==============================] - 0s 130us/step - loss: 1.3034 - acc: 0.4914 - val_loss: 2.4537 - val_acc: 0.2467\n",
      "Epoch 1997/3000\n",
      "700/700 [==============================] - 0s 140us/step - loss: 1.3034 - acc: 0.4943 - val_loss: 2.4204 - val_acc: 0.2433\n",
      "Epoch 1998/3000\n",
      "700/700 [==============================] - 0s 145us/step - loss: 1.3031 - acc: 0.4886 - val_loss: 2.4700 - val_acc: 0.2433\n",
      "Epoch 1999/3000\n",
      "700/700 [==============================] - 0s 226us/step - loss: 1.3042 - acc: 0.4886 - val_loss: 2.4574 - val_acc: 0.2467\n",
      "Epoch 2000/3000\n",
      "700/700 [==============================] - 0s 191us/step - loss: 1.3034 - acc: 0.4886 - val_loss: 2.4427 - val_acc: 0.2467\n",
      "Epoch 2001/3000\n",
      "700/700 [==============================] - 0s 175us/step - loss: 1.3032 - acc: 0.4900 - val_loss: 2.4129 - val_acc: 0.2433\n",
      "Epoch 2002/3000\n",
      "700/700 [==============================] - 0s 162us/step - loss: 1.3037 - acc: 0.4900 - val_loss: 2.4391 - val_acc: 0.2433\n",
      "Epoch 2003/3000\n",
      "700/700 [==============================] - 0s 179us/step - loss: 1.3037 - acc: 0.4900 - val_loss: 2.4626 - val_acc: 0.2433\n",
      "Epoch 2004/3000\n",
      "700/700 [==============================] - 0s 132us/step - loss: 1.3033 - acc: 0.4886 - val_loss: 2.4370 - val_acc: 0.2433\n",
      "Epoch 2005/3000\n",
      "700/700 [==============================] - 0s 170us/step - loss: 1.3031 - acc: 0.4871 - val_loss: 2.4502 - val_acc: 0.2500\n",
      "Epoch 2006/3000\n",
      "700/700 [==============================] - 0s 174us/step - loss: 1.3026 - acc: 0.4914 - val_loss: 2.4572 - val_acc: 0.2467\n",
      "Epoch 2007/3000\n",
      "700/700 [==============================] - 0s 132us/step - loss: 1.3023 - acc: 0.4957 - val_loss: 2.4344 - val_acc: 0.2433\n",
      "Epoch 2008/3000\n",
      "700/700 [==============================] - 0s 168us/step - loss: 1.3026 - acc: 0.4914 - val_loss: 2.4663 - val_acc: 0.2533\n",
      "Epoch 2009/3000\n",
      "700/700 [==============================] - 0s 143us/step - loss: 1.3039 - acc: 0.4943 - val_loss: 2.4358 - val_acc: 0.2433\n",
      "Epoch 2010/3000\n",
      "700/700 [==============================] - 0s 147us/step - loss: 1.3027 - acc: 0.4914 - val_loss: 2.4363 - val_acc: 0.2467\n",
      "Epoch 2011/3000\n",
      "700/700 [==============================] - 0s 124us/step - loss: 1.3031 - acc: 0.4957 - val_loss: 2.4518 - val_acc: 0.2500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2012/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.3027 - acc: 0.4886 - val_loss: 2.4264 - val_acc: 0.2467\n",
      "Epoch 2013/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.3024 - acc: 0.4943 - val_loss: 2.4326 - val_acc: 0.2400\n",
      "Epoch 2014/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.3023 - acc: 0.4971 - val_loss: 2.4859 - val_acc: 0.2433\n",
      "Epoch 2015/3000\n",
      "700/700 [==============================] - 0s 140us/step - loss: 1.3021 - acc: 0.4914 - val_loss: 2.4355 - val_acc: 0.2467\n",
      "Epoch 2016/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.3022 - acc: 0.4871 - val_loss: 2.4712 - val_acc: 0.2433\n",
      "Epoch 2017/3000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.3022 - acc: 0.4929 - val_loss: 2.4344 - val_acc: 0.2433\n",
      "Epoch 2018/3000\n",
      "700/700 [==============================] - 0s 119us/step - loss: 1.3018 - acc: 0.4914 - val_loss: 2.4527 - val_acc: 0.2467\n",
      "Epoch 2019/3000\n",
      "700/700 [==============================] - 0s 125us/step - loss: 1.3026 - acc: 0.4900 - val_loss: 2.4196 - val_acc: 0.2433\n",
      "Epoch 2020/3000\n",
      "700/700 [==============================] - 0s 202us/step - loss: 1.3023 - acc: 0.4986 - val_loss: 2.4488 - val_acc: 0.2467\n",
      "Epoch 2021/3000\n",
      "700/700 [==============================] - 0s 134us/step - loss: 1.3023 - acc: 0.4943 - val_loss: 2.4569 - val_acc: 0.2467\n",
      "Epoch 2022/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.3026 - acc: 0.4943 - val_loss: 2.4399 - val_acc: 0.2400\n",
      "Epoch 2023/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.3022 - acc: 0.4914 - val_loss: 2.4296 - val_acc: 0.2433\n",
      "Epoch 2024/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.3023 - acc: 0.4886 - val_loss: 2.4700 - val_acc: 0.2433\n",
      "Epoch 2025/3000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.3022 - acc: 0.4986 - val_loss: 2.4508 - val_acc: 0.2467\n",
      "Epoch 2026/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.3020 - acc: 0.4943 - val_loss: 2.4350 - val_acc: 0.2433\n",
      "Epoch 2027/3000\n",
      "700/700 [==============================] - 0s 98us/step - loss: 1.3024 - acc: 0.4971 - val_loss: 2.4366 - val_acc: 0.2400\n",
      "Epoch 2028/3000\n",
      "700/700 [==============================] - 0s 112us/step - loss: 1.3016 - acc: 0.4943 - val_loss: 2.4652 - val_acc: 0.2467\n",
      "Epoch 2029/3000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.3011 - acc: 0.4957 - val_loss: 2.4213 - val_acc: 0.2400\n",
      "Epoch 2030/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.3010 - acc: 0.5014 - val_loss: 2.4709 - val_acc: 0.2433\n",
      "Epoch 2031/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.3014 - acc: 0.4914 - val_loss: 2.4196 - val_acc: 0.2400\n",
      "Epoch 2032/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.3021 - acc: 0.4957 - val_loss: 2.4411 - val_acc: 0.2467\n",
      "Epoch 2033/3000\n",
      "700/700 [==============================] - 0s 108us/step - loss: 1.3015 - acc: 0.4929 - val_loss: 2.4544 - val_acc: 0.2467\n",
      "Epoch 2034/3000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 1.3017 - acc: 0.4857 - val_loss: 2.4386 - val_acc: 0.2400\n",
      "Epoch 2035/3000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.3010 - acc: 0.4929 - val_loss: 2.4296 - val_acc: 0.2400\n",
      "Epoch 2036/3000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 1.3018 - acc: 0.4900 - val_loss: 2.4391 - val_acc: 0.2467\n",
      "Epoch 2037/3000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.2999 - acc: 0.4943 - val_loss: 2.4401 - val_acc: 0.2467\n",
      "Epoch 2038/3000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 1.3010 - acc: 0.4900 - val_loss: 2.4413 - val_acc: 0.2433\n",
      "Epoch 2039/3000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 1.3019 - acc: 0.4971 - val_loss: 2.4606 - val_acc: 0.2467\n",
      "Epoch 2040/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.3016 - acc: 0.4986 - val_loss: 2.4567 - val_acc: 0.2467\n",
      "Epoch 2041/3000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.3003 - acc: 0.4886 - val_loss: 2.4597 - val_acc: 0.2500\n",
      "Epoch 2042/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.3011 - acc: 0.4943 - val_loss: 2.4712 - val_acc: 0.2500\n",
      "Epoch 2043/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.3008 - acc: 0.4914 - val_loss: 2.4627 - val_acc: 0.2467\n",
      "Epoch 2044/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.3010 - acc: 0.4929 - val_loss: 2.4516 - val_acc: 0.2467\n",
      "Epoch 2045/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.3015 - acc: 0.4957 - val_loss: 2.4767 - val_acc: 0.2433\n",
      "Epoch 2046/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3006 - acc: 0.4957 - val_loss: 2.4361 - val_acc: 0.2433\n",
      "Epoch 2047/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3000 - acc: 0.4929 - val_loss: 2.4499 - val_acc: 0.2500\n",
      "Epoch 2048/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3002 - acc: 0.4986 - val_loss: 2.4353 - val_acc: 0.2467\n",
      "Epoch 2049/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3027 - acc: 0.4929 - val_loss: 2.4673 - val_acc: 0.2467\n",
      "Epoch 2050/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3009 - acc: 0.4900 - val_loss: 2.4643 - val_acc: 0.2433\n",
      "Epoch 2051/3000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.3010 - acc: 0.4914 - val_loss: 2.4495 - val_acc: 0.2400\n",
      "Epoch 2052/3000\n",
      "700/700 [==============================] - 0s 87us/step - loss: 1.3010 - acc: 0.4986 - val_loss: 2.4456 - val_acc: 0.2467\n",
      "Epoch 2053/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.3010 - acc: 0.4900 - val_loss: 2.4446 - val_acc: 0.2400\n",
      "Epoch 2054/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.3001 - acc: 0.4971 - val_loss: 2.4510 - val_acc: 0.2433\n",
      "Epoch 2055/3000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.3009 - acc: 0.4914 - val_loss: 2.4450 - val_acc: 0.2400\n",
      "Epoch 2056/3000\n",
      "700/700 [==============================] - 0s 112us/step - loss: 1.2997 - acc: 0.4971 - val_loss: 2.4661 - val_acc: 0.2433\n",
      "Epoch 2057/3000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.3009 - acc: 0.4929 - val_loss: 2.4549 - val_acc: 0.2433\n",
      "Epoch 2058/3000\n",
      "700/700 [==============================] - 0s 108us/step - loss: 1.2992 - acc: 0.4957 - val_loss: 2.4701 - val_acc: 0.2467\n",
      "Epoch 2059/3000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.3000 - acc: 0.4957 - val_loss: 2.4543 - val_acc: 0.2467\n",
      "Epoch 2060/3000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 1.3001 - acc: 0.4929 - val_loss: 2.4565 - val_acc: 0.2467\n",
      "Epoch 2061/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.2998 - acc: 0.4914 - val_loss: 2.4527 - val_acc: 0.2500\n",
      "Epoch 2062/3000\n",
      "700/700 [==============================] - 0s 75us/step - loss: 1.2999 - acc: 0.4914 - val_loss: 2.4581 - val_acc: 0.2467\n",
      "Epoch 2063/3000\n",
      "700/700 [==============================] - 0s 78us/step - loss: 1.2992 - acc: 0.4929 - val_loss: 2.4588 - val_acc: 0.2433\n",
      "Epoch 2064/3000\n",
      "700/700 [==============================] - 0s 76us/step - loss: 1.2997 - acc: 0.4900 - val_loss: 2.4588 - val_acc: 0.2500\n",
      "Epoch 2065/3000\n",
      "700/700 [==============================] - 0s 75us/step - loss: 1.2999 - acc: 0.4943 - val_loss: 2.4649 - val_acc: 0.2467\n",
      "Epoch 2066/3000\n",
      "700/700 [==============================] - 0s 75us/step - loss: 1.2998 - acc: 0.4971 - val_loss: 2.4641 - val_acc: 0.2433\n",
      "Epoch 2067/3000\n",
      "700/700 [==============================] - 0s 78us/step - loss: 1.2998 - acc: 0.4900 - val_loss: 2.4589 - val_acc: 0.2500\n",
      "Epoch 2068/3000\n",
      "700/700 [==============================] - 0s 75us/step - loss: 1.2994 - acc: 0.4914 - val_loss: 2.4595 - val_acc: 0.2467\n",
      "Epoch 2069/3000\n",
      "700/700 [==============================] - 0s 76us/step - loss: 1.2988 - acc: 0.4957 - val_loss: 2.4994 - val_acc: 0.2467\n",
      "Epoch 2070/3000\n",
      "700/700 [==============================] - 0s 76us/step - loss: 1.2995 - acc: 0.4929 - val_loss: 2.4809 - val_acc: 0.2433\n",
      "Epoch 2071/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 76us/step - loss: 1.2997 - acc: 0.4943 - val_loss: 2.4696 - val_acc: 0.2467\n",
      "Epoch 2072/3000\n",
      "700/700 [==============================] - 0s 77us/step - loss: 1.2992 - acc: 0.4929 - val_loss: 2.4766 - val_acc: 0.2467\n",
      "Epoch 2073/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.2997 - acc: 0.4886 - val_loss: 2.4637 - val_acc: 0.2500\n",
      "Epoch 2074/3000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.2992 - acc: 0.4971 - val_loss: 2.4524 - val_acc: 0.2467\n",
      "Epoch 2075/3000\n",
      "700/700 [==============================] - 0s 108us/step - loss: 1.2995 - acc: 0.4929 - val_loss: 2.4490 - val_acc: 0.2467\n",
      "Epoch 2076/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.2994 - acc: 0.4886 - val_loss: 2.4519 - val_acc: 0.2433\n",
      "Epoch 2077/3000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 1.2988 - acc: 0.4943 - val_loss: 2.4691 - val_acc: 0.2500\n",
      "Epoch 2078/3000\n",
      "700/700 [==============================] - 0s 83us/step - loss: 1.2989 - acc: 0.4914 - val_loss: 2.4584 - val_acc: 0.2433\n",
      "Epoch 2079/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.2988 - acc: 0.4957 - val_loss: 2.4758 - val_acc: 0.2433\n",
      "Epoch 2080/3000\n",
      "700/700 [==============================] - 0s 88us/step - loss: 1.2991 - acc: 0.4986 - val_loss: 2.4716 - val_acc: 0.2433\n",
      "Epoch 2081/3000\n",
      "700/700 [==============================] - 0s 86us/step - loss: 1.2996 - acc: 0.4929 - val_loss: 2.4861 - val_acc: 0.2400\n",
      "Epoch 2082/3000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 1.2989 - acc: 0.4871 - val_loss: 2.4354 - val_acc: 0.2367\n",
      "Epoch 2083/3000\n",
      "700/700 [==============================] - 0s 78us/step - loss: 1.2995 - acc: 0.4943 - val_loss: 2.4545 - val_acc: 0.2467\n",
      "Epoch 2084/3000\n",
      "700/700 [==============================] - 0s 78us/step - loss: 1.2980 - acc: 0.4943 - val_loss: 2.4486 - val_acc: 0.2533\n",
      "Epoch 2085/3000\n",
      "700/700 [==============================] - 0s 76us/step - loss: 1.2988 - acc: 0.4929 - val_loss: 2.4398 - val_acc: 0.2433\n",
      "Epoch 2086/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.2981 - acc: 0.4929 - val_loss: 2.4545 - val_acc: 0.2500\n",
      "Epoch 2087/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.2986 - acc: 0.4971 - val_loss: 2.4854 - val_acc: 0.2500\n",
      "Epoch 2088/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.2992 - acc: 0.4957 - val_loss: 2.4626 - val_acc: 0.2467\n",
      "Epoch 2089/3000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 1.2988 - acc: 0.4914 - val_loss: 2.4632 - val_acc: 0.2467\n",
      "Epoch 2090/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.2982 - acc: 0.4957 - val_loss: 2.4897 - val_acc: 0.2467\n",
      "Epoch 2091/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.2980 - acc: 0.4943 - val_loss: 2.4606 - val_acc: 0.2500\n",
      "Epoch 2092/3000\n",
      "700/700 [==============================] - 0s 119us/step - loss: 1.2981 - acc: 0.4943 - val_loss: 2.4767 - val_acc: 0.2467\n",
      "Epoch 2093/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.2982 - acc: 0.4871 - val_loss: 2.4733 - val_acc: 0.2467\n",
      "Epoch 2094/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.2985 - acc: 0.4957 - val_loss: 2.4782 - val_acc: 0.2467\n",
      "Epoch 2095/3000\n",
      "700/700 [==============================] - 0s 116us/step - loss: 1.2973 - acc: 0.4943 - val_loss: 2.4831 - val_acc: 0.2500\n",
      "Epoch 2096/3000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 1.2981 - acc: 0.4914 - val_loss: 2.4651 - val_acc: 0.2467\n",
      "Epoch 2097/3000\n",
      "700/700 [==============================] - 0s 121us/step - loss: 1.2972 - acc: 0.4929 - val_loss: 2.4590 - val_acc: 0.2467\n",
      "Epoch 2098/3000\n",
      "700/700 [==============================] - 0s 118us/step - loss: 1.2968 - acc: 0.4943 - val_loss: 2.4519 - val_acc: 0.2433\n",
      "Epoch 2099/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.2983 - acc: 0.4914 - val_loss: 2.4648 - val_acc: 0.2467\n",
      "Epoch 2100/3000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 1.2978 - acc: 0.4914 - val_loss: 2.4563 - val_acc: 0.2433\n",
      "Epoch 2101/3000\n",
      "700/700 [==============================] - 0s 84us/step - loss: 1.2982 - acc: 0.5000 - val_loss: 2.4637 - val_acc: 0.2467\n",
      "Epoch 2102/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.2982 - acc: 0.4957 - val_loss: 2.4694 - val_acc: 0.2467\n",
      "Epoch 2103/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.2974 - acc: 0.4943 - val_loss: 2.4745 - val_acc: 0.2467\n",
      "Epoch 2104/3000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.2977 - acc: 0.4971 - val_loss: 2.4507 - val_acc: 0.2433\n",
      "Epoch 2105/3000\n",
      "700/700 [==============================] - 0s 115us/step - loss: 1.2970 - acc: 0.4900 - val_loss: 2.4647 - val_acc: 0.2500\n",
      "Epoch 2106/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.2980 - acc: 0.4971 - val_loss: 2.4468 - val_acc: 0.2500\n",
      "Epoch 2107/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.2974 - acc: 0.4900 - val_loss: 2.4580 - val_acc: 0.2433\n",
      "Epoch 2108/3000\n",
      "700/700 [==============================] - 0s 112us/step - loss: 1.2975 - acc: 0.4929 - val_loss: 2.4763 - val_acc: 0.2467\n",
      "Epoch 2109/3000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 1.2975 - acc: 0.4943 - val_loss: 2.4715 - val_acc: 0.2500\n",
      "Epoch 2110/3000\n",
      "700/700 [==============================] - 0s 119us/step - loss: 1.2982 - acc: 0.4971 - val_loss: 2.4631 - val_acc: 0.2433\n",
      "Epoch 2111/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.2983 - acc: 0.4957 - val_loss: 2.4550 - val_acc: 0.2467\n",
      "Epoch 2112/3000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.2969 - acc: 0.4971 - val_loss: 2.4858 - val_acc: 0.2467\n",
      "Epoch 2113/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.2977 - acc: 0.4957 - val_loss: 2.4664 - val_acc: 0.2467\n",
      "Epoch 2114/3000\n",
      "700/700 [==============================] - 0s 118us/step - loss: 1.2966 - acc: 0.4971 - val_loss: 2.4580 - val_acc: 0.2433\n",
      "Epoch 2115/3000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.2975 - acc: 0.4971 - val_loss: 2.4843 - val_acc: 0.2400\n",
      "Epoch 2116/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.2974 - acc: 0.4971 - val_loss: 2.4733 - val_acc: 0.2467\n",
      "Epoch 2117/3000\n",
      "700/700 [==============================] - 0s 83us/step - loss: 1.2972 - acc: 0.4957 - val_loss: 2.4881 - val_acc: 0.2467\n",
      "Epoch 2118/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.2965 - acc: 0.4971 - val_loss: 2.4681 - val_acc: 0.2467\n",
      "Epoch 2119/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.2968 - acc: 0.4929 - val_loss: 2.4712 - val_acc: 0.2433\n",
      "Epoch 2120/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.2963 - acc: 0.4943 - val_loss: 2.4752 - val_acc: 0.2467\n",
      "Epoch 2121/3000\n",
      "700/700 [==============================] - 0s 164us/step - loss: 1.2965 - acc: 0.4986 - val_loss: 2.4960 - val_acc: 0.2400\n",
      "Epoch 2122/3000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.2971 - acc: 0.4971 - val_loss: 2.4813 - val_acc: 0.2467\n",
      "Epoch 2123/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.2964 - acc: 0.4986 - val_loss: 2.4780 - val_acc: 0.2400\n",
      "Epoch 2124/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.2966 - acc: 0.4971 - val_loss: 2.4745 - val_acc: 0.2467\n",
      "Epoch 2125/3000\n",
      "700/700 [==============================] - 0s 120us/step - loss: 1.2963 - acc: 0.5000 - val_loss: 2.4574 - val_acc: 0.2467\n",
      "Epoch 2126/3000\n",
      "700/700 [==============================] - 0s 112us/step - loss: 1.2968 - acc: 0.4929 - val_loss: 2.4727 - val_acc: 0.2467\n",
      "Epoch 2127/3000\n",
      "700/700 [==============================] - 0s 135us/step - loss: 1.2968 - acc: 0.4929 - val_loss: 2.4635 - val_acc: 0.2467\n",
      "Epoch 2128/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.2965 - acc: 0.4957 - val_loss: 2.4904 - val_acc: 0.2467\n",
      "Epoch 2129/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.2966 - acc: 0.4914 - val_loss: 2.4708 - val_acc: 0.2433\n",
      "Epoch 2130/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 109us/step - loss: 1.2965 - acc: 0.4971 - val_loss: 2.4645 - val_acc: 0.2433\n",
      "Epoch 2131/3000\n",
      "700/700 [==============================] - 0s 108us/step - loss: 1.2963 - acc: 0.4957 - val_loss: 2.4678 - val_acc: 0.2467\n",
      "Epoch 2132/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.2968 - acc: 0.4929 - val_loss: 2.4702 - val_acc: 0.2400\n",
      "Epoch 2133/3000\n",
      "700/700 [==============================] - 0s 112us/step - loss: 1.2961 - acc: 0.4900 - val_loss: 2.4769 - val_acc: 0.2500\n",
      "Epoch 2134/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.2963 - acc: 0.4986 - val_loss: 2.4696 - val_acc: 0.2433\n",
      "Epoch 2135/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.2955 - acc: 0.4971 - val_loss: 2.4729 - val_acc: 0.2467\n",
      "Epoch 2136/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.2963 - acc: 0.4914 - val_loss: 2.4537 - val_acc: 0.2433\n",
      "Epoch 2137/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.2957 - acc: 0.4943 - val_loss: 2.4775 - val_acc: 0.2433\n",
      "Epoch 2138/3000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 1.2967 - acc: 0.4900 - val_loss: 2.4863 - val_acc: 0.2467\n",
      "Epoch 2139/3000\n",
      "700/700 [==============================] - 0s 122us/step - loss: 1.2954 - acc: 0.4986 - val_loss: 2.4723 - val_acc: 0.2433\n",
      "Epoch 2140/3000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.2958 - acc: 0.4886 - val_loss: 2.4800 - val_acc: 0.2433\n",
      "Epoch 2141/3000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.2965 - acc: 0.4943 - val_loss: 2.4799 - val_acc: 0.2467\n",
      "Epoch 2142/3000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 1.2952 - acc: 0.4971 - val_loss: 2.4766 - val_acc: 0.2433\n",
      "Epoch 2143/3000\n",
      "700/700 [==============================] - 0s 116us/step - loss: 1.2961 - acc: 0.4929 - val_loss: 2.4866 - val_acc: 0.2433\n",
      "Epoch 2144/3000\n",
      "700/700 [==============================] - 0s 117us/step - loss: 1.2960 - acc: 0.4914 - val_loss: 2.4777 - val_acc: 0.2467\n",
      "Epoch 2145/3000\n",
      "700/700 [==============================] - 0s 133us/step - loss: 1.2951 - acc: 0.4929 - val_loss: 2.4603 - val_acc: 0.2467\n",
      "Epoch 2146/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.2947 - acc: 0.4943 - val_loss: 2.4420 - val_acc: 0.2467\n",
      "Epoch 2147/3000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.2954 - acc: 0.5014 - val_loss: 2.4796 - val_acc: 0.2467\n",
      "Epoch 2148/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.2960 - acc: 0.4814 - val_loss: 2.4760 - val_acc: 0.2500\n",
      "Epoch 2149/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.2946 - acc: 0.4971 - val_loss: 2.4446 - val_acc: 0.2433\n",
      "Epoch 2150/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.2951 - acc: 0.4929 - val_loss: 2.4616 - val_acc: 0.2533\n",
      "Epoch 2151/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.2953 - acc: 0.4957 - val_loss: 2.4908 - val_acc: 0.2400\n",
      "Epoch 2152/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.2947 - acc: 0.4900 - val_loss: 2.4911 - val_acc: 0.2467\n",
      "Epoch 2153/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.2950 - acc: 0.4914 - val_loss: 2.4754 - val_acc: 0.2467\n",
      "Epoch 2154/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.2948 - acc: 0.4986 - val_loss: 2.4995 - val_acc: 0.2400\n",
      "Epoch 2155/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.2949 - acc: 0.4943 - val_loss: 2.4922 - val_acc: 0.2433\n",
      "Epoch 2156/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.2944 - acc: 0.5000 - val_loss: 2.4978 - val_acc: 0.2433\n",
      "Epoch 2157/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.2947 - acc: 0.4914 - val_loss: 2.4538 - val_acc: 0.2467\n",
      "Epoch 2158/3000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 1.2944 - acc: 0.4971 - val_loss: 2.5045 - val_acc: 0.2433\n",
      "Epoch 2159/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.2944 - acc: 0.4971 - val_loss: 2.4635 - val_acc: 0.2433\n",
      "Epoch 2160/3000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.2949 - acc: 0.4957 - val_loss: 2.4945 - val_acc: 0.2467\n",
      "Epoch 2161/3000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.2948 - acc: 0.4986 - val_loss: 2.4811 - val_acc: 0.2467\n",
      "Epoch 2162/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.2940 - acc: 0.4971 - val_loss: 2.4690 - val_acc: 0.2433\n",
      "Epoch 2163/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.2947 - acc: 0.4886 - val_loss: 2.4613 - val_acc: 0.2433\n",
      "Epoch 2164/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.2953 - acc: 0.5000 - val_loss: 2.4816 - val_acc: 0.2467\n",
      "Epoch 2165/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.2944 - acc: 0.4929 - val_loss: 2.4723 - val_acc: 0.2500\n",
      "Epoch 2166/3000\n",
      "700/700 [==============================] - 0s 115us/step - loss: 1.2947 - acc: 0.4971 - val_loss: 2.4783 - val_acc: 0.2467\n",
      "Epoch 2167/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.2941 - acc: 0.4943 - val_loss: 2.4753 - val_acc: 0.2433\n",
      "Epoch 2168/3000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.2947 - acc: 0.4971 - val_loss: 2.4860 - val_acc: 0.2433\n",
      "Epoch 2169/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.2941 - acc: 0.4971 - val_loss: 2.4613 - val_acc: 0.2467\n",
      "Epoch 2170/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.2940 - acc: 0.4971 - val_loss: 2.4807 - val_acc: 0.2400\n",
      "Epoch 2171/3000\n",
      "700/700 [==============================] - 0s 129us/step - loss: 1.2936 - acc: 0.5000 - val_loss: 2.4653 - val_acc: 0.2533\n",
      "Epoch 2172/3000\n",
      "700/700 [==============================] - 0s 144us/step - loss: 1.2936 - acc: 0.4986 - val_loss: 2.5007 - val_acc: 0.2467\n",
      "Epoch 2173/3000\n",
      "700/700 [==============================] - 0s 139us/step - loss: 1.2932 - acc: 0.4986 - val_loss: 2.4881 - val_acc: 0.2500\n",
      "Epoch 2174/3000\n",
      "700/700 [==============================] - 0s 151us/step - loss: 1.2943 - acc: 0.5029 - val_loss: 2.4800 - val_acc: 0.2400\n",
      "Epoch 2175/3000\n",
      "700/700 [==============================] - 0s 146us/step - loss: 1.2931 - acc: 0.4957 - val_loss: 2.4548 - val_acc: 0.2467\n",
      "Epoch 2176/3000\n",
      "700/700 [==============================] - 0s 148us/step - loss: 1.2934 - acc: 0.4943 - val_loss: 2.4576 - val_acc: 0.2467\n",
      "Epoch 2177/3000\n",
      "700/700 [==============================] - 0s 128us/step - loss: 1.2940 - acc: 0.4929 - val_loss: 2.4839 - val_acc: 0.2533\n",
      "Epoch 2178/3000\n",
      "700/700 [==============================] - 0s 155us/step - loss: 1.2937 - acc: 0.4971 - val_loss: 2.4833 - val_acc: 0.2467\n",
      "Epoch 2179/3000\n",
      "700/700 [==============================] - 0s 143us/step - loss: 1.2931 - acc: 0.4957 - val_loss: 2.4800 - val_acc: 0.2467\n",
      "Epoch 2180/3000\n",
      "700/700 [==============================] - 0s 141us/step - loss: 1.2946 - acc: 0.4943 - val_loss: 2.4790 - val_acc: 0.2467\n",
      "Epoch 2181/3000\n",
      "700/700 [==============================] - 0s 137us/step - loss: 1.2932 - acc: 0.4986 - val_loss: 2.4801 - val_acc: 0.2400\n",
      "Epoch 2182/3000\n",
      "700/700 [==============================] - 0s 144us/step - loss: 1.2937 - acc: 0.4957 - val_loss: 2.4932 - val_acc: 0.2433\n",
      "Epoch 2183/3000\n",
      "700/700 [==============================] - 0s 139us/step - loss: 1.2930 - acc: 0.5014 - val_loss: 2.5112 - val_acc: 0.2400\n",
      "Epoch 2184/3000\n",
      "700/700 [==============================] - 0s 151us/step - loss: 1.2937 - acc: 0.4971 - val_loss: 2.4805 - val_acc: 0.2467\n",
      "Epoch 2185/3000\n",
      "700/700 [==============================] - 0s 144us/step - loss: 1.2927 - acc: 0.4929 - val_loss: 2.4651 - val_acc: 0.2433\n",
      "Epoch 2186/3000\n",
      "700/700 [==============================] - 0s 142us/step - loss: 1.2941 - acc: 0.4986 - val_loss: 2.4871 - val_acc: 0.2533\n",
      "Epoch 2187/3000\n",
      "700/700 [==============================] - 0s 141us/step - loss: 1.2931 - acc: 0.4986 - val_loss: 2.4882 - val_acc: 0.2467\n",
      "Epoch 2188/3000\n",
      "700/700 [==============================] - 0s 143us/step - loss: 1.2942 - acc: 0.4986 - val_loss: 2.5004 - val_acc: 0.2433\n",
      "Epoch 2189/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 150us/step - loss: 1.2931 - acc: 0.4929 - val_loss: 2.5121 - val_acc: 0.2433\n",
      "Epoch 2190/3000\n",
      "700/700 [==============================] - 0s 155us/step - loss: 1.2921 - acc: 0.4957 - val_loss: 2.4954 - val_acc: 0.2400\n",
      "Epoch 2191/3000\n",
      "700/700 [==============================] - 0s 144us/step - loss: 1.2926 - acc: 0.4900 - val_loss: 2.4876 - val_acc: 0.2400\n",
      "Epoch 2192/3000\n",
      "700/700 [==============================] - 0s 141us/step - loss: 1.2927 - acc: 0.4971 - val_loss: 2.4689 - val_acc: 0.2433\n",
      "Epoch 2193/3000\n",
      "700/700 [==============================] - 0s 143us/step - loss: 1.2928 - acc: 0.4986 - val_loss: 2.4824 - val_acc: 0.2400\n",
      "Epoch 2194/3000\n",
      "700/700 [==============================] - 0s 139us/step - loss: 1.2929 - acc: 0.4971 - val_loss: 2.4977 - val_acc: 0.2433\n",
      "Epoch 2195/3000\n",
      "700/700 [==============================] - 0s 155us/step - loss: 1.2922 - acc: 0.4929 - val_loss: 2.4907 - val_acc: 0.2433\n",
      "Epoch 2196/3000\n",
      "700/700 [==============================] - 0s 147us/step - loss: 1.2928 - acc: 0.4971 - val_loss: 2.4995 - val_acc: 0.2433\n",
      "Epoch 2197/3000\n",
      "700/700 [==============================] - 0s 158us/step - loss: 1.2927 - acc: 0.5000 - val_loss: 2.4928 - val_acc: 0.2467\n",
      "Epoch 2198/3000\n",
      "700/700 [==============================] - 0s 155us/step - loss: 1.2924 - acc: 0.4943 - val_loss: 2.4840 - val_acc: 0.2433\n",
      "Epoch 2199/3000\n",
      "700/700 [==============================] - 0s 145us/step - loss: 1.2928 - acc: 0.4986 - val_loss: 2.4947 - val_acc: 0.2433\n",
      "Epoch 2200/3000\n",
      "700/700 [==============================] - 0s 151us/step - loss: 1.2928 - acc: 0.4986 - val_loss: 2.4632 - val_acc: 0.2400\n",
      "Epoch 2201/3000\n",
      "700/700 [==============================] - 0s 148us/step - loss: 1.2918 - acc: 0.4943 - val_loss: 2.5107 - val_acc: 0.2500\n",
      "Epoch 2202/3000\n",
      "700/700 [==============================] - 0s 156us/step - loss: 1.2906 - acc: 0.4929 - val_loss: 2.4914 - val_acc: 0.2467\n",
      "Epoch 2203/3000\n",
      "700/700 [==============================] - 0s 144us/step - loss: 1.2924 - acc: 0.4929 - val_loss: 2.4942 - val_acc: 0.2433\n",
      "Epoch 2204/3000\n",
      "700/700 [==============================] - 0s 160us/step - loss: 1.2916 - acc: 0.4971 - val_loss: 2.4669 - val_acc: 0.2400\n",
      "Epoch 2205/3000\n",
      "700/700 [==============================] - 0s 144us/step - loss: 1.2918 - acc: 0.4971 - val_loss: 2.5070 - val_acc: 0.2433\n",
      "Epoch 2206/3000\n",
      "700/700 [==============================] - 0s 140us/step - loss: 1.2923 - acc: 0.4957 - val_loss: 2.4834 - val_acc: 0.2467\n",
      "Epoch 2207/3000\n",
      "700/700 [==============================] - 0s 143us/step - loss: 1.2920 - acc: 0.4914 - val_loss: 2.5011 - val_acc: 0.2433\n",
      "Epoch 2208/3000\n",
      "700/700 [==============================] - 0s 145us/step - loss: 1.2917 - acc: 0.5014 - val_loss: 2.4905 - val_acc: 0.2433\n",
      "Epoch 2209/3000\n",
      "700/700 [==============================] - 0s 139us/step - loss: 1.2916 - acc: 0.4971 - val_loss: 2.4519 - val_acc: 0.2533\n",
      "Epoch 2210/3000\n",
      "700/700 [==============================] - 0s 123us/step - loss: 1.2923 - acc: 0.4929 - val_loss: 2.4870 - val_acc: 0.2433\n",
      "Epoch 2211/3000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 1.2916 - acc: 0.4943 - val_loss: 2.4949 - val_acc: 0.2500\n",
      "Epoch 2212/3000\n",
      "700/700 [==============================] - 0s 130us/step - loss: 1.2913 - acc: 0.4986 - val_loss: 2.5102 - val_acc: 0.2467\n",
      "Epoch 2213/3000\n",
      "700/700 [==============================] - 0s 131us/step - loss: 1.2917 - acc: 0.4943 - val_loss: 2.4812 - val_acc: 0.2400\n",
      "Epoch 2214/3000\n",
      "700/700 [==============================] - 0s 131us/step - loss: 1.2903 - acc: 0.4957 - val_loss: 2.4971 - val_acc: 0.2433\n",
      "Epoch 2215/3000\n",
      "700/700 [==============================] - 0s 123us/step - loss: 1.2916 - acc: 0.4971 - val_loss: 2.4834 - val_acc: 0.2433\n",
      "Epoch 2216/3000\n",
      "700/700 [==============================] - 0s 138us/step - loss: 1.2918 - acc: 0.4943 - val_loss: 2.4782 - val_acc: 0.2433\n",
      "Epoch 2217/3000\n",
      "700/700 [==============================] - 0s 130us/step - loss: 1.2915 - acc: 0.4957 - val_loss: 2.4981 - val_acc: 0.2467\n",
      "Epoch 2218/3000\n",
      "700/700 [==============================] - 0s 125us/step - loss: 1.2910 - acc: 0.5029 - val_loss: 2.5008 - val_acc: 0.2367\n",
      "Epoch 2219/3000\n",
      "700/700 [==============================] - 0s 130us/step - loss: 1.2913 - acc: 0.5043 - val_loss: 2.4859 - val_acc: 0.2433\n",
      "Epoch 2220/3000\n",
      "700/700 [==============================] - 0s 128us/step - loss: 1.2902 - acc: 0.4957 - val_loss: 2.4821 - val_acc: 0.2500\n",
      "Epoch 2221/3000\n",
      "700/700 [==============================] - 0s 117us/step - loss: 1.2905 - acc: 0.5014 - val_loss: 2.4854 - val_acc: 0.2500\n",
      "Epoch 2222/3000\n",
      "700/700 [==============================] - 0s 127us/step - loss: 1.2926 - acc: 0.4929 - val_loss: 2.4621 - val_acc: 0.2400\n",
      "Epoch 2223/3000\n",
      "700/700 [==============================] - 0s 129us/step - loss: 1.2909 - acc: 0.4971 - val_loss: 2.5016 - val_acc: 0.2500\n",
      "Epoch 2224/3000\n",
      "700/700 [==============================] - 0s 227us/step - loss: 1.2905 - acc: 0.4943 - val_loss: 2.4938 - val_acc: 0.2467\n",
      "Epoch 2225/3000\n",
      "700/700 [==============================] - 0s 131us/step - loss: 1.2901 - acc: 0.4986 - val_loss: 2.4870 - val_acc: 0.2500\n",
      "Epoch 2226/3000\n",
      "700/700 [==============================] - 0s 135us/step - loss: 1.2905 - acc: 0.4986 - val_loss: 2.5105 - val_acc: 0.2433\n",
      "Epoch 2227/3000\n",
      "700/700 [==============================] - 0s 120us/step - loss: 1.2909 - acc: 0.5014 - val_loss: 2.4859 - val_acc: 0.2400\n",
      "Epoch 2228/3000\n",
      "700/700 [==============================] - 0s 143us/step - loss: 1.2909 - acc: 0.4943 - val_loss: 2.4982 - val_acc: 0.2467\n",
      "Epoch 2229/3000\n",
      "700/700 [==============================] - 0s 179us/step - loss: 1.2904 - acc: 0.5029 - val_loss: 2.4735 - val_acc: 0.2400\n",
      "Epoch 2230/3000\n",
      "700/700 [==============================] - 0s 159us/step - loss: 1.2908 - acc: 0.5029 - val_loss: 2.4847 - val_acc: 0.2433\n",
      "Epoch 2231/3000\n",
      "700/700 [==============================] - 0s 147us/step - loss: 1.2899 - acc: 0.5000 - val_loss: 2.4844 - val_acc: 0.2500\n",
      "Epoch 2232/3000\n",
      "700/700 [==============================] - 0s 142us/step - loss: 1.2908 - acc: 0.4957 - val_loss: 2.4962 - val_acc: 0.2433\n",
      "Epoch 2233/3000\n",
      "700/700 [==============================] - 0s 132us/step - loss: 1.2903 - acc: 0.4957 - val_loss: 2.4988 - val_acc: 0.2433\n",
      "Epoch 2234/3000\n",
      "700/700 [==============================] - 0s 130us/step - loss: 1.2904 - acc: 0.4971 - val_loss: 2.4764 - val_acc: 0.2400\n",
      "Epoch 2235/3000\n",
      "700/700 [==============================] - 0s 148us/step - loss: 1.2900 - acc: 0.4986 - val_loss: 2.4831 - val_acc: 0.2400\n",
      "Epoch 2236/3000\n",
      "700/700 [==============================] - 0s 136us/step - loss: 1.2899 - acc: 0.4971 - val_loss: 2.4720 - val_acc: 0.2433\n",
      "Epoch 2237/3000\n",
      "700/700 [==============================] - 0s 127us/step - loss: 1.2901 - acc: 0.4986 - val_loss: 2.5151 - val_acc: 0.2400\n",
      "Epoch 2238/3000\n",
      "700/700 [==============================] - 0s 98us/step - loss: 1.2903 - acc: 0.5000 - val_loss: 2.5278 - val_acc: 0.2333\n",
      "Epoch 2239/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.2893 - acc: 0.4957 - val_loss: 2.4823 - val_acc: 0.2567\n",
      "Epoch 2240/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.2901 - acc: 0.5029 - val_loss: 2.5090 - val_acc: 0.2433\n",
      "Epoch 2241/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.2902 - acc: 0.4957 - val_loss: 2.4853 - val_acc: 0.2500\n",
      "Epoch 2242/3000\n",
      "700/700 [==============================] - 0s 143us/step - loss: 1.2898 - acc: 0.4957 - val_loss: 2.4948 - val_acc: 0.2467\n",
      "Epoch 2243/3000\n",
      "700/700 [==============================] - 0s 133us/step - loss: 1.2899 - acc: 0.4986 - val_loss: 2.4899 - val_acc: 0.2467\n",
      "Epoch 2244/3000\n",
      "700/700 [==============================] - 0s 152us/step - loss: 1.2899 - acc: 0.4957 - val_loss: 2.4882 - val_acc: 0.2433\n",
      "Epoch 2245/3000\n",
      "700/700 [==============================] - 0s 141us/step - loss: 1.2893 - acc: 0.5029 - val_loss: 2.5195 - val_acc: 0.2400\n",
      "Epoch 2246/3000\n",
      "700/700 [==============================] - 0s 133us/step - loss: 1.2892 - acc: 0.5014 - val_loss: 2.4980 - val_acc: 0.2433\n",
      "Epoch 2247/3000\n",
      "700/700 [==============================] - 0s 153us/step - loss: 1.2893 - acc: 0.4957 - val_loss: 2.4918 - val_acc: 0.2467\n",
      "Epoch 2248/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 134us/step - loss: 1.2896 - acc: 0.4943 - val_loss: 2.5437 - val_acc: 0.2367\n",
      "Epoch 2249/3000\n",
      "700/700 [==============================] - 0s 129us/step - loss: 1.2901 - acc: 0.5000 - val_loss: 2.4927 - val_acc: 0.2500\n",
      "Epoch 2250/3000\n",
      "700/700 [==============================] - 0s 125us/step - loss: 1.2888 - acc: 0.4957 - val_loss: 2.4823 - val_acc: 0.2433\n",
      "Epoch 2251/3000\n",
      "700/700 [==============================] - 0s 119us/step - loss: 1.2903 - acc: 0.4914 - val_loss: 2.4919 - val_acc: 0.2433\n",
      "Epoch 2252/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.2890 - acc: 0.4971 - val_loss: 2.4799 - val_acc: 0.2400\n",
      "Epoch 2253/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.2879 - acc: 0.4971 - val_loss: 2.5122 - val_acc: 0.2467\n",
      "Epoch 2254/3000\n",
      "700/700 [==============================] - 0s 151us/step - loss: 1.2896 - acc: 0.4971 - val_loss: 2.5085 - val_acc: 0.2467\n",
      "Epoch 2255/3000\n",
      "700/700 [==============================] - 0s 127us/step - loss: 1.2887 - acc: 0.5029 - val_loss: 2.5123 - val_acc: 0.2400\n",
      "Epoch 2256/3000\n",
      "700/700 [==============================] - 0s 121us/step - loss: 1.2893 - acc: 0.5000 - val_loss: 2.4922 - val_acc: 0.2400\n",
      "Epoch 2257/3000\n",
      "700/700 [==============================] - 0s 119us/step - loss: 1.2889 - acc: 0.5000 - val_loss: 2.5274 - val_acc: 0.2367\n",
      "Epoch 2258/3000\n",
      "700/700 [==============================] - 0s 112us/step - loss: 1.2888 - acc: 0.4986 - val_loss: 2.4618 - val_acc: 0.2367\n",
      "Epoch 2259/3000\n",
      "700/700 [==============================] - 0s 124us/step - loss: 1.2878 - acc: 0.5029 - val_loss: 2.5278 - val_acc: 0.2433\n",
      "Epoch 2260/3000\n",
      "700/700 [==============================] - 0s 118us/step - loss: 1.2887 - acc: 0.4957 - val_loss: 2.5068 - val_acc: 0.2500\n",
      "Epoch 2261/3000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 1.2882 - acc: 0.4986 - val_loss: 2.4997 - val_acc: 0.2433\n",
      "Epoch 2262/3000\n",
      "700/700 [==============================] - 0s 112us/step - loss: 1.2887 - acc: 0.5057 - val_loss: 2.4957 - val_acc: 0.2433\n",
      "Epoch 2263/3000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 1.2882 - acc: 0.4971 - val_loss: 2.5347 - val_acc: 0.2333\n",
      "Epoch 2264/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.2887 - acc: 0.4957 - val_loss: 2.5310 - val_acc: 0.2433\n",
      "Epoch 2265/3000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.2885 - acc: 0.4957 - val_loss: 2.5032 - val_acc: 0.2467\n",
      "Epoch 2266/3000\n",
      "700/700 [==============================] - 0s 108us/step - loss: 1.2884 - acc: 0.5029 - val_loss: 2.5250 - val_acc: 0.2367\n",
      "Epoch 2267/3000\n",
      "700/700 [==============================] - 0s 112us/step - loss: 1.2888 - acc: 0.4929 - val_loss: 2.4876 - val_acc: 0.2433\n",
      "Epoch 2268/3000\n",
      "700/700 [==============================] - 0s 112us/step - loss: 1.2881 - acc: 0.5000 - val_loss: 2.4814 - val_acc: 0.2433\n",
      "Epoch 2269/3000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.2870 - acc: 0.5014 - val_loss: 2.5246 - val_acc: 0.2500\n",
      "Epoch 2270/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.2885 - acc: 0.5043 - val_loss: 2.4930 - val_acc: 0.2500\n",
      "Epoch 2271/3000\n",
      "700/700 [==============================] - 0s 123us/step - loss: 1.2882 - acc: 0.4929 - val_loss: 2.5187 - val_acc: 0.2433\n",
      "Epoch 2272/3000\n",
      "700/700 [==============================] - 0s 125us/step - loss: 1.2875 - acc: 0.4957 - val_loss: 2.5284 - val_acc: 0.2433\n",
      "Epoch 2273/3000\n",
      "700/700 [==============================] - 0s 124us/step - loss: 1.2882 - acc: 0.4957 - val_loss: 2.4908 - val_acc: 0.2400\n",
      "Epoch 2274/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.2882 - acc: 0.4943 - val_loss: 2.4862 - val_acc: 0.2500\n",
      "Epoch 2275/3000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.2878 - acc: 0.5014 - val_loss: 2.5091 - val_acc: 0.2433\n",
      "Epoch 2276/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.2878 - acc: 0.4986 - val_loss: 2.5044 - val_acc: 0.2467\n",
      "Epoch 2277/3000\n",
      "700/700 [==============================] - 0s 112us/step - loss: 1.2877 - acc: 0.4986 - val_loss: 2.5090 - val_acc: 0.2367\n",
      "Epoch 2278/3000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.2875 - acc: 0.4943 - val_loss: 2.5038 - val_acc: 0.2467\n",
      "Epoch 2279/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.2875 - acc: 0.4929 - val_loss: 2.5075 - val_acc: 0.2433\n",
      "Epoch 2280/3000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 1.2875 - acc: 0.4971 - val_loss: 2.5225 - val_acc: 0.2367\n",
      "Epoch 2281/3000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.2857 - acc: 0.4986 - val_loss: 2.5110 - val_acc: 0.2500\n",
      "Epoch 2282/3000\n",
      "700/700 [==============================] - 0s 115us/step - loss: 1.2873 - acc: 0.4929 - val_loss: 2.5061 - val_acc: 0.2433\n",
      "Epoch 2283/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.2862 - acc: 0.4971 - val_loss: 2.4757 - val_acc: 0.2500\n",
      "Epoch 2284/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.2881 - acc: 0.5029 - val_loss: 2.5020 - val_acc: 0.2533\n",
      "Epoch 2285/3000\n",
      "700/700 [==============================] - 0s 85us/step - loss: 1.2887 - acc: 0.4914 - val_loss: 2.5199 - val_acc: 0.2400\n",
      "Epoch 2286/3000\n",
      "700/700 [==============================] - 0s 85us/step - loss: 1.2875 - acc: 0.5014 - val_loss: 2.5040 - val_acc: 0.2467\n",
      "Epoch 2287/3000\n",
      "700/700 [==============================] - 0s 85us/step - loss: 1.2875 - acc: 0.4971 - val_loss: 2.4941 - val_acc: 0.2400\n",
      "Epoch 2288/3000\n",
      "700/700 [==============================] - 0s 145us/step - loss: 1.2873 - acc: 0.5014 - val_loss: 2.4984 - val_acc: 0.2467\n",
      "Epoch 2289/3000\n",
      "700/700 [==============================] - 0s 138us/step - loss: 1.2876 - acc: 0.4986 - val_loss: 2.5231 - val_acc: 0.2433\n",
      "Epoch 2290/3000\n",
      "700/700 [==============================] - 0s 135us/step - loss: 1.2875 - acc: 0.4914 - val_loss: 2.5130 - val_acc: 0.2367\n",
      "Epoch 2291/3000\n",
      "700/700 [==============================] - 0s 140us/step - loss: 1.2871 - acc: 0.5000 - val_loss: 2.5125 - val_acc: 0.2467\n",
      "Epoch 2292/3000\n",
      "700/700 [==============================] - 0s 132us/step - loss: 1.2861 - acc: 0.4986 - val_loss: 2.5160 - val_acc: 0.2400\n",
      "Epoch 2293/3000\n",
      "700/700 [==============================] - 0s 121us/step - loss: 1.2868 - acc: 0.4986 - val_loss: 2.5129 - val_acc: 0.2467\n",
      "Epoch 2294/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.2866 - acc: 0.5014 - val_loss: 2.5218 - val_acc: 0.2500\n",
      "Epoch 2295/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.2869 - acc: 0.4957 - val_loss: 2.5158 - val_acc: 0.2367\n",
      "Epoch 2296/3000\n",
      "700/700 [==============================] - 0s 112us/step - loss: 1.2869 - acc: 0.4943 - val_loss: 2.4872 - val_acc: 0.2467\n",
      "Epoch 2297/3000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 1.2860 - acc: 0.4957 - val_loss: 2.5104 - val_acc: 0.2433\n",
      "Epoch 2298/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.2863 - acc: 0.5000 - val_loss: 2.5275 - val_acc: 0.2467\n",
      "Epoch 2299/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.2870 - acc: 0.5043 - val_loss: 2.5230 - val_acc: 0.2500\n",
      "Epoch 2300/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.2861 - acc: 0.5000 - val_loss: 2.5030 - val_acc: 0.2367\n",
      "Epoch 2301/3000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.2869 - acc: 0.4957 - val_loss: 2.5097 - val_acc: 0.2433\n",
      "Epoch 2302/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.2859 - acc: 0.4943 - val_loss: 2.5302 - val_acc: 0.2433\n",
      "Epoch 2303/3000\n",
      "700/700 [==============================] - 0s 108us/step - loss: 1.2862 - acc: 0.4986 - val_loss: 2.4958 - val_acc: 0.2367\n",
      "Epoch 2304/3000\n",
      "700/700 [==============================] - 0s 119us/step - loss: 1.2866 - acc: 0.5000 - val_loss: 2.5123 - val_acc: 0.2533\n",
      "Epoch 2305/3000\n",
      "700/700 [==============================] - 0s 121us/step - loss: 1.2858 - acc: 0.4943 - val_loss: 2.5543 - val_acc: 0.2433\n",
      "Epoch 2306/3000\n",
      "700/700 [==============================] - 0s 143us/step - loss: 1.2868 - acc: 0.5014 - val_loss: 2.4728 - val_acc: 0.2400\n",
      "Epoch 2307/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 116us/step - loss: 1.2863 - acc: 0.5000 - val_loss: 2.5022 - val_acc: 0.2433\n",
      "Epoch 2308/3000\n",
      "700/700 [==============================] - 0s 118us/step - loss: 1.2860 - acc: 0.5029 - val_loss: 2.4981 - val_acc: 0.2500\n",
      "Epoch 2309/3000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.2858 - acc: 0.4929 - val_loss: 2.5272 - val_acc: 0.2467\n",
      "Epoch 2310/3000\n",
      "700/700 [==============================] - 0s 115us/step - loss: 1.2855 - acc: 0.5000 - val_loss: 2.5130 - val_acc: 0.2433\n",
      "Epoch 2311/3000\n",
      "700/700 [==============================] - 0s 153us/step - loss: 1.2858 - acc: 0.4943 - val_loss: 2.5126 - val_acc: 0.2400\n",
      "Epoch 2312/3000\n",
      "700/700 [==============================] - 0s 146us/step - loss: 1.2858 - acc: 0.4986 - val_loss: 2.5286 - val_acc: 0.2367\n",
      "Epoch 2313/3000\n",
      "700/700 [==============================] - 0s 147us/step - loss: 1.2853 - acc: 0.4971 - val_loss: 2.5017 - val_acc: 0.2500\n",
      "Epoch 2314/3000\n",
      "700/700 [==============================] - 0s 151us/step - loss: 1.2860 - acc: 0.5000 - val_loss: 2.5175 - val_acc: 0.2433\n",
      "Epoch 2315/3000\n",
      "700/700 [==============================] - 0s 145us/step - loss: 1.2856 - acc: 0.5043 - val_loss: 2.5069 - val_acc: 0.2433\n",
      "Epoch 2316/3000\n",
      "700/700 [==============================] - 0s 122us/step - loss: 1.2854 - acc: 0.4943 - val_loss: 2.5352 - val_acc: 0.2367\n",
      "Epoch 2317/3000\n",
      "700/700 [==============================] - 0s 130us/step - loss: 1.2839 - acc: 0.5043 - val_loss: 2.5198 - val_acc: 0.2500\n",
      "Epoch 2318/3000\n",
      "700/700 [==============================] - 0s 135us/step - loss: 1.2856 - acc: 0.4971 - val_loss: 2.5155 - val_acc: 0.2400\n",
      "Epoch 2319/3000\n",
      "700/700 [==============================] - 0s 161us/step - loss: 1.2858 - acc: 0.4957 - val_loss: 2.4996 - val_acc: 0.2400\n",
      "Epoch 2320/3000\n",
      "700/700 [==============================] - 0s 158us/step - loss: 1.2855 - acc: 0.4971 - val_loss: 2.5107 - val_acc: 0.2533\n",
      "Epoch 2321/3000\n",
      "700/700 [==============================] - 0s 135us/step - loss: 1.2851 - acc: 0.5000 - val_loss: 2.5210 - val_acc: 0.2400\n",
      "Epoch 2322/3000\n",
      "700/700 [==============================] - 0s 118us/step - loss: 1.2853 - acc: 0.4986 - val_loss: 2.5181 - val_acc: 0.2400\n",
      "Epoch 2323/3000\n",
      "700/700 [==============================] - 0s 127us/step - loss: 1.2846 - acc: 0.4986 - val_loss: 2.4960 - val_acc: 0.2533\n",
      "Epoch 2324/3000\n",
      "700/700 [==============================] - 0s 127us/step - loss: 1.2852 - acc: 0.5057 - val_loss: 2.5368 - val_acc: 0.2433\n",
      "Epoch 2325/3000\n",
      "700/700 [==============================] - 0s 162us/step - loss: 1.2856 - acc: 0.4929 - val_loss: 2.5142 - val_acc: 0.2400\n",
      "Epoch 2326/3000\n",
      "700/700 [==============================] - 0s 132us/step - loss: 1.2852 - acc: 0.5000 - val_loss: 2.5176 - val_acc: 0.2400\n",
      "Epoch 2327/3000\n",
      "700/700 [==============================] - 0s 135us/step - loss: 1.2852 - acc: 0.5043 - val_loss: 2.5149 - val_acc: 0.2333\n",
      "Epoch 2328/3000\n",
      "700/700 [==============================] - 0s 119us/step - loss: 1.2852 - acc: 0.4943 - val_loss: 2.5340 - val_acc: 0.2300\n",
      "Epoch 2329/3000\n",
      "700/700 [==============================] - 0s 116us/step - loss: 1.2850 - acc: 0.4986 - val_loss: 2.5374 - val_acc: 0.2367\n",
      "Epoch 2330/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.2848 - acc: 0.5043 - val_loss: 2.5066 - val_acc: 0.2500\n",
      "Epoch 2331/3000\n",
      "700/700 [==============================] - 0s 117us/step - loss: 1.2839 - acc: 0.5000 - val_loss: 2.5160 - val_acc: 0.2467\n",
      "Epoch 2332/3000\n",
      "700/700 [==============================] - 0s 120us/step - loss: 1.2856 - acc: 0.4971 - val_loss: 2.5150 - val_acc: 0.2533\n",
      "Epoch 2333/3000\n",
      "700/700 [==============================] - 0s 128us/step - loss: 1.2848 - acc: 0.5057 - val_loss: 2.5228 - val_acc: 0.2400\n",
      "Epoch 2334/3000\n",
      "700/700 [==============================] - 0s 135us/step - loss: 1.2844 - acc: 0.4957 - val_loss: 2.5238 - val_acc: 0.2467\n",
      "Epoch 2335/3000\n",
      "700/700 [==============================] - 0s 120us/step - loss: 1.2836 - acc: 0.4971 - val_loss: 2.5228 - val_acc: 0.2400\n",
      "Epoch 2336/3000\n",
      "700/700 [==============================] - 0s 134us/step - loss: 1.2845 - acc: 0.4957 - val_loss: 2.5343 - val_acc: 0.2467\n",
      "Epoch 2337/3000\n",
      "700/700 [==============================] - 0s 150us/step - loss: 1.2852 - acc: 0.4957 - val_loss: 2.5228 - val_acc: 0.2433\n",
      "Epoch 2338/3000\n",
      "700/700 [==============================] - 0s 143us/step - loss: 1.2848 - acc: 0.4957 - val_loss: 2.5255 - val_acc: 0.2433\n",
      "Epoch 2339/3000\n",
      "700/700 [==============================] - 0s 124us/step - loss: 1.2839 - acc: 0.4986 - val_loss: 2.5028 - val_acc: 0.2500\n",
      "Epoch 2340/3000\n",
      "700/700 [==============================] - 0s 124us/step - loss: 1.2838 - acc: 0.4986 - val_loss: 2.5483 - val_acc: 0.2433\n",
      "Epoch 2341/3000\n",
      "700/700 [==============================] - 0s 146us/step - loss: 1.2843 - acc: 0.4943 - val_loss: 2.5259 - val_acc: 0.2500\n",
      "Epoch 2342/3000\n",
      "700/700 [==============================] - 0s 173us/step - loss: 1.2840 - acc: 0.4986 - val_loss: 2.5114 - val_acc: 0.2533\n",
      "Epoch 2343/3000\n",
      "700/700 [==============================] - 0s 158us/step - loss: 1.2837 - acc: 0.5014 - val_loss: 2.5301 - val_acc: 0.2500\n",
      "Epoch 2344/3000\n",
      "700/700 [==============================] - 0s 143us/step - loss: 1.2836 - acc: 0.4943 - val_loss: 2.5174 - val_acc: 0.2500\n",
      "Epoch 2345/3000\n",
      "700/700 [==============================] - 0s 119us/step - loss: 1.2840 - acc: 0.5014 - val_loss: 2.5251 - val_acc: 0.2533\n",
      "Epoch 2346/3000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.2841 - acc: 0.5014 - val_loss: 2.5420 - val_acc: 0.2433\n",
      "Epoch 2347/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.2845 - acc: 0.5000 - val_loss: 2.5258 - val_acc: 0.2467\n",
      "Epoch 2348/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.2831 - acc: 0.5043 - val_loss: 2.5088 - val_acc: 0.2433\n",
      "Epoch 2349/3000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.2830 - acc: 0.4957 - val_loss: 2.5210 - val_acc: 0.2500\n",
      "Epoch 2350/3000\n",
      "700/700 [==============================] - 0s 117us/step - loss: 1.2830 - acc: 0.4943 - val_loss: 2.5328 - val_acc: 0.2567\n",
      "Epoch 2351/3000\n",
      "700/700 [==============================] - 0s 112us/step - loss: 1.2838 - acc: 0.4986 - val_loss: 2.5294 - val_acc: 0.2433\n",
      "Epoch 2352/3000\n",
      "700/700 [==============================] - 0s 126us/step - loss: 1.2841 - acc: 0.4943 - val_loss: 2.5379 - val_acc: 0.2467\n",
      "Epoch 2353/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.2832 - acc: 0.4986 - val_loss: 2.5125 - val_acc: 0.2500\n",
      "Epoch 2354/3000\n",
      "700/700 [==============================] - 0s 127us/step - loss: 1.2828 - acc: 0.5000 - val_loss: 2.5381 - val_acc: 0.2267\n",
      "Epoch 2355/3000\n",
      "700/700 [==============================] - 0s 121us/step - loss: 1.2834 - acc: 0.4986 - val_loss: 2.5342 - val_acc: 0.2367\n",
      "Epoch 2356/3000\n",
      "700/700 [==============================] - 0s 134us/step - loss: 1.2825 - acc: 0.4986 - val_loss: 2.5200 - val_acc: 0.2433\n",
      "Epoch 2357/3000\n",
      "700/700 [==============================] - 0s 147us/step - loss: 1.2835 - acc: 0.4943 - val_loss: 2.5099 - val_acc: 0.2433\n",
      "Epoch 2358/3000\n",
      "700/700 [==============================] - 0s 151us/step - loss: 1.2835 - acc: 0.4971 - val_loss: 2.5414 - val_acc: 0.2400\n",
      "Epoch 2359/3000\n",
      "700/700 [==============================] - 0s 124us/step - loss: 1.2827 - acc: 0.4971 - val_loss: 2.5169 - val_acc: 0.2533\n",
      "Epoch 2360/3000\n",
      "700/700 [==============================] - 0s 112us/step - loss: 1.2830 - acc: 0.4957 - val_loss: 2.5377 - val_acc: 0.2400\n",
      "Epoch 2361/3000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.2832 - acc: 0.5014 - val_loss: 2.5297 - val_acc: 0.2367\n",
      "Epoch 2362/3000\n",
      "700/700 [==============================] - 0s 121us/step - loss: 1.2830 - acc: 0.4943 - val_loss: 2.5007 - val_acc: 0.2500\n",
      "Epoch 2363/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.2822 - acc: 0.5000 - val_loss: 2.5153 - val_acc: 0.2433\n",
      "Epoch 2364/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.2827 - acc: 0.5043 - val_loss: 2.5251 - val_acc: 0.2367\n",
      "Epoch 2365/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.2821 - acc: 0.5014 - val_loss: 2.5486 - val_acc: 0.2467\n",
      "Epoch 2366/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 132us/step - loss: 1.2824 - acc: 0.5057 - val_loss: 2.5376 - val_acc: 0.2333\n",
      "Epoch 2367/3000\n",
      "700/700 [==============================] - 0s 130us/step - loss: 1.2823 - acc: 0.5000 - val_loss: 2.5194 - val_acc: 0.2333\n",
      "Epoch 2368/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.2829 - acc: 0.5029 - val_loss: 2.5283 - val_acc: 0.2333\n",
      "Epoch 2369/3000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.2823 - acc: 0.5029 - val_loss: 2.5251 - val_acc: 0.2400\n",
      "Epoch 2370/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.2816 - acc: 0.5014 - val_loss: 2.5221 - val_acc: 0.2467\n",
      "Epoch 2371/3000\n",
      "700/700 [==============================] - 0s 98us/step - loss: 1.2829 - acc: 0.5000 - val_loss: 2.5111 - val_acc: 0.2533\n",
      "Epoch 2372/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.2818 - acc: 0.4971 - val_loss: 2.5306 - val_acc: 0.2433\n",
      "Epoch 2373/3000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.2834 - acc: 0.4971 - val_loss: 2.5465 - val_acc: 0.2433\n",
      "Epoch 2374/3000\n",
      "700/700 [==============================] - 0s 143us/step - loss: 1.2821 - acc: 0.5000 - val_loss: 2.5397 - val_acc: 0.2333\n",
      "Epoch 2375/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.2823 - acc: 0.5043 - val_loss: 2.5293 - val_acc: 0.2467\n",
      "Epoch 2376/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.2822 - acc: 0.5000 - val_loss: 2.5329 - val_acc: 0.2433\n",
      "Epoch 2377/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.2829 - acc: 0.4943 - val_loss: 2.5197 - val_acc: 0.2400\n",
      "Epoch 2378/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.2820 - acc: 0.5000 - val_loss: 2.5274 - val_acc: 0.2467\n",
      "Epoch 2379/3000\n",
      "700/700 [==============================] - 0s 120us/step - loss: 1.2823 - acc: 0.5000 - val_loss: 2.5210 - val_acc: 0.2500\n",
      "Epoch 2380/3000\n",
      "700/700 [==============================] - 0s 118us/step - loss: 1.2815 - acc: 0.4986 - val_loss: 2.5186 - val_acc: 0.2467\n",
      "Epoch 2381/3000\n",
      "700/700 [==============================] - 0s 117us/step - loss: 1.2824 - acc: 0.5057 - val_loss: 2.5351 - val_acc: 0.2467\n",
      "Epoch 2382/3000\n",
      "700/700 [==============================] - 0s 118us/step - loss: 1.2818 - acc: 0.4986 - val_loss: 2.5348 - val_acc: 0.2467\n",
      "Epoch 2383/3000\n",
      "700/700 [==============================] - 0s 121us/step - loss: 1.2817 - acc: 0.4971 - val_loss: 2.5402 - val_acc: 0.2433\n",
      "Epoch 2384/3000\n",
      "700/700 [==============================] - 0s 112us/step - loss: 1.2815 - acc: 0.4957 - val_loss: 2.5341 - val_acc: 0.2433\n",
      "Epoch 2385/3000\n",
      "700/700 [==============================] - 0s 123us/step - loss: 1.2816 - acc: 0.5029 - val_loss: 2.5436 - val_acc: 0.2467\n",
      "Epoch 2386/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.2808 - acc: 0.4986 - val_loss: 2.5345 - val_acc: 0.2400\n",
      "Epoch 2387/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.2813 - acc: 0.5029 - val_loss: 2.5472 - val_acc: 0.2400\n",
      "Epoch 2388/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.2811 - acc: 0.5000 - val_loss: 2.5438 - val_acc: 0.2367\n",
      "Epoch 2389/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.2817 - acc: 0.5014 - val_loss: 2.5229 - val_acc: 0.2367\n",
      "Epoch 2390/3000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.2811 - acc: 0.4943 - val_loss: 2.5507 - val_acc: 0.2467\n",
      "Epoch 2391/3000\n",
      "700/700 [==============================] - 0s 140us/step - loss: 1.2810 - acc: 0.4986 - val_loss: 2.5463 - val_acc: 0.2467\n",
      "Epoch 2392/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.2822 - acc: 0.5000 - val_loss: 2.5428 - val_acc: 0.2400\n",
      "Epoch 2393/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.2811 - acc: 0.5014 - val_loss: 2.5334 - val_acc: 0.2467\n",
      "Epoch 2394/3000\n",
      "700/700 [==============================] - 0s 117us/step - loss: 1.2812 - acc: 0.5057 - val_loss: 2.5392 - val_acc: 0.2467\n",
      "Epoch 2395/3000\n",
      "700/700 [==============================] - 0s 130us/step - loss: 1.2810 - acc: 0.5000 - val_loss: 2.5488 - val_acc: 0.2433\n",
      "Epoch 2396/3000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.2805 - acc: 0.5000 - val_loss: 2.5646 - val_acc: 0.2433\n",
      "Epoch 2397/3000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.2807 - acc: 0.5014 - val_loss: 2.5447 - val_acc: 0.2433\n",
      "Epoch 2398/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.2808 - acc: 0.5057 - val_loss: 2.5404 - val_acc: 0.2467\n",
      "Epoch 2399/3000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.2809 - acc: 0.5071 - val_loss: 2.5622 - val_acc: 0.2433\n",
      "Epoch 2400/3000\n",
      "700/700 [==============================] - 0s 124us/step - loss: 1.2803 - acc: 0.5029 - val_loss: 2.5431 - val_acc: 0.2400\n",
      "Epoch 2401/3000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.2799 - acc: 0.4957 - val_loss: 2.5605 - val_acc: 0.2400\n",
      "Epoch 2402/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.2817 - acc: 0.4957 - val_loss: 2.4999 - val_acc: 0.2433\n",
      "Epoch 2403/3000\n",
      "700/700 [==============================] - 0s 98us/step - loss: 1.2812 - acc: 0.5000 - val_loss: 2.5323 - val_acc: 0.2467\n",
      "Epoch 2404/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.2798 - acc: 0.5029 - val_loss: 2.5364 - val_acc: 0.2500\n",
      "Epoch 2405/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.2811 - acc: 0.5029 - val_loss: 2.5199 - val_acc: 0.2500\n",
      "Epoch 2406/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.2811 - acc: 0.5014 - val_loss: 2.5393 - val_acc: 0.2433\n",
      "Epoch 2407/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.2798 - acc: 0.5057 - val_loss: 2.5322 - val_acc: 0.2367\n",
      "Epoch 2408/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.2797 - acc: 0.4986 - val_loss: 2.5502 - val_acc: 0.2467\n",
      "Epoch 2409/3000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.2804 - acc: 0.4971 - val_loss: 2.5344 - val_acc: 0.2433\n",
      "Epoch 2410/3000\n",
      "700/700 [==============================] - 0s 152us/step - loss: 1.2800 - acc: 0.5014 - val_loss: 2.5540 - val_acc: 0.2367\n",
      "Epoch 2411/3000\n",
      "700/700 [==============================] - 0s 124us/step - loss: 1.2800 - acc: 0.5057 - val_loss: 2.5305 - val_acc: 0.2467\n",
      "Epoch 2412/3000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 1.2802 - acc: 0.5029 - val_loss: 2.5807 - val_acc: 0.2467\n",
      "Epoch 2413/3000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.2805 - acc: 0.4986 - val_loss: 2.5481 - val_acc: 0.2367\n",
      "Epoch 2414/3000\n",
      "700/700 [==============================] - 0s 137us/step - loss: 1.2801 - acc: 0.4986 - val_loss: 2.5512 - val_acc: 0.2433\n",
      "Epoch 2415/3000\n",
      "700/700 [==============================] - 0s 146us/step - loss: 1.2807 - acc: 0.5057 - val_loss: 2.5471 - val_acc: 0.2433\n",
      "Epoch 2416/3000\n",
      "700/700 [==============================] - 0s 121us/step - loss: 1.2795 - acc: 0.4971 - val_loss: 2.5303 - val_acc: 0.2400\n",
      "Epoch 2417/3000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.2801 - acc: 0.4943 - val_loss: 2.5396 - val_acc: 0.2467\n",
      "Epoch 2418/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.2804 - acc: 0.4971 - val_loss: 2.5589 - val_acc: 0.2267\n",
      "Epoch 2419/3000\n",
      "700/700 [==============================] - 0s 123us/step - loss: 1.2797 - acc: 0.5029 - val_loss: 2.5342 - val_acc: 0.2500\n",
      "Epoch 2420/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.2797 - acc: 0.5043 - val_loss: 2.5196 - val_acc: 0.2367\n",
      "Epoch 2421/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.2801 - acc: 0.5000 - val_loss: 2.5189 - val_acc: 0.2367\n",
      "Epoch 2422/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.2795 - acc: 0.5043 - val_loss: 2.5449 - val_acc: 0.2367\n",
      "Epoch 2423/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.2797 - acc: 0.4957 - val_loss: 2.5576 - val_acc: 0.2400\n",
      "Epoch 2424/3000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 1.2795 - acc: 0.5000 - val_loss: 2.5305 - val_acc: 0.2467\n",
      "Epoch 2425/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 109us/step - loss: 1.2797 - acc: 0.5014 - val_loss: 2.5495 - val_acc: 0.2367\n",
      "Epoch 2426/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.2785 - acc: 0.5057 - val_loss: 2.5430 - val_acc: 0.2367\n",
      "Epoch 2427/3000\n",
      "700/700 [==============================] - 0s 135us/step - loss: 1.2798 - acc: 0.5014 - val_loss: 2.5437 - val_acc: 0.2400\n",
      "Epoch 2428/3000\n",
      "700/700 [==============================] - 0s 156us/step - loss: 1.2792 - acc: 0.5071 - val_loss: 2.5326 - val_acc: 0.2433\n",
      "Epoch 2429/3000\n",
      "700/700 [==============================] - 0s 165us/step - loss: 1.2786 - acc: 0.5029 - val_loss: 2.5400 - val_acc: 0.2433\n",
      "Epoch 2430/3000\n",
      "700/700 [==============================] - 0s 133us/step - loss: 1.2788 - acc: 0.4986 - val_loss: 2.5219 - val_acc: 0.2467\n",
      "Epoch 2431/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.2785 - acc: 0.5071 - val_loss: 2.5428 - val_acc: 0.2433\n",
      "Epoch 2432/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.2786 - acc: 0.5043 - val_loss: 2.5506 - val_acc: 0.2433\n",
      "Epoch 2433/3000\n",
      "700/700 [==============================] - 0s 98us/step - loss: 1.2789 - acc: 0.5014 - val_loss: 2.5379 - val_acc: 0.2467\n",
      "Epoch 2434/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.2793 - acc: 0.4957 - val_loss: 2.5326 - val_acc: 0.2433\n",
      "Epoch 2435/3000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 1.2794 - acc: 0.5086 - val_loss: 2.5603 - val_acc: 0.2367\n",
      "Epoch 2436/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.2785 - acc: 0.5043 - val_loss: 2.5629 - val_acc: 0.2400\n",
      "Epoch 2437/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.2793 - acc: 0.4957 - val_loss: 2.5440 - val_acc: 0.2467\n",
      "Epoch 2438/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.2794 - acc: 0.5000 - val_loss: 2.5532 - val_acc: 0.2433\n",
      "Epoch 2439/3000\n",
      "700/700 [==============================] - 0s 98us/step - loss: 1.2794 - acc: 0.5057 - val_loss: 2.5655 - val_acc: 0.2433\n",
      "Epoch 2440/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.2791 - acc: 0.5057 - val_loss: 2.5640 - val_acc: 0.2433\n",
      "Epoch 2441/3000\n",
      "700/700 [==============================] - 0s 139us/step - loss: 1.2778 - acc: 0.4971 - val_loss: 2.5323 - val_acc: 0.2433\n",
      "Epoch 2442/3000\n",
      "700/700 [==============================] - 0s 157us/step - loss: 1.2790 - acc: 0.5029 - val_loss: 2.5782 - val_acc: 0.2367\n",
      "Epoch 2443/3000\n",
      "700/700 [==============================] - 0s 158us/step - loss: 1.2785 - acc: 0.5057 - val_loss: 2.5658 - val_acc: 0.2433\n",
      "Epoch 2444/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.2780 - acc: 0.5000 - val_loss: 2.5442 - val_acc: 0.2467\n",
      "Epoch 2445/3000\n",
      "700/700 [==============================] - 0s 82us/step - loss: 1.2787 - acc: 0.4971 - val_loss: 2.5463 - val_acc: 0.2400\n",
      "Epoch 2446/3000\n",
      "700/700 [==============================] - 0s 84us/step - loss: 1.2782 - acc: 0.5043 - val_loss: 2.5347 - val_acc: 0.2467\n",
      "Epoch 2447/3000\n",
      "700/700 [==============================] - 0s 86us/step - loss: 1.2780 - acc: 0.5086 - val_loss: 2.5695 - val_acc: 0.2400\n",
      "Epoch 2448/3000\n",
      "700/700 [==============================] - 0s 83us/step - loss: 1.2780 - acc: 0.5043 - val_loss: 2.5448 - val_acc: 0.2467\n",
      "Epoch 2449/3000\n",
      "700/700 [==============================] - 0s 85us/step - loss: 1.2782 - acc: 0.5000 - val_loss: 2.5561 - val_acc: 0.2367\n",
      "Epoch 2450/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 1.2777 - acc: 0.5043 - val_loss: 2.5417 - val_acc: 0.2300\n",
      "Epoch 2451/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.2780 - acc: 0.5043 - val_loss: 2.5512 - val_acc: 0.2400\n",
      "Epoch 2452/3000\n",
      "700/700 [==============================] - 0s 92us/step - loss: 1.2785 - acc: 0.5043 - val_loss: 2.5548 - val_acc: 0.2400\n",
      "Epoch 2453/3000\n",
      "700/700 [==============================] - 0s 87us/step - loss: 1.2776 - acc: 0.5000 - val_loss: 2.5404 - val_acc: 0.2367\n",
      "Epoch 2454/3000\n",
      "700/700 [==============================] - 0s 92us/step - loss: 1.2779 - acc: 0.4986 - val_loss: 2.5824 - val_acc: 0.2467\n",
      "Epoch 2455/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.2784 - acc: 0.5000 - val_loss: 2.5627 - val_acc: 0.2367\n",
      "Epoch 2456/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.2773 - acc: 0.5086 - val_loss: 2.5781 - val_acc: 0.2467\n",
      "Epoch 2457/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.2784 - acc: 0.5057 - val_loss: 2.5594 - val_acc: 0.2433\n",
      "Epoch 2458/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.2776 - acc: 0.5029 - val_loss: 2.5358 - val_acc: 0.2467\n",
      "Epoch 2459/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.2775 - acc: 0.5014 - val_loss: 2.5410 - val_acc: 0.2433\n",
      "Epoch 2460/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.2777 - acc: 0.5000 - val_loss: 2.5391 - val_acc: 0.2433\n",
      "Epoch 2461/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.2775 - acc: 0.5014 - val_loss: 2.5285 - val_acc: 0.2500\n",
      "Epoch 2462/3000\n",
      "700/700 [==============================] - 0s 117us/step - loss: 1.2771 - acc: 0.4971 - val_loss: 2.5591 - val_acc: 0.2367\n",
      "Epoch 2463/3000\n",
      "700/700 [==============================] - 0s 108us/step - loss: 1.2774 - acc: 0.5014 - val_loss: 2.5420 - val_acc: 0.2400\n",
      "Epoch 2464/3000\n",
      "700/700 [==============================] - 0s 116us/step - loss: 1.2769 - acc: 0.5000 - val_loss: 2.5492 - val_acc: 0.2433\n",
      "Epoch 2465/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.2772 - acc: 0.5000 - val_loss: 2.5664 - val_acc: 0.2433\n",
      "Epoch 2466/3000\n",
      "700/700 [==============================] - 0s 115us/step - loss: 1.2764 - acc: 0.4971 - val_loss: 2.5496 - val_acc: 0.2433\n",
      "Epoch 2467/3000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 1.2774 - acc: 0.5029 - val_loss: 2.5451 - val_acc: 0.2333\n",
      "Epoch 2468/3000\n",
      "700/700 [==============================] - 0s 115us/step - loss: 1.2766 - acc: 0.4986 - val_loss: 2.5369 - val_acc: 0.2500\n",
      "Epoch 2469/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.2769 - acc: 0.4971 - val_loss: 2.5179 - val_acc: 0.2367\n",
      "Epoch 2470/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.2774 - acc: 0.5029 - val_loss: 2.5595 - val_acc: 0.2433\n",
      "Epoch 2471/3000\n",
      "700/700 [==============================] - 0s 120us/step - loss: 1.2772 - acc: 0.4986 - val_loss: 2.5383 - val_acc: 0.2500\n",
      "Epoch 2472/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.2765 - acc: 0.5000 - val_loss: 2.5648 - val_acc: 0.2367\n",
      "Epoch 2473/3000\n",
      "700/700 [==============================] - 0s 115us/step - loss: 1.2770 - acc: 0.5043 - val_loss: 2.5831 - val_acc: 0.2333\n",
      "Epoch 2474/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.2781 - acc: 0.5000 - val_loss: 2.5505 - val_acc: 0.2300\n",
      "Epoch 2475/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.2763 - acc: 0.5000 - val_loss: 2.5731 - val_acc: 0.2433\n",
      "Epoch 2476/3000\n",
      "700/700 [==============================] - 0s 119us/step - loss: 1.2765 - acc: 0.5043 - val_loss: 2.5603 - val_acc: 0.2433\n",
      "Epoch 2477/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.2767 - acc: 0.5000 - val_loss: 2.5482 - val_acc: 0.2367\n",
      "Epoch 2478/3000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 1.2763 - acc: 0.4957 - val_loss: 2.5637 - val_acc: 0.2400\n",
      "Epoch 2479/3000\n",
      "700/700 [==============================] - 0s 84us/step - loss: 1.2753 - acc: 0.5043 - val_loss: 2.5297 - val_acc: 0.2467\n",
      "Epoch 2480/3000\n",
      "700/700 [==============================] - 0s 84us/step - loss: 1.2751 - acc: 0.5100 - val_loss: 2.5842 - val_acc: 0.2333\n",
      "Epoch 2481/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.2758 - acc: 0.5014 - val_loss: 2.5649 - val_acc: 0.2433\n",
      "Epoch 2482/3000\n",
      "700/700 [==============================] - 0s 122us/step - loss: 1.2758 - acc: 0.5014 - val_loss: 2.5716 - val_acc: 0.2367\n",
      "Epoch 2483/3000\n",
      "700/700 [==============================] - 0s 112us/step - loss: 1.2766 - acc: 0.5029 - val_loss: 2.5497 - val_acc: 0.2333\n",
      "Epoch 2484/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 108us/step - loss: 1.2769 - acc: 0.5000 - val_loss: 2.5561 - val_acc: 0.2367\n",
      "Epoch 2485/3000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 1.2763 - acc: 0.5014 - val_loss: 2.5517 - val_acc: 0.2300\n",
      "Epoch 2486/3000\n",
      "700/700 [==============================] - 0s 115us/step - loss: 1.2760 - acc: 0.5000 - val_loss: 2.5500 - val_acc: 0.2433\n",
      "Epoch 2487/3000\n",
      "700/700 [==============================] - 0s 115us/step - loss: 1.2761 - acc: 0.5071 - val_loss: 2.5760 - val_acc: 0.2467\n",
      "Epoch 2488/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.2758 - acc: 0.5000 - val_loss: 2.5505 - val_acc: 0.2433\n",
      "Epoch 2489/3000\n",
      "700/700 [==============================] - 0s 120us/step - loss: 1.2767 - acc: 0.5043 - val_loss: 2.5685 - val_acc: 0.2400\n",
      "Epoch 2490/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.2754 - acc: 0.5029 - val_loss: 2.5673 - val_acc: 0.2433\n",
      "Epoch 2491/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.2763 - acc: 0.4986 - val_loss: 2.5563 - val_acc: 0.2367\n",
      "Epoch 2492/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.2763 - acc: 0.5014 - val_loss: 2.5495 - val_acc: 0.2467\n",
      "Epoch 2493/3000\n",
      "700/700 [==============================] - 0s 112us/step - loss: 1.2758 - acc: 0.5029 - val_loss: 2.5807 - val_acc: 0.2400\n",
      "Epoch 2494/3000\n",
      "700/700 [==============================] - 0s 129us/step - loss: 1.2761 - acc: 0.4943 - val_loss: 2.5482 - val_acc: 0.2433\n",
      "Epoch 2495/3000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.2754 - acc: 0.4986 - val_loss: 2.5869 - val_acc: 0.2367\n",
      "Epoch 2496/3000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.2767 - acc: 0.4971 - val_loss: 2.5798 - val_acc: 0.2433\n",
      "Epoch 2497/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.2757 - acc: 0.4986 - val_loss: 2.5738 - val_acc: 0.2400\n",
      "Epoch 2498/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.2756 - acc: 0.5043 - val_loss: 2.5860 - val_acc: 0.2467\n",
      "Epoch 2499/3000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 1.2756 - acc: 0.5071 - val_loss: 2.5466 - val_acc: 0.2333\n",
      "Epoch 2500/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.2747 - acc: 0.5071 - val_loss: 2.5410 - val_acc: 0.2500\n",
      "Epoch 2501/3000\n",
      "700/700 [==============================] - 0s 127us/step - loss: 1.2757 - acc: 0.5057 - val_loss: 2.5945 - val_acc: 0.2433\n",
      "Epoch 2502/3000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.2754 - acc: 0.5043 - val_loss: 2.5627 - val_acc: 0.2433\n",
      "Epoch 2503/3000\n",
      "700/700 [==============================] - 0s 81us/step - loss: 1.2749 - acc: 0.5029 - val_loss: 2.5706 - val_acc: 0.2400\n",
      "Epoch 2504/3000\n",
      "700/700 [==============================] - 0s 79us/step - loss: 1.2752 - acc: 0.5086 - val_loss: 2.5694 - val_acc: 0.2433\n",
      "Epoch 2505/3000\n",
      "700/700 [==============================] - 0s 82us/step - loss: 1.2763 - acc: 0.5000 - val_loss: 2.5544 - val_acc: 0.2433\n",
      "Epoch 2506/3000\n",
      "700/700 [==============================] - 0s 80us/step - loss: 1.2748 - acc: 0.5071 - val_loss: 2.5671 - val_acc: 0.2400\n",
      "Epoch 2507/3000\n",
      "700/700 [==============================] - 0s 88us/step - loss: 1.2751 - acc: 0.5057 - val_loss: 2.5563 - val_acc: 0.2400\n",
      "Epoch 2508/3000\n",
      "700/700 [==============================] - 0s 82us/step - loss: 1.2745 - acc: 0.5000 - val_loss: 2.5984 - val_acc: 0.2467\n",
      "Epoch 2509/3000\n",
      "700/700 [==============================] - 0s 85us/step - loss: 1.2749 - acc: 0.5057 - val_loss: 2.5664 - val_acc: 0.2433\n",
      "Epoch 2510/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.2745 - acc: 0.5014 - val_loss: 2.5750 - val_acc: 0.2367\n",
      "Epoch 2511/3000\n",
      "700/700 [==============================] - 0s 92us/step - loss: 1.2747 - acc: 0.5014 - val_loss: 2.5695 - val_acc: 0.2367\n",
      "Epoch 2512/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.2745 - acc: 0.5029 - val_loss: 2.5761 - val_acc: 0.2467\n",
      "Epoch 2513/3000\n",
      "700/700 [==============================] - 0s 127us/step - loss: 1.2754 - acc: 0.5057 - val_loss: 2.5591 - val_acc: 0.2433\n",
      "Epoch 2514/3000\n",
      "700/700 [==============================] - 0s 120us/step - loss: 1.2739 - acc: 0.4986 - val_loss: 2.5497 - val_acc: 0.2433\n",
      "Epoch 2515/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.2742 - acc: 0.5029 - val_loss: 2.5554 - val_acc: 0.2400\n",
      "Epoch 2516/3000\n",
      "700/700 [==============================] - 0s 117us/step - loss: 1.2744 - acc: 0.5043 - val_loss: 2.5803 - val_acc: 0.2433\n",
      "Epoch 2517/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.2748 - acc: 0.5029 - val_loss: 2.5817 - val_acc: 0.2433\n",
      "Epoch 2518/3000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 1.2746 - acc: 0.5043 - val_loss: 2.5721 - val_acc: 0.2433\n",
      "Epoch 2519/3000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.2746 - acc: 0.5057 - val_loss: 2.5796 - val_acc: 0.2400\n",
      "Epoch 2520/3000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.2739 - acc: 0.4957 - val_loss: 2.5762 - val_acc: 0.2367\n",
      "Epoch 2521/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.2739 - acc: 0.5000 - val_loss: 2.5710 - val_acc: 0.2333\n",
      "Epoch 2522/3000\n",
      "700/700 [==============================] - 0s 120us/step - loss: 1.2748 - acc: 0.4986 - val_loss: 2.5617 - val_acc: 0.2367\n",
      "Epoch 2523/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.2746 - acc: 0.5000 - val_loss: 2.5652 - val_acc: 0.2333\n",
      "Epoch 2524/3000\n",
      "700/700 [==============================] - 0s 112us/step - loss: 1.2736 - acc: 0.4971 - val_loss: 2.5656 - val_acc: 0.2400\n",
      "Epoch 2525/3000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 1.2740 - acc: 0.5000 - val_loss: 2.5843 - val_acc: 0.2433\n",
      "Epoch 2526/3000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.2741 - acc: 0.5057 - val_loss: 2.5623 - val_acc: 0.2367\n",
      "Epoch 2527/3000\n",
      "700/700 [==============================] - 0s 115us/step - loss: 1.2736 - acc: 0.5014 - val_loss: 2.5747 - val_acc: 0.2367\n",
      "Epoch 2528/3000\n",
      "700/700 [==============================] - 0s 115us/step - loss: 1.2731 - acc: 0.5029 - val_loss: 2.5735 - val_acc: 0.2333\n",
      "Epoch 2529/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.2746 - acc: 0.5086 - val_loss: 2.5878 - val_acc: 0.2367\n",
      "Epoch 2530/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.2733 - acc: 0.5100 - val_loss: 2.5700 - val_acc: 0.2367\n",
      "Epoch 2531/3000\n",
      "700/700 [==============================] - 0s 108us/step - loss: 1.2735 - acc: 0.5029 - val_loss: 2.5752 - val_acc: 0.2367\n",
      "Epoch 2532/3000\n",
      "700/700 [==============================] - 0s 108us/step - loss: 1.2735 - acc: 0.5043 - val_loss: 2.5779 - val_acc: 0.2433\n",
      "Epoch 2533/3000\n",
      "700/700 [==============================] - 0s 119us/step - loss: 1.2746 - acc: 0.5014 - val_loss: 2.5747 - val_acc: 0.2433\n",
      "Epoch 2534/3000\n",
      "700/700 [==============================] - 0s 108us/step - loss: 1.2743 - acc: 0.5014 - val_loss: 2.5852 - val_acc: 0.2400\n",
      "Epoch 2535/3000\n",
      "700/700 [==============================] - 0s 108us/step - loss: 1.2740 - acc: 0.4971 - val_loss: 2.5678 - val_acc: 0.2433\n",
      "Epoch 2536/3000\n",
      "700/700 [==============================] - 0s 121us/step - loss: 1.2734 - acc: 0.5043 - val_loss: 2.5896 - val_acc: 0.2367\n",
      "Epoch 2537/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.2741 - acc: 0.5043 - val_loss: 2.5589 - val_acc: 0.2400\n",
      "Epoch 2538/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.2731 - acc: 0.5029 - val_loss: 2.5753 - val_acc: 0.2367\n",
      "Epoch 2539/3000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.2741 - acc: 0.5014 - val_loss: 2.5858 - val_acc: 0.2433\n",
      "Epoch 2540/3000\n",
      "700/700 [==============================] - 0s 75us/step - loss: 1.2737 - acc: 0.5029 - val_loss: 2.5926 - val_acc: 0.2433\n",
      "Epoch 2541/3000\n",
      "700/700 [==============================] - 0s 82us/step - loss: 1.2734 - acc: 0.5057 - val_loss: 2.5746 - val_acc: 0.2367\n",
      "Epoch 2542/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.2729 - acc: 0.5014 - val_loss: 2.5699 - val_acc: 0.2433\n",
      "Epoch 2543/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 117us/step - loss: 1.2733 - acc: 0.5043 - val_loss: 2.5747 - val_acc: 0.2333\n",
      "Epoch 2544/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.2735 - acc: 0.4986 - val_loss: 2.5730 - val_acc: 0.2367\n",
      "Epoch 2545/3000\n",
      "700/700 [==============================] - 0s 118us/step - loss: 1.2736 - acc: 0.5014 - val_loss: 2.5945 - val_acc: 0.2367\n",
      "Epoch 2546/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.2732 - acc: 0.5057 - val_loss: 2.5936 - val_acc: 0.2400\n",
      "Epoch 2547/3000\n",
      "700/700 [==============================] - 0s 77us/step - loss: 1.2733 - acc: 0.5043 - val_loss: 2.5863 - val_acc: 0.2433\n",
      "Epoch 2548/3000\n",
      "700/700 [==============================] - 0s 75us/step - loss: 1.2727 - acc: 0.5071 - val_loss: 2.5787 - val_acc: 0.2400\n",
      "Epoch 2549/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.2727 - acc: 0.5014 - val_loss: 2.5689 - val_acc: 0.2367\n",
      "Epoch 2550/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.2730 - acc: 0.5057 - val_loss: 2.5716 - val_acc: 0.2367\n",
      "Epoch 2551/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.2721 - acc: 0.5014 - val_loss: 2.5952 - val_acc: 0.2433\n",
      "Epoch 2552/3000\n",
      "700/700 [==============================] - 0s 119us/step - loss: 1.2725 - acc: 0.5043 - val_loss: 2.5607 - val_acc: 0.2333\n",
      "Epoch 2553/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.2723 - acc: 0.5014 - val_loss: 2.5678 - val_acc: 0.2367\n",
      "Epoch 2554/3000\n",
      "700/700 [==============================] - 0s 76us/step - loss: 1.2724 - acc: 0.4986 - val_loss: 2.5606 - val_acc: 0.2367\n",
      "Epoch 2555/3000\n",
      "700/700 [==============================] - 0s 77us/step - loss: 1.2727 - acc: 0.5043 - val_loss: 2.5978 - val_acc: 0.2433\n",
      "Epoch 2556/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.2731 - acc: 0.4971 - val_loss: 2.5608 - val_acc: 0.2400\n",
      "Epoch 2557/3000\n",
      "700/700 [==============================] - 0s 120us/step - loss: 1.2722 - acc: 0.5029 - val_loss: 2.5941 - val_acc: 0.2433\n",
      "Epoch 2558/3000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.2726 - acc: 0.5029 - val_loss: 2.5967 - val_acc: 0.2433\n",
      "Epoch 2559/3000\n",
      "700/700 [==============================] - 0s 98us/step - loss: 1.2723 - acc: 0.5029 - val_loss: 2.5852 - val_acc: 0.2367\n",
      "Epoch 2560/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.2738 - acc: 0.5043 - val_loss: 2.5741 - val_acc: 0.2400\n",
      "Epoch 2561/3000\n",
      "700/700 [==============================] - 0s 78us/step - loss: 1.2724 - acc: 0.5014 - val_loss: 2.5732 - val_acc: 0.2333\n",
      "Epoch 2562/3000\n",
      "700/700 [==============================] - 0s 78us/step - loss: 1.2714 - acc: 0.5000 - val_loss: 2.5686 - val_acc: 0.2433\n",
      "Epoch 2563/3000\n",
      "700/700 [==============================] - 0s 81us/step - loss: 1.2720 - acc: 0.5071 - val_loss: 2.5813 - val_acc: 0.2467\n",
      "Epoch 2564/3000\n",
      "700/700 [==============================] - 0s 112us/step - loss: 1.2724 - acc: 0.5043 - val_loss: 2.5744 - val_acc: 0.2400\n",
      "Epoch 2565/3000\n",
      "700/700 [==============================] - 0s 118us/step - loss: 1.2720 - acc: 0.5071 - val_loss: 2.5813 - val_acc: 0.2400\n",
      "Epoch 2566/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.2729 - acc: 0.5029 - val_loss: 2.5859 - val_acc: 0.2367\n",
      "Epoch 2567/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.2729 - acc: 0.5029 - val_loss: 2.5788 - val_acc: 0.2433\n",
      "Epoch 2568/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.2719 - acc: 0.5043 - val_loss: 2.5740 - val_acc: 0.2333\n",
      "Epoch 2569/3000\n",
      "700/700 [==============================] - 0s 76us/step - loss: 1.2707 - acc: 0.5029 - val_loss: 2.5661 - val_acc: 0.2433\n",
      "Epoch 2570/3000\n",
      "700/700 [==============================] - 0s 76us/step - loss: 1.2720 - acc: 0.4957 - val_loss: 2.5976 - val_acc: 0.2433\n",
      "Epoch 2571/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.2717 - acc: 0.5057 - val_loss: 2.5859 - val_acc: 0.2400\n",
      "Epoch 2572/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.2717 - acc: 0.5071 - val_loss: 2.5966 - val_acc: 0.2433\n",
      "Epoch 2573/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.2710 - acc: 0.5029 - val_loss: 2.6160 - val_acc: 0.2400\n",
      "Epoch 2574/3000\n",
      "700/700 [==============================] - 0s 80us/step - loss: 1.2719 - acc: 0.5043 - val_loss: 2.5799 - val_acc: 0.2400\n",
      "Epoch 2575/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.2716 - acc: 0.5029 - val_loss: 2.6026 - val_acc: 0.2367\n",
      "Epoch 2576/3000\n",
      "700/700 [==============================] - 0s 81us/step - loss: 1.2711 - acc: 0.5057 - val_loss: 2.5943 - val_acc: 0.2433\n",
      "Epoch 2577/3000\n",
      "700/700 [==============================] - 0s 75us/step - loss: 1.2715 - acc: 0.5029 - val_loss: 2.5906 - val_acc: 0.2433\n",
      "Epoch 2578/3000\n",
      "700/700 [==============================] - 0s 78us/step - loss: 1.2714 - acc: 0.5014 - val_loss: 2.5872 - val_acc: 0.2433\n",
      "Epoch 2579/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.2713 - acc: 0.5029 - val_loss: 2.5762 - val_acc: 0.2367\n",
      "Epoch 2580/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.2711 - acc: 0.5029 - val_loss: 2.5861 - val_acc: 0.2433\n",
      "Epoch 2581/3000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 1.2706 - acc: 0.5029 - val_loss: 2.5620 - val_acc: 0.2333\n",
      "Epoch 2582/3000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.2712 - acc: 0.5043 - val_loss: 2.6025 - val_acc: 0.2367\n",
      "Epoch 2583/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.2715 - acc: 0.5043 - val_loss: 2.5893 - val_acc: 0.2367\n",
      "Epoch 2584/3000\n",
      "700/700 [==============================] - 0s 75us/step - loss: 1.2708 - acc: 0.5086 - val_loss: 2.5863 - val_acc: 0.2367\n",
      "Epoch 2585/3000\n",
      "700/700 [==============================] - 0s 75us/step - loss: 1.2707 - acc: 0.4957 - val_loss: 2.5839 - val_acc: 0.2400\n",
      "Epoch 2586/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.2709 - acc: 0.5029 - val_loss: 2.5638 - val_acc: 0.2400\n",
      "Epoch 2587/3000\n",
      "700/700 [==============================] - 0s 116us/step - loss: 1.2709 - acc: 0.5029 - val_loss: 2.5970 - val_acc: 0.2367\n",
      "Epoch 2588/3000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.2712 - acc: 0.5029 - val_loss: 2.5865 - val_acc: 0.2400\n",
      "Epoch 2589/3000\n",
      "700/700 [==============================] - 0s 116us/step - loss: 1.2708 - acc: 0.5014 - val_loss: 2.5809 - val_acc: 0.2367\n",
      "Epoch 2590/3000\n",
      "700/700 [==============================] - 0s 115us/step - loss: 1.2699 - acc: 0.5029 - val_loss: 2.5894 - val_acc: 0.2333\n",
      "Epoch 2591/3000\n",
      "700/700 [==============================] - 0s 117us/step - loss: 1.2701 - acc: 0.5071 - val_loss: 2.5745 - val_acc: 0.2433\n",
      "Epoch 2592/3000\n",
      "700/700 [==============================] - 0s 117us/step - loss: 1.2710 - acc: 0.5043 - val_loss: 2.6060 - val_acc: 0.2433\n",
      "Epoch 2593/3000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.2704 - acc: 0.5029 - val_loss: 2.5664 - val_acc: 0.2400\n",
      "Epoch 2594/3000\n",
      "700/700 [==============================] - 0s 82us/step - loss: 1.2708 - acc: 0.5043 - val_loss: 2.5987 - val_acc: 0.2400\n",
      "Epoch 2595/3000\n",
      "700/700 [==============================] - 0s 79us/step - loss: 1.2709 - acc: 0.4957 - val_loss: 2.5856 - val_acc: 0.2333\n",
      "Epoch 2596/3000\n",
      "700/700 [==============================] - 0s 81us/step - loss: 1.2705 - acc: 0.5057 - val_loss: 2.5834 - val_acc: 0.2367\n",
      "Epoch 2597/3000\n",
      "700/700 [==============================] - 0s 84us/step - loss: 1.2705 - acc: 0.5043 - val_loss: 2.5631 - val_acc: 0.2367\n",
      "Epoch 2598/3000\n",
      "700/700 [==============================] - 0s 85us/step - loss: 1.2699 - acc: 0.4971 - val_loss: 2.5877 - val_acc: 0.2433\n",
      "Epoch 2599/3000\n",
      "700/700 [==============================] - 0s 83us/step - loss: 1.2704 - acc: 0.5043 - val_loss: 2.5732 - val_acc: 0.2367\n",
      "Epoch 2600/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.2698 - acc: 0.5071 - val_loss: 2.5816 - val_acc: 0.2433\n",
      "Epoch 2601/3000\n",
      "700/700 [==============================] - 0s 81us/step - loss: 1.2697 - acc: 0.5043 - val_loss: 2.5851 - val_acc: 0.2433\n",
      "Epoch 2602/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 87us/step - loss: 1.2707 - acc: 0.5100 - val_loss: 2.6025 - val_acc: 0.2433\n",
      "Epoch 2603/3000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.2704 - acc: 0.5043 - val_loss: 2.5864 - val_acc: 0.2433\n",
      "Epoch 2604/3000\n",
      "700/700 [==============================] - 0s 117us/step - loss: 1.2696 - acc: 0.5071 - val_loss: 2.5931 - val_acc: 0.2400\n",
      "Epoch 2605/3000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 1.2702 - acc: 0.5000 - val_loss: 2.5840 - val_acc: 0.2333\n",
      "Epoch 2606/3000\n",
      "700/700 [==============================] - 0s 131us/step - loss: 1.2697 - acc: 0.5043 - val_loss: 2.5896 - val_acc: 0.2367\n",
      "Epoch 2607/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.2694 - acc: 0.5014 - val_loss: 2.5667 - val_acc: 0.2400\n",
      "Epoch 2608/3000\n",
      "700/700 [==============================] - 0s 117us/step - loss: 1.2700 - acc: 0.5043 - val_loss: 2.5997 - val_acc: 0.2367\n",
      "Epoch 2609/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.2695 - acc: 0.5057 - val_loss: 2.5832 - val_acc: 0.2400\n",
      "Epoch 2610/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.2697 - acc: 0.5043 - val_loss: 2.5673 - val_acc: 0.2433\n",
      "Epoch 2611/3000\n",
      "700/700 [==============================] - 0s 112us/step - loss: 1.2691 - acc: 0.5086 - val_loss: 2.5814 - val_acc: 0.2400\n",
      "Epoch 2612/3000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.2703 - acc: 0.5086 - val_loss: 2.5980 - val_acc: 0.2400\n",
      "Epoch 2613/3000\n",
      "700/700 [==============================] - 0s 117us/step - loss: 1.2695 - acc: 0.5071 - val_loss: 2.5899 - val_acc: 0.2433\n",
      "Epoch 2614/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.2694 - acc: 0.5043 - val_loss: 2.6040 - val_acc: 0.2433\n",
      "Epoch 2615/3000\n",
      "700/700 [==============================] - 0s 115us/step - loss: 1.2690 - acc: 0.5043 - val_loss: 2.5871 - val_acc: 0.2433\n",
      "Epoch 2616/3000\n",
      "700/700 [==============================] - 0s 115us/step - loss: 1.2694 - acc: 0.5043 - val_loss: 2.6118 - val_acc: 0.2400\n",
      "Epoch 2617/3000\n",
      "700/700 [==============================] - 0s 122us/step - loss: 1.2696 - acc: 0.5043 - val_loss: 2.5979 - val_acc: 0.2367\n",
      "Epoch 2618/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.2694 - acc: 0.5029 - val_loss: 2.5864 - val_acc: 0.2367\n",
      "Epoch 2619/3000\n",
      "700/700 [==============================] - 0s 115us/step - loss: 1.2694 - acc: 0.5043 - val_loss: 2.5984 - val_acc: 0.2367\n",
      "Epoch 2620/3000\n",
      "700/700 [==============================] - 0s 117us/step - loss: 1.2707 - acc: 0.5029 - val_loss: 2.6000 - val_acc: 0.2367\n",
      "Epoch 2621/3000\n",
      "700/700 [==============================] - 0s 108us/step - loss: 1.2693 - acc: 0.5043 - val_loss: 2.5952 - val_acc: 0.2333\n",
      "Epoch 2622/3000\n",
      "700/700 [==============================] - 0s 119us/step - loss: 1.2691 - acc: 0.4971 - val_loss: 2.5719 - val_acc: 0.2400\n",
      "Epoch 2623/3000\n",
      "700/700 [==============================] - 0s 132us/step - loss: 1.2694 - acc: 0.5029 - val_loss: 2.6028 - val_acc: 0.2400\n",
      "Epoch 2624/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.2684 - acc: 0.5029 - val_loss: 2.5768 - val_acc: 0.2333\n",
      "Epoch 2625/3000\n",
      "700/700 [==============================] - 0s 119us/step - loss: 1.2689 - acc: 0.5043 - val_loss: 2.5986 - val_acc: 0.2433\n",
      "Epoch 2626/3000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.2693 - acc: 0.5029 - val_loss: 2.6062 - val_acc: 0.2400\n",
      "Epoch 2627/3000\n",
      "700/700 [==============================] - 0s 118us/step - loss: 1.2694 - acc: 0.5043 - val_loss: 2.5904 - val_acc: 0.2367\n",
      "Epoch 2628/3000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.2682 - acc: 0.5029 - val_loss: 2.5888 - val_acc: 0.2367\n",
      "Epoch 2629/3000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 1.2686 - acc: 0.5014 - val_loss: 2.5954 - val_acc: 0.2367\n",
      "Epoch 2630/3000\n",
      "700/700 [==============================] - 0s 122us/step - loss: 1.2683 - acc: 0.5014 - val_loss: 2.5643 - val_acc: 0.2367\n",
      "Epoch 2631/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.2690 - acc: 0.5086 - val_loss: 2.5811 - val_acc: 0.2333\n",
      "Epoch 2632/3000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 1.2692 - acc: 0.5071 - val_loss: 2.5853 - val_acc: 0.2433\n",
      "Epoch 2633/3000\n",
      "700/700 [==============================] - 0s 118us/step - loss: 1.2680 - acc: 0.5029 - val_loss: 2.5918 - val_acc: 0.2367\n",
      "Epoch 2634/3000\n",
      "700/700 [==============================] - 0s 116us/step - loss: 1.2680 - acc: 0.5057 - val_loss: 2.5816 - val_acc: 0.2367\n",
      "Epoch 2635/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.2692 - acc: 0.4971 - val_loss: 2.5866 - val_acc: 0.2400\n",
      "Epoch 2636/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.2683 - acc: 0.5086 - val_loss: 2.5989 - val_acc: 0.2367\n",
      "Epoch 2637/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.2687 - acc: 0.5043 - val_loss: 2.6035 - val_acc: 0.2367\n",
      "Epoch 2638/3000\n",
      "700/700 [==============================] - 0s 112us/step - loss: 1.2684 - acc: 0.5043 - val_loss: 2.6039 - val_acc: 0.2433\n",
      "Epoch 2639/3000\n",
      "700/700 [==============================] - 0s 121us/step - loss: 1.2683 - acc: 0.5043 - val_loss: 2.5676 - val_acc: 0.2433\n",
      "Epoch 2640/3000\n",
      "700/700 [==============================] - 0s 116us/step - loss: 1.2682 - acc: 0.5114 - val_loss: 2.6141 - val_acc: 0.2467\n",
      "Epoch 2641/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.2676 - acc: 0.5043 - val_loss: 2.6403 - val_acc: 0.2467\n",
      "Epoch 2642/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.2679 - acc: 0.5000 - val_loss: 2.5986 - val_acc: 0.2433\n",
      "Epoch 2643/3000\n",
      "700/700 [==============================] - 0s 116us/step - loss: 1.2678 - acc: 0.5100 - val_loss: 2.5685 - val_acc: 0.2367\n",
      "Epoch 2644/3000\n",
      "700/700 [==============================] - 0s 124us/step - loss: 1.2686 - acc: 0.5014 - val_loss: 2.6006 - val_acc: 0.2433\n",
      "Epoch 2645/3000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 1.2676 - acc: 0.5057 - val_loss: 2.5963 - val_acc: 0.2433\n",
      "Epoch 2646/3000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.2684 - acc: 0.5057 - val_loss: 2.6070 - val_acc: 0.2433\n",
      "Epoch 2647/3000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.2680 - acc: 0.5029 - val_loss: 2.6021 - val_acc: 0.2467\n",
      "Epoch 2648/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.2680 - acc: 0.5043 - val_loss: 2.6139 - val_acc: 0.2433\n",
      "Epoch 2649/3000\n",
      "700/700 [==============================] - 0s 120us/step - loss: 1.2680 - acc: 0.5100 - val_loss: 2.5865 - val_acc: 0.2400\n",
      "Epoch 2650/3000\n",
      "700/700 [==============================] - 0s 123us/step - loss: 1.2672 - acc: 0.5043 - val_loss: 2.5830 - val_acc: 0.2367\n",
      "Epoch 2651/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.2670 - acc: 0.5029 - val_loss: 2.5961 - val_acc: 0.2433\n",
      "Epoch 2652/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.2673 - acc: 0.5086 - val_loss: 2.5841 - val_acc: 0.2433\n",
      "Epoch 2653/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.2682 - acc: 0.5086 - val_loss: 2.6189 - val_acc: 0.2433\n",
      "Epoch 2654/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.2677 - acc: 0.4971 - val_loss: 2.5978 - val_acc: 0.2400\n",
      "Epoch 2655/3000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.2676 - acc: 0.5029 - val_loss: 2.6014 - val_acc: 0.2367\n",
      "Epoch 2656/3000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.2674 - acc: 0.5057 - val_loss: 2.6116 - val_acc: 0.2367\n",
      "Epoch 2657/3000\n",
      "700/700 [==============================] - 0s 112us/step - loss: 1.2667 - acc: 0.5057 - val_loss: 2.5655 - val_acc: 0.2367\n",
      "Epoch 2658/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.2672 - acc: 0.5029 - val_loss: 2.6050 - val_acc: 0.2367\n",
      "Epoch 2659/3000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.2670 - acc: 0.5000 - val_loss: 2.5910 - val_acc: 0.2367\n",
      "Epoch 2660/3000\n",
      "700/700 [==============================] - 0s 108us/step - loss: 1.2673 - acc: 0.5029 - val_loss: 2.6218 - val_acc: 0.2400\n",
      "Epoch 2661/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 108us/step - loss: 1.2682 - acc: 0.5057 - val_loss: 2.6002 - val_acc: 0.2367\n",
      "Epoch 2662/3000\n",
      "700/700 [==============================] - 0s 118us/step - loss: 1.2677 - acc: 0.5014 - val_loss: 2.5929 - val_acc: 0.2367\n",
      "Epoch 2663/3000\n",
      "700/700 [==============================] - 0s 112us/step - loss: 1.2668 - acc: 0.5071 - val_loss: 2.5820 - val_acc: 0.2367\n",
      "Epoch 2664/3000\n",
      "700/700 [==============================] - 0s 129us/step - loss: 1.2667 - acc: 0.5014 - val_loss: 2.5912 - val_acc: 0.2367\n",
      "Epoch 2665/3000\n",
      "700/700 [==============================] - 0s 116us/step - loss: 1.2672 - acc: 0.5057 - val_loss: 2.5849 - val_acc: 0.2367\n",
      "Epoch 2666/3000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 1.2676 - acc: 0.5071 - val_loss: 2.5921 - val_acc: 0.2367\n",
      "Epoch 2667/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.2665 - acc: 0.5143 - val_loss: 2.6163 - val_acc: 0.2467\n",
      "Epoch 2668/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.2670 - acc: 0.5071 - val_loss: 2.6336 - val_acc: 0.2500\n",
      "Epoch 2669/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.2667 - acc: 0.5086 - val_loss: 2.6175 - val_acc: 0.2400\n",
      "Epoch 2670/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.2667 - acc: 0.5043 - val_loss: 2.6215 - val_acc: 0.2433\n",
      "Epoch 2671/3000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.2671 - acc: 0.5071 - val_loss: 2.6238 - val_acc: 0.2433\n",
      "Epoch 2672/3000\n",
      "700/700 [==============================] - 0s 112us/step - loss: 1.2666 - acc: 0.5086 - val_loss: 2.6273 - val_acc: 0.2433\n",
      "Epoch 2673/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.2668 - acc: 0.5086 - val_loss: 2.5933 - val_acc: 0.2367\n",
      "Epoch 2674/3000\n",
      "700/700 [==============================] - 0s 121us/step - loss: 1.2665 - acc: 0.5057 - val_loss: 2.6077 - val_acc: 0.2400\n",
      "Epoch 2675/3000\n",
      "700/700 [==============================] - 0s 119us/step - loss: 1.2663 - acc: 0.5043 - val_loss: 2.5851 - val_acc: 0.2367\n",
      "Epoch 2676/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.2667 - acc: 0.5086 - val_loss: 2.6171 - val_acc: 0.2367\n",
      "Epoch 2677/3000\n",
      "700/700 [==============================] - 0s 119us/step - loss: 1.2663 - acc: 0.5071 - val_loss: 2.6177 - val_acc: 0.2467\n",
      "Epoch 2678/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.2668 - acc: 0.5071 - val_loss: 2.6004 - val_acc: 0.2400\n",
      "Epoch 2679/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 1.2666 - acc: 0.5043 - val_loss: 2.6113 - val_acc: 0.2467\n",
      "Epoch 2680/3000\n",
      "700/700 [==============================] - 0s 85us/step - loss: 1.2683 - acc: 0.5071 - val_loss: 2.5936 - val_acc: 0.2367\n",
      "Epoch 2681/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 1.2669 - acc: 0.5043 - val_loss: 2.6215 - val_acc: 0.2367\n",
      "Epoch 2682/3000\n",
      "700/700 [==============================] - 0s 82us/step - loss: 1.2659 - acc: 0.5043 - val_loss: 2.6023 - val_acc: 0.2400\n",
      "Epoch 2683/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.2663 - acc: 0.5057 - val_loss: 2.6094 - val_acc: 0.2433\n",
      "Epoch 2684/3000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.2656 - acc: 0.5057 - val_loss: 2.6006 - val_acc: 0.2400\n",
      "Epoch 2685/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.2659 - acc: 0.5043 - val_loss: 2.5993 - val_acc: 0.2400\n",
      "Epoch 2686/3000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 1.2661 - acc: 0.5071 - val_loss: 2.6043 - val_acc: 0.2367\n",
      "Epoch 2687/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.2659 - acc: 0.5014 - val_loss: 2.6007 - val_acc: 0.2333\n",
      "Epoch 2688/3000\n",
      "700/700 [==============================] - 0s 116us/step - loss: 1.2661 - acc: 0.5086 - val_loss: 2.6234 - val_acc: 0.2400\n",
      "Epoch 2689/3000\n",
      "700/700 [==============================] - 0s 78us/step - loss: 1.2654 - acc: 0.5057 - val_loss: 2.6100 - val_acc: 0.2433\n",
      "Epoch 2690/3000\n",
      "700/700 [==============================] - 0s 82us/step - loss: 1.2663 - acc: 0.5057 - val_loss: 2.5685 - val_acc: 0.2400\n",
      "Epoch 2691/3000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.2659 - acc: 0.5043 - val_loss: 2.6188 - val_acc: 0.2467\n",
      "Epoch 2692/3000\n",
      "700/700 [==============================] - 0s 112us/step - loss: 1.2656 - acc: 0.5014 - val_loss: 2.6051 - val_acc: 0.2367\n",
      "Epoch 2693/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.2657 - acc: 0.5071 - val_loss: 2.6154 - val_acc: 0.2400\n",
      "Epoch 2694/3000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.2654 - acc: 0.5014 - val_loss: 2.6172 - val_acc: 0.2467\n",
      "Epoch 2695/3000\n",
      "700/700 [==============================] - 0s 108us/step - loss: 1.2644 - acc: 0.5114 - val_loss: 2.6184 - val_acc: 0.2467\n",
      "Epoch 2696/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.2652 - acc: 0.5043 - val_loss: 2.6010 - val_acc: 0.2367\n",
      "Epoch 2697/3000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 1.2660 - acc: 0.5057 - val_loss: 2.5957 - val_acc: 0.2400\n",
      "Epoch 2698/3000\n",
      "700/700 [==============================] - 0s 118us/step - loss: 1.2660 - acc: 0.5043 - val_loss: 2.6159 - val_acc: 0.2333\n",
      "Epoch 2699/3000\n",
      "700/700 [==============================] - 0s 116us/step - loss: 1.2657 - acc: 0.5043 - val_loss: 2.6070 - val_acc: 0.2367\n",
      "Epoch 2700/3000\n",
      "700/700 [==============================] - 0s 119us/step - loss: 1.2653 - acc: 0.5100 - val_loss: 2.5931 - val_acc: 0.2433\n",
      "Epoch 2701/3000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 1.2653 - acc: 0.5057 - val_loss: 2.6269 - val_acc: 0.2467\n",
      "Epoch 2702/3000\n",
      "700/700 [==============================] - 0s 121us/step - loss: 1.2651 - acc: 0.5057 - val_loss: 2.6305 - val_acc: 0.2367\n",
      "Epoch 2703/3000\n",
      "700/700 [==============================] - 0s 115us/step - loss: 1.2649 - acc: 0.5043 - val_loss: 2.6396 - val_acc: 0.2500\n",
      "Epoch 2704/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.2646 - acc: 0.5057 - val_loss: 2.6145 - val_acc: 0.2433\n",
      "Epoch 2705/3000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 1.2649 - acc: 0.5057 - val_loss: 2.6044 - val_acc: 0.2400\n",
      "Epoch 2706/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.2655 - acc: 0.5057 - val_loss: 2.6136 - val_acc: 0.2433\n",
      "Epoch 2707/3000\n",
      "700/700 [==============================] - 0s 116us/step - loss: 1.2667 - acc: 0.5043 - val_loss: 2.6221 - val_acc: 0.2400\n",
      "Epoch 2708/3000\n",
      "700/700 [==============================] - 0s 121us/step - loss: 1.2648 - acc: 0.5000 - val_loss: 2.6251 - val_acc: 0.2367\n",
      "Epoch 2709/3000\n",
      "700/700 [==============================] - 0s 116us/step - loss: 1.2646 - acc: 0.5071 - val_loss: 2.6196 - val_acc: 0.2333\n",
      "Epoch 2710/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.2647 - acc: 0.5057 - val_loss: 2.6311 - val_acc: 0.2367\n",
      "Epoch 2711/3000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.2652 - acc: 0.5071 - val_loss: 2.6129 - val_acc: 0.2433\n",
      "Epoch 2712/3000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 1.2644 - acc: 0.5029 - val_loss: 2.5818 - val_acc: 0.2367\n",
      "Epoch 2713/3000\n",
      "700/700 [==============================] - 0s 112us/step - loss: 1.2648 - acc: 0.5086 - val_loss: 2.6372 - val_acc: 0.2500\n",
      "Epoch 2714/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.2650 - acc: 0.5029 - val_loss: 2.6353 - val_acc: 0.2467\n",
      "Epoch 2715/3000\n",
      "700/700 [==============================] - 0s 117us/step - loss: 1.2650 - acc: 0.5071 - val_loss: 2.6134 - val_acc: 0.2367\n",
      "Epoch 2716/3000\n",
      "700/700 [==============================] - 0s 115us/step - loss: 1.2645 - acc: 0.5071 - val_loss: 2.6022 - val_acc: 0.2400\n",
      "Epoch 2717/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.2644 - acc: 0.5043 - val_loss: 2.6163 - val_acc: 0.2433\n",
      "Epoch 2718/3000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.2649 - acc: 0.5071 - val_loss: 2.6273 - val_acc: 0.2467\n",
      "Epoch 2719/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.2646 - acc: 0.5071 - val_loss: 2.6066 - val_acc: 0.2433\n",
      "Epoch 2720/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 112us/step - loss: 1.2649 - acc: 0.5029 - val_loss: 2.6116 - val_acc: 0.2367\n",
      "Epoch 2721/3000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 1.2649 - acc: 0.5071 - val_loss: 2.6112 - val_acc: 0.2367\n",
      "Epoch 2722/3000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.2642 - acc: 0.5057 - val_loss: 2.6224 - val_acc: 0.2467\n",
      "Epoch 2723/3000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 1.2647 - acc: 0.5057 - val_loss: 2.6197 - val_acc: 0.2467\n",
      "Epoch 2724/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.2647 - acc: 0.5086 - val_loss: 2.6237 - val_acc: 0.2467\n",
      "Epoch 2725/3000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 1.2640 - acc: 0.5043 - val_loss: 2.6332 - val_acc: 0.2467\n",
      "Epoch 2726/3000\n",
      "700/700 [==============================] - 0s 130us/step - loss: 1.2640 - acc: 0.5057 - val_loss: 2.6262 - val_acc: 0.2467\n",
      "Epoch 2727/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.2639 - acc: 0.5100 - val_loss: 2.6176 - val_acc: 0.2367\n",
      "Epoch 2728/3000\n",
      "700/700 [==============================] - 0s 126us/step - loss: 1.2631 - acc: 0.5057 - val_loss: 2.5929 - val_acc: 0.2433\n",
      "Epoch 2729/3000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 1.2643 - acc: 0.5086 - val_loss: 2.6301 - val_acc: 0.2433\n",
      "Epoch 2730/3000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 1.2633 - acc: 0.5086 - val_loss: 2.5940 - val_acc: 0.2333\n",
      "Epoch 2731/3000\n",
      "700/700 [==============================] - 0s 124us/step - loss: 1.2634 - acc: 0.5014 - val_loss: 2.6152 - val_acc: 0.2400\n",
      "Epoch 2732/3000\n",
      "700/700 [==============================] - 0s 108us/step - loss: 1.2648 - acc: 0.5071 - val_loss: 2.6278 - val_acc: 0.2400\n",
      "Epoch 2733/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.2640 - acc: 0.5071 - val_loss: 2.6008 - val_acc: 0.2367\n",
      "Epoch 2734/3000\n",
      "700/700 [==============================] - 0s 84us/step - loss: 1.2632 - acc: 0.5114 - val_loss: 2.6155 - val_acc: 0.2433\n",
      "Epoch 2735/3000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.2635 - acc: 0.5043 - val_loss: 2.6224 - val_acc: 0.2400\n",
      "Epoch 2736/3000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.2633 - acc: 0.5114 - val_loss: 2.6292 - val_acc: 0.2433\n",
      "Epoch 2737/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.2628 - acc: 0.5100 - val_loss: 2.6357 - val_acc: 0.2467\n",
      "Epoch 2738/3000\n",
      "700/700 [==============================] - 0s 116us/step - loss: 1.2639 - acc: 0.5071 - val_loss: 2.6097 - val_acc: 0.2400\n",
      "Epoch 2739/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.2631 - acc: 0.5086 - val_loss: 2.6540 - val_acc: 0.2467\n",
      "Epoch 2740/3000\n",
      "700/700 [==============================] - 0s 116us/step - loss: 1.2637 - acc: 0.5043 - val_loss: 2.6028 - val_acc: 0.2400\n",
      "Epoch 2741/3000\n",
      "700/700 [==============================] - 0s 125us/step - loss: 1.2643 - acc: 0.5043 - val_loss: 2.6396 - val_acc: 0.2400\n",
      "Epoch 2742/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.2639 - acc: 0.5014 - val_loss: 2.6343 - val_acc: 0.2400\n",
      "Epoch 2743/3000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.2634 - acc: 0.5043 - val_loss: 2.6156 - val_acc: 0.2400\n",
      "Epoch 2744/3000\n",
      "700/700 [==============================] - 0s 98us/step - loss: 1.2639 - acc: 0.5043 - val_loss: 2.6162 - val_acc: 0.2433\n",
      "Epoch 2745/3000\n",
      "700/700 [==============================] - 0s 119us/step - loss: 1.2632 - acc: 0.5057 - val_loss: 2.6316 - val_acc: 0.2433\n",
      "Epoch 2746/3000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.2638 - acc: 0.5057 - val_loss: 2.6162 - val_acc: 0.2400\n",
      "Epoch 2747/3000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.2636 - acc: 0.5000 - val_loss: 2.6189 - val_acc: 0.2333\n",
      "Epoch 2748/3000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.2635 - acc: 0.5071 - val_loss: 2.6466 - val_acc: 0.2467\n",
      "Epoch 2749/3000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.2637 - acc: 0.5000 - val_loss: 2.6385 - val_acc: 0.2467\n",
      "Epoch 2750/3000\n",
      "700/700 [==============================] - 0s 108us/step - loss: 1.2632 - acc: 0.5043 - val_loss: 2.6436 - val_acc: 0.2467\n",
      "Epoch 2751/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.2628 - acc: 0.5057 - val_loss: 2.6334 - val_acc: 0.2400\n",
      "Epoch 2752/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.2631 - acc: 0.5071 - val_loss: 2.6272 - val_acc: 0.2367\n",
      "Epoch 2753/3000\n",
      "700/700 [==============================] - 0s 81us/step - loss: 1.2625 - acc: 0.5057 - val_loss: 2.6363 - val_acc: 0.2467\n",
      "Epoch 2754/3000\n",
      "700/700 [==============================] - 0s 98us/step - loss: 1.2633 - acc: 0.5071 - val_loss: 2.6038 - val_acc: 0.2400\n",
      "Epoch 2755/3000\n",
      "700/700 [==============================] - 0s 92us/step - loss: 1.2620 - acc: 0.5043 - val_loss: 2.6010 - val_acc: 0.2400\n",
      "Epoch 2756/3000\n",
      "700/700 [==============================] - 0s 122us/step - loss: 1.2628 - acc: 0.5071 - val_loss: 2.6754 - val_acc: 0.2467\n",
      "Epoch 2757/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.2635 - acc: 0.5043 - val_loss: 2.6209 - val_acc: 0.2400\n",
      "Epoch 2758/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.2634 - acc: 0.5057 - val_loss: 2.5808 - val_acc: 0.2367\n",
      "Epoch 2759/3000\n",
      "700/700 [==============================] - 0s 125us/step - loss: 1.2629 - acc: 0.5071 - val_loss: 2.6440 - val_acc: 0.2433\n",
      "Epoch 2760/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.2626 - acc: 0.5086 - val_loss: 2.6336 - val_acc: 0.2400\n",
      "Epoch 2761/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.2623 - acc: 0.5071 - val_loss: 2.6244 - val_acc: 0.2433\n",
      "Epoch 2762/3000\n",
      "700/700 [==============================] - 0s 126us/step - loss: 1.2623 - acc: 0.5143 - val_loss: 2.6237 - val_acc: 0.2400\n",
      "Epoch 2763/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.2630 - acc: 0.5071 - val_loss: 2.6397 - val_acc: 0.2400\n",
      "Epoch 2764/3000\n",
      "700/700 [==============================] - 0s 115us/step - loss: 1.2613 - acc: 0.5029 - val_loss: 2.6503 - val_acc: 0.2467\n",
      "Epoch 2765/3000\n",
      "700/700 [==============================] - 0s 121us/step - loss: 1.2628 - acc: 0.4986 - val_loss: 2.6282 - val_acc: 0.2400\n",
      "Epoch 2766/3000\n",
      "700/700 [==============================] - 0s 130us/step - loss: 1.2618 - acc: 0.5114 - val_loss: 2.6395 - val_acc: 0.2433\n",
      "Epoch 2767/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.2626 - acc: 0.5114 - val_loss: 2.6371 - val_acc: 0.2367\n",
      "Epoch 2768/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.2621 - acc: 0.5071 - val_loss: 2.6413 - val_acc: 0.2467\n",
      "Epoch 2769/3000\n",
      "700/700 [==============================] - 0s 119us/step - loss: 1.2612 - acc: 0.5071 - val_loss: 2.6372 - val_acc: 0.2433\n",
      "Epoch 2770/3000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.2618 - acc: 0.5057 - val_loss: 2.6186 - val_acc: 0.2367\n",
      "Epoch 2771/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.2616 - acc: 0.5114 - val_loss: 2.6148 - val_acc: 0.2367\n",
      "Epoch 2772/3000\n",
      "700/700 [==============================] - 0s 82us/step - loss: 1.2631 - acc: 0.5086 - val_loss: 2.6147 - val_acc: 0.2400\n",
      "Epoch 2773/3000\n",
      "700/700 [==============================] - 0s 82us/step - loss: 1.2619 - acc: 0.5029 - val_loss: 2.5961 - val_acc: 0.2400\n",
      "Epoch 2774/3000\n",
      "700/700 [==============================] - 0s 117us/step - loss: 1.2619 - acc: 0.5086 - val_loss: 2.6318 - val_acc: 0.2467\n",
      "Epoch 2775/3000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 1.2615 - acc: 0.5086 - val_loss: 2.6274 - val_acc: 0.2400\n",
      "Epoch 2776/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.2621 - acc: 0.5057 - val_loss: 2.6328 - val_acc: 0.2433\n",
      "Epoch 2777/3000\n",
      "700/700 [==============================] - 0s 112us/step - loss: 1.2628 - acc: 0.5043 - val_loss: 2.6525 - val_acc: 0.2467\n",
      "Epoch 2778/3000\n",
      "700/700 [==============================] - 0s 121us/step - loss: 1.2624 - acc: 0.5071 - val_loss: 2.6403 - val_acc: 0.2333\n",
      "Epoch 2779/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 116us/step - loss: 1.2605 - acc: 0.5129 - val_loss: 2.6346 - val_acc: 0.2467\n",
      "Epoch 2780/3000\n",
      "700/700 [==============================] - 0s 117us/step - loss: 1.2617 - acc: 0.5029 - val_loss: 2.6492 - val_acc: 0.2467\n",
      "Epoch 2781/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.2620 - acc: 0.5029 - val_loss: 2.6383 - val_acc: 0.2433\n",
      "Epoch 2782/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 1.2613 - acc: 0.5086 - val_loss: 2.6274 - val_acc: 0.2367\n",
      "Epoch 2783/3000\n",
      "700/700 [==============================] - 0s 122us/step - loss: 1.2618 - acc: 0.5043 - val_loss: 2.6440 - val_acc: 0.2400\n",
      "Epoch 2784/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.2608 - acc: 0.5043 - val_loss: 2.6423 - val_acc: 0.2467\n",
      "Epoch 2785/3000\n",
      "700/700 [==============================] - 0s 123us/step - loss: 1.2613 - acc: 0.5129 - val_loss: 2.6352 - val_acc: 0.2400\n",
      "Epoch 2786/3000\n",
      "700/700 [==============================] - 0s 122us/step - loss: 1.2618 - acc: 0.5114 - val_loss: 2.6498 - val_acc: 0.2433\n",
      "Epoch 2787/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.2611 - acc: 0.5029 - val_loss: 2.6290 - val_acc: 0.2367\n",
      "Epoch 2788/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.2610 - acc: 0.5086 - val_loss: 2.6594 - val_acc: 0.2400\n",
      "Epoch 2789/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.2614 - acc: 0.5014 - val_loss: 2.6507 - val_acc: 0.2367\n",
      "Epoch 2790/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.2617 - acc: 0.5071 - val_loss: 2.5976 - val_acc: 0.2367\n",
      "Epoch 2791/3000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 1.2615 - acc: 0.5071 - val_loss: 2.6072 - val_acc: 0.2367\n",
      "Epoch 2792/3000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.2613 - acc: 0.5043 - val_loss: 2.6325 - val_acc: 0.2367\n",
      "Epoch 2793/3000\n",
      "700/700 [==============================] - 0s 112us/step - loss: 1.2601 - acc: 0.5086 - val_loss: 2.6165 - val_acc: 0.2367\n",
      "Epoch 2794/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.2612 - acc: 0.5057 - val_loss: 2.6408 - val_acc: 0.2433\n",
      "Epoch 2795/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.2612 - acc: 0.5086 - val_loss: 2.6161 - val_acc: 0.2367\n",
      "Epoch 2796/3000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 1.2607 - acc: 0.5043 - val_loss: 2.6407 - val_acc: 0.2433\n",
      "Epoch 2797/3000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.2608 - acc: 0.5014 - val_loss: 2.6360 - val_acc: 0.2367\n",
      "Epoch 2798/3000\n",
      "700/700 [==============================] - 0s 108us/step - loss: 1.2600 - acc: 0.5129 - val_loss: 2.6556 - val_acc: 0.2400\n",
      "Epoch 2799/3000\n",
      "700/700 [==============================] - 0s 121us/step - loss: 1.2607 - acc: 0.5086 - val_loss: 2.6168 - val_acc: 0.2367\n",
      "Epoch 2800/3000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 1.2617 - acc: 0.5043 - val_loss: 2.6387 - val_acc: 0.2400\n",
      "Epoch 2801/3000\n",
      "700/700 [==============================] - 0s 120us/step - loss: 1.2608 - acc: 0.5100 - val_loss: 2.6573 - val_acc: 0.2400\n",
      "Epoch 2802/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.2613 - acc: 0.5071 - val_loss: 2.6469 - val_acc: 0.2433\n",
      "Epoch 2803/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.2597 - acc: 0.5100 - val_loss: 2.6383 - val_acc: 0.2467\n",
      "Epoch 2804/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.2605 - acc: 0.5114 - val_loss: 2.6459 - val_acc: 0.2433\n",
      "Epoch 2805/3000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.2602 - acc: 0.5057 - val_loss: 2.6451 - val_acc: 0.2400\n",
      "Epoch 2806/3000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.2604 - acc: 0.5014 - val_loss: 2.6380 - val_acc: 0.2433\n",
      "Epoch 2807/3000\n",
      "700/700 [==============================] - 0s 115us/step - loss: 1.2606 - acc: 0.5100 - val_loss: 2.6604 - val_acc: 0.2467\n",
      "Epoch 2808/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.2598 - acc: 0.5086 - val_loss: 2.6223 - val_acc: 0.2433\n",
      "Epoch 2809/3000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.2601 - acc: 0.5043 - val_loss: 2.6563 - val_acc: 0.2467\n",
      "Epoch 2810/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.2600 - acc: 0.5043 - val_loss: 2.6332 - val_acc: 0.2467\n",
      "Epoch 2811/3000\n",
      "700/700 [==============================] - 0s 130us/step - loss: 1.2598 - acc: 0.5057 - val_loss: 2.6460 - val_acc: 0.2467\n",
      "Epoch 2812/3000\n",
      "700/700 [==============================] - 0s 122us/step - loss: 1.2605 - acc: 0.5057 - val_loss: 2.6340 - val_acc: 0.2433\n",
      "Epoch 2813/3000\n",
      "700/700 [==============================] - 0s 112us/step - loss: 1.2610 - acc: 0.5143 - val_loss: 2.6492 - val_acc: 0.2400\n",
      "Epoch 2814/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.2601 - acc: 0.5086 - val_loss: 2.6342 - val_acc: 0.2367\n",
      "Epoch 2815/3000\n",
      "700/700 [==============================] - 0s 120us/step - loss: 1.2598 - acc: 0.5086 - val_loss: 2.6544 - val_acc: 0.2433\n",
      "Epoch 2816/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.2607 - acc: 0.5043 - val_loss: 2.6300 - val_acc: 0.2400\n",
      "Epoch 2817/3000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 1.2597 - acc: 0.5043 - val_loss: 2.6511 - val_acc: 0.2367\n",
      "Epoch 2818/3000\n",
      "700/700 [==============================] - 0s 119us/step - loss: 1.2600 - acc: 0.5057 - val_loss: 2.6416 - val_acc: 0.2433\n",
      "Epoch 2819/3000\n",
      "700/700 [==============================] - 0s 119us/step - loss: 1.2601 - acc: 0.5100 - val_loss: 2.6422 - val_acc: 0.2433\n",
      "Epoch 2820/3000\n",
      "700/700 [==============================] - 0s 112us/step - loss: 1.2602 - acc: 0.5071 - val_loss: 2.6260 - val_acc: 0.2333\n",
      "Epoch 2821/3000\n",
      "700/700 [==============================] - 0s 115us/step - loss: 1.2602 - acc: 0.5029 - val_loss: 2.6634 - val_acc: 0.2467\n",
      "Epoch 2822/3000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.2596 - acc: 0.5071 - val_loss: 2.6528 - val_acc: 0.2400\n",
      "Epoch 2823/3000\n",
      "700/700 [==============================] - 0s 98us/step - loss: 1.2594 - acc: 0.5029 - val_loss: 2.6549 - val_acc: 0.2400\n",
      "Epoch 2824/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.2592 - acc: 0.5100 - val_loss: 2.6530 - val_acc: 0.2367\n",
      "Epoch 2825/3000\n",
      "700/700 [==============================] - 0s 115us/step - loss: 1.2601 - acc: 0.5057 - val_loss: 2.6559 - val_acc: 0.2433\n",
      "Epoch 2826/3000\n",
      "700/700 [==============================] - 0s 119us/step - loss: 1.2587 - acc: 0.5086 - val_loss: 2.6576 - val_acc: 0.2400\n",
      "Epoch 2827/3000\n",
      "700/700 [==============================] - 0s 112us/step - loss: 1.2605 - acc: 0.5029 - val_loss: 2.6317 - val_acc: 0.2367\n",
      "Epoch 2828/3000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 1.2599 - acc: 0.5086 - val_loss: 2.6672 - val_acc: 0.2400\n",
      "Epoch 2829/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.2600 - acc: 0.5057 - val_loss: 2.6324 - val_acc: 0.2367\n",
      "Epoch 2830/3000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.2583 - acc: 0.5071 - val_loss: 2.6249 - val_acc: 0.2367\n",
      "Epoch 2831/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.2601 - acc: 0.5114 - val_loss: 2.6243 - val_acc: 0.2367\n",
      "Epoch 2832/3000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 1.2590 - acc: 0.5100 - val_loss: 2.6729 - val_acc: 0.2433\n",
      "Epoch 2833/3000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.2594 - acc: 0.5043 - val_loss: 2.6479 - val_acc: 0.2400\n",
      "Epoch 2834/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.2594 - acc: 0.5029 - val_loss: 2.6468 - val_acc: 0.2467\n",
      "Epoch 2835/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.2589 - acc: 0.5014 - val_loss: 2.6503 - val_acc: 0.2400\n",
      "Epoch 2836/3000\n",
      "700/700 [==============================] - 0s 118us/step - loss: 1.2590 - acc: 0.5086 - val_loss: 2.6430 - val_acc: 0.2400\n",
      "Epoch 2837/3000\n",
      "700/700 [==============================] - 0s 118us/step - loss: 1.2587 - acc: 0.5086 - val_loss: 2.6581 - val_acc: 0.2400\n",
      "Epoch 2838/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 107us/step - loss: 1.2594 - acc: 0.5143 - val_loss: 2.6041 - val_acc: 0.2333\n",
      "Epoch 2839/3000\n",
      "700/700 [==============================] - 0s 112us/step - loss: 1.2588 - acc: 0.5086 - val_loss: 2.6426 - val_acc: 0.2433\n",
      "Epoch 2840/3000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 1.2587 - acc: 0.5071 - val_loss: 2.6535 - val_acc: 0.2400\n",
      "Epoch 2841/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.2589 - acc: 0.5071 - val_loss: 2.6548 - val_acc: 0.2467\n",
      "Epoch 2842/3000\n",
      "700/700 [==============================] - 0s 116us/step - loss: 1.2590 - acc: 0.5100 - val_loss: 2.6444 - val_acc: 0.2367\n",
      "Epoch 2843/3000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 1.2591 - acc: 0.5043 - val_loss: 2.6470 - val_acc: 0.2367\n",
      "Epoch 2844/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.2583 - acc: 0.5100 - val_loss: 2.6526 - val_acc: 0.2433\n",
      "Epoch 2845/3000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 1.2592 - acc: 0.5100 - val_loss: 2.6695 - val_acc: 0.2400\n",
      "Epoch 2846/3000\n",
      "700/700 [==============================] - 0s 115us/step - loss: 1.2580 - acc: 0.5086 - val_loss: 2.6938 - val_acc: 0.2467\n",
      "Epoch 2847/3000\n",
      "700/700 [==============================] - 0s 112us/step - loss: 1.2587 - acc: 0.5086 - val_loss: 2.6558 - val_acc: 0.2433\n",
      "Epoch 2848/3000\n",
      "700/700 [==============================] - 0s 122us/step - loss: 1.2579 - acc: 0.5071 - val_loss: 2.6349 - val_acc: 0.2367\n",
      "Epoch 2849/3000\n",
      "700/700 [==============================] - 0s 116us/step - loss: 1.2584 - acc: 0.5057 - val_loss: 2.6548 - val_acc: 0.2400\n",
      "Epoch 2850/3000\n",
      "700/700 [==============================] - 0s 112us/step - loss: 1.2585 - acc: 0.5071 - val_loss: 2.6505 - val_acc: 0.2400\n",
      "Epoch 2851/3000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 1.2584 - acc: 0.5057 - val_loss: 2.6501 - val_acc: 0.2367\n",
      "Epoch 2852/3000\n",
      "700/700 [==============================] - 0s 86us/step - loss: 1.2582 - acc: 0.5086 - val_loss: 2.6756 - val_acc: 0.2467\n",
      "Epoch 2853/3000\n",
      "700/700 [==============================] - 0s 80us/step - loss: 1.2581 - acc: 0.5029 - val_loss: 2.6656 - val_acc: 0.2467\n",
      "Epoch 2854/3000\n",
      "700/700 [==============================] - 0s 81us/step - loss: 1.2586 - acc: 0.5043 - val_loss: 2.6288 - val_acc: 0.2333\n",
      "Epoch 2855/3000\n",
      "700/700 [==============================] - 0s 80us/step - loss: 1.2581 - acc: 0.5071 - val_loss: 2.6599 - val_acc: 0.2367\n",
      "Epoch 2856/3000\n",
      "700/700 [==============================] - 0s 80us/step - loss: 1.2584 - acc: 0.5086 - val_loss: 2.6603 - val_acc: 0.2367\n",
      "Epoch 2857/3000\n",
      "700/700 [==============================] - 0s 86us/step - loss: 1.2580 - acc: 0.5071 - val_loss: 2.6727 - val_acc: 0.2467\n",
      "Epoch 2858/3000\n",
      "700/700 [==============================] - 0s 84us/step - loss: 1.2579 - acc: 0.5071 - val_loss: 2.6752 - val_acc: 0.2467\n",
      "Epoch 2859/3000\n",
      "700/700 [==============================] - 0s 98us/step - loss: 1.2576 - acc: 0.5014 - val_loss: 2.6406 - val_acc: 0.2367\n",
      "Epoch 2860/3000\n",
      "700/700 [==============================] - 0s 79us/step - loss: 1.2581 - acc: 0.5114 - val_loss: 2.6136 - val_acc: 0.2367\n",
      "Epoch 2861/3000\n",
      "700/700 [==============================] - 0s 77us/step - loss: 1.2581 - acc: 0.5100 - val_loss: 2.6547 - val_acc: 0.2400\n",
      "Epoch 2862/3000\n",
      "700/700 [==============================] - 0s 76us/step - loss: 1.2577 - acc: 0.5086 - val_loss: 2.6572 - val_acc: 0.2400\n",
      "Epoch 2863/3000\n",
      "700/700 [==============================] - 0s 77us/step - loss: 1.2574 - acc: 0.5071 - val_loss: 2.6541 - val_acc: 0.2433\n",
      "Epoch 2864/3000\n",
      "700/700 [==============================] - 0s 76us/step - loss: 1.2580 - acc: 0.5014 - val_loss: 2.6438 - val_acc: 0.2433\n",
      "Epoch 2865/3000\n",
      "700/700 [==============================] - 0s 75us/step - loss: 1.2582 - acc: 0.5129 - val_loss: 2.6747 - val_acc: 0.2433\n",
      "Epoch 2866/3000\n",
      "700/700 [==============================] - 0s 76us/step - loss: 1.2579 - acc: 0.5100 - val_loss: 2.6676 - val_acc: 0.2400\n",
      "Epoch 2867/3000\n",
      "700/700 [==============================] - 0s 75us/step - loss: 1.2572 - acc: 0.5114 - val_loss: 2.6665 - val_acc: 0.2467\n",
      "Epoch 2868/3000\n",
      "700/700 [==============================] - 0s 76us/step - loss: 1.2579 - acc: 0.5086 - val_loss: 2.6310 - val_acc: 0.2333\n",
      "Epoch 2869/3000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.2574 - acc: 0.5071 - val_loss: 2.6381 - val_acc: 0.2400\n",
      "Epoch 2870/3000\n",
      "700/700 [==============================] - 0s 77us/step - loss: 1.2574 - acc: 0.5043 - val_loss: 2.7028 - val_acc: 0.2467\n",
      "Epoch 2871/3000\n",
      "700/700 [==============================] - 0s 76us/step - loss: 1.2581 - acc: 0.5071 - val_loss: 2.6791 - val_acc: 0.2400\n",
      "Epoch 2872/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.2575 - acc: 0.5043 - val_loss: 2.6574 - val_acc: 0.2367\n",
      "Epoch 2873/3000\n",
      "700/700 [==============================] - 0s 112us/step - loss: 1.2571 - acc: 0.5114 - val_loss: 2.6324 - val_acc: 0.2333\n",
      "Epoch 2874/3000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.2570 - acc: 0.5171 - val_loss: 2.6271 - val_acc: 0.2367\n",
      "Epoch 2875/3000\n",
      "700/700 [==============================] - 0s 122us/step - loss: 1.2574 - acc: 0.5114 - val_loss: 2.6564 - val_acc: 0.2433\n",
      "Epoch 2876/3000\n",
      "700/700 [==============================] - 0s 125us/step - loss: 1.2585 - acc: 0.5043 - val_loss: 2.6888 - val_acc: 0.2467\n",
      "Epoch 2877/3000\n",
      "700/700 [==============================] - 0s 117us/step - loss: 1.2575 - acc: 0.5071 - val_loss: 2.6792 - val_acc: 0.2433\n",
      "Epoch 2878/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.2568 - acc: 0.5029 - val_loss: 2.6538 - val_acc: 0.2433\n",
      "Epoch 2879/3000\n",
      "700/700 [==============================] - 0s 115us/step - loss: 1.2563 - acc: 0.5129 - val_loss: 2.6679 - val_acc: 0.2467\n",
      "Epoch 2880/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.2565 - acc: 0.5100 - val_loss: 2.6750 - val_acc: 0.2400\n",
      "Epoch 2881/3000\n",
      "700/700 [==============================] - 0s 119us/step - loss: 1.2576 - acc: 0.5129 - val_loss: 2.6605 - val_acc: 0.2400\n",
      "Epoch 2882/3000\n",
      "700/700 [==============================] - 0s 122us/step - loss: 1.2571 - acc: 0.5100 - val_loss: 2.6258 - val_acc: 0.2367\n",
      "Epoch 2883/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.2564 - acc: 0.5129 - val_loss: 2.6788 - val_acc: 0.2433\n",
      "Epoch 2884/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.2569 - acc: 0.5100 - val_loss: 2.6965 - val_acc: 0.2433\n",
      "Epoch 2885/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.2572 - acc: 0.5071 - val_loss: 2.6325 - val_acc: 0.2400\n",
      "Epoch 2886/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.2573 - acc: 0.5086 - val_loss: 2.6520 - val_acc: 0.2400\n",
      "Epoch 2887/3000\n",
      "700/700 [==============================] - 0s 124us/step - loss: 1.2567 - acc: 0.5129 - val_loss: 2.6708 - val_acc: 0.2433\n",
      "Epoch 2888/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.2567 - acc: 0.5043 - val_loss: 2.6865 - val_acc: 0.2467\n",
      "Epoch 2889/3000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.2570 - acc: 0.5100 - val_loss: 2.6370 - val_acc: 0.2400\n",
      "Epoch 2890/3000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.2567 - acc: 0.5143 - val_loss: 2.6423 - val_acc: 0.2367\n",
      "Epoch 2891/3000\n",
      "700/700 [==============================] - 0s 84us/step - loss: 1.2569 - acc: 0.5071 - val_loss: 2.6640 - val_acc: 0.2433\n",
      "Epoch 2892/3000\n",
      "700/700 [==============================] - 0s 80us/step - loss: 1.2568 - acc: 0.5043 - val_loss: 2.6644 - val_acc: 0.2400\n",
      "Epoch 2893/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.2577 - acc: 0.5071 - val_loss: 2.6573 - val_acc: 0.2433\n",
      "Epoch 2894/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.2570 - acc: 0.5071 - val_loss: 2.6907 - val_acc: 0.2467\n",
      "Epoch 2895/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.2563 - acc: 0.5100 - val_loss: 2.6746 - val_acc: 0.2367\n",
      "Epoch 2896/3000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.2563 - acc: 0.5057 - val_loss: 2.6687 - val_acc: 0.2400\n",
      "Epoch 2897/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 108us/step - loss: 1.2562 - acc: 0.5129 - val_loss: 2.6960 - val_acc: 0.2400\n",
      "Epoch 2898/3000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.2560 - acc: 0.5057 - val_loss: 2.6795 - val_acc: 0.2400\n",
      "Epoch 2899/3000\n",
      "700/700 [==============================] - 0s 121us/step - loss: 1.2566 - acc: 0.5143 - val_loss: 2.6639 - val_acc: 0.2433\n",
      "Epoch 2900/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.2557 - acc: 0.5100 - val_loss: 2.6695 - val_acc: 0.2433\n",
      "Epoch 2901/3000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.2560 - acc: 0.5129 - val_loss: 2.6585 - val_acc: 0.2400\n",
      "Epoch 2902/3000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.2563 - acc: 0.5100 - val_loss: 2.6997 - val_acc: 0.2433\n",
      "Epoch 2903/3000\n",
      "700/700 [==============================] - 0s 108us/step - loss: 1.2561 - acc: 0.5086 - val_loss: 2.6587 - val_acc: 0.2367\n",
      "Epoch 2904/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.2561 - acc: 0.5114 - val_loss: 2.6581 - val_acc: 0.2367\n",
      "Epoch 2905/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.2564 - acc: 0.5100 - val_loss: 2.6724 - val_acc: 0.2400\n",
      "Epoch 2906/3000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.2560 - acc: 0.5086 - val_loss: 2.6678 - val_acc: 0.2367\n",
      "Epoch 2907/3000\n",
      "700/700 [==============================] - 0s 120us/step - loss: 1.2553 - acc: 0.5086 - val_loss: 2.6747 - val_acc: 0.2433\n",
      "Epoch 2908/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.2554 - acc: 0.5171 - val_loss: 2.6650 - val_acc: 0.2367\n",
      "Epoch 2909/3000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 1.2560 - acc: 0.5071 - val_loss: 2.6442 - val_acc: 0.2400\n",
      "Epoch 2910/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.2558 - acc: 0.5143 - val_loss: 2.6594 - val_acc: 0.2367\n",
      "Epoch 2911/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.2560 - acc: 0.5043 - val_loss: 2.6334 - val_acc: 0.2367\n",
      "Epoch 2912/3000\n",
      "700/700 [==============================] - 0s 120us/step - loss: 1.2560 - acc: 0.5086 - val_loss: 2.6367 - val_acc: 0.2333\n",
      "Epoch 2913/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.2559 - acc: 0.5043 - val_loss: 2.6598 - val_acc: 0.2400\n",
      "Epoch 2914/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.2555 - acc: 0.5086 - val_loss: 2.6579 - val_acc: 0.2367\n",
      "Epoch 2915/3000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.2560 - acc: 0.5086 - val_loss: 2.6289 - val_acc: 0.2367\n",
      "Epoch 2916/3000\n",
      "700/700 [==============================] - 0s 121us/step - loss: 1.2559 - acc: 0.5071 - val_loss: 2.6877 - val_acc: 0.2433\n",
      "Epoch 2917/3000\n",
      "700/700 [==============================] - 0s 116us/step - loss: 1.2554 - acc: 0.5114 - val_loss: 2.6673 - val_acc: 0.2400\n",
      "Epoch 2918/3000\n",
      "700/700 [==============================] - 0s 115us/step - loss: 1.2558 - acc: 0.5129 - val_loss: 2.6787 - val_acc: 0.2433\n",
      "Epoch 2919/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.2549 - acc: 0.5129 - val_loss: 2.6830 - val_acc: 0.2400\n",
      "Epoch 2920/3000\n",
      "700/700 [==============================] - 0s 108us/step - loss: 1.2549 - acc: 0.5071 - val_loss: 2.6552 - val_acc: 0.2367\n",
      "Epoch 2921/3000\n",
      "700/700 [==============================] - 0s 118us/step - loss: 1.2553 - acc: 0.5143 - val_loss: 2.6491 - val_acc: 0.2400\n",
      "Epoch 2922/3000\n",
      "700/700 [==============================] - 0s 122us/step - loss: 1.2550 - acc: 0.5043 - val_loss: 2.6822 - val_acc: 0.2400\n",
      "Epoch 2923/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.2548 - acc: 0.5129 - val_loss: 2.6551 - val_acc: 0.2367\n",
      "Epoch 2924/3000\n",
      "700/700 [==============================] - 0s 125us/step - loss: 1.2554 - acc: 0.5071 - val_loss: 2.6724 - val_acc: 0.2367\n",
      "Epoch 2925/3000\n",
      "700/700 [==============================] - 0s 112us/step - loss: 1.2547 - acc: 0.5114 - val_loss: 2.6964 - val_acc: 0.2433\n",
      "Epoch 2926/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.2551 - acc: 0.5114 - val_loss: 2.6734 - val_acc: 0.2433\n",
      "Epoch 2927/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.2555 - acc: 0.5114 - val_loss: 2.7160 - val_acc: 0.2467\n",
      "Epoch 2928/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.2551 - acc: 0.5114 - val_loss: 2.6580 - val_acc: 0.2400\n",
      "Epoch 2929/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.2546 - acc: 0.5100 - val_loss: 2.6783 - val_acc: 0.2400\n",
      "Epoch 2930/3000\n",
      "700/700 [==============================] - 0s 108us/step - loss: 1.2538 - acc: 0.5086 - val_loss: 2.7047 - val_acc: 0.2467\n",
      "Epoch 2931/3000\n",
      "700/700 [==============================] - 0s 120us/step - loss: 1.2551 - acc: 0.5114 - val_loss: 2.6992 - val_acc: 0.2400\n",
      "Epoch 2932/3000\n",
      "700/700 [==============================] - 0s 116us/step - loss: 1.2551 - acc: 0.5057 - val_loss: 2.6662 - val_acc: 0.2367\n",
      "Epoch 2933/3000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.2545 - acc: 0.5143 - val_loss: 2.6617 - val_acc: 0.2400\n",
      "Epoch 2934/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.2554 - acc: 0.5114 - val_loss: 2.6768 - val_acc: 0.2433\n",
      "Epoch 2935/3000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.2553 - acc: 0.5100 - val_loss: 2.6690 - val_acc: 0.2400\n",
      "Epoch 2936/3000\n",
      "700/700 [==============================] - 0s 120us/step - loss: 1.2541 - acc: 0.5114 - val_loss: 2.6569 - val_acc: 0.2367\n",
      "Epoch 2937/3000\n",
      "700/700 [==============================] - 0s 112us/step - loss: 1.2548 - acc: 0.5129 - val_loss: 2.6876 - val_acc: 0.2433\n",
      "Epoch 2938/3000\n",
      "700/700 [==============================] - 0s 115us/step - loss: 1.2556 - acc: 0.5071 - val_loss: 2.6723 - val_acc: 0.2400\n",
      "Epoch 2939/3000\n",
      "700/700 [==============================] - 0s 112us/step - loss: 1.2545 - acc: 0.5114 - val_loss: 2.6413 - val_acc: 0.2300\n",
      "Epoch 2940/3000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 1.2546 - acc: 0.5100 - val_loss: 2.6852 - val_acc: 0.2367\n",
      "Epoch 2941/3000\n",
      "700/700 [==============================] - 0s 119us/step - loss: 1.2534 - acc: 0.5071 - val_loss: 2.6614 - val_acc: 0.2400\n",
      "Epoch 2942/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.2568 - acc: 0.5129 - val_loss: 2.6782 - val_acc: 0.2367\n",
      "Epoch 2943/3000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.2542 - acc: 0.5157 - val_loss: 2.6974 - val_acc: 0.2433\n",
      "Epoch 2944/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.2540 - acc: 0.5143 - val_loss: 2.6763 - val_acc: 0.2433\n",
      "Epoch 2945/3000\n",
      "700/700 [==============================] - 0s 77us/step - loss: 1.2539 - acc: 0.5143 - val_loss: 2.6920 - val_acc: 0.2467\n",
      "Epoch 2946/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.2540 - acc: 0.5071 - val_loss: 2.6960 - val_acc: 0.2400\n",
      "Epoch 2947/3000\n",
      "700/700 [==============================] - 0s 118us/step - loss: 1.2544 - acc: 0.5143 - val_loss: 2.6641 - val_acc: 0.2367\n",
      "Epoch 2948/3000\n",
      "700/700 [==============================] - 0s 112us/step - loss: 1.2540 - acc: 0.5057 - val_loss: 2.6926 - val_acc: 0.2433\n",
      "Epoch 2949/3000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.2549 - acc: 0.5114 - val_loss: 2.6709 - val_acc: 0.2333\n",
      "Epoch 2950/3000\n",
      "700/700 [==============================] - 0s 116us/step - loss: 1.2538 - acc: 0.5129 - val_loss: 2.6733 - val_acc: 0.2433\n",
      "Epoch 2951/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.2542 - acc: 0.5114 - val_loss: 2.7107 - val_acc: 0.2400\n",
      "Epoch 2952/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.2541 - acc: 0.5086 - val_loss: 2.6783 - val_acc: 0.2367\n",
      "Epoch 2953/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.2535 - acc: 0.5086 - val_loss: 2.6824 - val_acc: 0.2433\n",
      "Epoch 2954/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.2552 - acc: 0.5100 - val_loss: 2.6783 - val_acc: 0.2367\n",
      "Epoch 2955/3000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 1.2539 - acc: 0.5114 - val_loss: 2.6453 - val_acc: 0.2400\n",
      "Epoch 2956/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 109us/step - loss: 1.2542 - acc: 0.5100 - val_loss: 2.6497 - val_acc: 0.2333\n",
      "Epoch 2957/3000\n",
      "700/700 [==============================] - 0s 118us/step - loss: 1.2532 - acc: 0.5157 - val_loss: 2.6978 - val_acc: 0.2400\n",
      "Epoch 2958/3000\n",
      "700/700 [==============================] - 0s 117us/step - loss: 1.2546 - acc: 0.5086 - val_loss: 2.6789 - val_acc: 0.2433\n",
      "Epoch 2959/3000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.2540 - acc: 0.5057 - val_loss: 2.6685 - val_acc: 0.2367\n",
      "Epoch 2960/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.2542 - acc: 0.5129 - val_loss: 2.6713 - val_acc: 0.2400\n",
      "Epoch 2961/3000\n",
      "700/700 [==============================] - 0s 115us/step - loss: 1.2534 - acc: 0.5157 - val_loss: 2.6661 - val_acc: 0.2400\n",
      "Epoch 2962/3000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 1.2542 - acc: 0.5129 - val_loss: 2.6872 - val_acc: 0.2400\n",
      "Epoch 2963/3000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 1.2533 - acc: 0.5100 - val_loss: 2.6723 - val_acc: 0.2367\n",
      "Epoch 2964/3000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 1.2534 - acc: 0.5086 - val_loss: 2.6689 - val_acc: 0.2367\n",
      "Epoch 2965/3000\n",
      "700/700 [==============================] - 0s 115us/step - loss: 1.2535 - acc: 0.5143 - val_loss: 2.6504 - val_acc: 0.2400\n",
      "Epoch 2966/3000\n",
      "700/700 [==============================] - 0s 122us/step - loss: 1.2536 - acc: 0.5129 - val_loss: 2.6644 - val_acc: 0.2367\n",
      "Epoch 2967/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.2531 - acc: 0.5114 - val_loss: 2.6634 - val_acc: 0.2367\n",
      "Epoch 2968/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.2532 - acc: 0.5129 - val_loss: 2.6965 - val_acc: 0.2400\n",
      "Epoch 2969/3000\n",
      "700/700 [==============================] - 0s 117us/step - loss: 1.2532 - acc: 0.5100 - val_loss: 2.6949 - val_acc: 0.2400\n",
      "Epoch 2970/3000\n",
      "700/700 [==============================] - 0s 118us/step - loss: 1.2524 - acc: 0.5086 - val_loss: 2.7126 - val_acc: 0.2433\n",
      "Epoch 2971/3000\n",
      "700/700 [==============================] - 0s 117us/step - loss: 1.2533 - acc: 0.5100 - val_loss: 2.6600 - val_acc: 0.2400\n",
      "Epoch 2972/3000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 1.2533 - acc: 0.5114 - val_loss: 2.6689 - val_acc: 0.2400\n",
      "Epoch 2973/3000\n",
      "700/700 [==============================] - 0s 112us/step - loss: 1.2533 - acc: 0.5100 - val_loss: 2.6550 - val_acc: 0.2367\n",
      "Epoch 2974/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.2526 - acc: 0.5143 - val_loss: 2.6611 - val_acc: 0.2367\n",
      "Epoch 2975/3000\n",
      "700/700 [==============================] - 0s 116us/step - loss: 1.2532 - acc: 0.5129 - val_loss: 2.6847 - val_acc: 0.2367\n",
      "Epoch 2976/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.2530 - acc: 0.5114 - val_loss: 2.6851 - val_acc: 0.2367\n",
      "Epoch 2977/3000\n",
      "700/700 [==============================] - 0s 128us/step - loss: 1.2525 - acc: 0.5086 - val_loss: 2.6987 - val_acc: 0.2333\n",
      "Epoch 2978/3000\n",
      "700/700 [==============================] - 0s 108us/step - loss: 1.2526 - acc: 0.5114 - val_loss: 2.6875 - val_acc: 0.2433\n",
      "Epoch 2979/3000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 1.2525 - acc: 0.5143 - val_loss: 2.6518 - val_acc: 0.2367\n",
      "Epoch 2980/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.2525 - acc: 0.5114 - val_loss: 2.6989 - val_acc: 0.2467\n",
      "Epoch 2981/3000\n",
      "700/700 [==============================] - 0s 108us/step - loss: 1.2525 - acc: 0.5086 - val_loss: 2.6879 - val_acc: 0.2333\n",
      "Epoch 2982/3000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.2527 - acc: 0.5100 - val_loss: 2.6606 - val_acc: 0.2400\n",
      "Epoch 2983/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.2526 - acc: 0.5114 - val_loss: 2.6919 - val_acc: 0.2367\n",
      "Epoch 2984/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.2523 - acc: 0.5129 - val_loss: 2.6909 - val_acc: 0.2433\n",
      "Epoch 2985/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.2527 - acc: 0.5100 - val_loss: 2.6930 - val_acc: 0.2433\n",
      "Epoch 2986/3000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.2522 - acc: 0.5114 - val_loss: 2.6883 - val_acc: 0.2367\n",
      "Epoch 2987/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.2523 - acc: 0.5143 - val_loss: 2.6947 - val_acc: 0.2400\n",
      "Epoch 2988/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.2527 - acc: 0.5143 - val_loss: 2.6755 - val_acc: 0.2300\n",
      "Epoch 2989/3000\n",
      "700/700 [==============================] - 0s 122us/step - loss: 1.2524 - acc: 0.5086 - val_loss: 2.7074 - val_acc: 0.2400\n",
      "Epoch 2990/3000\n",
      "700/700 [==============================] - 0s 108us/step - loss: 1.2524 - acc: 0.5129 - val_loss: 2.6877 - val_acc: 0.2433\n",
      "Epoch 2991/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.2523 - acc: 0.5129 - val_loss: 2.6774 - val_acc: 0.2400\n",
      "Epoch 2992/3000\n",
      "700/700 [==============================] - 0s 125us/step - loss: 1.2520 - acc: 0.5143 - val_loss: 2.6879 - val_acc: 0.2367\n",
      "Epoch 2993/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.2521 - acc: 0.5086 - val_loss: 2.6837 - val_acc: 0.2433\n",
      "Epoch 2994/3000\n",
      "700/700 [==============================] - 0s 116us/step - loss: 1.2525 - acc: 0.5086 - val_loss: 2.6856 - val_acc: 0.2400\n",
      "Epoch 2995/3000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 1.2515 - acc: 0.5114 - val_loss: 2.6991 - val_acc: 0.2467\n",
      "Epoch 2996/3000\n",
      "700/700 [==============================] - 0s 132us/step - loss: 1.2520 - acc: 0.5114 - val_loss: 2.7080 - val_acc: 0.2467\n",
      "Epoch 2997/3000\n",
      "700/700 [==============================] - 0s 119us/step - loss: 1.2518 - acc: 0.5129 - val_loss: 2.6722 - val_acc: 0.2400\n",
      "Epoch 2998/3000\n",
      "700/700 [==============================] - 0s 124us/step - loss: 1.2522 - acc: 0.5143 - val_loss: 2.6953 - val_acc: 0.2333\n",
      "Epoch 2999/3000\n",
      "700/700 [==============================] - 0s 121us/step - loss: 1.2518 - acc: 0.5114 - val_loss: 2.6887 - val_acc: 0.2367\n",
      "Epoch 3000/3000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.2527 - acc: 0.5100 - val_loss: 2.6815 - val_acc: 0.2467\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import np_utils\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(3)\n",
    "\n",
    "# 1.  \n",
    "\n",
    "#   \n",
    "(X_train, Y_train), (X_test, Y_test) = mnist.load_data()\n",
    "\n",
    "#   \n",
    "X_val = X_train[50000:]\n",
    "Y_val = Y_train[50000:]\n",
    "X_train = X_train[:50000]\n",
    "Y_train = Y_train[:50000]\n",
    "\n",
    "X_train = X_train.reshape(50000, 784).astype('float32') / 255.0\n",
    "X_val = X_val.reshape(10000, 784).astype('float32') / 255.0\n",
    "X_test = X_test.reshape(10000, 784).astype('float32') / 255.0\n",
    "\n",
    "# ,  \n",
    "train_rand_idxs = np.random.choice(50000, 700)\n",
    "val_rand_idxs = np.random.choice(10000, 300)\n",
    "\n",
    "X_train = X_train[train_rand_idxs]\n",
    "Y_train = Y_train[train_rand_idxs]\n",
    "X_val = X_val[val_rand_idxs]\n",
    "Y_val = Y_val[val_rand_idxs]\n",
    "\n",
    "#  \n",
    "Y_train = np_utils.to_categorical(Y_train)\n",
    "Y_val = np_utils.to_categorical(Y_val)\n",
    "Y_test = np_utils.to_categorical(Y_test)\n",
    "\n",
    "# 2.  \n",
    "model = Sequential()\n",
    "model.add(Dense(units=2, input_dim=28*28, activation='relu'))\n",
    "model.add(Dense(units=10, activation='softmax'))\n",
    "\n",
    "# 3.  \n",
    "model.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])\n",
    "\n",
    "# 4.  \n",
    "hist = model.fit(X_train, Y_train, epochs=3000, batch_size=10, validation_data=(X_val, Y_val))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 5.    \n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, loss_ax = plt.subplots()\n",
    "\n",
    "acc_ax = loss_ax.twinx()\n",
    "\n",
    "loss_ax.plot(hist.history['loss'], 'y', label='train loss')\n",
    "loss_ax.plot(hist.history['val_loss'], 'r', label='val loss')\n",
    "\n",
    "acc_ax.plot(hist.history['acc'], 'b', label='train acc')\n",
    "acc_ax.plot(hist.history['val_acc'], 'g', label='val acc')\n",
    "\n",
    "loss_ax.set_xlabel('epoch')\n",
    "loss_ax.set_ylabel('loss')\n",
    "acc_ax.set_ylabel('accuray')\n",
    "\n",
    "loss_ax.legend(loc='upper left')\n",
    "acc_ax.legend(loc='lower left')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s 11us/step\n",
      "\n",
      "loss : 2.9697278076171876\n",
      "accuray : 0.2596\n"
     ]
    }
   ],
   "source": [
    "# 6.  \n",
    "loss_and_metrics = model.evaluate(X_test, Y_test, batch_size=32)\n",
    "\n",
    "print('')\n",
    "print('loss : ' + str(loss_and_metrics[0]))\n",
    "print('accuray : ' + str(loss_and_metrics[1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/3000\n",
      "700/700 [==============================] - 0s 88us/step - loss: 1.2526 - acc: 0.5171 - val_loss: 2.6640 - val_acc: 0.2400\n",
      "Epoch 2/3000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.2518 - acc: 0.5100 - val_loss: 2.6903 - val_acc: 0.2367\n"
     ]
    }
   ],
   "source": [
    "## Early Stopping - Applied..\n",
    "# 4.  \n",
    "from keras.callbacks import EarlyStopping\n",
    "early_stopping = EarlyStopping() #   \n",
    "hist = model.fit(X_train, Y_train, epochs=3000, batch_size=10, validation_data=(X_val, Y_val), callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 5.    \n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, loss_ax = plt.subplots()\n",
    "\n",
    "acc_ax = loss_ax.twinx()\n",
    "\n",
    "loss_ax.plot(hist.history['loss'], 'y', label='train loss')\n",
    "loss_ax.plot(hist.history['val_loss'], 'r', label='val loss')\n",
    "\n",
    "acc_ax.plot(hist.history['acc'], 'b', label='train acc')\n",
    "acc_ax.plot(hist.history['val_acc'], 'g', label='val acc')\n",
    "\n",
    "loss_ax.set_xlabel('epoch')\n",
    "loss_ax.set_ylabel('loss')\n",
    "acc_ax.set_ylabel('accuray')\n",
    "\n",
    "loss_ax.legend(loc='upper left')\n",
    "acc_ax.legend(loc='lower left')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s 10us/step\n",
      "\n",
      "loss : 2.971750642776489\n",
      "accuray : 0.2586\n"
     ]
    }
   ],
   "source": [
    "# 6.  \n",
    "loss_and_metrics = model.evaluate(X_test, Y_test, batch_size=32)\n",
    "\n",
    "print('')\n",
    "print('loss : ' + str(loss_and_metrics[0]))\n",
    "print('accuray : ' + str(loss_and_metrics[1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/3000\n",
      "700/700 [==============================] - 0s 84us/step - loss: 1.2517 - acc: 0.5171 - val_loss: 2.6880 - val_acc: 0.2367\n",
      "Epoch 2/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.2518 - acc: 0.5171 - val_loss: 2.6830 - val_acc: 0.2400\n",
      "Epoch 3/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.2522 - acc: 0.5129 - val_loss: 2.6398 - val_acc: 0.2333\n",
      "Epoch 4/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.2522 - acc: 0.5100 - val_loss: 2.6771 - val_acc: 0.2400\n",
      "Epoch 5/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.2519 - acc: 0.5129 - val_loss: 2.6875 - val_acc: 0.2333\n",
      "Epoch 6/3000\n",
      "700/700 [==============================] - 0s 92us/step - loss: 1.2516 - acc: 0.5157 - val_loss: 2.6852 - val_acc: 0.2400\n",
      "Epoch 7/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.2518 - acc: 0.5157 - val_loss: 2.6745 - val_acc: 0.2367\n",
      "Epoch 8/3000\n",
      "700/700 [==============================] - 0s 98us/step - loss: 1.2521 - acc: 0.5157 - val_loss: 2.7054 - val_acc: 0.2433\n",
      "Epoch 9/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.2511 - acc: 0.5129 - val_loss: 2.6854 - val_acc: 0.2400\n",
      "Epoch 10/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.2522 - acc: 0.5100 - val_loss: 2.6949 - val_acc: 0.2400\n",
      "Epoch 11/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.2512 - acc: 0.5200 - val_loss: 2.7040 - val_acc: 0.2400\n",
      "Epoch 12/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.2510 - acc: 0.5114 - val_loss: 2.6959 - val_acc: 0.2433\n",
      "Epoch 13/3000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.2512 - acc: 0.5086 - val_loss: 2.6988 - val_acc: 0.2433\n",
      "Epoch 14/3000\n",
      "700/700 [==============================] - 0s 108us/step - loss: 1.2508 - acc: 0.5086 - val_loss: 2.6859 - val_acc: 0.2400\n",
      "Epoch 15/3000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.2510 - acc: 0.5114 - val_loss: 2.6720 - val_acc: 0.2367\n",
      "Epoch 16/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.2518 - acc: 0.5114 - val_loss: 2.6910 - val_acc: 0.2367\n",
      "Epoch 17/3000\n",
      "700/700 [==============================] - 0s 112us/step - loss: 1.2507 - acc: 0.5100 - val_loss: 2.6614 - val_acc: 0.2367\n",
      "Epoch 18/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.2519 - acc: 0.5157 - val_loss: 2.7039 - val_acc: 0.2433\n",
      "Epoch 19/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.2513 - acc: 0.5114 - val_loss: 2.6696 - val_acc: 0.2400\n",
      "Epoch 20/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.2513 - acc: 0.5043 - val_loss: 2.6906 - val_acc: 0.2400\n",
      "Epoch 21/3000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.2503 - acc: 0.5100 - val_loss: 2.6828 - val_acc: 0.2433\n",
      "Epoch 22/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.2512 - acc: 0.5057 - val_loss: 2.6622 - val_acc: 0.2400\n",
      "Epoch 23/3000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.2514 - acc: 0.5071 - val_loss: 2.6624 - val_acc: 0.2367\n"
     ]
    }
   ],
   "source": [
    "# NG so we should add extra Patience\n",
    "early_stopping = EarlyStopping(patience = 20)\n",
    "## Early Stopping - Applied..\n",
    "# 4.  \n",
    "hist = model.fit(X_train, Y_train, epochs=3000, batch_size=10, validation_data=(X_val, Y_val), callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 5.    \n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, loss_ax = plt.subplots()\n",
    "\n",
    "acc_ax = loss_ax.twinx()\n",
    "\n",
    "loss_ax.plot(hist.history['loss'], 'y', label='train loss')\n",
    "loss_ax.plot(hist.history['val_loss'], 'r', label='val loss')\n",
    "\n",
    "acc_ax.plot(hist.history['acc'], 'b', label='train acc')\n",
    "acc_ax.plot(hist.history['val_acc'], 'g', label='val acc')\n",
    "\n",
    "loss_ax.set_xlabel('epoch')\n",
    "loss_ax.set_ylabel('loss')\n",
    "acc_ax.set_ylabel('accuray')\n",
    "\n",
    "loss_ax.legend(loc='upper left')\n",
    "acc_ax.legend(loc='lower left')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/3000\n",
      "700/700 [==============================] - 0s 278us/step - loss: 2.2576 - acc: 0.1643 - val_loss: 2.2272 - val_acc: 0.1633\n",
      "Epoch 2/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 2.2072 - acc: 0.1657 - val_loss: 2.1908 - val_acc: 0.1800\n",
      "Epoch 3/3000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 2.1730 - acc: 0.1729 - val_loss: 2.1631 - val_acc: 0.1867\n",
      "Epoch 4/3000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 2.1441 - acc: 0.1786 - val_loss: 2.1372 - val_acc: 0.1867\n",
      "Epoch 5/3000\n",
      "700/700 [==============================] - 0s 108us/step - loss: 2.1177 - acc: 0.1900 - val_loss: 2.1141 - val_acc: 0.1867\n",
      "Epoch 6/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 2.0940 - acc: 0.2029 - val_loss: 2.0931 - val_acc: 0.2033\n",
      "Epoch 7/3000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 2.0721 - acc: 0.2071 - val_loss: 2.0727 - val_acc: 0.2067\n",
      "Epoch 8/3000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 2.0520 - acc: 0.2129 - val_loss: 2.0564 - val_acc: 0.2067\n",
      "Epoch 9/3000\n",
      "700/700 [==============================] - 0s 182us/step - loss: 2.0342 - acc: 0.2157 - val_loss: 2.0410 - val_acc: 0.2033\n",
      "Epoch 10/3000\n",
      "700/700 [==============================] - 0s 115us/step - loss: 2.0190 - acc: 0.2143 - val_loss: 2.0269 - val_acc: 0.2067\n",
      "Epoch 11/3000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 2.0041 - acc: 0.2186 - val_loss: 2.0125 - val_acc: 0.2100\n",
      "Epoch 12/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.9911 - acc: 0.2200 - val_loss: 2.0037 - val_acc: 0.2100\n",
      "Epoch 13/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.9789 - acc: 0.2286 - val_loss: 1.9955 - val_acc: 0.2100\n",
      "Epoch 14/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.9685 - acc: 0.2329 - val_loss: 1.9833 - val_acc: 0.2067\n",
      "Epoch 15/3000\n",
      "700/700 [==============================] - 0s 116us/step - loss: 1.9582 - acc: 0.2214 - val_loss: 1.9753 - val_acc: 0.2100\n",
      "Epoch 16/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.9484 - acc: 0.2357 - val_loss: 1.9686 - val_acc: 0.2000\n",
      "Epoch 17/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.9393 - acc: 0.2343 - val_loss: 1.9612 - val_acc: 0.2033\n",
      "Epoch 18/3000\n",
      "700/700 [==============================] - 0s 115us/step - loss: 1.9309 - acc: 0.2314 - val_loss: 1.9537 - val_acc: 0.2100\n",
      "Epoch 19/3000\n",
      "700/700 [==============================] - 0s 118us/step - loss: 1.9232 - acc: 0.2286 - val_loss: 1.9452 - val_acc: 0.2100\n",
      "Epoch 20/3000\n",
      "700/700 [==============================] - 0s 98us/step - loss: 1.9156 - acc: 0.2386 - val_loss: 1.9392 - val_acc: 0.2100\n",
      "Epoch 21/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.9085 - acc: 0.2343 - val_loss: 1.9363 - val_acc: 0.2100\n",
      "Epoch 22/3000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.9011 - acc: 0.2386 - val_loss: 1.9289 - val_acc: 0.2033\n",
      "Epoch 23/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.8954 - acc: 0.2357 - val_loss: 1.9234 - val_acc: 0.2100\n",
      "Epoch 24/3000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 1.8895 - acc: 0.2314 - val_loss: 1.9201 - val_acc: 0.2067\n",
      "Epoch 25/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.8830 - acc: 0.2343 - val_loss: 1.9178 - val_acc: 0.2167\n",
      "Epoch 26/3000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 1.8769 - acc: 0.2300 - val_loss: 1.9105 - val_acc: 0.2167\n",
      "Epoch 27/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.8715 - acc: 0.2357 - val_loss: 1.9098 - val_acc: 0.2167\n",
      "Epoch 28/3000\n",
      "700/700 [==============================] - 0s 119us/step - loss: 1.8662 - acc: 0.2400 - val_loss: 1.9094 - val_acc: 0.2000\n",
      "Epoch 29/3000\n",
      "700/700 [==============================] - 0s 112us/step - loss: 1.8615 - acc: 0.2400 - val_loss: 1.9041 - val_acc: 0.1900\n",
      "Epoch 30/3000\n",
      "700/700 [==============================] - 0s 117us/step - loss: 1.8565 - acc: 0.2243 - val_loss: 1.8976 - val_acc: 0.2167\n",
      "Epoch 31/3000\n",
      "700/700 [==============================] - 0s 92us/step - loss: 1.8513 - acc: 0.2471 - val_loss: 1.8971 - val_acc: 0.1933\n",
      "Epoch 32/3000\n",
      "700/700 [==============================] - 0s 122us/step - loss: 1.8463 - acc: 0.2371 - val_loss: 1.8925 - val_acc: 0.1900\n",
      "Epoch 33/3000\n",
      "700/700 [==============================] - 0s 146us/step - loss: 1.8423 - acc: 0.2229 - val_loss: 1.8874 - val_acc: 0.2067\n",
      "Epoch 34/3000\n",
      "700/700 [==============================] - 0s 153us/step - loss: 1.8382 - acc: 0.2371 - val_loss: 1.8808 - val_acc: 0.1933\n",
      "Epoch 35/3000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.8335 - acc: 0.2471 - val_loss: 1.8836 - val_acc: 0.1900\n",
      "Epoch 36/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.8299 - acc: 0.2343 - val_loss: 1.8756 - val_acc: 0.1967\n",
      "Epoch 37/3000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.8257 - acc: 0.2486 - val_loss: 1.8745 - val_acc: 0.1800\n",
      "Epoch 38/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.8220 - acc: 0.2371 - val_loss: 1.8700 - val_acc: 0.1933\n",
      "Epoch 39/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.8184 - acc: 0.2457 - val_loss: 1.8706 - val_acc: 0.1767\n",
      "Epoch 40/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.8144 - acc: 0.2314 - val_loss: 1.8677 - val_acc: 0.2000\n",
      "Epoch 41/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.8105 - acc: 0.2400 - val_loss: 1.8668 - val_acc: 0.1833\n",
      "Epoch 42/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.8075 - acc: 0.2471 - val_loss: 1.8635 - val_acc: 0.1800\n",
      "Epoch 43/3000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 1.8046 - acc: 0.2429 - val_loss: 1.8611 - val_acc: 0.1700\n",
      "Epoch 44/3000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.8001 - acc: 0.2371 - val_loss: 1.8566 - val_acc: 0.1967\n",
      "Epoch 45/3000\n",
      "700/700 [==============================] - 0s 88us/step - loss: 1.7970 - acc: 0.2429 - val_loss: 1.8564 - val_acc: 0.1700\n",
      "Epoch 46/3000\n",
      "700/700 [==============================] - 0s 146us/step - loss: 1.7939 - acc: 0.2271 - val_loss: 1.8528 - val_acc: 0.1933\n",
      "Epoch 47/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.7913 - acc: 0.2600 - val_loss: 1.8551 - val_acc: 0.1833\n",
      "Epoch 48/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.7886 - acc: 0.2471 - val_loss: 1.8543 - val_acc: 0.1867\n",
      "Epoch 49/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.7858 - acc: 0.2486 - val_loss: 1.8504 - val_acc: 0.1867\n",
      "Epoch 50/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.7819 - acc: 0.2471 - val_loss: 1.8443 - val_acc: 0.2267\n",
      "Epoch 51/3000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.7794 - acc: 0.2643 - val_loss: 1.8468 - val_acc: 0.1900\n",
      "Epoch 52/3000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.7762 - acc: 0.2486 - val_loss: 1.8411 - val_acc: 0.1933\n",
      "Epoch 53/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.7744 - acc: 0.2514 - val_loss: 1.8486 - val_acc: 0.2000\n",
      "Epoch 54/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.7716 - acc: 0.2700 - val_loss: 1.8472 - val_acc: 0.1800\n",
      "Epoch 55/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.7687 - acc: 0.2500 - val_loss: 1.8364 - val_acc: 0.2033\n",
      "Epoch 56/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.7672 - acc: 0.2543 - val_loss: 1.8430 - val_acc: 0.2200\n",
      "Epoch 57/3000\n",
      "700/700 [==============================] - 0s 118us/step - loss: 1.7641 - acc: 0.2714 - val_loss: 1.8390 - val_acc: 0.2167\n",
      "Epoch 58/3000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.7616 - acc: 0.2557 - val_loss: 1.8347 - val_acc: 0.2267\n",
      "Epoch 59/3000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.7590 - acc: 0.2671 - val_loss: 1.8329 - val_acc: 0.2233\n",
      "Epoch 60/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 111us/step - loss: 1.7552 - acc: 0.2614 - val_loss: 1.8256 - val_acc: 0.2500\n",
      "Epoch 61/3000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.7566 - acc: 0.2814 - val_loss: 1.8336 - val_acc: 0.2400\n",
      "Epoch 62/3000\n",
      "700/700 [==============================] - 0s 112us/step - loss: 1.7531 - acc: 0.2729 - val_loss: 1.8312 - val_acc: 0.2267\n",
      "Epoch 63/3000\n",
      "700/700 [==============================] - 0s 116us/step - loss: 1.7505 - acc: 0.2857 - val_loss: 1.8299 - val_acc: 0.2000\n",
      "Epoch 64/3000\n",
      "700/700 [==============================] - 0s 77us/step - loss: 1.7484 - acc: 0.2800 - val_loss: 1.8268 - val_acc: 0.2200\n",
      "Epoch 65/3000\n",
      "700/700 [==============================] - 0s 76us/step - loss: 1.7457 - acc: 0.2814 - val_loss: 1.8298 - val_acc: 0.2033\n",
      "Epoch 66/3000\n",
      "700/700 [==============================] - 0s 108us/step - loss: 1.7439 - acc: 0.2786 - val_loss: 1.8296 - val_acc: 0.2067\n",
      "Epoch 67/3000\n",
      "700/700 [==============================] - 0s 115us/step - loss: 1.7419 - acc: 0.2700 - val_loss: 1.8299 - val_acc: 0.2067\n",
      "Epoch 68/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.7405 - acc: 0.2729 - val_loss: 1.8238 - val_acc: 0.2000\n",
      "Epoch 69/3000\n",
      "700/700 [==============================] - 0s 117us/step - loss: 1.7376 - acc: 0.2814 - val_loss: 1.8298 - val_acc: 0.2167\n",
      "Epoch 70/3000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 1.7356 - acc: 0.2857 - val_loss: 1.8269 - val_acc: 0.2433\n",
      "Epoch 71/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.7345 - acc: 0.2800 - val_loss: 1.8214 - val_acc: 0.2167\n",
      "Epoch 72/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.7328 - acc: 0.2857 - val_loss: 1.8226 - val_acc: 0.2133\n",
      "Epoch 73/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.7298 - acc: 0.2814 - val_loss: 1.8252 - val_acc: 0.2467\n",
      "Epoch 74/3000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 1.7283 - acc: 0.2857 - val_loss: 1.8257 - val_acc: 0.1967\n",
      "Epoch 75/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.7268 - acc: 0.2786 - val_loss: 1.8190 - val_acc: 0.2267\n",
      "Epoch 76/3000\n",
      "700/700 [==============================] - 0s 120us/step - loss: 1.7255 - acc: 0.2857 - val_loss: 1.8196 - val_acc: 0.2233\n",
      "Epoch 77/3000\n",
      "700/700 [==============================] - 0s 119us/step - loss: 1.7228 - acc: 0.3057 - val_loss: 1.8232 - val_acc: 0.2033\n",
      "Epoch 78/3000\n",
      "700/700 [==============================] - 0s 126us/step - loss: 1.7212 - acc: 0.2857 - val_loss: 1.8187 - val_acc: 0.1933\n",
      "Epoch 79/3000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.7199 - acc: 0.2829 - val_loss: 1.8203 - val_acc: 0.2433\n",
      "Epoch 80/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.7188 - acc: 0.2929 - val_loss: 1.8197 - val_acc: 0.2067\n",
      "Epoch 81/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.7165 - acc: 0.2843 - val_loss: 1.8256 - val_acc: 0.2067\n",
      "Epoch 82/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.7142 - acc: 0.2829 - val_loss: 1.8144 - val_acc: 0.2667\n",
      "Epoch 83/3000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.7132 - acc: 0.2857 - val_loss: 1.8190 - val_acc: 0.2400\n",
      "Epoch 84/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.7127 - acc: 0.2986 - val_loss: 1.8220 - val_acc: 0.2167\n",
      "Epoch 85/3000\n",
      "700/700 [==============================] - 0s 120us/step - loss: 1.7097 - acc: 0.2971 - val_loss: 1.8159 - val_acc: 0.2267\n",
      "Epoch 86/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.7082 - acc: 0.2800 - val_loss: 1.8136 - val_acc: 0.2633\n",
      "Epoch 87/3000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.7051 - acc: 0.3100 - val_loss: 1.8191 - val_acc: 0.2733\n",
      "Epoch 88/3000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.7062 - acc: 0.3043 - val_loss: 1.8125 - val_acc: 0.2433\n",
      "Epoch 89/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.7043 - acc: 0.3043 - val_loss: 1.8167 - val_acc: 0.2167\n",
      "Epoch 90/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.7027 - acc: 0.2843 - val_loss: 1.8151 - val_acc: 0.2233\n",
      "Epoch 91/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.7017 - acc: 0.3086 - val_loss: 1.8185 - val_acc: 0.2167\n",
      "Epoch 92/3000\n",
      "700/700 [==============================] - 0s 108us/step - loss: 1.6987 - acc: 0.3129 - val_loss: 1.8215 - val_acc: 0.2067\n",
      "Epoch 93/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.6980 - acc: 0.3071 - val_loss: 1.8173 - val_acc: 0.2767\n",
      "Epoch 94/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.6970 - acc: 0.3157 - val_loss: 1.8176 - val_acc: 0.2100\n",
      "Epoch 95/3000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.6943 - acc: 0.2986 - val_loss: 1.8194 - val_acc: 0.2833\n",
      "Epoch 96/3000\n",
      "700/700 [==============================] - 0s 115us/step - loss: 1.6948 - acc: 0.3014 - val_loss: 1.8095 - val_acc: 0.2233\n",
      "Epoch 97/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.6930 - acc: 0.3057 - val_loss: 1.8228 - val_acc: 0.2300\n",
      "Epoch 98/3000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.6921 - acc: 0.3043 - val_loss: 1.8117 - val_acc: 0.2200\n",
      "Epoch 99/3000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 1.6901 - acc: 0.3129 - val_loss: 1.8252 - val_acc: 0.2233\n",
      "Epoch 100/3000\n",
      "700/700 [==============================] - 0s 108us/step - loss: 1.6890 - acc: 0.3129 - val_loss: 1.8210 - val_acc: 0.2267\n",
      "Epoch 101/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.6878 - acc: 0.3143 - val_loss: 1.8190 - val_acc: 0.2200\n",
      "Epoch 102/3000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 1.6877 - acc: 0.3014 - val_loss: 1.8219 - val_acc: 0.2300\n",
      "Epoch 103/3000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.6843 - acc: 0.3000 - val_loss: 1.8102 - val_acc: 0.2500\n",
      "Epoch 104/3000\n",
      "700/700 [==============================] - 0s 123us/step - loss: 1.6842 - acc: 0.3200 - val_loss: 1.8122 - val_acc: 0.2200\n",
      "Epoch 105/3000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 1.6821 - acc: 0.3071 - val_loss: 1.8063 - val_acc: 0.2067\n",
      "Epoch 106/3000\n",
      "700/700 [==============================] - 0s 118us/step - loss: 1.6814 - acc: 0.3114 - val_loss: 1.8173 - val_acc: 0.2200\n",
      "Epoch 107/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.6805 - acc: 0.3071 - val_loss: 1.8228 - val_acc: 0.2367\n",
      "Epoch 108/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.6784 - acc: 0.3071 - val_loss: 1.8167 - val_acc: 0.2767\n",
      "Epoch 109/3000\n",
      "700/700 [==============================] - 0s 112us/step - loss: 1.6782 - acc: 0.3143 - val_loss: 1.8178 - val_acc: 0.2300\n",
      "Epoch 110/3000\n",
      "700/700 [==============================] - 0s 112us/step - loss: 1.6775 - acc: 0.3171 - val_loss: 1.8147 - val_acc: 0.2133\n",
      "Epoch 111/3000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.6775 - acc: 0.3043 - val_loss: 1.8173 - val_acc: 0.2233\n",
      "Epoch 112/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.6745 - acc: 0.3129 - val_loss: 1.8193 - val_acc: 0.2267\n",
      "Epoch 113/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.6737 - acc: 0.3100 - val_loss: 1.8196 - val_acc: 0.2300\n",
      "Epoch 114/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.6724 - acc: 0.3014 - val_loss: 1.8221 - val_acc: 0.2300\n",
      "Epoch 115/3000\n",
      "700/700 [==============================] - 0s 115us/step - loss: 1.6711 - acc: 0.3071 - val_loss: 1.8128 - val_acc: 0.2333\n",
      "Epoch 116/3000\n",
      "700/700 [==============================] - 0s 115us/step - loss: 1.6703 - acc: 0.3157 - val_loss: 1.8255 - val_acc: 0.2300\n",
      "Epoch 117/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.6694 - acc: 0.3100 - val_loss: 1.8228 - val_acc: 0.2333\n",
      "Epoch 118/3000\n",
      "700/700 [==============================] - 0s 92us/step - loss: 1.6682 - acc: 0.3114 - val_loss: 1.8262 - val_acc: 0.2333\n",
      "Epoch 119/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.6670 - acc: 0.3257 - val_loss: 1.8216 - val_acc: 0.2200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 120/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.6661 - acc: 0.3129 - val_loss: 1.8219 - val_acc: 0.2200\n",
      "Epoch 121/3000\n",
      "700/700 [==============================] - 0s 115us/step - loss: 1.6646 - acc: 0.3071 - val_loss: 1.8132 - val_acc: 0.2233\n",
      "Epoch 122/3000\n",
      "700/700 [==============================] - 0s 116us/step - loss: 1.6637 - acc: 0.3229 - val_loss: 1.8194 - val_acc: 0.2200\n",
      "Epoch 123/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.6629 - acc: 0.3100 - val_loss: 1.8139 - val_acc: 0.2200\n",
      "Epoch 124/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.6619 - acc: 0.3143 - val_loss: 1.8187 - val_acc: 0.2267\n",
      "Epoch 125/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.6606 - acc: 0.3257 - val_loss: 1.8212 - val_acc: 0.2333\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import np_utils\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(3)\n",
    "\n",
    "# 1.  \n",
    "\n",
    "#   \n",
    "(X_train, Y_train), (X_test, Y_test) = mnist.load_data()\n",
    "\n",
    "#   \n",
    "X_val = X_train[50000:]\n",
    "Y_val = Y_train[50000:]\n",
    "X_train = X_train[:50000]\n",
    "Y_train = Y_train[:50000]\n",
    "\n",
    "X_train = X_train.reshape(50000, 784).astype('float32') / 255.0\n",
    "X_val = X_val.reshape(10000, 784).astype('float32') / 255.0\n",
    "X_test = X_test.reshape(10000, 784).astype('float32') / 255.0\n",
    "\n",
    "# ,  \n",
    "train_rand_idxs = np.random.choice(50000, 700)\n",
    "val_rand_idxs = np.random.choice(10000, 300)\n",
    "\n",
    "X_train = X_train[train_rand_idxs]\n",
    "Y_train = Y_train[train_rand_idxs]\n",
    "X_val = X_val[val_rand_idxs]\n",
    "Y_val = Y_val[val_rand_idxs]\n",
    "\n",
    "#  \n",
    "Y_train = np_utils.to_categorical(Y_train)\n",
    "Y_val = np_utils.to_categorical(Y_val)\n",
    "Y_test = np_utils.to_categorical(Y_test)\n",
    "\n",
    "# 2.  \n",
    "model = Sequential()\n",
    "model.add(Dense(units=2, input_dim=28*28, activation='relu'))\n",
    "model.add(Dense(units=10, activation='softmax'))\n",
    "\n",
    "# 3.  \n",
    "model.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])\n",
    "\n",
    "# 4.  \n",
    "from keras.callbacks import EarlyStopping\n",
    "early_stopping = EarlyStopping(patience = 20) #   \n",
    "hist = model.fit(X_train, Y_train, epochs=3000, batch_size=10, validation_data=(X_val, Y_val), callbacks=[early_stopping])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 5.    \n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, loss_ax = plt.subplots()\n",
    "\n",
    "acc_ax = loss_ax.twinx()\n",
    "\n",
    "loss_ax.plot(hist.history['loss'], 'y', label='train loss')\n",
    "loss_ax.plot(hist.history['val_loss'], 'r', label='val loss')\n",
    "\n",
    "acc_ax.plot(hist.history['acc'], 'b', label='train acc')\n",
    "acc_ax.plot(hist.history['val_acc'], 'g', label='val acc')\n",
    "\n",
    "loss_ax.set_xlabel('epoch')\n",
    "loss_ax.set_ylabel('loss')\n",
    "acc_ax.set_ylabel('accuray')\n",
    "\n",
    "loss_ax.legend(loc='upper left')\n",
    "acc_ax.legend(loc='lower left')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s 13us/step\n",
      "\n",
      "loss : 1.8416428043365478\n",
      "accuray : 0.2717\n"
     ]
    }
   ],
   "source": [
    "# 6.  \n",
    "loss_and_metrics = model.evaluate(X_test, Y_test, batch_size=32)\n",
    "\n",
    "print('')\n",
    "print('loss : ' + str(loss_and_metrics[0]))\n",
    "print('accuray : ' + str(loss_and_metrics[1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
