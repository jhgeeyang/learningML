{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1000\n",
      "700/700 [==============================] - 0s 299us/step - loss: 2.2576 - acc: 0.1643 - val_loss: 2.2272 - val_acc: 0.1633\n",
      "Epoch 2/1000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 2.2072 - acc: 0.1657 - val_loss: 2.1908 - val_acc: 0.1800\n",
      "Epoch 3/1000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 2.1730 - acc: 0.1729 - val_loss: 2.1631 - val_acc: 0.1867\n",
      "Epoch 4/1000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 2.1441 - acc: 0.1786 - val_loss: 2.1372 - val_acc: 0.1867\n",
      "Epoch 5/1000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 2.1177 - acc: 0.1900 - val_loss: 2.1141 - val_acc: 0.1867\n",
      "Epoch 6/1000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 2.0940 - acc: 0.2029 - val_loss: 2.0931 - val_acc: 0.2033\n",
      "Epoch 7/1000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 2.0721 - acc: 0.2071 - val_loss: 2.0727 - val_acc: 0.2067\n",
      "Epoch 8/1000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 2.0520 - acc: 0.2129 - val_loss: 2.0564 - val_acc: 0.2067\n",
      "Epoch 9/1000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 2.0342 - acc: 0.2157 - val_loss: 2.0410 - val_acc: 0.2033\n",
      "Epoch 10/1000\n",
      "700/700 [==============================] - 0s 127us/step - loss: 2.0190 - acc: 0.2143 - val_loss: 2.0269 - val_acc: 0.2067\n",
      "Epoch 11/1000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 2.0041 - acc: 0.2186 - val_loss: 2.0125 - val_acc: 0.2100\n",
      "Epoch 12/1000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 1.9911 - acc: 0.2200 - val_loss: 2.0037 - val_acc: 0.2100\n",
      "Epoch 13/1000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.9789 - acc: 0.2286 - val_loss: 1.9955 - val_acc: 0.2100\n",
      "Epoch 14/1000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 1.9685 - acc: 0.2329 - val_loss: 1.9833 - val_acc: 0.2067\n",
      "Epoch 15/1000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.9582 - acc: 0.2214 - val_loss: 1.9753 - val_acc: 0.2100\n",
      "Epoch 16/1000\n",
      "700/700 [==============================] - 0s 116us/step - loss: 1.9484 - acc: 0.2357 - val_loss: 1.9686 - val_acc: 0.2000\n",
      "Epoch 17/1000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.9393 - acc: 0.2343 - val_loss: 1.9612 - val_acc: 0.2033\n",
      "Epoch 18/1000\n",
      "700/700 [==============================] - 0s 118us/step - loss: 1.9309 - acc: 0.2314 - val_loss: 1.9537 - val_acc: 0.2100\n",
      "Epoch 19/1000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 1.9232 - acc: 0.2286 - val_loss: 1.9452 - val_acc: 0.2100\n",
      "Epoch 20/1000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.9156 - acc: 0.2386 - val_loss: 1.9392 - val_acc: 0.2100\n",
      "Epoch 21/1000\n",
      "700/700 [==============================] - 0s 98us/step - loss: 1.9085 - acc: 0.2343 - val_loss: 1.9363 - val_acc: 0.2100\n",
      "Epoch 22/1000\n",
      "700/700 [==============================] - 0s 98us/step - loss: 1.9011 - acc: 0.2386 - val_loss: 1.9289 - val_acc: 0.2033\n",
      "Epoch 23/1000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.8954 - acc: 0.2357 - val_loss: 1.9234 - val_acc: 0.2100\n",
      "Epoch 24/1000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.8895 - acc: 0.2314 - val_loss: 1.9201 - val_acc: 0.2067\n",
      "Epoch 25/1000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.8830 - acc: 0.2343 - val_loss: 1.9178 - val_acc: 0.2167\n",
      "Epoch 26/1000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.8769 - acc: 0.2300 - val_loss: 1.9105 - val_acc: 0.2167\n",
      "Epoch 27/1000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 1.8715 - acc: 0.2357 - val_loss: 1.9098 - val_acc: 0.2167\n",
      "Epoch 28/1000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 1.8662 - acc: 0.2400 - val_loss: 1.9094 - val_acc: 0.2000\n",
      "Epoch 29/1000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 1.8615 - acc: 0.2400 - val_loss: 1.9041 - val_acc: 0.1900\n",
      "Epoch 30/1000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.8565 - acc: 0.2243 - val_loss: 1.8976 - val_acc: 0.2167\n",
      "Epoch 31/1000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.8513 - acc: 0.2471 - val_loss: 1.8971 - val_acc: 0.1933\n",
      "Epoch 32/1000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 1.8463 - acc: 0.2371 - val_loss: 1.8925 - val_acc: 0.1900\n",
      "Epoch 33/1000\n",
      "700/700 [==============================] - 0s 108us/step - loss: 1.8423 - acc: 0.2229 - val_loss: 1.8874 - val_acc: 0.2067\n",
      "Epoch 34/1000\n",
      "700/700 [==============================] - 0s 115us/step - loss: 1.8382 - acc: 0.2371 - val_loss: 1.8808 - val_acc: 0.1933\n",
      "Epoch 35/1000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.8335 - acc: 0.2471 - val_loss: 1.8836 - val_acc: 0.1900\n",
      "Epoch 36/1000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.8299 - acc: 0.2343 - val_loss: 1.8756 - val_acc: 0.1967\n",
      "Epoch 37/1000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.8257 - acc: 0.2486 - val_loss: 1.8745 - val_acc: 0.1800\n",
      "Epoch 38/1000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.8220 - acc: 0.2371 - val_loss: 1.8700 - val_acc: 0.1933\n",
      "Epoch 39/1000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.8184 - acc: 0.2457 - val_loss: 1.8706 - val_acc: 0.1767\n",
      "Epoch 40/1000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.8144 - acc: 0.2314 - val_loss: 1.8677 - val_acc: 0.2000\n",
      "Epoch 41/1000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.8105 - acc: 0.2400 - val_loss: 1.8668 - val_acc: 0.1833\n",
      "Epoch 42/1000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.8075 - acc: 0.2471 - val_loss: 1.8635 - val_acc: 0.1800\n",
      "Epoch 43/1000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.8046 - acc: 0.2429 - val_loss: 1.8611 - val_acc: 0.1700\n",
      "Epoch 44/1000\n",
      "700/700 [==============================] - 0s 98us/step - loss: 1.8001 - acc: 0.2371 - val_loss: 1.8566 - val_acc: 0.1967\n",
      "Epoch 45/1000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.7970 - acc: 0.2429 - val_loss: 1.8564 - val_acc: 0.1700\n",
      "Epoch 46/1000\n",
      "700/700 [==============================] - 0s 108us/step - loss: 1.7939 - acc: 0.2271 - val_loss: 1.8528 - val_acc: 0.1933\n",
      "Epoch 47/1000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.7913 - acc: 0.2600 - val_loss: 1.8551 - val_acc: 0.1833\n",
      "Epoch 48/1000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.7886 - acc: 0.2471 - val_loss: 1.8543 - val_acc: 0.1867\n",
      "Epoch 49/1000\n",
      "700/700 [==============================] - 0s 112us/step - loss: 1.7858 - acc: 0.2486 - val_loss: 1.8504 - val_acc: 0.1867\n",
      "Epoch 50/1000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.7819 - acc: 0.2471 - val_loss: 1.8443 - val_acc: 0.2267\n",
      "Epoch 51/1000\n",
      "700/700 [==============================] - 0s 98us/step - loss: 1.7794 - acc: 0.2643 - val_loss: 1.8468 - val_acc: 0.1900\n",
      "Epoch 52/1000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.7762 - acc: 0.2486 - val_loss: 1.8411 - val_acc: 0.1933\n",
      "Epoch 53/1000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.7744 - acc: 0.2514 - val_loss: 1.8486 - val_acc: 0.2000\n",
      "Epoch 54/1000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.7716 - acc: 0.2700 - val_loss: 1.8472 - val_acc: 0.1800\n",
      "Epoch 55/1000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.7687 - acc: 0.2500 - val_loss: 1.8364 - val_acc: 0.2033\n",
      "Epoch 56/1000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.7672 - acc: 0.2543 - val_loss: 1.8430 - val_acc: 0.2200\n",
      "Epoch 57/1000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.7641 - acc: 0.2714 - val_loss: 1.8390 - val_acc: 0.2167\n",
      "Epoch 58/1000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.7616 - acc: 0.2557 - val_loss: 1.8347 - val_acc: 0.2267\n",
      "Epoch 59/1000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.7590 - acc: 0.2671 - val_loss: 1.8329 - val_acc: 0.2233\n",
      "Epoch 60/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 105us/step - loss: 1.7552 - acc: 0.2614 - val_loss: 1.8256 - val_acc: 0.2500\n",
      "Epoch 61/1000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.7566 - acc: 0.2814 - val_loss: 1.8336 - val_acc: 0.2400\n",
      "Epoch 62/1000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.7531 - acc: 0.2729 - val_loss: 1.8312 - val_acc: 0.2267\n",
      "Epoch 63/1000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.7505 - acc: 0.2857 - val_loss: 1.8299 - val_acc: 0.2000\n",
      "Epoch 64/1000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.7484 - acc: 0.2800 - val_loss: 1.8268 - val_acc: 0.2200\n",
      "Epoch 65/1000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.7457 - acc: 0.2814 - val_loss: 1.8298 - val_acc: 0.2033\n",
      "Epoch 66/1000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.7439 - acc: 0.2786 - val_loss: 1.8296 - val_acc: 0.2067\n",
      "Epoch 67/1000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.7419 - acc: 0.2700 - val_loss: 1.8299 - val_acc: 0.2067\n",
      "Epoch 68/1000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.7405 - acc: 0.2729 - val_loss: 1.8238 - val_acc: 0.2000\n",
      "Epoch 69/1000\n",
      "700/700 [==============================] - 0s 108us/step - loss: 1.7376 - acc: 0.2814 - val_loss: 1.8298 - val_acc: 0.2167\n",
      "Epoch 70/1000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.7356 - acc: 0.2857 - val_loss: 1.8269 - val_acc: 0.2433\n",
      "Epoch 71/1000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.7345 - acc: 0.2800 - val_loss: 1.8214 - val_acc: 0.2167\n",
      "Epoch 72/1000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.7328 - acc: 0.2857 - val_loss: 1.8226 - val_acc: 0.2133\n",
      "Epoch 73/1000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.7298 - acc: 0.2800 - val_loss: 1.8252 - val_acc: 0.2467\n",
      "Epoch 74/1000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.7283 - acc: 0.2857 - val_loss: 1.8257 - val_acc: 0.1967\n",
      "Epoch 75/1000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.7268 - acc: 0.2786 - val_loss: 1.8190 - val_acc: 0.2267\n",
      "Epoch 76/1000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.7255 - acc: 0.2857 - val_loss: 1.8196 - val_acc: 0.2233\n",
      "Epoch 77/1000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.7228 - acc: 0.3057 - val_loss: 1.8232 - val_acc: 0.2033\n",
      "Epoch 78/1000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.7212 - acc: 0.2857 - val_loss: 1.8187 - val_acc: 0.1933\n",
      "Epoch 79/1000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.7199 - acc: 0.2829 - val_loss: 1.8203 - val_acc: 0.2433\n",
      "Epoch 80/1000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.7188 - acc: 0.2929 - val_loss: 1.8197 - val_acc: 0.2067\n",
      "Epoch 81/1000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.7165 - acc: 0.2843 - val_loss: 1.8256 - val_acc: 0.2067\n",
      "Epoch 82/1000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.7142 - acc: 0.2829 - val_loss: 1.8144 - val_acc: 0.2667\n",
      "Epoch 83/1000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.7132 - acc: 0.2857 - val_loss: 1.8190 - val_acc: 0.2400\n",
      "Epoch 84/1000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.7127 - acc: 0.2986 - val_loss: 1.8220 - val_acc: 0.2167\n",
      "Epoch 85/1000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.7097 - acc: 0.2971 - val_loss: 1.8159 - val_acc: 0.2267\n",
      "Epoch 86/1000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.7082 - acc: 0.2800 - val_loss: 1.8136 - val_acc: 0.2633\n",
      "Epoch 87/1000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.7051 - acc: 0.3100 - val_loss: 1.8191 - val_acc: 0.2733\n",
      "Epoch 88/1000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.7062 - acc: 0.3043 - val_loss: 1.8125 - val_acc: 0.2433\n",
      "Epoch 89/1000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.7043 - acc: 0.3043 - val_loss: 1.8167 - val_acc: 0.2167\n",
      "Epoch 90/1000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.7027 - acc: 0.2843 - val_loss: 1.8151 - val_acc: 0.2233\n",
      "Epoch 91/1000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.7017 - acc: 0.3086 - val_loss: 1.8185 - val_acc: 0.2167\n",
      "Epoch 92/1000\n",
      "700/700 [==============================] - 0s 108us/step - loss: 1.6987 - acc: 0.3129 - val_loss: 1.8215 - val_acc: 0.2067\n",
      "Epoch 93/1000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.6980 - acc: 0.3071 - val_loss: 1.8173 - val_acc: 0.2767\n",
      "Epoch 94/1000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.6970 - acc: 0.3157 - val_loss: 1.8176 - val_acc: 0.2100\n",
      "Epoch 95/1000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.6943 - acc: 0.2986 - val_loss: 1.8194 - val_acc: 0.2833\n",
      "Epoch 96/1000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.6948 - acc: 0.3014 - val_loss: 1.8095 - val_acc: 0.2233\n",
      "Epoch 97/1000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.6930 - acc: 0.3057 - val_loss: 1.8228 - val_acc: 0.2300\n",
      "Epoch 98/1000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.6921 - acc: 0.3043 - val_loss: 1.8117 - val_acc: 0.2200\n",
      "Epoch 99/1000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.6901 - acc: 0.3129 - val_loss: 1.8252 - val_acc: 0.2233\n",
      "Epoch 100/1000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.6890 - acc: 0.3129 - val_loss: 1.8210 - val_acc: 0.2267\n",
      "Epoch 101/1000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 1.6878 - acc: 0.3143 - val_loss: 1.8190 - val_acc: 0.2200\n",
      "Epoch 102/1000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.6877 - acc: 0.3014 - val_loss: 1.8219 - val_acc: 0.2300\n",
      "Epoch 103/1000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.6843 - acc: 0.3000 - val_loss: 1.8102 - val_acc: 0.2500\n",
      "Epoch 104/1000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.6842 - acc: 0.3200 - val_loss: 1.8122 - val_acc: 0.2200\n",
      "Epoch 105/1000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.6821 - acc: 0.3071 - val_loss: 1.8063 - val_acc: 0.2067\n",
      "Epoch 106/1000\n",
      "700/700 [==============================] - 0s 98us/step - loss: 1.6814 - acc: 0.3114 - val_loss: 1.8173 - val_acc: 0.2200\n",
      "Epoch 107/1000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.6805 - acc: 0.3071 - val_loss: 1.8228 - val_acc: 0.2367\n",
      "Epoch 108/1000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.6784 - acc: 0.3071 - val_loss: 1.8167 - val_acc: 0.2767\n",
      "Epoch 109/1000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.6782 - acc: 0.3143 - val_loss: 1.8178 - val_acc: 0.2300\n",
      "Epoch 110/1000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.6775 - acc: 0.3171 - val_loss: 1.8147 - val_acc: 0.2133\n",
      "Epoch 111/1000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.6775 - acc: 0.3043 - val_loss: 1.8173 - val_acc: 0.2233\n",
      "Epoch 112/1000\n",
      "700/700 [==============================] - 0s 98us/step - loss: 1.6745 - acc: 0.3129 - val_loss: 1.8193 - val_acc: 0.2267\n",
      "Epoch 113/1000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.6737 - acc: 0.3100 - val_loss: 1.8196 - val_acc: 0.2300\n",
      "Epoch 114/1000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.6724 - acc: 0.3014 - val_loss: 1.8221 - val_acc: 0.2300\n",
      "Epoch 115/1000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.6711 - acc: 0.3071 - val_loss: 1.8128 - val_acc: 0.2333\n",
      "Epoch 116/1000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.6703 - acc: 0.3157 - val_loss: 1.8255 - val_acc: 0.2300\n",
      "Epoch 117/1000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.6694 - acc: 0.3100 - val_loss: 1.8228 - val_acc: 0.2333\n",
      "Epoch 118/1000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.6682 - acc: 0.3114 - val_loss: 1.8262 - val_acc: 0.2333\n",
      "Epoch 119/1000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.6670 - acc: 0.3257 - val_loss: 1.8216 - val_acc: 0.2200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 120/1000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.6661 - acc: 0.3129 - val_loss: 1.8219 - val_acc: 0.2200\n",
      "Epoch 121/1000\n",
      "700/700 [==============================] - 0s 98us/step - loss: 1.6646 - acc: 0.3071 - val_loss: 1.8132 - val_acc: 0.2233\n",
      "Epoch 122/1000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.6637 - acc: 0.3229 - val_loss: 1.8194 - val_acc: 0.2200\n",
      "Epoch 123/1000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.6629 - acc: 0.3100 - val_loss: 1.8139 - val_acc: 0.2200\n",
      "Epoch 124/1000\n",
      "700/700 [==============================] - 0s 98us/step - loss: 1.6619 - acc: 0.3143 - val_loss: 1.8187 - val_acc: 0.2267\n",
      "Epoch 125/1000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.6606 - acc: 0.3257 - val_loss: 1.8212 - val_acc: 0.2333\n",
      "Epoch 126/1000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.6592 - acc: 0.3143 - val_loss: 1.8245 - val_acc: 0.2233\n",
      "Epoch 127/1000\n",
      "700/700 [==============================] - 0s 98us/step - loss: 1.6583 - acc: 0.3129 - val_loss: 1.8147 - val_acc: 0.2333\n",
      "Epoch 128/1000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.6565 - acc: 0.3300 - val_loss: 1.8280 - val_acc: 0.2300\n",
      "Epoch 129/1000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.6570 - acc: 0.3143 - val_loss: 1.8193 - val_acc: 0.2200\n",
      "Epoch 130/1000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.6548 - acc: 0.3214 - val_loss: 1.8124 - val_acc: 0.2533\n",
      "Epoch 131/1000\n",
      "700/700 [==============================] - 0s 108us/step - loss: 1.6547 - acc: 0.3229 - val_loss: 1.8202 - val_acc: 0.2500\n",
      "Epoch 132/1000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.6545 - acc: 0.3200 - val_loss: 1.8133 - val_acc: 0.2267\n",
      "Epoch 133/1000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.6524 - acc: 0.3143 - val_loss: 1.8317 - val_acc: 0.2400\n",
      "Epoch 134/1000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.6514 - acc: 0.3214 - val_loss: 1.8226 - val_acc: 0.2733\n",
      "Epoch 135/1000\n",
      "700/700 [==============================] - 0s 98us/step - loss: 1.6512 - acc: 0.3314 - val_loss: 1.8233 - val_acc: 0.2267\n",
      "Epoch 136/1000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.6493 - acc: 0.3186 - val_loss: 1.8168 - val_acc: 0.2200\n",
      "Epoch 137/1000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.6483 - acc: 0.3214 - val_loss: 1.8191 - val_acc: 0.2200\n",
      "Epoch 138/1000\n",
      "700/700 [==============================] - 0s 98us/step - loss: 1.6488 - acc: 0.3257 - val_loss: 1.8199 - val_acc: 0.2167\n",
      "Epoch 139/1000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.6466 - acc: 0.3257 - val_loss: 1.8512 - val_acc: 0.2433\n",
      "Epoch 140/1000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.6465 - acc: 0.3214 - val_loss: 1.8168 - val_acc: 0.2200\n",
      "Epoch 141/1000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.6446 - acc: 0.3229 - val_loss: 1.8284 - val_acc: 0.2267\n",
      "Epoch 142/1000\n",
      "700/700 [==============================] - 0s 108us/step - loss: 1.6437 - acc: 0.3243 - val_loss: 1.8154 - val_acc: 0.2633\n",
      "Epoch 143/1000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.6437 - acc: 0.3329 - val_loss: 1.8292 - val_acc: 0.2433\n",
      "Epoch 144/1000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.6431 - acc: 0.3329 - val_loss: 1.8273 - val_acc: 0.2300\n",
      "Epoch 145/1000\n",
      "700/700 [==============================] - 0s 115us/step - loss: 1.6419 - acc: 0.3271 - val_loss: 1.8197 - val_acc: 0.2200\n",
      "Epoch 146/1000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.6392 - acc: 0.3343 - val_loss: 1.8324 - val_acc: 0.2233\n",
      "Epoch 147/1000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.6412 - acc: 0.3100 - val_loss: 1.8328 - val_acc: 0.2333\n",
      "Epoch 148/1000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.6390 - acc: 0.3243 - val_loss: 1.8306 - val_acc: 0.2500\n",
      "Epoch 149/1000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.6375 - acc: 0.3271 - val_loss: 1.8189 - val_acc: 0.2133\n",
      "Epoch 150/1000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.6367 - acc: 0.3229 - val_loss: 1.8276 - val_acc: 0.2233\n",
      "Epoch 151/1000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.6364 - acc: 0.3257 - val_loss: 1.8245 - val_acc: 0.2267\n",
      "Epoch 152/1000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.6350 - acc: 0.3214 - val_loss: 1.8290 - val_acc: 0.2233\n",
      "Epoch 153/1000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.6340 - acc: 0.3400 - val_loss: 1.8270 - val_acc: 0.2300\n",
      "Epoch 154/1000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.6319 - acc: 0.3457 - val_loss: 1.8343 - val_acc: 0.2233\n",
      "Epoch 155/1000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.6316 - acc: 0.3243 - val_loss: 1.8183 - val_acc: 0.2367\n",
      "Epoch 156/1000\n",
      "700/700 [==============================] - 0s 88us/step - loss: 1.6326 - acc: 0.3329 - val_loss: 1.8309 - val_acc: 0.2200\n",
      "Epoch 157/1000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.6308 - acc: 0.3300 - val_loss: 1.8241 - val_acc: 0.2200\n",
      "Epoch 158/1000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.6308 - acc: 0.3343 - val_loss: 1.8329 - val_acc: 0.2300\n",
      "Epoch 159/1000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.6285 - acc: 0.3257 - val_loss: 1.8336 - val_acc: 0.2433\n",
      "Epoch 160/1000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.6278 - acc: 0.3300 - val_loss: 1.8304 - val_acc: 0.2233\n",
      "Epoch 161/1000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.6271 - acc: 0.3257 - val_loss: 1.8406 - val_acc: 0.2300\n",
      "Epoch 162/1000\n",
      "700/700 [==============================] - 0s 98us/step - loss: 1.6265 - acc: 0.3271 - val_loss: 1.8350 - val_acc: 0.2267\n",
      "Epoch 163/1000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.6254 - acc: 0.3371 - val_loss: 1.8365 - val_acc: 0.2300\n",
      "Epoch 164/1000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.6239 - acc: 0.3314 - val_loss: 1.8264 - val_acc: 0.2100\n",
      "Epoch 165/1000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.6236 - acc: 0.3200 - val_loss: 1.8396 - val_acc: 0.2367\n",
      "Epoch 166/1000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.6230 - acc: 0.3286 - val_loss: 1.8344 - val_acc: 0.2233\n",
      "Epoch 167/1000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.6221 - acc: 0.3314 - val_loss: 1.8389 - val_acc: 0.2633\n",
      "Epoch 168/1000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.6208 - acc: 0.3386 - val_loss: 1.8444 - val_acc: 0.2200\n",
      "Epoch 169/1000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.6198 - acc: 0.3386 - val_loss: 1.8525 - val_acc: 0.2233\n",
      "Epoch 170/1000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.6191 - acc: 0.3371 - val_loss: 1.8369 - val_acc: 0.2233\n",
      "Epoch 171/1000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.6170 - acc: 0.3271 - val_loss: 1.8517 - val_acc: 0.2600\n",
      "Epoch 172/1000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.6164 - acc: 0.3386 - val_loss: 1.8397 - val_acc: 0.2133\n",
      "Epoch 173/1000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.6182 - acc: 0.3386 - val_loss: 1.8392 - val_acc: 0.2367\n",
      "Epoch 174/1000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.6167 - acc: 0.3300 - val_loss: 1.8420 - val_acc: 0.2200\n",
      "Epoch 175/1000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.6166 - acc: 0.3357 - val_loss: 1.8406 - val_acc: 0.2200\n",
      "Epoch 176/1000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.6143 - acc: 0.3229 - val_loss: 1.8437 - val_acc: 0.2600\n",
      "Epoch 177/1000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.6134 - acc: 0.3371 - val_loss: 1.8384 - val_acc: 0.2167\n",
      "Epoch 178/1000\n",
      "700/700 [==============================] - 0s 139us/step - loss: 1.6139 - acc: 0.3371 - val_loss: 1.8446 - val_acc: 0.2267\n",
      "Epoch 179/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 101us/step - loss: 1.6134 - acc: 0.3400 - val_loss: 1.8376 - val_acc: 0.2233\n",
      "Epoch 180/1000\n",
      "700/700 [==============================] - 0s 98us/step - loss: 1.6110 - acc: 0.3371 - val_loss: 1.8415 - val_acc: 0.2667\n",
      "Epoch 181/1000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 1.6115 - acc: 0.3457 - val_loss: 1.8339 - val_acc: 0.2567\n",
      "Epoch 182/1000\n",
      "700/700 [==============================] - 0s 108us/step - loss: 1.6106 - acc: 0.3471 - val_loss: 1.8365 - val_acc: 0.2167\n",
      "Epoch 183/1000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.6115 - acc: 0.3300 - val_loss: 1.8411 - val_acc: 0.2333\n",
      "Epoch 184/1000\n",
      "700/700 [==============================] - 0s 108us/step - loss: 1.6093 - acc: 0.3443 - val_loss: 1.8453 - val_acc: 0.2267\n",
      "Epoch 185/1000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.6076 - acc: 0.3386 - val_loss: 1.8641 - val_acc: 0.2200\n",
      "Epoch 186/1000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.6086 - acc: 0.3443 - val_loss: 1.8449 - val_acc: 0.2233\n",
      "Epoch 187/1000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.6065 - acc: 0.3543 - val_loss: 1.8442 - val_acc: 0.2167\n",
      "Epoch 188/1000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.6075 - acc: 0.3386 - val_loss: 1.8412 - val_acc: 0.2133\n",
      "Epoch 189/1000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.6045 - acc: 0.3529 - val_loss: 1.8517 - val_acc: 0.2233\n",
      "Epoch 190/1000\n",
      "700/700 [==============================] - 0s 108us/step - loss: 1.6065 - acc: 0.3314 - val_loss: 1.8401 - val_acc: 0.2300\n",
      "Epoch 191/1000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 1.6042 - acc: 0.3529 - val_loss: 1.8564 - val_acc: 0.2233\n",
      "Epoch 192/1000\n",
      "700/700 [==============================] - 0s 80us/step - loss: 1.6044 - acc: 0.3500 - val_loss: 1.8503 - val_acc: 0.2200\n",
      "Epoch 193/1000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.6029 - acc: 0.3357 - val_loss: 1.8539 - val_acc: 0.2267\n",
      "Epoch 194/1000\n",
      "700/700 [==============================] - 0s 116us/step - loss: 1.6025 - acc: 0.3414 - val_loss: 1.8470 - val_acc: 0.2267\n",
      "Epoch 195/1000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 1.6019 - acc: 0.3457 - val_loss: 1.8453 - val_acc: 0.2467\n",
      "Epoch 196/1000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.6016 - acc: 0.3514 - val_loss: 1.8472 - val_acc: 0.2167\n",
      "Epoch 197/1000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.6002 - acc: 0.3443 - val_loss: 1.8488 - val_acc: 0.2300\n",
      "Epoch 198/1000\n",
      "700/700 [==============================] - 0s 98us/step - loss: 1.6005 - acc: 0.3386 - val_loss: 1.8591 - val_acc: 0.2200\n",
      "Epoch 199/1000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.6003 - acc: 0.3429 - val_loss: 1.8558 - val_acc: 0.2200\n",
      "Epoch 200/1000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.5975 - acc: 0.3457 - val_loss: 1.8604 - val_acc: 0.2633\n",
      "Epoch 201/1000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.5986 - acc: 0.3457 - val_loss: 1.8469 - val_acc: 0.2167\n",
      "Epoch 202/1000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 1.5979 - acc: 0.3414 - val_loss: 1.8478 - val_acc: 0.2100\n",
      "Epoch 203/1000\n",
      "700/700 [==============================] - 0s 112us/step - loss: 1.5965 - acc: 0.3343 - val_loss: 1.8562 - val_acc: 0.2267\n",
      "Epoch 204/1000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.5953 - acc: 0.3557 - val_loss: 1.8461 - val_acc: 0.2067\n",
      "Epoch 205/1000\n",
      "700/700 [==============================] - 0s 98us/step - loss: 1.5953 - acc: 0.3429 - val_loss: 1.8508 - val_acc: 0.2200\n",
      "Epoch 206/1000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.5946 - acc: 0.3500 - val_loss: 1.8463 - val_acc: 0.2133\n",
      "Epoch 207/1000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.5947 - acc: 0.3543 - val_loss: 1.8537 - val_acc: 0.2233\n",
      "Epoch 208/1000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.5920 - acc: 0.3414 - val_loss: 1.8557 - val_acc: 0.2233\n",
      "Epoch 209/1000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.5919 - acc: 0.3514 - val_loss: 1.8521 - val_acc: 0.2300\n",
      "Epoch 210/1000\n",
      "700/700 [==============================] - 0s 116us/step - loss: 1.5915 - acc: 0.3443 - val_loss: 1.8523 - val_acc: 0.2267\n",
      "Epoch 211/1000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.5903 - acc: 0.3371 - val_loss: 1.8456 - val_acc: 0.2567\n",
      "Epoch 212/1000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.5913 - acc: 0.3471 - val_loss: 1.8593 - val_acc: 0.2200\n",
      "Epoch 213/1000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 1.5894 - acc: 0.3500 - val_loss: 1.8519 - val_acc: 0.2233\n",
      "Epoch 214/1000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.5905 - acc: 0.3457 - val_loss: 1.8541 - val_acc: 0.2267\n",
      "Epoch 215/1000\n",
      "700/700 [==============================] - 0s 92us/step - loss: 1.5886 - acc: 0.3514 - val_loss: 1.8602 - val_acc: 0.2667\n",
      "Epoch 216/1000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.5895 - acc: 0.3486 - val_loss: 1.8624 - val_acc: 0.2267\n",
      "Epoch 217/1000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.5881 - acc: 0.3471 - val_loss: 1.8638 - val_acc: 0.2300\n",
      "Epoch 218/1000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.5876 - acc: 0.3486 - val_loss: 1.8600 - val_acc: 0.2300\n",
      "Epoch 219/1000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.5865 - acc: 0.3500 - val_loss: 1.8659 - val_acc: 0.2267\n",
      "Epoch 220/1000\n",
      "700/700 [==============================] - 0s 112us/step - loss: 1.5855 - acc: 0.3514 - val_loss: 1.8581 - val_acc: 0.2267\n",
      "Epoch 221/1000\n",
      "700/700 [==============================] - 0s 112us/step - loss: 1.5855 - acc: 0.3471 - val_loss: 1.8621 - val_acc: 0.2267\n",
      "Epoch 222/1000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.5845 - acc: 0.3514 - val_loss: 1.8753 - val_acc: 0.2500\n",
      "Epoch 223/1000\n",
      "700/700 [==============================] - 0s 125us/step - loss: 1.5844 - acc: 0.3443 - val_loss: 1.8615 - val_acc: 0.2600\n",
      "Epoch 224/1000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.5845 - acc: 0.3529 - val_loss: 1.8766 - val_acc: 0.2467\n",
      "Epoch 225/1000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 1.5833 - acc: 0.3457 - val_loss: 1.8572 - val_acc: 0.2167\n",
      "Epoch 226/1000\n",
      "700/700 [==============================] - 0s 122us/step - loss: 1.5835 - acc: 0.3486 - val_loss: 1.8686 - val_acc: 0.2233\n",
      "Epoch 227/1000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.5825 - acc: 0.3486 - val_loss: 1.8611 - val_acc: 0.2133\n",
      "Epoch 228/1000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.5825 - acc: 0.3443 - val_loss: 1.8693 - val_acc: 0.2267\n",
      "Epoch 229/1000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.5801 - acc: 0.3471 - val_loss: 1.8688 - val_acc: 0.2233\n",
      "Epoch 230/1000\n",
      "700/700 [==============================] - 0s 118us/step - loss: 1.5818 - acc: 0.3471 - val_loss: 1.8635 - val_acc: 0.2133\n",
      "Epoch 231/1000\n",
      "700/700 [==============================] - 0s 112us/step - loss: 1.5797 - acc: 0.3529 - val_loss: 1.8606 - val_acc: 0.2200\n",
      "Epoch 232/1000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.5809 - acc: 0.3514 - val_loss: 1.8731 - val_acc: 0.2133\n",
      "Epoch 233/1000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.5796 - acc: 0.3486 - val_loss: 1.8781 - val_acc: 0.2200\n",
      "Epoch 234/1000\n",
      "700/700 [==============================] - 0s 92us/step - loss: 1.5791 - acc: 0.3457 - val_loss: 1.8666 - val_acc: 0.2133\n",
      "Epoch 235/1000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.5777 - acc: 0.3571 - val_loss: 1.8693 - val_acc: 0.2100\n",
      "Epoch 236/1000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.5778 - acc: 0.3443 - val_loss: 1.8664 - val_acc: 0.2133\n",
      "Epoch 237/1000\n",
      "700/700 [==============================] - 0s 81us/step - loss: 1.5770 - acc: 0.3429 - val_loss: 1.8718 - val_acc: 0.2300\n",
      "Epoch 238/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 100us/step - loss: 1.5774 - acc: 0.3471 - val_loss: 1.8613 - val_acc: 0.2200\n",
      "Epoch 239/1000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 1.5770 - acc: 0.3571 - val_loss: 1.8682 - val_acc: 0.2267\n",
      "Epoch 240/1000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.5749 - acc: 0.3571 - val_loss: 1.8719 - val_acc: 0.2500\n",
      "Epoch 241/1000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.5749 - acc: 0.3571 - val_loss: 1.8738 - val_acc: 0.2433\n",
      "Epoch 242/1000\n",
      "700/700 [==============================] - 0s 120us/step - loss: 1.5743 - acc: 0.3514 - val_loss: 1.8733 - val_acc: 0.2100\n",
      "Epoch 243/1000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.5743 - acc: 0.3629 - val_loss: 1.8806 - val_acc: 0.2200\n",
      "Epoch 244/1000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.5713 - acc: 0.3557 - val_loss: 1.8724 - val_acc: 0.2200\n",
      "Epoch 245/1000\n",
      "700/700 [==============================] - 0s 112us/step - loss: 1.5715 - acc: 0.3586 - val_loss: 1.8839 - val_acc: 0.2233\n",
      "Epoch 246/1000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.5712 - acc: 0.3543 - val_loss: 1.8710 - val_acc: 0.2533\n",
      "Epoch 247/1000\n",
      "700/700 [==============================] - 0s 116us/step - loss: 1.5722 - acc: 0.3557 - val_loss: 1.8631 - val_acc: 0.2167\n",
      "Epoch 248/1000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.5716 - acc: 0.3557 - val_loss: 1.8700 - val_acc: 0.2233\n",
      "Epoch 249/1000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.5712 - acc: 0.3471 - val_loss: 1.8840 - val_acc: 0.2233\n",
      "Epoch 250/1000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.5680 - acc: 0.3657 - val_loss: 1.8981 - val_acc: 0.2167\n",
      "Epoch 251/1000\n",
      "700/700 [==============================] - 0s 124us/step - loss: 1.5704 - acc: 0.3486 - val_loss: 1.8793 - val_acc: 0.2400\n",
      "Epoch 252/1000\n",
      "700/700 [==============================] - 0s 124us/step - loss: 1.5682 - acc: 0.3643 - val_loss: 1.8744 - val_acc: 0.2200\n",
      "Epoch 253/1000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.5689 - acc: 0.3586 - val_loss: 1.8820 - val_acc: 0.2133\n",
      "Epoch 254/1000\n",
      "700/700 [==============================] - 0s 112us/step - loss: 1.5677 - acc: 0.3571 - val_loss: 1.8835 - val_acc: 0.2267\n",
      "Epoch 255/1000\n",
      "700/700 [==============================] - 0s 118us/step - loss: 1.5681 - acc: 0.3457 - val_loss: 1.8713 - val_acc: 0.2267\n",
      "Epoch 256/1000\n",
      "700/700 [==============================] - 0s 122us/step - loss: 1.5657 - acc: 0.3571 - val_loss: 1.8761 - val_acc: 0.2533\n",
      "Epoch 257/1000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.5667 - acc: 0.3514 - val_loss: 1.8912 - val_acc: 0.2467\n",
      "Epoch 258/1000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.5649 - acc: 0.3614 - val_loss: 1.8946 - val_acc: 0.2567\n",
      "Epoch 259/1000\n",
      "700/700 [==============================] - 0s 118us/step - loss: 1.5648 - acc: 0.3643 - val_loss: 1.8911 - val_acc: 0.2167\n",
      "Epoch 260/1000\n",
      "700/700 [==============================] - 0s 92us/step - loss: 1.5657 - acc: 0.3600 - val_loss: 1.8989 - val_acc: 0.2200\n",
      "Epoch 261/1000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.5637 - acc: 0.3571 - val_loss: 1.8751 - val_acc: 0.2167\n",
      "Epoch 262/1000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.5638 - acc: 0.3614 - val_loss: 1.8836 - val_acc: 0.2100\n",
      "Epoch 263/1000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.5631 - acc: 0.3629 - val_loss: 1.8858 - val_acc: 0.2100\n",
      "Epoch 264/1000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.5640 - acc: 0.3571 - val_loss: 1.8812 - val_acc: 0.2133\n",
      "Epoch 265/1000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.5638 - acc: 0.3686 - val_loss: 1.8902 - val_acc: 0.2200\n",
      "Epoch 266/1000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.5614 - acc: 0.3614 - val_loss: 1.8968 - val_acc: 0.2500\n",
      "Epoch 267/1000\n",
      "700/700 [==============================] - 0s 117us/step - loss: 1.5612 - acc: 0.3629 - val_loss: 1.8919 - val_acc: 0.2300\n",
      "Epoch 268/1000\n",
      "700/700 [==============================] - 0s 133us/step - loss: 1.5613 - acc: 0.3614 - val_loss: 1.8757 - val_acc: 0.2100\n",
      "Epoch 269/1000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.5601 - acc: 0.3643 - val_loss: 1.8854 - val_acc: 0.2133\n",
      "Epoch 270/1000\n",
      "700/700 [==============================] - 0s 126us/step - loss: 1.5594 - acc: 0.3671 - val_loss: 1.8674 - val_acc: 0.2333\n",
      "Epoch 271/1000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.5610 - acc: 0.3657 - val_loss: 1.8914 - val_acc: 0.2333\n",
      "Epoch 272/1000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.5595 - acc: 0.3600 - val_loss: 1.9030 - val_acc: 0.2267\n",
      "Epoch 273/1000\n",
      "700/700 [==============================] - 0s 98us/step - loss: 1.5591 - acc: 0.3571 - val_loss: 1.8964 - val_acc: 0.2200\n",
      "Epoch 274/1000\n",
      "700/700 [==============================] - 0s 112us/step - loss: 1.5589 - acc: 0.3457 - val_loss: 1.8841 - val_acc: 0.2233\n",
      "Epoch 275/1000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.5589 - acc: 0.3629 - val_loss: 1.8914 - val_acc: 0.2200\n",
      "Epoch 276/1000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.5579 - acc: 0.3529 - val_loss: 1.8967 - val_acc: 0.2533\n",
      "Epoch 277/1000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.5581 - acc: 0.3714 - val_loss: 1.8909 - val_acc: 0.2167\n",
      "Epoch 278/1000\n",
      "700/700 [==============================] - 0s 108us/step - loss: 1.5578 - acc: 0.3600 - val_loss: 1.9032 - val_acc: 0.2300\n",
      "Epoch 279/1000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.5559 - acc: 0.3571 - val_loss: 1.8859 - val_acc: 0.2167\n",
      "Epoch 280/1000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.5559 - acc: 0.3700 - val_loss: 1.8876 - val_acc: 0.2167\n",
      "Epoch 281/1000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.5541 - acc: 0.3586 - val_loss: 1.8906 - val_acc: 0.2333\n",
      "Epoch 282/1000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.5553 - acc: 0.3671 - val_loss: 1.8840 - val_acc: 0.2133\n",
      "Epoch 283/1000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.5543 - acc: 0.3557 - val_loss: 1.8927 - val_acc: 0.2167\n",
      "Epoch 284/1000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.5542 - acc: 0.3614 - val_loss: 1.8936 - val_acc: 0.2567\n",
      "Epoch 285/1000\n",
      "700/700 [==============================] - 0s 108us/step - loss: 1.5535 - acc: 0.3557 - val_loss: 1.8887 - val_acc: 0.2200\n",
      "Epoch 286/1000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.5536 - acc: 0.3586 - val_loss: 1.8989 - val_acc: 0.2233\n",
      "Epoch 287/1000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.5527 - acc: 0.3686 - val_loss: 1.9019 - val_acc: 0.2133\n",
      "Epoch 288/1000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.5525 - acc: 0.3600 - val_loss: 1.8930 - val_acc: 0.2133\n",
      "Epoch 289/1000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 1.5519 - acc: 0.3600 - val_loss: 1.9014 - val_acc: 0.2167\n",
      "Epoch 290/1000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.5514 - acc: 0.3657 - val_loss: 1.9032 - val_acc: 0.2200\n",
      "Epoch 291/1000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.5513 - acc: 0.3586 - val_loss: 1.9037 - val_acc: 0.2167\n",
      "Epoch 292/1000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.5509 - acc: 0.3543 - val_loss: 1.8995 - val_acc: 0.2433\n",
      "Epoch 293/1000\n",
      "700/700 [==============================] - 0s 121us/step - loss: 1.5507 - acc: 0.3543 - val_loss: 1.9011 - val_acc: 0.2300\n",
      "Epoch 294/1000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 1.5497 - acc: 0.3543 - val_loss: 1.9002 - val_acc: 0.2567\n",
      "Epoch 295/1000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.5499 - acc: 0.3657 - val_loss: 1.9120 - val_acc: 0.2200\n",
      "Epoch 296/1000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.5495 - acc: 0.3571 - val_loss: 1.9104 - val_acc: 0.2133\n",
      "Epoch 297/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 109us/step - loss: 1.5479 - acc: 0.3571 - val_loss: 1.9128 - val_acc: 0.2167\n",
      "Epoch 298/1000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.5477 - acc: 0.3486 - val_loss: 1.8958 - val_acc: 0.2267\n",
      "Epoch 299/1000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.5485 - acc: 0.3686 - val_loss: 1.9145 - val_acc: 0.2267\n",
      "Epoch 300/1000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.5472 - acc: 0.3629 - val_loss: 1.9031 - val_acc: 0.2300\n",
      "Epoch 301/1000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.5470 - acc: 0.3629 - val_loss: 1.8934 - val_acc: 0.2200\n",
      "Epoch 302/1000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.5479 - acc: 0.3657 - val_loss: 1.9081 - val_acc: 0.2167\n",
      "Epoch 303/1000\n",
      "700/700 [==============================] - 0s 92us/step - loss: 1.5465 - acc: 0.3529 - val_loss: 1.9016 - val_acc: 0.2333\n",
      "Epoch 304/1000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.5452 - acc: 0.3671 - val_loss: 1.9066 - val_acc: 0.2200\n",
      "Epoch 305/1000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.5431 - acc: 0.3643 - val_loss: 1.9152 - val_acc: 0.2267\n",
      "Epoch 306/1000\n",
      "700/700 [==============================] - 0s 98us/step - loss: 1.5458 - acc: 0.3614 - val_loss: 1.9108 - val_acc: 0.2267\n",
      "Epoch 307/1000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.5436 - acc: 0.3657 - val_loss: 1.9070 - val_acc: 0.2267\n",
      "Epoch 308/1000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.5452 - acc: 0.3600 - val_loss: 1.9136 - val_acc: 0.2333\n",
      "Epoch 309/1000\n",
      "700/700 [==============================] - 0s 86us/step - loss: 1.5436 - acc: 0.3643 - val_loss: 1.9127 - val_acc: 0.2367\n",
      "Epoch 310/1000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.5448 - acc: 0.3657 - val_loss: 1.9116 - val_acc: 0.2167\n",
      "Epoch 311/1000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.5426 - acc: 0.3571 - val_loss: 1.9064 - val_acc: 0.2300\n",
      "Epoch 312/1000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.5423 - acc: 0.3714 - val_loss: 1.9278 - val_acc: 0.2367\n",
      "Epoch 313/1000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.5387 - acc: 0.3671 - val_loss: 1.9050 - val_acc: 0.2633\n",
      "Epoch 314/1000\n",
      "700/700 [==============================] - 0s 119us/step - loss: 1.5432 - acc: 0.3714 - val_loss: 1.9102 - val_acc: 0.2300\n",
      "Epoch 315/1000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 1.5406 - acc: 0.3657 - val_loss: 1.9128 - val_acc: 0.2233\n",
      "Epoch 316/1000\n",
      "700/700 [==============================] - 0s 122us/step - loss: 1.5404 - acc: 0.3600 - val_loss: 1.9141 - val_acc: 0.2267\n",
      "Epoch 317/1000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.5412 - acc: 0.3614 - val_loss: 1.9217 - val_acc: 0.2300\n",
      "Epoch 318/1000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.5408 - acc: 0.3614 - val_loss: 1.9104 - val_acc: 0.2300\n",
      "Epoch 319/1000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.5390 - acc: 0.3614 - val_loss: 1.9098 - val_acc: 0.2300\n",
      "Epoch 320/1000\n",
      "700/700 [==============================] - 0s 84us/step - loss: 1.5392 - acc: 0.3629 - val_loss: 1.9285 - val_acc: 0.2267\n",
      "Epoch 321/1000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.5392 - acc: 0.3686 - val_loss: 1.9263 - val_acc: 0.2300\n",
      "Epoch 322/1000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.5375 - acc: 0.3671 - val_loss: 1.9186 - val_acc: 0.2533\n",
      "Epoch 323/1000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.5383 - acc: 0.3714 - val_loss: 1.9198 - val_acc: 0.2300\n",
      "Epoch 324/1000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.5373 - acc: 0.3671 - val_loss: 1.9231 - val_acc: 0.2200\n",
      "Epoch 325/1000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.5386 - acc: 0.3600 - val_loss: 1.9138 - val_acc: 0.2100\n",
      "Epoch 326/1000\n",
      "700/700 [==============================] - 0s 119us/step - loss: 1.5366 - acc: 0.3614 - val_loss: 1.9261 - val_acc: 0.2267\n",
      "Epoch 327/1000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.5360 - acc: 0.3729 - val_loss: 1.9367 - val_acc: 0.2333\n",
      "Epoch 328/1000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.5367 - acc: 0.3614 - val_loss: 1.9303 - val_acc: 0.2233\n",
      "Epoch 329/1000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.5355 - acc: 0.3729 - val_loss: 1.9142 - val_acc: 0.2300\n",
      "Epoch 330/1000\n",
      "700/700 [==============================] - 0s 108us/step - loss: 1.5352 - acc: 0.3586 - val_loss: 1.9218 - val_acc: 0.2333\n",
      "Epoch 331/1000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 1.5338 - acc: 0.3700 - val_loss: 1.9150 - val_acc: 0.2200\n",
      "Epoch 332/1000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 1.5345 - acc: 0.3586 - val_loss: 1.9314 - val_acc: 0.2500\n",
      "Epoch 333/1000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.5358 - acc: 0.3686 - val_loss: 1.9231 - val_acc: 0.2233\n",
      "Epoch 334/1000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 1.5349 - acc: 0.3629 - val_loss: 1.9284 - val_acc: 0.2233\n",
      "Epoch 335/1000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.5327 - acc: 0.3771 - val_loss: 1.9240 - val_acc: 0.2567\n",
      "Epoch 336/1000\n",
      "700/700 [==============================] - 0s 119us/step - loss: 1.5335 - acc: 0.3800 - val_loss: 1.9179 - val_acc: 0.2300\n",
      "Epoch 337/1000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.5330 - acc: 0.3771 - val_loss: 1.9325 - val_acc: 0.2300\n",
      "Epoch 338/1000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.5320 - acc: 0.3743 - val_loss: 1.9237 - val_acc: 0.2133\n",
      "Epoch 339/1000\n",
      "700/700 [==============================] - 0s 118us/step - loss: 1.5313 - acc: 0.3714 - val_loss: 1.9155 - val_acc: 0.2167\n",
      "Epoch 340/1000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.5328 - acc: 0.3729 - val_loss: 1.9402 - val_acc: 0.2267\n",
      "Epoch 341/1000\n",
      "700/700 [==============================] - 0s 84us/step - loss: 1.5316 - acc: 0.3771 - val_loss: 1.9256 - val_acc: 0.2267\n",
      "Epoch 342/1000\n",
      "700/700 [==============================] - 0s 98us/step - loss: 1.5313 - acc: 0.3614 - val_loss: 1.9438 - val_acc: 0.2200\n",
      "Epoch 343/1000\n",
      "700/700 [==============================] - 0s 112us/step - loss: 1.5311 - acc: 0.3671 - val_loss: 1.9306 - val_acc: 0.2300\n",
      "Epoch 344/1000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 1.5308 - acc: 0.3671 - val_loss: 1.9427 - val_acc: 0.2300\n",
      "Epoch 345/1000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.5291 - acc: 0.3686 - val_loss: 1.9436 - val_acc: 0.2567\n",
      "Epoch 346/1000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 1.5301 - acc: 0.3714 - val_loss: 1.9313 - val_acc: 0.2267\n",
      "Epoch 347/1000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.5278 - acc: 0.3800 - val_loss: 1.9200 - val_acc: 0.2200\n",
      "Epoch 348/1000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.5284 - acc: 0.3643 - val_loss: 1.9296 - val_acc: 0.2133\n",
      "Epoch 349/1000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.5282 - acc: 0.3700 - val_loss: 1.9272 - val_acc: 0.2133\n",
      "Epoch 350/1000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.5281 - acc: 0.3657 - val_loss: 1.9311 - val_acc: 0.2300\n",
      "Epoch 351/1000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.5264 - acc: 0.3743 - val_loss: 1.9308 - val_acc: 0.2333\n",
      "Epoch 352/1000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.5283 - acc: 0.3729 - val_loss: 1.9282 - val_acc: 0.2300\n",
      "Epoch 353/1000\n",
      "700/700 [==============================] - 0s 108us/step - loss: 1.5256 - acc: 0.3657 - val_loss: 1.9422 - val_acc: 0.2333\n",
      "Epoch 354/1000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 1.5280 - acc: 0.3714 - val_loss: 1.9345 - val_acc: 0.2167\n",
      "Epoch 355/1000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.5261 - acc: 0.3600 - val_loss: 1.9556 - val_acc: 0.2267\n",
      "Epoch 356/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 106us/step - loss: 1.5260 - acc: 0.3700 - val_loss: 1.9440 - val_acc: 0.2433\n",
      "Epoch 357/1000\n",
      "700/700 [==============================] - 0s 115us/step - loss: 1.5260 - acc: 0.3714 - val_loss: 1.9361 - val_acc: 0.2267\n",
      "Epoch 358/1000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.5250 - acc: 0.3700 - val_loss: 1.9502 - val_acc: 0.2200\n",
      "Epoch 359/1000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.5252 - acc: 0.3700 - val_loss: 1.9458 - val_acc: 0.2133\n",
      "Epoch 360/1000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.5232 - acc: 0.3729 - val_loss: 1.9458 - val_acc: 0.2233\n",
      "Epoch 361/1000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.5231 - acc: 0.3671 - val_loss: 1.9473 - val_acc: 0.2333\n",
      "Epoch 362/1000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.5240 - acc: 0.3629 - val_loss: 1.9493 - val_acc: 0.2233\n",
      "Epoch 363/1000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.5216 - acc: 0.3757 - val_loss: 1.9514 - val_acc: 0.2333\n",
      "Epoch 364/1000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.5230 - acc: 0.3643 - val_loss: 1.9370 - val_acc: 0.2300\n",
      "Epoch 365/1000\n",
      "700/700 [==============================] - 0s 118us/step - loss: 1.5225 - acc: 0.3771 - val_loss: 1.9517 - val_acc: 0.2267\n",
      "Epoch 366/1000\n",
      "700/700 [==============================] - 0s 98us/step - loss: 1.5223 - acc: 0.3714 - val_loss: 1.9400 - val_acc: 0.2133\n",
      "Epoch 367/1000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.5222 - acc: 0.3771 - val_loss: 1.9564 - val_acc: 0.2300\n",
      "Epoch 368/1000\n",
      "700/700 [==============================] - 0s 83us/step - loss: 1.5206 - acc: 0.3786 - val_loss: 1.9550 - val_acc: 0.2367\n",
      "Epoch 369/1000\n",
      "700/700 [==============================] - 0s 76us/step - loss: 1.5208 - acc: 0.3629 - val_loss: 1.9319 - val_acc: 0.2367\n",
      "Epoch 370/1000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.5200 - acc: 0.3757 - val_loss: 1.9531 - val_acc: 0.2400\n",
      "Epoch 371/1000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.5210 - acc: 0.3671 - val_loss: 1.9506 - val_acc: 0.2233\n",
      "Epoch 372/1000\n",
      "700/700 [==============================] - 0s 121us/step - loss: 1.5194 - acc: 0.3729 - val_loss: 1.9587 - val_acc: 0.2333\n",
      "Epoch 373/1000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.5205 - acc: 0.3757 - val_loss: 1.9450 - val_acc: 0.2133\n",
      "Epoch 374/1000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.5196 - acc: 0.3671 - val_loss: 1.9517 - val_acc: 0.2267\n",
      "Epoch 375/1000\n",
      "700/700 [==============================] - 0s 108us/step - loss: 1.5181 - acc: 0.3843 - val_loss: 1.9385 - val_acc: 0.2267\n",
      "Epoch 376/1000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 1.5183 - acc: 0.3786 - val_loss: 1.9456 - val_acc: 0.2200\n",
      "Epoch 377/1000\n",
      "700/700 [==============================] - 0s 88us/step - loss: 1.5171 - acc: 0.3714 - val_loss: 1.9755 - val_acc: 0.2267\n",
      "Epoch 378/1000\n",
      "700/700 [==============================] - 0s 119us/step - loss: 1.5182 - acc: 0.3757 - val_loss: 1.9754 - val_acc: 0.2367\n",
      "Epoch 379/1000\n",
      "700/700 [==============================] - 0s 119us/step - loss: 1.5188 - acc: 0.3700 - val_loss: 1.9514 - val_acc: 0.2333\n",
      "Epoch 380/1000\n",
      "700/700 [==============================] - 0s 112us/step - loss: 1.5166 - acc: 0.3686 - val_loss: 1.9600 - val_acc: 0.2567\n",
      "Epoch 381/1000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.5178 - acc: 0.3786 - val_loss: 1.9712 - val_acc: 0.2167\n",
      "Epoch 382/1000\n",
      "700/700 [==============================] - 0s 112us/step - loss: 1.5162 - acc: 0.3714 - val_loss: 1.9587 - val_acc: 0.2233\n",
      "Epoch 383/1000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.5155 - acc: 0.3700 - val_loss: 1.9716 - val_acc: 0.2433\n",
      "Epoch 384/1000\n",
      "700/700 [==============================] - 0s 115us/step - loss: 1.5164 - acc: 0.3771 - val_loss: 1.9481 - val_acc: 0.2233\n",
      "Epoch 385/1000\n",
      "700/700 [==============================] - 0s 121us/step - loss: 1.5163 - acc: 0.3771 - val_loss: 1.9585 - val_acc: 0.2267\n",
      "Epoch 386/1000\n",
      "700/700 [==============================] - 0s 117us/step - loss: 1.5156 - acc: 0.3700 - val_loss: 1.9508 - val_acc: 0.2333\n",
      "Epoch 387/1000\n",
      "700/700 [==============================] - 0s 121us/step - loss: 1.5153 - acc: 0.3743 - val_loss: 1.9584 - val_acc: 0.2300\n",
      "Epoch 388/1000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.5143 - acc: 0.3700 - val_loss: 1.9673 - val_acc: 0.2467\n",
      "Epoch 389/1000\n",
      "700/700 [==============================] - 0s 116us/step - loss: 1.5159 - acc: 0.3800 - val_loss: 1.9494 - val_acc: 0.2267\n",
      "Epoch 390/1000\n",
      "700/700 [==============================] - 0s 112us/step - loss: 1.5125 - acc: 0.3671 - val_loss: 1.9575 - val_acc: 0.2400\n",
      "Epoch 391/1000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.5132 - acc: 0.3757 - val_loss: 1.9542 - val_acc: 0.2367\n",
      "Epoch 392/1000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 1.5137 - acc: 0.3714 - val_loss: 1.9602 - val_acc: 0.2200\n",
      "Epoch 393/1000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.5136 - acc: 0.3743 - val_loss: 1.9733 - val_acc: 0.2233\n",
      "Epoch 394/1000\n",
      "700/700 [==============================] - 0s 121us/step - loss: 1.5136 - acc: 0.3771 - val_loss: 1.9572 - val_acc: 0.2233\n",
      "Epoch 395/1000\n",
      "700/700 [==============================] - 0s 98us/step - loss: 1.5130 - acc: 0.3786 - val_loss: 1.9567 - val_acc: 0.2167\n",
      "Epoch 396/1000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.5122 - acc: 0.3771 - val_loss: 1.9646 - val_acc: 0.2167\n",
      "Epoch 397/1000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.5110 - acc: 0.3843 - val_loss: 1.9755 - val_acc: 0.2333\n",
      "Epoch 398/1000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.5124 - acc: 0.3657 - val_loss: 1.9590 - val_acc: 0.2200\n",
      "Epoch 399/1000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.5107 - acc: 0.3771 - val_loss: 1.9850 - val_acc: 0.2333\n",
      "Epoch 400/1000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.5112 - acc: 0.3657 - val_loss: 1.9600 - val_acc: 0.2167\n",
      "Epoch 401/1000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.5109 - acc: 0.3657 - val_loss: 1.9595 - val_acc: 0.2267\n",
      "Epoch 402/1000\n",
      "700/700 [==============================] - 0s 80us/step - loss: 1.5086 - acc: 0.3771 - val_loss: 1.9651 - val_acc: 0.2233\n",
      "Epoch 403/1000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.5068 - acc: 0.3843 - val_loss: 1.9932 - val_acc: 0.2200\n",
      "Epoch 404/1000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.5085 - acc: 0.3743 - val_loss: 1.9676 - val_acc: 0.2333\n",
      "Epoch 405/1000\n",
      "700/700 [==============================] - 0s 80us/step - loss: 1.5074 - acc: 0.3814 - val_loss: 1.9811 - val_acc: 0.2267\n",
      "Epoch 406/1000\n",
      "700/700 [==============================] - 0s 87us/step - loss: 1.5083 - acc: 0.3771 - val_loss: 1.9812 - val_acc: 0.2233\n",
      "Epoch 407/1000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.5081 - acc: 0.3714 - val_loss: 1.9783 - val_acc: 0.2233\n",
      "Epoch 408/1000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.5077 - acc: 0.3771 - val_loss: 1.9699 - val_acc: 0.2267\n",
      "Epoch 409/1000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.5040 - acc: 0.3700 - val_loss: 1.9780 - val_acc: 0.2367\n",
      "Epoch 410/1000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.5058 - acc: 0.3743 - val_loss: 1.9609 - val_acc: 0.2267\n",
      "Epoch 411/1000\n",
      "700/700 [==============================] - 0s 125us/step - loss: 1.5057 - acc: 0.3700 - val_loss: 1.9819 - val_acc: 0.2300\n",
      "Epoch 412/1000\n",
      "700/700 [==============================] - 0s 85us/step - loss: 1.5049 - acc: 0.3843 - val_loss: 1.9720 - val_acc: 0.2233\n",
      "Epoch 413/1000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.5033 - acc: 0.3757 - val_loss: 1.9751 - val_acc: 0.2333\n",
      "Epoch 414/1000\n",
      "700/700 [==============================] - 0s 112us/step - loss: 1.5043 - acc: 0.3800 - val_loss: 1.9844 - val_acc: 0.2333\n",
      "Epoch 415/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 114us/step - loss: 1.5015 - acc: 0.3757 - val_loss: 1.9780 - val_acc: 0.2333\n",
      "Epoch 416/1000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.5031 - acc: 0.3843 - val_loss: 1.9887 - val_acc: 0.2267\n",
      "Epoch 417/1000\n",
      "700/700 [==============================] - 0s 115us/step - loss: 1.5032 - acc: 0.3771 - val_loss: 1.9804 - val_acc: 0.2233\n",
      "Epoch 418/1000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.5016 - acc: 0.3871 - val_loss: 1.9744 - val_acc: 0.2367\n",
      "Epoch 419/1000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.5019 - acc: 0.3771 - val_loss: 1.9661 - val_acc: 0.2200\n",
      "Epoch 420/1000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.5015 - acc: 0.3800 - val_loss: 1.9877 - val_acc: 0.2300\n",
      "Epoch 421/1000\n",
      "700/700 [==============================] - 0s 112us/step - loss: 1.5011 - acc: 0.3814 - val_loss: 1.9693 - val_acc: 0.2433\n",
      "Epoch 422/1000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.5005 - acc: 0.3743 - val_loss: 1.9747 - val_acc: 0.2433\n",
      "Epoch 423/1000\n",
      "700/700 [==============================] - 0s 117us/step - loss: 1.5003 - acc: 0.3814 - val_loss: 1.9792 - val_acc: 0.2367\n",
      "Epoch 424/1000\n",
      "700/700 [==============================] - 0s 117us/step - loss: 1.5002 - acc: 0.3757 - val_loss: 1.9681 - val_acc: 0.2200\n",
      "Epoch 425/1000\n",
      "700/700 [==============================] - 0s 116us/step - loss: 1.4991 - acc: 0.3886 - val_loss: 1.9622 - val_acc: 0.2400\n",
      "Epoch 426/1000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 1.4984 - acc: 0.3914 - val_loss: 1.9793 - val_acc: 0.2167\n",
      "Epoch 427/1000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.4983 - acc: 0.3829 - val_loss: 1.9835 - val_acc: 0.2533\n",
      "Epoch 428/1000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.4984 - acc: 0.3843 - val_loss: 2.0050 - val_acc: 0.2300\n",
      "Epoch 429/1000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.4982 - acc: 0.3771 - val_loss: 1.9699 - val_acc: 0.2300\n",
      "Epoch 430/1000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.4978 - acc: 0.3829 - val_loss: 1.9812 - val_acc: 0.2467\n",
      "Epoch 431/1000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.4991 - acc: 0.3800 - val_loss: 1.9870 - val_acc: 0.2333\n",
      "Epoch 432/1000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.4975 - acc: 0.3829 - val_loss: 1.9817 - val_acc: 0.2233\n",
      "Epoch 433/1000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.4967 - acc: 0.3786 - val_loss: 1.9856 - val_acc: 0.2333\n",
      "Epoch 434/1000\n",
      "700/700 [==============================] - 0s 118us/step - loss: 1.4976 - acc: 0.3786 - val_loss: 1.9877 - val_acc: 0.2233\n",
      "Epoch 435/1000\n",
      "700/700 [==============================] - 0s 115us/step - loss: 1.4957 - acc: 0.3857 - val_loss: 1.9829 - val_acc: 0.2267\n",
      "Epoch 436/1000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.4974 - acc: 0.3843 - val_loss: 1.9700 - val_acc: 0.2200\n",
      "Epoch 437/1000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.4958 - acc: 0.3929 - val_loss: 1.9907 - val_acc: 0.2233\n",
      "Epoch 438/1000\n",
      "700/700 [==============================] - 0s 108us/step - loss: 1.4949 - acc: 0.3857 - val_loss: 1.9668 - val_acc: 0.2267\n",
      "Epoch 439/1000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.4946 - acc: 0.3757 - val_loss: 1.9786 - val_acc: 0.2233\n",
      "Epoch 440/1000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.4960 - acc: 0.3829 - val_loss: 1.9801 - val_acc: 0.2300\n",
      "Epoch 441/1000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.4951 - acc: 0.3886 - val_loss: 1.9829 - val_acc: 0.2300\n",
      "Epoch 442/1000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.4945 - acc: 0.3843 - val_loss: 1.9939 - val_acc: 0.2233\n",
      "Epoch 443/1000\n",
      "700/700 [==============================] - 0s 115us/step - loss: 1.4937 - acc: 0.3857 - val_loss: 1.9900 - val_acc: 0.2400\n",
      "Epoch 444/1000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.4946 - acc: 0.3814 - val_loss: 1.9927 - val_acc: 0.2233\n",
      "Epoch 445/1000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 1.4943 - acc: 0.3829 - val_loss: 1.9956 - val_acc: 0.2300\n",
      "Epoch 446/1000\n",
      "700/700 [==============================] - 0s 127us/step - loss: 1.4931 - acc: 0.3871 - val_loss: 2.0016 - val_acc: 0.2267\n",
      "Epoch 447/1000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 1.4925 - acc: 0.3800 - val_loss: 2.0156 - val_acc: 0.2300\n",
      "Epoch 448/1000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.4928 - acc: 0.3843 - val_loss: 1.9923 - val_acc: 0.2267\n",
      "Epoch 449/1000\n",
      "700/700 [==============================] - 0s 118us/step - loss: 1.4918 - acc: 0.3886 - val_loss: 2.0020 - val_acc: 0.2333\n",
      "Epoch 450/1000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.4930 - acc: 0.3843 - val_loss: 1.9925 - val_acc: 0.2233\n",
      "Epoch 451/1000\n",
      "700/700 [==============================] - 0s 115us/step - loss: 1.4920 - acc: 0.3829 - val_loss: 1.9980 - val_acc: 0.2233\n",
      "Epoch 452/1000\n",
      "700/700 [==============================] - 0s 118us/step - loss: 1.4911 - acc: 0.3871 - val_loss: 1.9958 - val_acc: 0.2300\n",
      "Epoch 453/1000\n",
      "700/700 [==============================] - 0s 86us/step - loss: 1.4909 - acc: 0.3886 - val_loss: 1.9906 - val_acc: 0.2300\n",
      "Epoch 454/1000\n",
      "700/700 [==============================] - 0s 82us/step - loss: 1.4908 - acc: 0.3871 - val_loss: 1.9974 - val_acc: 0.2333\n",
      "Epoch 455/1000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.4907 - acc: 0.3843 - val_loss: 1.9885 - val_acc: 0.2267\n",
      "Epoch 456/1000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.4898 - acc: 0.3786 - val_loss: 1.9920 - val_acc: 0.2467\n",
      "Epoch 457/1000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.4899 - acc: 0.3871 - val_loss: 1.9974 - val_acc: 0.2333\n",
      "Epoch 458/1000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.4902 - acc: 0.3857 - val_loss: 1.9946 - val_acc: 0.2267\n",
      "Epoch 459/1000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.4881 - acc: 0.3943 - val_loss: 1.9914 - val_acc: 0.2467\n",
      "Epoch 460/1000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 1.4900 - acc: 0.3886 - val_loss: 2.0004 - val_acc: 0.2300\n",
      "Epoch 461/1000\n",
      "700/700 [==============================] - 0s 121us/step - loss: 1.4883 - acc: 0.3957 - val_loss: 2.0038 - val_acc: 0.2300\n",
      "Epoch 462/1000\n",
      "700/700 [==============================] - 0s 108us/step - loss: 1.4883 - acc: 0.3900 - val_loss: 1.9934 - val_acc: 0.2267\n",
      "Epoch 463/1000\n",
      "700/700 [==============================] - 0s 112us/step - loss: 1.4872 - acc: 0.3871 - val_loss: 2.0000 - val_acc: 0.2467\n",
      "Epoch 464/1000\n",
      "700/700 [==============================] - 0s 125us/step - loss: 1.4873 - acc: 0.3857 - val_loss: 1.9911 - val_acc: 0.2333\n",
      "Epoch 465/1000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 1.4877 - acc: 0.3900 - val_loss: 1.9968 - val_acc: 0.2233\n",
      "Epoch 466/1000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.4871 - acc: 0.3757 - val_loss: 2.0009 - val_acc: 0.2267\n",
      "Epoch 467/1000\n",
      "700/700 [==============================] - 0s 108us/step - loss: 1.4874 - acc: 0.3871 - val_loss: 2.0060 - val_acc: 0.2300\n",
      "Epoch 468/1000\n",
      "700/700 [==============================] - 0s 117us/step - loss: 1.4865 - acc: 0.3829 - val_loss: 1.9907 - val_acc: 0.2267\n",
      "Epoch 469/1000\n",
      "700/700 [==============================] - 0s 115us/step - loss: 1.4859 - acc: 0.3871 - val_loss: 2.0312 - val_acc: 0.2333\n",
      "Epoch 470/1000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.4870 - acc: 0.3871 - val_loss: 2.0094 - val_acc: 0.2233\n",
      "Epoch 471/1000\n",
      "700/700 [==============================] - 0s 115us/step - loss: 1.4858 - acc: 0.3957 - val_loss: 2.0055 - val_acc: 0.2233\n",
      "Epoch 472/1000\n",
      "700/700 [==============================] - 0s 108us/step - loss: 1.4844 - acc: 0.3971 - val_loss: 2.0110 - val_acc: 0.2367\n",
      "Epoch 473/1000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 1.4849 - acc: 0.3929 - val_loss: 2.0123 - val_acc: 0.2367\n",
      "Epoch 474/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 118us/step - loss: 1.4838 - acc: 0.3900 - val_loss: 1.9973 - val_acc: 0.2267\n",
      "Epoch 475/1000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.4842 - acc: 0.3900 - val_loss: 2.0049 - val_acc: 0.2233\n",
      "Epoch 476/1000\n",
      "700/700 [==============================] - 0s 116us/step - loss: 1.4834 - acc: 0.3914 - val_loss: 2.0060 - val_acc: 0.2267\n",
      "Epoch 477/1000\n",
      "700/700 [==============================] - 0s 117us/step - loss: 1.4840 - acc: 0.3929 - val_loss: 2.0111 - val_acc: 0.2267\n",
      "Epoch 478/1000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 1.4838 - acc: 0.3914 - val_loss: 2.0055 - val_acc: 0.2333\n",
      "Epoch 479/1000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.4834 - acc: 0.3914 - val_loss: 2.0014 - val_acc: 0.2300\n",
      "Epoch 480/1000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.4823 - acc: 0.3986 - val_loss: 2.0105 - val_acc: 0.2367\n",
      "Epoch 481/1000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.4821 - acc: 0.3871 - val_loss: 2.0187 - val_acc: 0.2400\n",
      "Epoch 482/1000\n",
      "700/700 [==============================] - 0s 84us/step - loss: 1.4810 - acc: 0.4000 - val_loss: 2.0164 - val_acc: 0.2300\n",
      "Epoch 483/1000\n",
      "700/700 [==============================] - 0s 86us/step - loss: 1.4820 - acc: 0.3986 - val_loss: 2.0146 - val_acc: 0.2367\n",
      "Epoch 484/1000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.4815 - acc: 0.3971 - val_loss: 2.0156 - val_acc: 0.2400\n",
      "Epoch 485/1000\n",
      "700/700 [==============================] - 0s 98us/step - loss: 1.4809 - acc: 0.3986 - val_loss: 2.0145 - val_acc: 0.2267\n",
      "Epoch 486/1000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.4807 - acc: 0.3886 - val_loss: 2.0033 - val_acc: 0.2467\n",
      "Epoch 487/1000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.4812 - acc: 0.3929 - val_loss: 2.0113 - val_acc: 0.2500\n",
      "Epoch 488/1000\n",
      "700/700 [==============================] - 0s 98us/step - loss: 1.4809 - acc: 0.3900 - val_loss: 2.0128 - val_acc: 0.2500\n",
      "Epoch 489/1000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 1.4805 - acc: 0.3857 - val_loss: 2.0069 - val_acc: 0.2300\n",
      "Epoch 490/1000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.4809 - acc: 0.3929 - val_loss: 2.0012 - val_acc: 0.2333\n",
      "Epoch 491/1000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.4808 - acc: 0.3914 - val_loss: 2.0223 - val_acc: 0.2300\n",
      "Epoch 492/1000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.4800 - acc: 0.3900 - val_loss: 2.0019 - val_acc: 0.2267\n",
      "Epoch 493/1000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.4798 - acc: 0.4000 - val_loss: 2.0080 - val_acc: 0.2333\n",
      "Epoch 494/1000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 1.4801 - acc: 0.3914 - val_loss: 2.0077 - val_acc: 0.2233\n",
      "Epoch 495/1000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.4792 - acc: 0.4000 - val_loss: 2.0261 - val_acc: 0.2333\n",
      "Epoch 496/1000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.4786 - acc: 0.3857 - val_loss: 2.0101 - val_acc: 0.2400\n",
      "Epoch 497/1000\n",
      "700/700 [==============================] - 0s 82us/step - loss: 1.4772 - acc: 0.3914 - val_loss: 2.0124 - val_acc: 0.2500\n",
      "Epoch 498/1000\n",
      "700/700 [==============================] - 0s 78us/step - loss: 1.4763 - acc: 0.3886 - val_loss: 2.0469 - val_acc: 0.2367\n",
      "Epoch 499/1000\n",
      "700/700 [==============================] - 0s 92us/step - loss: 1.4774 - acc: 0.4043 - val_loss: 2.0273 - val_acc: 0.2367\n",
      "Epoch 500/1000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.4780 - acc: 0.3943 - val_loss: 2.0256 - val_acc: 0.2367\n",
      "Epoch 501/1000\n",
      "700/700 [==============================] - 0s 115us/step - loss: 1.4782 - acc: 0.4000 - val_loss: 2.0254 - val_acc: 0.2300\n",
      "Epoch 502/1000\n",
      "700/700 [==============================] - 0s 108us/step - loss: 1.4759 - acc: 0.3971 - val_loss: 2.0252 - val_acc: 0.2267\n",
      "Epoch 503/1000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 1.4764 - acc: 0.3943 - val_loss: 2.0206 - val_acc: 0.2267\n",
      "Epoch 504/1000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 1.4757 - acc: 0.3971 - val_loss: 2.0242 - val_acc: 0.2267\n",
      "Epoch 505/1000\n",
      "700/700 [==============================] - 0s 117us/step - loss: 1.4754 - acc: 0.3957 - val_loss: 2.0208 - val_acc: 0.2400\n",
      "Epoch 506/1000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.4753 - acc: 0.4000 - val_loss: 2.0164 - val_acc: 0.2300\n",
      "Epoch 507/1000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.4769 - acc: 0.3986 - val_loss: 2.0211 - val_acc: 0.2233\n",
      "Epoch 508/1000\n",
      "700/700 [==============================] - 0s 122us/step - loss: 1.4749 - acc: 0.3914 - val_loss: 2.0239 - val_acc: 0.2267\n",
      "Epoch 509/1000\n",
      "700/700 [==============================] - 0s 115us/step - loss: 1.4743 - acc: 0.3943 - val_loss: 2.0372 - val_acc: 0.2333\n",
      "Epoch 510/1000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.4745 - acc: 0.3914 - val_loss: 2.0232 - val_acc: 0.2233\n",
      "Epoch 511/1000\n",
      "700/700 [==============================] - 0s 117us/step - loss: 1.4738 - acc: 0.4071 - val_loss: 2.0147 - val_acc: 0.2267\n",
      "Epoch 512/1000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.4740 - acc: 0.3971 - val_loss: 2.0095 - val_acc: 0.2433\n",
      "Epoch 513/1000\n",
      "700/700 [==============================] - 0s 108us/step - loss: 1.4731 - acc: 0.3986 - val_loss: 2.0139 - val_acc: 0.2433\n",
      "Epoch 514/1000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.4727 - acc: 0.4000 - val_loss: 2.0278 - val_acc: 0.2267\n",
      "Epoch 515/1000\n",
      "700/700 [==============================] - 0s 108us/step - loss: 1.4733 - acc: 0.4043 - val_loss: 2.0269 - val_acc: 0.2300\n",
      "Epoch 516/1000\n",
      "700/700 [==============================] - 0s 116us/step - loss: 1.4741 - acc: 0.3914 - val_loss: 2.0268 - val_acc: 0.2267\n",
      "Epoch 517/1000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.4705 - acc: 0.3957 - val_loss: 2.0346 - val_acc: 0.2500\n",
      "Epoch 518/1000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 1.4740 - acc: 0.4029 - val_loss: 2.0339 - val_acc: 0.2267\n",
      "Epoch 519/1000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 1.4726 - acc: 0.4043 - val_loss: 2.0235 - val_acc: 0.2300\n",
      "Epoch 520/1000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 1.4718 - acc: 0.3957 - val_loss: 2.0306 - val_acc: 0.2400\n",
      "Epoch 521/1000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.4714 - acc: 0.4157 - val_loss: 2.0128 - val_acc: 0.2333\n",
      "Epoch 522/1000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.4724 - acc: 0.3986 - val_loss: 2.0338 - val_acc: 0.2267\n",
      "Epoch 523/1000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.4720 - acc: 0.3943 - val_loss: 2.0312 - val_acc: 0.2267\n",
      "Epoch 524/1000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.4712 - acc: 0.4000 - val_loss: 2.0233 - val_acc: 0.2333\n",
      "Epoch 525/1000\n",
      "700/700 [==============================] - 0s 118us/step - loss: 1.4696 - acc: 0.4000 - val_loss: 2.0289 - val_acc: 0.2467\n",
      "Epoch 526/1000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.4710 - acc: 0.3986 - val_loss: 2.0257 - val_acc: 0.2267\n",
      "Epoch 527/1000\n",
      "700/700 [==============================] - 0s 117us/step - loss: 1.4701 - acc: 0.3943 - val_loss: 2.0257 - val_acc: 0.2300\n",
      "Epoch 528/1000\n",
      "700/700 [==============================] - 0s 116us/step - loss: 1.4694 - acc: 0.4029 - val_loss: 2.0278 - val_acc: 0.2267\n",
      "Epoch 529/1000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.4680 - acc: 0.3943 - val_loss: 2.0332 - val_acc: 0.2267\n",
      "Epoch 530/1000\n",
      "700/700 [==============================] - 0s 123us/step - loss: 1.4687 - acc: 0.4014 - val_loss: 2.0408 - val_acc: 0.2267\n",
      "Epoch 531/1000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.4688 - acc: 0.3957 - val_loss: 2.0246 - val_acc: 0.2433\n",
      "Epoch 532/1000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.4690 - acc: 0.4014 - val_loss: 2.0352 - val_acc: 0.2433\n",
      "Epoch 533/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 106us/step - loss: 1.4685 - acc: 0.4000 - val_loss: 2.0309 - val_acc: 0.2300\n",
      "Epoch 534/1000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.4688 - acc: 0.3971 - val_loss: 2.0265 - val_acc: 0.2300\n",
      "Epoch 535/1000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.4673 - acc: 0.4043 - val_loss: 2.0498 - val_acc: 0.2433\n",
      "Epoch 536/1000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.4671 - acc: 0.4043 - val_loss: 2.0466 - val_acc: 0.2267\n",
      "Epoch 537/1000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.4676 - acc: 0.4043 - val_loss: 2.0287 - val_acc: 0.2300\n",
      "Epoch 538/1000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.4671 - acc: 0.3971 - val_loss: 2.0356 - val_acc: 0.2333\n",
      "Epoch 539/1000\n",
      "700/700 [==============================] - 0s 92us/step - loss: 1.4691 - acc: 0.3943 - val_loss: 2.0296 - val_acc: 0.2267\n",
      "Epoch 540/1000\n",
      "700/700 [==============================] - 0s 98us/step - loss: 1.4677 - acc: 0.4000 - val_loss: 2.0411 - val_acc: 0.2267\n",
      "Epoch 541/1000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.4668 - acc: 0.3986 - val_loss: 2.0376 - val_acc: 0.2267\n",
      "Epoch 542/1000\n",
      "700/700 [==============================] - 0s 108us/step - loss: 1.4665 - acc: 0.4043 - val_loss: 2.0419 - val_acc: 0.2433\n",
      "Epoch 543/1000\n",
      "700/700 [==============================] - 0s 115us/step - loss: 1.4671 - acc: 0.4000 - val_loss: 2.0301 - val_acc: 0.2333\n",
      "Epoch 544/1000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.4657 - acc: 0.3943 - val_loss: 2.0245 - val_acc: 0.2367\n",
      "Epoch 545/1000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.4665 - acc: 0.4014 - val_loss: 2.0328 - val_acc: 0.2300\n",
      "Epoch 546/1000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.4636 - acc: 0.4000 - val_loss: 2.0436 - val_acc: 0.2533\n",
      "Epoch 547/1000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 1.4657 - acc: 0.3986 - val_loss: 2.0516 - val_acc: 0.2400\n",
      "Epoch 548/1000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.4643 - acc: 0.3957 - val_loss: 2.0293 - val_acc: 0.2300\n",
      "Epoch 549/1000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.4646 - acc: 0.4057 - val_loss: 2.0262 - val_acc: 0.2333\n",
      "Epoch 550/1000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.4638 - acc: 0.4000 - val_loss: 2.0388 - val_acc: 0.2300\n",
      "Epoch 551/1000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.4646 - acc: 0.3986 - val_loss: 2.0365 - val_acc: 0.2300\n",
      "Epoch 552/1000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.4631 - acc: 0.4086 - val_loss: 2.0366 - val_acc: 0.2333\n",
      "Epoch 553/1000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.4654 - acc: 0.4000 - val_loss: 2.0342 - val_acc: 0.2300\n",
      "Epoch 554/1000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.4629 - acc: 0.4000 - val_loss: 2.0435 - val_acc: 0.2300\n",
      "Epoch 555/1000\n",
      "700/700 [==============================] - 0s 112us/step - loss: 1.4638 - acc: 0.4071 - val_loss: 2.0445 - val_acc: 0.2400\n",
      "Epoch 556/1000\n",
      "700/700 [==============================] - 0s 115us/step - loss: 1.4621 - acc: 0.4000 - val_loss: 2.0384 - val_acc: 0.2467\n",
      "Epoch 557/1000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.4614 - acc: 0.4100 - val_loss: 2.0554 - val_acc: 0.2500\n",
      "Epoch 558/1000\n",
      "700/700 [==============================] - 0s 122us/step - loss: 1.4631 - acc: 0.4057 - val_loss: 2.0378 - val_acc: 0.2300\n",
      "Epoch 559/1000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.4613 - acc: 0.4043 - val_loss: 2.0428 - val_acc: 0.2533\n",
      "Epoch 560/1000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.4612 - acc: 0.4014 - val_loss: 2.0444 - val_acc: 0.2567\n",
      "Epoch 561/1000\n",
      "700/700 [==============================] - 0s 108us/step - loss: 1.4623 - acc: 0.4057 - val_loss: 2.0386 - val_acc: 0.2267\n",
      "Epoch 562/1000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.4619 - acc: 0.4043 - val_loss: 2.0324 - val_acc: 0.2300\n",
      "Epoch 563/1000\n",
      "700/700 [==============================] - 0s 112us/step - loss: 1.4613 - acc: 0.4014 - val_loss: 2.0359 - val_acc: 0.2267\n",
      "Epoch 564/1000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.4610 - acc: 0.4086 - val_loss: 2.0521 - val_acc: 0.2300\n",
      "Epoch 565/1000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.4604 - acc: 0.4057 - val_loss: 2.0371 - val_acc: 0.2333\n",
      "Epoch 566/1000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.4619 - acc: 0.4100 - val_loss: 2.0528 - val_acc: 0.2300\n",
      "Epoch 567/1000\n",
      "700/700 [==============================] - 0s 108us/step - loss: 1.4599 - acc: 0.4186 - val_loss: 2.0458 - val_acc: 0.2333\n",
      "Epoch 568/1000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.4597 - acc: 0.4029 - val_loss: 2.0466 - val_acc: 0.2433\n",
      "Epoch 569/1000\n",
      "700/700 [==============================] - 0s 88us/step - loss: 1.4592 - acc: 0.4071 - val_loss: 2.0413 - val_acc: 0.2533\n",
      "Epoch 570/1000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.4588 - acc: 0.4114 - val_loss: 2.0499 - val_acc: 0.2333\n",
      "Epoch 571/1000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.4587 - acc: 0.4043 - val_loss: 2.0483 - val_acc: 0.2300\n",
      "Epoch 572/1000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 1.4580 - acc: 0.4000 - val_loss: 2.0400 - val_acc: 0.2333\n",
      "Epoch 573/1000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.4573 - acc: 0.4100 - val_loss: 2.0584 - val_acc: 0.2533\n",
      "Epoch 574/1000\n",
      "700/700 [==============================] - 0s 108us/step - loss: 1.4598 - acc: 0.4043 - val_loss: 2.0417 - val_acc: 0.2500\n",
      "Epoch 575/1000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.4598 - acc: 0.4114 - val_loss: 2.0442 - val_acc: 0.2300\n",
      "Epoch 576/1000\n",
      "700/700 [==============================] - 0s 108us/step - loss: 1.4585 - acc: 0.3971 - val_loss: 2.0449 - val_acc: 0.2333\n",
      "Epoch 577/1000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.4584 - acc: 0.4000 - val_loss: 2.0456 - val_acc: 0.2300\n",
      "Epoch 578/1000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 1.4578 - acc: 0.4043 - val_loss: 2.0452 - val_acc: 0.2367\n",
      "Epoch 579/1000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.4583 - acc: 0.4057 - val_loss: 2.0435 - val_acc: 0.2267\n",
      "Epoch 580/1000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.4573 - acc: 0.4071 - val_loss: 2.0557 - val_acc: 0.2367\n",
      "Epoch 581/1000\n",
      "700/700 [==============================] - 0s 112us/step - loss: 1.4571 - acc: 0.4057 - val_loss: 2.0497 - val_acc: 0.2567\n",
      "Epoch 582/1000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.4569 - acc: 0.4086 - val_loss: 2.0523 - val_acc: 0.2267\n",
      "Epoch 583/1000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.4564 - acc: 0.4014 - val_loss: 2.0515 - val_acc: 0.2267\n",
      "Epoch 584/1000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.4570 - acc: 0.4057 - val_loss: 2.0545 - val_acc: 0.2267\n",
      "Epoch 585/1000\n",
      "700/700 [==============================] - 0s 112us/step - loss: 1.4557 - acc: 0.4114 - val_loss: 2.0557 - val_acc: 0.2300\n",
      "Epoch 586/1000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.4549 - acc: 0.4029 - val_loss: 2.0552 - val_acc: 0.2500\n",
      "Epoch 587/1000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.4572 - acc: 0.4114 - val_loss: 2.0554 - val_acc: 0.2333\n",
      "Epoch 588/1000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.4560 - acc: 0.4071 - val_loss: 2.0578 - val_acc: 0.2300\n",
      "Epoch 589/1000\n",
      "700/700 [==============================] - 0s 98us/step - loss: 1.4552 - acc: 0.4057 - val_loss: 2.0573 - val_acc: 0.2267\n",
      "Epoch 590/1000\n",
      "700/700 [==============================] - 0s 87us/step - loss: 1.4553 - acc: 0.4000 - val_loss: 2.0518 - val_acc: 0.2267\n",
      "Epoch 591/1000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.4553 - acc: 0.4114 - val_loss: 2.0597 - val_acc: 0.2267\n",
      "Epoch 592/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 99us/step - loss: 1.4545 - acc: 0.4100 - val_loss: 2.0555 - val_acc: 0.2333\n",
      "Epoch 593/1000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 1.4545 - acc: 0.4071 - val_loss: 2.0495 - val_acc: 0.2267\n",
      "Epoch 594/1000\n",
      "700/700 [==============================] - 0s 108us/step - loss: 1.4539 - acc: 0.4157 - val_loss: 2.0520 - val_acc: 0.2333\n",
      "Epoch 595/1000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.4541 - acc: 0.4057 - val_loss: 2.0535 - val_acc: 0.2433\n",
      "Epoch 596/1000\n",
      "700/700 [==============================] - 0s 108us/step - loss: 1.4537 - acc: 0.4114 - val_loss: 2.0467 - val_acc: 0.2300\n",
      "Epoch 597/1000\n",
      "700/700 [==============================] - 0s 112us/step - loss: 1.4525 - acc: 0.4143 - val_loss: 2.0484 - val_acc: 0.2500\n",
      "Epoch 598/1000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.4537 - acc: 0.3943 - val_loss: 2.0533 - val_acc: 0.2267\n",
      "Epoch 599/1000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 1.4541 - acc: 0.4014 - val_loss: 2.0477 - val_acc: 0.2333\n",
      "Epoch 600/1000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.4525 - acc: 0.4143 - val_loss: 2.0621 - val_acc: 0.2300\n",
      "Epoch 601/1000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.4522 - acc: 0.4100 - val_loss: 2.0619 - val_acc: 0.2433\n",
      "Epoch 602/1000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.4525 - acc: 0.4043 - val_loss: 2.0582 - val_acc: 0.2333\n",
      "Epoch 603/1000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.4528 - acc: 0.4100 - val_loss: 2.0487 - val_acc: 0.2400\n",
      "Epoch 604/1000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.4526 - acc: 0.4043 - val_loss: 2.0475 - val_acc: 0.2400\n",
      "Epoch 605/1000\n",
      "700/700 [==============================] - 0s 124us/step - loss: 1.4515 - acc: 0.4071 - val_loss: 2.0539 - val_acc: 0.2367\n",
      "Epoch 606/1000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.4517 - acc: 0.4114 - val_loss: 2.0438 - val_acc: 0.2333\n",
      "Epoch 607/1000\n",
      "700/700 [==============================] - 0s 84us/step - loss: 1.4519 - acc: 0.4100 - val_loss: 2.0537 - val_acc: 0.2300\n",
      "Epoch 608/1000\n",
      "700/700 [==============================] - 0s 81us/step - loss: 1.4516 - acc: 0.4086 - val_loss: 2.0498 - val_acc: 0.2367\n",
      "Epoch 609/1000\n",
      "700/700 [==============================] - 0s 82us/step - loss: 1.4501 - acc: 0.4171 - val_loss: 2.0640 - val_acc: 0.2567\n",
      "Epoch 610/1000\n",
      "700/700 [==============================] - 0s 83us/step - loss: 1.4508 - acc: 0.4129 - val_loss: 2.0639 - val_acc: 0.2333\n",
      "Epoch 611/1000\n",
      "700/700 [==============================] - 0s 98us/step - loss: 1.4508 - acc: 0.4129 - val_loss: 2.0611 - val_acc: 0.2367\n",
      "Epoch 612/1000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.4506 - acc: 0.4086 - val_loss: 2.0592 - val_acc: 0.2433\n",
      "Epoch 613/1000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.4505 - acc: 0.4071 - val_loss: 2.0679 - val_acc: 0.2300\n",
      "Epoch 614/1000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.4494 - acc: 0.4129 - val_loss: 2.0691 - val_acc: 0.2500\n",
      "Epoch 615/1000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.4502 - acc: 0.4143 - val_loss: 2.0559 - val_acc: 0.2533\n",
      "Epoch 616/1000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.4494 - acc: 0.4129 - val_loss: 2.0734 - val_acc: 0.2333\n",
      "Epoch 617/1000\n",
      "700/700 [==============================] - 0s 108us/step - loss: 1.4481 - acc: 0.4157 - val_loss: 2.0652 - val_acc: 0.2533\n",
      "Epoch 618/1000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.4490 - acc: 0.4057 - val_loss: 2.0607 - val_acc: 0.2400\n",
      "Epoch 619/1000\n",
      "700/700 [==============================] - 0s 98us/step - loss: 1.4479 - acc: 0.4114 - val_loss: 2.0705 - val_acc: 0.2333\n",
      "Epoch 620/1000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.4485 - acc: 0.4157 - val_loss: 2.0572 - val_acc: 0.2300\n",
      "Epoch 621/1000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.4486 - acc: 0.4157 - val_loss: 2.0741 - val_acc: 0.2333\n",
      "Epoch 622/1000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.4477 - acc: 0.4114 - val_loss: 2.0715 - val_acc: 0.2367\n",
      "Epoch 623/1000\n",
      "700/700 [==============================] - 0s 115us/step - loss: 1.4471 - acc: 0.4186 - val_loss: 2.0689 - val_acc: 0.2300\n",
      "Epoch 624/1000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.4480 - acc: 0.4157 - val_loss: 2.0654 - val_acc: 0.2333\n",
      "Epoch 625/1000\n",
      "700/700 [==============================] - 0s 117us/step - loss: 1.4478 - acc: 0.4043 - val_loss: 2.0722 - val_acc: 0.2367\n",
      "Epoch 626/1000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.4471 - acc: 0.4114 - val_loss: 2.0538 - val_acc: 0.2367\n",
      "Epoch 627/1000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.4478 - acc: 0.4271 - val_loss: 2.0630 - val_acc: 0.2333\n",
      "Epoch 628/1000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.4458 - acc: 0.4143 - val_loss: 2.0498 - val_acc: 0.2400\n",
      "Epoch 629/1000\n",
      "700/700 [==============================] - 0s 112us/step - loss: 1.4475 - acc: 0.4114 - val_loss: 2.0616 - val_acc: 0.2333\n",
      "Epoch 630/1000\n",
      "700/700 [==============================] - 0s 120us/step - loss: 1.4460 - acc: 0.4100 - val_loss: 2.0541 - val_acc: 0.2333\n",
      "Epoch 631/1000\n",
      "700/700 [==============================] - 0s 112us/step - loss: 1.4468 - acc: 0.4129 - val_loss: 2.0813 - val_acc: 0.2400\n",
      "Epoch 632/1000\n",
      "700/700 [==============================] - 0s 119us/step - loss: 1.4467 - acc: 0.4086 - val_loss: 2.0747 - val_acc: 0.2400\n",
      "Epoch 633/1000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.4456 - acc: 0.4143 - val_loss: 2.0817 - val_acc: 0.2367\n",
      "Epoch 634/1000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.4457 - acc: 0.4143 - val_loss: 2.0705 - val_acc: 0.2333\n",
      "Epoch 635/1000\n",
      "700/700 [==============================] - 0s 112us/step - loss: 1.4444 - acc: 0.4071 - val_loss: 2.0647 - val_acc: 0.2567\n",
      "Epoch 636/1000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 1.4464 - acc: 0.4143 - val_loss: 2.0664 - val_acc: 0.2333\n",
      "Epoch 637/1000\n",
      "700/700 [==============================] - 0s 117us/step - loss: 1.4452 - acc: 0.4114 - val_loss: 2.0684 - val_acc: 0.2367\n",
      "Epoch 638/1000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.4452 - acc: 0.4129 - val_loss: 2.0814 - val_acc: 0.2300\n",
      "Epoch 639/1000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.4449 - acc: 0.4086 - val_loss: 2.0818 - val_acc: 0.2233\n",
      "Epoch 640/1000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.4440 - acc: 0.4171 - val_loss: 2.0580 - val_acc: 0.2367\n",
      "Epoch 641/1000\n",
      "700/700 [==============================] - 0s 118us/step - loss: 1.4438 - acc: 0.4157 - val_loss: 2.0744 - val_acc: 0.2467\n",
      "Epoch 642/1000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.4449 - acc: 0.4100 - val_loss: 2.0811 - val_acc: 0.2433\n",
      "Epoch 643/1000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.4439 - acc: 0.4129 - val_loss: 2.0847 - val_acc: 0.2300\n",
      "Epoch 644/1000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.4440 - acc: 0.4143 - val_loss: 2.0721 - val_acc: 0.2367\n",
      "Epoch 645/1000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 1.4432 - acc: 0.4186 - val_loss: 2.0795 - val_acc: 0.2333\n",
      "Epoch 646/1000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 1.4414 - acc: 0.4114 - val_loss: 2.0718 - val_acc: 0.2567\n",
      "Epoch 647/1000\n",
      "700/700 [==============================] - 0s 117us/step - loss: 1.4424 - acc: 0.4143 - val_loss: 2.0699 - val_acc: 0.2333\n",
      "Epoch 648/1000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 1.4431 - acc: 0.4100 - val_loss: 2.0856 - val_acc: 0.2333\n",
      "Epoch 649/1000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.4415 - acc: 0.4057 - val_loss: 2.0821 - val_acc: 0.2333\n",
      "Epoch 650/1000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.4432 - acc: 0.4143 - val_loss: 2.0745 - val_acc: 0.2333\n",
      "Epoch 651/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 102us/step - loss: 1.4419 - acc: 0.4143 - val_loss: 2.0895 - val_acc: 0.2400\n",
      "Epoch 652/1000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 1.4429 - acc: 0.4129 - val_loss: 2.0742 - val_acc: 0.2333\n",
      "Epoch 653/1000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.4417 - acc: 0.4171 - val_loss: 2.0778 - val_acc: 0.2467\n",
      "Epoch 654/1000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 1.4415 - acc: 0.4143 - val_loss: 2.0638 - val_acc: 0.2467\n",
      "Epoch 655/1000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.4406 - acc: 0.4114 - val_loss: 2.0744 - val_acc: 0.2533\n",
      "Epoch 656/1000\n",
      "700/700 [==============================] - 0s 108us/step - loss: 1.4426 - acc: 0.4086 - val_loss: 2.0880 - val_acc: 0.2433\n",
      "Epoch 657/1000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.4409 - acc: 0.4157 - val_loss: 2.0830 - val_acc: 0.2300\n",
      "Epoch 658/1000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.4410 - acc: 0.4129 - val_loss: 2.0788 - val_acc: 0.2300\n",
      "Epoch 659/1000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.4405 - acc: 0.4186 - val_loss: 2.0808 - val_acc: 0.2433\n",
      "Epoch 660/1000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.4409 - acc: 0.4100 - val_loss: 2.0812 - val_acc: 0.2367\n",
      "Epoch 661/1000\n",
      "700/700 [==============================] - 0s 115us/step - loss: 1.4418 - acc: 0.4100 - val_loss: 2.0760 - val_acc: 0.2333\n",
      "Epoch 662/1000\n",
      "700/700 [==============================] - 0s 98us/step - loss: 1.4409 - acc: 0.3986 - val_loss: 2.0818 - val_acc: 0.2367\n",
      "Epoch 663/1000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.4403 - acc: 0.4186 - val_loss: 2.0953 - val_acc: 0.2400\n",
      "Epoch 664/1000\n",
      "700/700 [==============================] - 0s 98us/step - loss: 1.4394 - acc: 0.4214 - val_loss: 2.0799 - val_acc: 0.2367\n",
      "Epoch 665/1000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.4395 - acc: 0.4157 - val_loss: 2.0883 - val_acc: 0.2333\n",
      "Epoch 666/1000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.4390 - acc: 0.4186 - val_loss: 2.0812 - val_acc: 0.2533\n",
      "Epoch 667/1000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.4405 - acc: 0.4114 - val_loss: 2.0753 - val_acc: 0.2367\n",
      "Epoch 668/1000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.4374 - acc: 0.4157 - val_loss: 2.0911 - val_acc: 0.2567\n",
      "Epoch 669/1000\n",
      "700/700 [==============================] - 0s 92us/step - loss: 1.4382 - acc: 0.4171 - val_loss: 2.0927 - val_acc: 0.2333\n",
      "Epoch 670/1000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.4393 - acc: 0.4157 - val_loss: 2.0812 - val_acc: 0.2367\n",
      "Epoch 671/1000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.4377 - acc: 0.4157 - val_loss: 2.0803 - val_acc: 0.2533\n",
      "Epoch 672/1000\n",
      "700/700 [==============================] - 0s 115us/step - loss: 1.4383 - acc: 0.4100 - val_loss: 2.0891 - val_acc: 0.2367\n",
      "Epoch 673/1000\n",
      "700/700 [==============================] - 0s 86us/step - loss: 1.4383 - acc: 0.4200 - val_loss: 2.0816 - val_acc: 0.2400\n",
      "Epoch 674/1000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.4374 - acc: 0.4114 - val_loss: 2.1037 - val_acc: 0.2433\n",
      "Epoch 675/1000\n",
      "700/700 [==============================] - 0s 112us/step - loss: 1.4366 - acc: 0.4214 - val_loss: 2.1025 - val_acc: 0.2533\n",
      "Epoch 676/1000\n",
      "700/700 [==============================] - 0s 108us/step - loss: 1.4368 - acc: 0.4186 - val_loss: 2.0745 - val_acc: 0.2567\n",
      "Epoch 677/1000\n",
      "700/700 [==============================] - 0s 82us/step - loss: 1.4360 - acc: 0.4143 - val_loss: 2.0977 - val_acc: 0.2300\n",
      "Epoch 678/1000\n",
      "700/700 [==============================] - 0s 88us/step - loss: 1.4355 - acc: 0.4229 - val_loss: 2.0718 - val_acc: 0.2333\n",
      "Epoch 679/1000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 1.4370 - acc: 0.4243 - val_loss: 2.0894 - val_acc: 0.2367\n",
      "Epoch 680/1000\n",
      "700/700 [==============================] - 0s 123us/step - loss: 1.4378 - acc: 0.4143 - val_loss: 2.0899 - val_acc: 0.2367\n",
      "Epoch 681/1000\n",
      "700/700 [==============================] - 0s 79us/step - loss: 1.4369 - acc: 0.4186 - val_loss: 2.0823 - val_acc: 0.2400\n",
      "Epoch 682/1000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.4360 - acc: 0.4229 - val_loss: 2.0870 - val_acc: 0.2567\n",
      "Epoch 683/1000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.4356 - acc: 0.4129 - val_loss: 2.0791 - val_acc: 0.2500\n",
      "Epoch 684/1000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.4330 - acc: 0.4143 - val_loss: 2.0901 - val_acc: 0.2600\n",
      "Epoch 685/1000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 1.4356 - acc: 0.4129 - val_loss: 2.0852 - val_acc: 0.2567\n",
      "Epoch 686/1000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.4352 - acc: 0.4186 - val_loss: 2.1073 - val_acc: 0.2533\n",
      "Epoch 687/1000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.4355 - acc: 0.4143 - val_loss: 2.0773 - val_acc: 0.2367\n",
      "Epoch 688/1000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.4355 - acc: 0.4171 - val_loss: 2.0838 - val_acc: 0.2400\n",
      "Epoch 689/1000\n",
      "700/700 [==============================] - 0s 108us/step - loss: 1.4348 - acc: 0.4200 - val_loss: 2.0932 - val_acc: 0.2367\n",
      "Epoch 690/1000\n",
      "700/700 [==============================] - 0s 120us/step - loss: 1.4344 - acc: 0.4143 - val_loss: 2.1001 - val_acc: 0.2300\n",
      "Epoch 691/1000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.4338 - acc: 0.4229 - val_loss: 2.0949 - val_acc: 0.2333\n",
      "Epoch 692/1000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.4339 - acc: 0.4186 - val_loss: 2.0872 - val_acc: 0.2400\n",
      "Epoch 693/1000\n",
      "700/700 [==============================] - 0s 116us/step - loss: 1.4347 - acc: 0.4129 - val_loss: 2.0835 - val_acc: 0.2400\n",
      "Epoch 694/1000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.4335 - acc: 0.4157 - val_loss: 2.1095 - val_acc: 0.2467\n",
      "Epoch 695/1000\n",
      "700/700 [==============================] - 0s 117us/step - loss: 1.4349 - acc: 0.4171 - val_loss: 2.0880 - val_acc: 0.2567\n",
      "Epoch 696/1000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.4323 - acc: 0.4214 - val_loss: 2.0994 - val_acc: 0.2333\n",
      "Epoch 697/1000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.4338 - acc: 0.4171 - val_loss: 2.1032 - val_acc: 0.2467\n",
      "Epoch 698/1000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.4333 - acc: 0.4257 - val_loss: 2.0940 - val_acc: 0.2433\n",
      "Epoch 699/1000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 1.4327 - acc: 0.4214 - val_loss: 2.1005 - val_acc: 0.2400\n",
      "Epoch 700/1000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.4329 - acc: 0.4200 - val_loss: 2.0954 - val_acc: 0.2467\n",
      "Epoch 701/1000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.4317 - acc: 0.4186 - val_loss: 2.0917 - val_acc: 0.2433\n",
      "Epoch 702/1000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.4327 - acc: 0.4129 - val_loss: 2.0979 - val_acc: 0.2367\n",
      "Epoch 703/1000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.4316 - acc: 0.4243 - val_loss: 2.1063 - val_acc: 0.2333\n",
      "Epoch 704/1000\n",
      "700/700 [==============================] - 0s 116us/step - loss: 1.4325 - acc: 0.4214 - val_loss: 2.0934 - val_acc: 0.2433\n",
      "Epoch 705/1000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.4320 - acc: 0.4157 - val_loss: 2.0873 - val_acc: 0.2400\n",
      "Epoch 706/1000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 1.4320 - acc: 0.4214 - val_loss: 2.0807 - val_acc: 0.2400\n",
      "Epoch 707/1000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.4315 - acc: 0.4243 - val_loss: 2.1027 - val_acc: 0.2367\n",
      "Epoch 708/1000\n",
      "700/700 [==============================] - 0s 98us/step - loss: 1.4315 - acc: 0.4214 - val_loss: 2.0936 - val_acc: 0.2333\n",
      "Epoch 709/1000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.4296 - acc: 0.4214 - val_loss: 2.1147 - val_acc: 0.2533\n",
      "Epoch 710/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 106us/step - loss: 1.4315 - acc: 0.4229 - val_loss: 2.0948 - val_acc: 0.2467\n",
      "Epoch 711/1000\n",
      "700/700 [==============================] - 0s 112us/step - loss: 1.4304 - acc: 0.4200 - val_loss: 2.0956 - val_acc: 0.2367\n",
      "Epoch 712/1000\n",
      "700/700 [==============================] - 0s 112us/step - loss: 1.4300 - acc: 0.4214 - val_loss: 2.1029 - val_acc: 0.2567\n",
      "Epoch 713/1000\n",
      "700/700 [==============================] - 0s 127us/step - loss: 1.4311 - acc: 0.4171 - val_loss: 2.0854 - val_acc: 0.2400\n",
      "Epoch 714/1000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.4305 - acc: 0.4243 - val_loss: 2.0969 - val_acc: 0.2367\n",
      "Epoch 715/1000\n",
      "700/700 [==============================] - 0s 115us/step - loss: 1.4282 - acc: 0.4257 - val_loss: 2.0853 - val_acc: 0.2567\n",
      "Epoch 716/1000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.4304 - acc: 0.4157 - val_loss: 2.1047 - val_acc: 0.2367\n",
      "Epoch 717/1000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 1.4298 - acc: 0.4171 - val_loss: 2.1006 - val_acc: 0.2367\n",
      "Epoch 718/1000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.4290 - acc: 0.4186 - val_loss: 2.1241 - val_acc: 0.2533\n",
      "Epoch 719/1000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.4301 - acc: 0.4171 - val_loss: 2.1159 - val_acc: 0.2400\n",
      "Epoch 720/1000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.4297 - acc: 0.4200 - val_loss: 2.1034 - val_acc: 0.2367\n",
      "Epoch 721/1000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.4290 - acc: 0.4186 - val_loss: 2.1025 - val_acc: 0.2433\n",
      "Epoch 722/1000\n",
      "700/700 [==============================] - 0s 80us/step - loss: 1.4287 - acc: 0.4186 - val_loss: 2.1022 - val_acc: 0.2367\n",
      "Epoch 723/1000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.4283 - acc: 0.4214 - val_loss: 2.0939 - val_acc: 0.2400\n",
      "Epoch 724/1000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.4282 - acc: 0.4229 - val_loss: 2.1099 - val_acc: 0.2367\n",
      "Epoch 725/1000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.4278 - acc: 0.4243 - val_loss: 2.1164 - val_acc: 0.2433\n",
      "Epoch 726/1000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.4277 - acc: 0.4271 - val_loss: 2.1036 - val_acc: 0.2333\n",
      "Epoch 727/1000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.4274 - acc: 0.4243 - val_loss: 2.1275 - val_acc: 0.2333\n",
      "Epoch 728/1000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.4275 - acc: 0.4229 - val_loss: 2.0942 - val_acc: 0.2433\n",
      "Epoch 729/1000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.4270 - acc: 0.4214 - val_loss: 2.1181 - val_acc: 0.2467\n",
      "Epoch 730/1000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.4270 - acc: 0.4257 - val_loss: 2.1239 - val_acc: 0.2367\n",
      "Epoch 731/1000\n",
      "700/700 [==============================] - 0s 86us/step - loss: 1.4276 - acc: 0.4143 - val_loss: 2.1097 - val_acc: 0.2367\n",
      "Epoch 732/1000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.4261 - acc: 0.4243 - val_loss: 2.1077 - val_acc: 0.2400\n",
      "Epoch 733/1000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.4264 - acc: 0.4286 - val_loss: 2.1087 - val_acc: 0.2333\n",
      "Epoch 734/1000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.4274 - acc: 0.4214 - val_loss: 2.1136 - val_acc: 0.2400\n",
      "Epoch 735/1000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.4260 - acc: 0.4300 - val_loss: 2.1097 - val_acc: 0.2367\n",
      "Epoch 736/1000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 1.4250 - acc: 0.4271 - val_loss: 2.1016 - val_acc: 0.2400\n",
      "Epoch 737/1000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.4264 - acc: 0.4214 - val_loss: 2.1195 - val_acc: 0.2433\n",
      "Epoch 738/1000\n",
      "700/700 [==============================] - 0s 117us/step - loss: 1.4265 - acc: 0.4214 - val_loss: 2.1078 - val_acc: 0.2433\n",
      "Epoch 739/1000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.4251 - acc: 0.4271 - val_loss: 2.1173 - val_acc: 0.2367\n",
      "Epoch 740/1000\n",
      "700/700 [==============================] - 0s 78us/step - loss: 1.4250 - acc: 0.4271 - val_loss: 2.1052 - val_acc: 0.2400\n",
      "Epoch 741/1000\n",
      "700/700 [==============================] - 0s 83us/step - loss: 1.4248 - acc: 0.4200 - val_loss: 2.1189 - val_acc: 0.2567\n",
      "Epoch 742/1000\n",
      "700/700 [==============================] - 0s 117us/step - loss: 1.4253 - acc: 0.4171 - val_loss: 2.1010 - val_acc: 0.2533\n",
      "Epoch 743/1000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.4240 - acc: 0.4286 - val_loss: 2.1043 - val_acc: 0.2533\n",
      "Epoch 744/1000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.4257 - acc: 0.4186 - val_loss: 2.1048 - val_acc: 0.2433\n",
      "Epoch 745/1000\n",
      "700/700 [==============================] - 0s 119us/step - loss: 1.4221 - acc: 0.4329 - val_loss: 2.1159 - val_acc: 0.2533\n",
      "Epoch 746/1000\n",
      "700/700 [==============================] - 0s 116us/step - loss: 1.4254 - acc: 0.4300 - val_loss: 2.1064 - val_acc: 0.2400\n",
      "Epoch 747/1000\n",
      "700/700 [==============================] - 0s 112us/step - loss: 1.4251 - acc: 0.4171 - val_loss: 2.1118 - val_acc: 0.2433\n",
      "Epoch 748/1000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.4233 - acc: 0.4257 - val_loss: 2.1289 - val_acc: 0.2600\n",
      "Epoch 749/1000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.4222 - acc: 0.4271 - val_loss: 2.0958 - val_acc: 0.2333\n",
      "Epoch 750/1000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.4240 - acc: 0.4329 - val_loss: 2.1025 - val_acc: 0.2333\n",
      "Epoch 751/1000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.4224 - acc: 0.4157 - val_loss: 2.1131 - val_acc: 0.2400\n",
      "Epoch 752/1000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.4235 - acc: 0.4257 - val_loss: 2.1184 - val_acc: 0.2367\n",
      "Epoch 753/1000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.4222 - acc: 0.4243 - val_loss: 2.1361 - val_acc: 0.2333\n",
      "Epoch 754/1000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.4236 - acc: 0.4257 - val_loss: 2.1187 - val_acc: 0.2333\n",
      "Epoch 755/1000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.4221 - acc: 0.4386 - val_loss: 2.1168 - val_acc: 0.2467\n",
      "Epoch 756/1000\n",
      "700/700 [==============================] - 0s 112us/step - loss: 1.4223 - acc: 0.4143 - val_loss: 2.1146 - val_acc: 0.2400\n",
      "Epoch 757/1000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.4231 - acc: 0.4214 - val_loss: 2.1242 - val_acc: 0.2433\n",
      "Epoch 758/1000\n",
      "700/700 [==============================] - 0s 98us/step - loss: 1.4221 - acc: 0.4300 - val_loss: 2.1189 - val_acc: 0.2433\n",
      "Epoch 759/1000\n",
      "700/700 [==============================] - 0s 115us/step - loss: 1.4222 - acc: 0.4286 - val_loss: 2.1160 - val_acc: 0.2400\n",
      "Epoch 760/1000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.4219 - acc: 0.4357 - val_loss: 2.1128 - val_acc: 0.2400\n",
      "Epoch 761/1000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 1.4215 - acc: 0.4243 - val_loss: 2.1351 - val_acc: 0.2500\n",
      "Epoch 762/1000\n",
      "700/700 [==============================] - 0s 115us/step - loss: 1.4225 - acc: 0.4286 - val_loss: 2.1276 - val_acc: 0.2400\n",
      "Epoch 763/1000\n",
      "700/700 [==============================] - 0s 118us/step - loss: 1.4216 - acc: 0.4186 - val_loss: 2.1154 - val_acc: 0.2400\n",
      "Epoch 764/1000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.4224 - acc: 0.4300 - val_loss: 2.1308 - val_acc: 0.2433\n",
      "Epoch 765/1000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.4203 - acc: 0.4171 - val_loss: 2.1419 - val_acc: 0.2333\n",
      "Epoch 766/1000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 1.4217 - acc: 0.4200 - val_loss: 2.1156 - val_acc: 0.2400\n",
      "Epoch 767/1000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.4217 - acc: 0.4257 - val_loss: 2.1165 - val_acc: 0.2367\n",
      "Epoch 768/1000\n",
      "700/700 [==============================] - 0s 112us/step - loss: 1.4204 - acc: 0.4271 - val_loss: 2.1061 - val_acc: 0.2400\n",
      "Epoch 769/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 117us/step - loss: 1.4206 - acc: 0.4229 - val_loss: 2.1187 - val_acc: 0.2367\n",
      "Epoch 770/1000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 1.4201 - acc: 0.4243 - val_loss: 2.1088 - val_acc: 0.2333\n",
      "Epoch 771/1000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.4196 - acc: 0.4229 - val_loss: 2.1224 - val_acc: 0.2367\n",
      "Epoch 772/1000\n",
      "700/700 [==============================] - 0s 80us/step - loss: 1.4202 - acc: 0.4257 - val_loss: 2.1259 - val_acc: 0.2433\n",
      "Epoch 773/1000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.4201 - acc: 0.4229 - val_loss: 2.1318 - val_acc: 0.2500\n",
      "Epoch 774/1000\n",
      "700/700 [==============================] - 0s 117us/step - loss: 1.4191 - acc: 0.4243 - val_loss: 2.1289 - val_acc: 0.2400\n",
      "Epoch 775/1000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.4182 - acc: 0.4286 - val_loss: 2.1297 - val_acc: 0.2533\n",
      "Epoch 776/1000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.4193 - acc: 0.4271 - val_loss: 2.1198 - val_acc: 0.2467\n",
      "Epoch 777/1000\n",
      "700/700 [==============================] - 0s 116us/step - loss: 1.4179 - acc: 0.4300 - val_loss: 2.1356 - val_acc: 0.2333\n",
      "Epoch 778/1000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.4191 - acc: 0.4200 - val_loss: 2.1267 - val_acc: 0.2333\n",
      "Epoch 779/1000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.4193 - acc: 0.4271 - val_loss: 2.1263 - val_acc: 0.2333\n",
      "Epoch 780/1000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.4188 - acc: 0.4257 - val_loss: 2.1174 - val_acc: 0.2400\n",
      "Epoch 781/1000\n",
      "700/700 [==============================] - 0s 118us/step - loss: 1.4196 - acc: 0.4200 - val_loss: 2.1248 - val_acc: 0.2467\n",
      "Epoch 782/1000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.4184 - acc: 0.4243 - val_loss: 2.1065 - val_acc: 0.2400\n",
      "Epoch 783/1000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.4186 - acc: 0.4329 - val_loss: 2.1302 - val_acc: 0.2433\n",
      "Epoch 784/1000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.4181 - acc: 0.4300 - val_loss: 2.1345 - val_acc: 0.2400\n",
      "Epoch 785/1000\n",
      "700/700 [==============================] - 0s 108us/step - loss: 1.4179 - acc: 0.4271 - val_loss: 2.1422 - val_acc: 0.2400\n",
      "Epoch 786/1000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.4180 - acc: 0.4257 - val_loss: 2.1254 - val_acc: 0.2467\n",
      "Epoch 787/1000\n",
      "700/700 [==============================] - 0s 83us/step - loss: 1.4185 - acc: 0.4243 - val_loss: 2.1142 - val_acc: 0.2500\n",
      "Epoch 788/1000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.4178 - acc: 0.4271 - val_loss: 2.1252 - val_acc: 0.2400\n",
      "Epoch 789/1000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.4173 - acc: 0.4229 - val_loss: 2.1261 - val_acc: 0.2400\n",
      "Epoch 790/1000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 1.4174 - acc: 0.4314 - val_loss: 2.1288 - val_acc: 0.2400\n",
      "Epoch 791/1000\n",
      "700/700 [==============================] - 0s 117us/step - loss: 1.4164 - acc: 0.4286 - val_loss: 2.1293 - val_acc: 0.2533\n",
      "Epoch 792/1000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.4171 - acc: 0.4214 - val_loss: 2.1203 - val_acc: 0.2367\n",
      "Epoch 793/1000\n",
      "700/700 [==============================] - 0s 118us/step - loss: 1.4165 - acc: 0.4257 - val_loss: 2.1363 - val_acc: 0.2467\n",
      "Epoch 794/1000\n",
      "700/700 [==============================] - 0s 108us/step - loss: 1.4168 - acc: 0.4286 - val_loss: 2.1316 - val_acc: 0.2367\n",
      "Epoch 795/1000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 1.4165 - acc: 0.4329 - val_loss: 2.1284 - val_acc: 0.2400\n",
      "Epoch 796/1000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.4160 - acc: 0.4314 - val_loss: 2.1292 - val_acc: 0.2367\n",
      "Epoch 797/1000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.4164 - acc: 0.4200 - val_loss: 2.1359 - val_acc: 0.2367\n",
      "Epoch 798/1000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.4162 - acc: 0.4371 - val_loss: 2.1364 - val_acc: 0.2400\n",
      "Epoch 799/1000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.4152 - acc: 0.4329 - val_loss: 2.1290 - val_acc: 0.2567\n",
      "Epoch 800/1000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.4158 - acc: 0.4200 - val_loss: 2.1394 - val_acc: 0.2333\n",
      "Epoch 801/1000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.4159 - acc: 0.4343 - val_loss: 2.1354 - val_acc: 0.2333\n",
      "Epoch 802/1000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.4158 - acc: 0.4343 - val_loss: 2.1725 - val_acc: 0.2400\n",
      "Epoch 803/1000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 1.4146 - acc: 0.4271 - val_loss: 2.1341 - val_acc: 0.2600\n",
      "Epoch 804/1000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.4148 - acc: 0.4243 - val_loss: 2.1275 - val_acc: 0.2433\n",
      "Epoch 805/1000\n",
      "700/700 [==============================] - 0s 119us/step - loss: 1.4143 - acc: 0.4329 - val_loss: 2.1287 - val_acc: 0.2467\n",
      "Epoch 806/1000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.4148 - acc: 0.4357 - val_loss: 2.1284 - val_acc: 0.2400\n",
      "Epoch 807/1000\n",
      "700/700 [==============================] - 0s 115us/step - loss: 1.4148 - acc: 0.4371 - val_loss: 2.1342 - val_acc: 0.2500\n",
      "Epoch 808/1000\n",
      "700/700 [==============================] - 0s 98us/step - loss: 1.4143 - acc: 0.4329 - val_loss: 2.1348 - val_acc: 0.2400\n",
      "Epoch 809/1000\n",
      "700/700 [==============================] - 0s 108us/step - loss: 1.4150 - acc: 0.4229 - val_loss: 2.1406 - val_acc: 0.2467\n",
      "Epoch 810/1000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.4139 - acc: 0.4343 - val_loss: 2.1416 - val_acc: 0.2433\n",
      "Epoch 811/1000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.4142 - acc: 0.4314 - val_loss: 2.1364 - val_acc: 0.2433\n",
      "Epoch 812/1000\n",
      "700/700 [==============================] - 0s 115us/step - loss: 1.4141 - acc: 0.4257 - val_loss: 2.1273 - val_acc: 0.2400\n",
      "Epoch 813/1000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.4139 - acc: 0.4329 - val_loss: 2.1424 - val_acc: 0.2367\n",
      "Epoch 814/1000\n",
      "700/700 [==============================] - 0s 122us/step - loss: 1.4130 - acc: 0.4286 - val_loss: 2.1359 - val_acc: 0.2533\n",
      "Epoch 815/1000\n",
      "700/700 [==============================] - 0s 119us/step - loss: 1.4139 - acc: 0.4286 - val_loss: 2.1407 - val_acc: 0.2467\n",
      "Epoch 816/1000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.4135 - acc: 0.4286 - val_loss: 2.1302 - val_acc: 0.2367\n",
      "Epoch 817/1000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.4118 - acc: 0.4243 - val_loss: 2.1350 - val_acc: 0.2367\n",
      "Epoch 818/1000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.4123 - acc: 0.4286 - val_loss: 2.1434 - val_acc: 0.2367\n",
      "Epoch 819/1000\n",
      "700/700 [==============================] - 0s 108us/step - loss: 1.4108 - acc: 0.4386 - val_loss: 2.1551 - val_acc: 0.2600\n",
      "Epoch 820/1000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.4132 - acc: 0.4343 - val_loss: 2.1405 - val_acc: 0.2567\n",
      "Epoch 821/1000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.4129 - acc: 0.4300 - val_loss: 2.1480 - val_acc: 0.2467\n",
      "Epoch 822/1000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.4130 - acc: 0.4329 - val_loss: 2.1389 - val_acc: 0.2367\n",
      "Epoch 823/1000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.4114 - acc: 0.4243 - val_loss: 2.1445 - val_acc: 0.2433\n",
      "Epoch 824/1000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.4108 - acc: 0.4286 - val_loss: 2.1443 - val_acc: 0.2433\n",
      "Epoch 825/1000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.4113 - acc: 0.4314 - val_loss: 2.1571 - val_acc: 0.2467\n",
      "Epoch 826/1000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.4122 - acc: 0.4243 - val_loss: 2.1486 - val_acc: 0.2467\n",
      "Epoch 827/1000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.4112 - acc: 0.4300 - val_loss: 2.1485 - val_acc: 0.2400\n",
      "Epoch 828/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 110us/step - loss: 1.4117 - acc: 0.4343 - val_loss: 2.1377 - val_acc: 0.2367\n",
      "Epoch 829/1000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.4111 - acc: 0.4357 - val_loss: 2.1408 - val_acc: 0.2433\n",
      "Epoch 830/1000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.4104 - acc: 0.4271 - val_loss: 2.1459 - val_acc: 0.2400\n",
      "Epoch 831/1000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.4104 - acc: 0.4443 - val_loss: 2.1584 - val_acc: 0.2467\n",
      "Epoch 832/1000\n",
      "700/700 [==============================] - 0s 84us/step - loss: 1.4111 - acc: 0.4329 - val_loss: 2.1612 - val_acc: 0.2500\n",
      "Epoch 833/1000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 1.4110 - acc: 0.4257 - val_loss: 2.1642 - val_acc: 0.2467\n",
      "Epoch 834/1000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.4107 - acc: 0.4329 - val_loss: 2.1742 - val_acc: 0.2433\n",
      "Epoch 835/1000\n",
      "700/700 [==============================] - 0s 88us/step - loss: 1.4095 - acc: 0.4300 - val_loss: 2.1435 - val_acc: 0.2367\n",
      "Epoch 836/1000\n",
      "700/700 [==============================] - 0s 121us/step - loss: 1.4098 - acc: 0.4286 - val_loss: 2.1515 - val_acc: 0.2500\n",
      "Epoch 837/1000\n",
      "700/700 [==============================] - 0s 119us/step - loss: 1.4102 - acc: 0.4300 - val_loss: 2.1378 - val_acc: 0.2433\n",
      "Epoch 838/1000\n",
      "700/700 [==============================] - 0s 117us/step - loss: 1.4107 - acc: 0.4286 - val_loss: 2.1495 - val_acc: 0.2367\n",
      "Epoch 839/1000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.4086 - acc: 0.4271 - val_loss: 2.1482 - val_acc: 0.2367\n",
      "Epoch 840/1000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.4081 - acc: 0.4371 - val_loss: 2.1414 - val_acc: 0.2433\n",
      "Epoch 841/1000\n",
      "700/700 [==============================] - 0s 122us/step - loss: 1.4093 - acc: 0.4371 - val_loss: 2.1458 - val_acc: 0.2367\n",
      "Epoch 842/1000\n",
      "700/700 [==============================] - 0s 108us/step - loss: 1.4098 - acc: 0.4286 - val_loss: 2.1582 - val_acc: 0.2500\n",
      "Epoch 843/1000\n",
      "700/700 [==============================] - 0s 108us/step - loss: 1.4090 - acc: 0.4286 - val_loss: 2.1471 - val_acc: 0.2367\n",
      "Epoch 844/1000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.4082 - acc: 0.4300 - val_loss: 2.1614 - val_acc: 0.2367\n",
      "Epoch 845/1000\n",
      "700/700 [==============================] - 0s 92us/step - loss: 1.4084 - acc: 0.4329 - val_loss: 2.1431 - val_acc: 0.2367\n",
      "Epoch 846/1000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.4093 - acc: 0.4343 - val_loss: 2.1487 - val_acc: 0.2400\n",
      "Epoch 847/1000\n",
      "700/700 [==============================] - 0s 116us/step - loss: 1.4074 - acc: 0.4243 - val_loss: 2.1541 - val_acc: 0.2433\n",
      "Epoch 848/1000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.4079 - acc: 0.4371 - val_loss: 2.1534 - val_acc: 0.2500\n",
      "Epoch 849/1000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.4085 - acc: 0.4300 - val_loss: 2.1563 - val_acc: 0.2433\n",
      "Epoch 850/1000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.4070 - acc: 0.4300 - val_loss: 2.1477 - val_acc: 0.2367\n",
      "Epoch 851/1000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.4071 - acc: 0.4214 - val_loss: 2.1473 - val_acc: 0.2367\n",
      "Epoch 852/1000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.4086 - acc: 0.4357 - val_loss: 2.1504 - val_acc: 0.2467\n",
      "Epoch 853/1000\n",
      "700/700 [==============================] - 0s 112us/step - loss: 1.4066 - acc: 0.4314 - val_loss: 2.1499 - val_acc: 0.2367\n",
      "Epoch 854/1000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.4047 - acc: 0.4357 - val_loss: 2.1749 - val_acc: 0.2600\n",
      "Epoch 855/1000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 1.4073 - acc: 0.4229 - val_loss: 2.1523 - val_acc: 0.2333\n",
      "Epoch 856/1000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.4075 - acc: 0.4357 - val_loss: 2.1666 - val_acc: 0.2467\n",
      "Epoch 857/1000\n",
      "700/700 [==============================] - 0s 112us/step - loss: 1.4070 - acc: 0.4343 - val_loss: 2.1626 - val_acc: 0.2500\n",
      "Epoch 858/1000\n",
      "700/700 [==============================] - 0s 108us/step - loss: 1.4069 - acc: 0.4329 - val_loss: 2.1538 - val_acc: 0.2367\n",
      "Epoch 859/1000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.4051 - acc: 0.4371 - val_loss: 2.1549 - val_acc: 0.2367\n",
      "Epoch 860/1000\n",
      "700/700 [==============================] - 0s 119us/step - loss: 1.4056 - acc: 0.4329 - val_loss: 2.1789 - val_acc: 0.2533\n",
      "Epoch 861/1000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.4064 - acc: 0.4371 - val_loss: 2.1643 - val_acc: 0.2433\n",
      "Epoch 862/1000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 1.4072 - acc: 0.4286 - val_loss: 2.1663 - val_acc: 0.2533\n",
      "Epoch 863/1000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.4054 - acc: 0.4329 - val_loss: 2.1680 - val_acc: 0.2533\n",
      "Epoch 864/1000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 1.4054 - acc: 0.4329 - val_loss: 2.1624 - val_acc: 0.2567\n",
      "Epoch 865/1000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.4045 - acc: 0.4371 - val_loss: 2.1698 - val_acc: 0.2633\n",
      "Epoch 866/1000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 1.4049 - acc: 0.4343 - val_loss: 2.1373 - val_acc: 0.2433\n",
      "Epoch 867/1000\n",
      "700/700 [==============================] - 0s 117us/step - loss: 1.4052 - acc: 0.4357 - val_loss: 2.1684 - val_acc: 0.2433\n",
      "Epoch 868/1000\n",
      "700/700 [==============================] - 0s 98us/step - loss: 1.4056 - acc: 0.4357 - val_loss: 2.1567 - val_acc: 0.2400\n",
      "Epoch 869/1000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.4049 - acc: 0.4400 - val_loss: 2.1571 - val_acc: 0.2400\n",
      "Epoch 870/1000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.4034 - acc: 0.4357 - val_loss: 2.1711 - val_acc: 0.2467\n",
      "Epoch 871/1000\n",
      "700/700 [==============================] - 0s 112us/step - loss: 1.4048 - acc: 0.4271 - val_loss: 2.1760 - val_acc: 0.2467\n",
      "Epoch 872/1000\n",
      "700/700 [==============================] - 0s 124us/step - loss: 1.4038 - acc: 0.4343 - val_loss: 2.1605 - val_acc: 0.2567\n",
      "Epoch 873/1000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.4044 - acc: 0.4314 - val_loss: 2.1414 - val_acc: 0.2367\n",
      "Epoch 874/1000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.4048 - acc: 0.4329 - val_loss: 2.1527 - val_acc: 0.2367\n",
      "Epoch 875/1000\n",
      "700/700 [==============================] - 0s 108us/step - loss: 1.4038 - acc: 0.4343 - val_loss: 2.1740 - val_acc: 0.2467\n",
      "Epoch 876/1000\n",
      "700/700 [==============================] - 0s 124us/step - loss: 1.4036 - acc: 0.4357 - val_loss: 2.1516 - val_acc: 0.2433\n",
      "Epoch 877/1000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.4035 - acc: 0.4257 - val_loss: 2.1731 - val_acc: 0.2333\n",
      "Epoch 878/1000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.4043 - acc: 0.4300 - val_loss: 2.1687 - val_acc: 0.2400\n",
      "Epoch 879/1000\n",
      "700/700 [==============================] - 0s 121us/step - loss: 1.4013 - acc: 0.4357 - val_loss: 2.1694 - val_acc: 0.2400\n",
      "Epoch 880/1000\n",
      "700/700 [==============================] - 0s 112us/step - loss: 1.4052 - acc: 0.4329 - val_loss: 2.1567 - val_acc: 0.2400\n",
      "Epoch 881/1000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.4033 - acc: 0.4414 - val_loss: 2.1842 - val_acc: 0.2500\n",
      "Epoch 882/1000\n",
      "700/700 [==============================] - 0s 108us/step - loss: 1.4036 - acc: 0.4371 - val_loss: 2.1707 - val_acc: 0.2433\n",
      "Epoch 883/1000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.4043 - acc: 0.4271 - val_loss: 2.1492 - val_acc: 0.2367\n",
      "Epoch 884/1000\n",
      "700/700 [==============================] - 0s 120us/step - loss: 1.4029 - acc: 0.4329 - val_loss: 2.1787 - val_acc: 0.2533\n",
      "Epoch 885/1000\n",
      "700/700 [==============================] - 0s 115us/step - loss: 1.4030 - acc: 0.4329 - val_loss: 2.1438 - val_acc: 0.2433\n",
      "Epoch 886/1000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.4034 - acc: 0.4386 - val_loss: 2.1672 - val_acc: 0.2433\n",
      "Epoch 887/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 105us/step - loss: 1.4028 - acc: 0.4371 - val_loss: 2.1604 - val_acc: 0.2400\n",
      "Epoch 888/1000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.4028 - acc: 0.4329 - val_loss: 2.1644 - val_acc: 0.2400\n",
      "Epoch 889/1000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.4010 - acc: 0.4414 - val_loss: 2.1803 - val_acc: 0.2600\n",
      "Epoch 890/1000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.4027 - acc: 0.4386 - val_loss: 2.1671 - val_acc: 0.2567\n",
      "Epoch 891/1000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 1.4024 - acc: 0.4286 - val_loss: 2.1701 - val_acc: 0.2433\n",
      "Epoch 892/1000\n",
      "700/700 [==============================] - 0s 117us/step - loss: 1.4025 - acc: 0.4357 - val_loss: 2.1730 - val_acc: 0.2433\n",
      "Epoch 893/1000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.4018 - acc: 0.4371 - val_loss: 2.1794 - val_acc: 0.2467\n",
      "Epoch 894/1000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.4020 - acc: 0.4414 - val_loss: 2.1660 - val_acc: 0.2400\n",
      "Epoch 895/1000\n",
      "700/700 [==============================] - 0s 118us/step - loss: 1.4013 - acc: 0.4357 - val_loss: 2.1755 - val_acc: 0.2467\n",
      "Epoch 896/1000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.4013 - acc: 0.4343 - val_loss: 2.1731 - val_acc: 0.2600\n",
      "Epoch 897/1000\n",
      "700/700 [==============================] - 0s 122us/step - loss: 1.4018 - acc: 0.4357 - val_loss: 2.1683 - val_acc: 0.2533\n",
      "Epoch 898/1000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.4011 - acc: 0.4400 - val_loss: 2.1742 - val_acc: 0.2433\n",
      "Epoch 899/1000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.4013 - acc: 0.4343 - val_loss: 2.1647 - val_acc: 0.2467\n",
      "Epoch 900/1000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.4001 - acc: 0.4486 - val_loss: 2.1649 - val_acc: 0.2467\n",
      "Epoch 901/1000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.3999 - acc: 0.4386 - val_loss: 2.1774 - val_acc: 0.2533\n",
      "Epoch 902/1000\n",
      "700/700 [==============================] - 0s 115us/step - loss: 1.4003 - acc: 0.4357 - val_loss: 2.1739 - val_acc: 0.2467\n",
      "Epoch 903/1000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.3993 - acc: 0.4414 - val_loss: 2.1812 - val_acc: 0.2567\n",
      "Epoch 904/1000\n",
      "700/700 [==============================] - 0s 117us/step - loss: 1.3989 - acc: 0.4386 - val_loss: 2.1639 - val_acc: 0.2400\n",
      "Epoch 905/1000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.4009 - acc: 0.4414 - val_loss: 2.1596 - val_acc: 0.2367\n",
      "Epoch 906/1000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 1.3999 - acc: 0.4357 - val_loss: 2.1557 - val_acc: 0.2367\n",
      "Epoch 907/1000\n",
      "700/700 [==============================] - 0s 112us/step - loss: 1.4004 - acc: 0.4386 - val_loss: 2.1803 - val_acc: 0.2433\n",
      "Epoch 908/1000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.3997 - acc: 0.4414 - val_loss: 2.1692 - val_acc: 0.2400\n",
      "Epoch 909/1000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.3994 - acc: 0.4343 - val_loss: 2.1762 - val_acc: 0.2500\n",
      "Epoch 910/1000\n",
      "700/700 [==============================] - 0s 118us/step - loss: 1.4003 - acc: 0.4357 - val_loss: 2.1610 - val_acc: 0.2400\n",
      "Epoch 911/1000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.3991 - acc: 0.4386 - val_loss: 2.1788 - val_acc: 0.2367\n",
      "Epoch 912/1000\n",
      "700/700 [==============================] - 0s 108us/step - loss: 1.3995 - acc: 0.4414 - val_loss: 2.1682 - val_acc: 0.2367\n",
      "Epoch 913/1000\n",
      "700/700 [==============================] - 0s 108us/step - loss: 1.4000 - acc: 0.4386 - val_loss: 2.1881 - val_acc: 0.2433\n",
      "Epoch 914/1000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.3983 - acc: 0.4400 - val_loss: 2.1835 - val_acc: 0.2567\n",
      "Epoch 915/1000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.3989 - acc: 0.4314 - val_loss: 2.1628 - val_acc: 0.2433\n",
      "Epoch 916/1000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.3989 - acc: 0.4386 - val_loss: 2.1808 - val_acc: 0.2433\n",
      "Epoch 917/1000\n",
      "700/700 [==============================] - 0s 92us/step - loss: 1.3978 - acc: 0.4400 - val_loss: 2.1785 - val_acc: 0.2400\n",
      "Epoch 918/1000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.3971 - acc: 0.4371 - val_loss: 2.1786 - val_acc: 0.2533\n",
      "Epoch 919/1000\n",
      "700/700 [==============================] - 0s 75us/step - loss: 1.3985 - acc: 0.4329 - val_loss: 2.1871 - val_acc: 0.2433\n",
      "Epoch 920/1000\n",
      "700/700 [==============================] - 0s 81us/step - loss: 1.3988 - acc: 0.4329 - val_loss: 2.1695 - val_acc: 0.2500\n",
      "Epoch 921/1000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.3984 - acc: 0.4386 - val_loss: 2.1699 - val_acc: 0.2400\n",
      "Epoch 922/1000\n",
      "700/700 [==============================] - 0s 98us/step - loss: 1.3967 - acc: 0.4400 - val_loss: 2.1862 - val_acc: 0.2500\n",
      "Epoch 923/1000\n",
      "700/700 [==============================] - 0s 75us/step - loss: 1.3965 - acc: 0.4400 - val_loss: 2.1703 - val_acc: 0.2533\n",
      "Epoch 924/1000\n",
      "700/700 [==============================] - 0s 78us/step - loss: 1.3987 - acc: 0.4386 - val_loss: 2.1771 - val_acc: 0.2467\n",
      "Epoch 925/1000\n",
      "700/700 [==============================] - 0s 80us/step - loss: 1.3970 - acc: 0.4343 - val_loss: 2.1817 - val_acc: 0.2367\n",
      "Epoch 926/1000\n",
      "700/700 [==============================] - 0s 119us/step - loss: 1.3972 - acc: 0.4457 - val_loss: 2.1763 - val_acc: 0.2467\n",
      "Epoch 927/1000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.3974 - acc: 0.4371 - val_loss: 2.1778 - val_acc: 0.2400\n",
      "Epoch 928/1000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.3971 - acc: 0.4400 - val_loss: 2.1910 - val_acc: 0.2433\n",
      "Epoch 929/1000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 1.3972 - acc: 0.4414 - val_loss: 2.1911 - val_acc: 0.2400\n",
      "Epoch 930/1000\n",
      "700/700 [==============================] - 0s 117us/step - loss: 1.3973 - acc: 0.4357 - val_loss: 2.1857 - val_acc: 0.2500\n",
      "Epoch 931/1000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.3967 - acc: 0.4343 - val_loss: 2.1803 - val_acc: 0.2467\n",
      "Epoch 932/1000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3962 - acc: 0.4400 - val_loss: 2.1715 - val_acc: 0.2500\n",
      "Epoch 933/1000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.3966 - acc: 0.4314 - val_loss: 2.1812 - val_acc: 0.2467\n",
      "Epoch 934/1000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.3959 - acc: 0.4414 - val_loss: 2.1832 - val_acc: 0.2500\n",
      "Epoch 935/1000\n",
      "700/700 [==============================] - 0s 129us/step - loss: 1.3965 - acc: 0.4443 - val_loss: 2.1828 - val_acc: 0.2467\n",
      "Epoch 936/1000\n",
      "700/700 [==============================] - 0s 119us/step - loss: 1.3964 - acc: 0.4443 - val_loss: 2.1904 - val_acc: 0.2500\n",
      "Epoch 937/1000\n",
      "700/700 [==============================] - 0s 115us/step - loss: 1.3961 - acc: 0.4414 - val_loss: 2.1826 - val_acc: 0.2367\n",
      "Epoch 938/1000\n",
      "700/700 [==============================] - 0s 115us/step - loss: 1.3953 - acc: 0.4457 - val_loss: 2.1928 - val_acc: 0.2500\n",
      "Epoch 939/1000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.3954 - acc: 0.4371 - val_loss: 2.1960 - val_acc: 0.2500\n",
      "Epoch 940/1000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 1.3960 - acc: 0.4357 - val_loss: 2.1778 - val_acc: 0.2400\n",
      "Epoch 941/1000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.3956 - acc: 0.4357 - val_loss: 2.1825 - val_acc: 0.2400\n",
      "Epoch 942/1000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.3947 - acc: 0.4357 - val_loss: 2.1669 - val_acc: 0.2333\n",
      "Epoch 943/1000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.3955 - acc: 0.4400 - val_loss: 2.1916 - val_acc: 0.2433\n",
      "Epoch 944/1000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.3943 - acc: 0.4357 - val_loss: 2.1942 - val_acc: 0.2467\n",
      "Epoch 945/1000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.3947 - acc: 0.4329 - val_loss: 2.1908 - val_acc: 0.2467\n",
      "Epoch 946/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 118us/step - loss: 1.3945 - acc: 0.4329 - val_loss: 2.1835 - val_acc: 0.2467\n",
      "Epoch 947/1000\n",
      "700/700 [==============================] - 0s 134us/step - loss: 1.3939 - acc: 0.4400 - val_loss: 2.1936 - val_acc: 0.2533\n",
      "Epoch 948/1000\n",
      "700/700 [==============================] - 0s 108us/step - loss: 1.3939 - acc: 0.4286 - val_loss: 2.1765 - val_acc: 0.2367\n",
      "Epoch 949/1000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.3939 - acc: 0.4457 - val_loss: 2.1854 - val_acc: 0.2467\n",
      "Epoch 950/1000\n",
      "700/700 [==============================] - 0s 119us/step - loss: 1.3928 - acc: 0.4386 - val_loss: 2.1833 - val_acc: 0.2333\n",
      "Epoch 951/1000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.3941 - acc: 0.4429 - val_loss: 2.1889 - val_acc: 0.2500\n",
      "Epoch 952/1000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.3936 - acc: 0.4429 - val_loss: 2.1921 - val_acc: 0.2433\n",
      "Epoch 953/1000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.3938 - acc: 0.4414 - val_loss: 2.1904 - val_acc: 0.2533\n",
      "Epoch 954/1000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.3939 - acc: 0.4457 - val_loss: 2.1860 - val_acc: 0.2500\n",
      "Epoch 955/1000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.3935 - acc: 0.4443 - val_loss: 2.1967 - val_acc: 0.2500\n",
      "Epoch 956/1000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 1.3930 - acc: 0.4386 - val_loss: 2.2006 - val_acc: 0.2433\n",
      "Epoch 957/1000\n",
      "700/700 [==============================] - 0s 121us/step - loss: 1.3926 - acc: 0.4414 - val_loss: 2.1841 - val_acc: 0.2433\n",
      "Epoch 958/1000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.3938 - acc: 0.4357 - val_loss: 2.2124 - val_acc: 0.2467\n",
      "Epoch 959/1000\n",
      "700/700 [==============================] - 0s 121us/step - loss: 1.3936 - acc: 0.4400 - val_loss: 2.1806 - val_acc: 0.2467\n",
      "Epoch 960/1000\n",
      "700/700 [==============================] - 0s 115us/step - loss: 1.3929 - acc: 0.4400 - val_loss: 2.1929 - val_acc: 0.2433\n",
      "Epoch 961/1000\n",
      "700/700 [==============================] - 0s 108us/step - loss: 1.3923 - acc: 0.4429 - val_loss: 2.1684 - val_acc: 0.2467\n",
      "Epoch 962/1000\n",
      "700/700 [==============================] - 0s 112us/step - loss: 1.3929 - acc: 0.4386 - val_loss: 2.1904 - val_acc: 0.2467\n",
      "Epoch 963/1000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.3925 - acc: 0.4414 - val_loss: 2.1839 - val_acc: 0.2500\n",
      "Epoch 964/1000\n",
      "700/700 [==============================] - 0s 121us/step - loss: 1.3920 - acc: 0.4371 - val_loss: 2.1879 - val_acc: 0.2500\n",
      "Epoch 965/1000\n",
      "700/700 [==============================] - 0s 121us/step - loss: 1.3912 - acc: 0.4400 - val_loss: 2.1863 - val_acc: 0.2533\n",
      "Epoch 966/1000\n",
      "700/700 [==============================] - 0s 123us/step - loss: 1.3923 - acc: 0.4429 - val_loss: 2.2034 - val_acc: 0.2533\n",
      "Epoch 967/1000\n",
      "700/700 [==============================] - 0s 123us/step - loss: 1.3922 - acc: 0.4400 - val_loss: 2.1963 - val_acc: 0.2467\n",
      "Epoch 968/1000\n",
      "700/700 [==============================] - 0s 127us/step - loss: 1.3913 - acc: 0.4400 - val_loss: 2.1869 - val_acc: 0.2433\n",
      "Epoch 969/1000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.3918 - acc: 0.4400 - val_loss: 2.1920 - val_acc: 0.2433\n",
      "Epoch 970/1000\n",
      "700/700 [==============================] - 0s 80us/step - loss: 1.3915 - acc: 0.4386 - val_loss: 2.2011 - val_acc: 0.2400\n",
      "Epoch 971/1000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.3916 - acc: 0.4400 - val_loss: 2.1872 - val_acc: 0.2467\n",
      "Epoch 972/1000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 1.3912 - acc: 0.4386 - val_loss: 2.1933 - val_acc: 0.2367\n",
      "Epoch 973/1000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.3903 - acc: 0.4429 - val_loss: 2.1885 - val_acc: 0.2500\n",
      "Epoch 974/1000\n",
      "700/700 [==============================] - 0s 120us/step - loss: 1.3909 - acc: 0.4357 - val_loss: 2.1962 - val_acc: 0.2500\n",
      "Epoch 975/1000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.3908 - acc: 0.4457 - val_loss: 2.2042 - val_acc: 0.2500\n",
      "Epoch 976/1000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.3904 - acc: 0.4429 - val_loss: 2.1917 - val_acc: 0.2533\n",
      "Epoch 977/1000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3906 - acc: 0.4357 - val_loss: 2.1897 - val_acc: 0.2400\n",
      "Epoch 978/1000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.3900 - acc: 0.4457 - val_loss: 2.1951 - val_acc: 0.2533\n",
      "Epoch 979/1000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.3906 - acc: 0.4429 - val_loss: 2.1928 - val_acc: 0.2467\n",
      "Epoch 980/1000\n",
      "700/700 [==============================] - 0s 108us/step - loss: 1.3906 - acc: 0.4429 - val_loss: 2.2050 - val_acc: 0.2533\n",
      "Epoch 981/1000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.3895 - acc: 0.4400 - val_loss: 2.2129 - val_acc: 0.2500\n",
      "Epoch 982/1000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.3903 - acc: 0.4400 - val_loss: 2.1965 - val_acc: 0.2533\n",
      "Epoch 983/1000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.3899 - acc: 0.4357 - val_loss: 2.2017 - val_acc: 0.2500\n",
      "Epoch 984/1000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.3898 - acc: 0.4414 - val_loss: 2.1945 - val_acc: 0.2500\n",
      "Epoch 985/1000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.3892 - acc: 0.4457 - val_loss: 2.2077 - val_acc: 0.2367\n",
      "Epoch 986/1000\n",
      "700/700 [==============================] - 0s 98us/step - loss: 1.3893 - acc: 0.4414 - val_loss: 2.2004 - val_acc: 0.2500\n",
      "Epoch 987/1000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.3888 - acc: 0.4429 - val_loss: 2.1919 - val_acc: 0.2367\n",
      "Epoch 988/1000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.3888 - acc: 0.4443 - val_loss: 2.2129 - val_acc: 0.2633\n",
      "Epoch 989/1000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.3902 - acc: 0.4357 - val_loss: 2.2110 - val_acc: 0.2567\n",
      "Epoch 990/1000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.3887 - acc: 0.4429 - val_loss: 2.2219 - val_acc: 0.2533\n",
      "Epoch 991/1000\n",
      "700/700 [==============================] - 0s 123us/step - loss: 1.3889 - acc: 0.4471 - val_loss: 2.1939 - val_acc: 0.2433\n",
      "Epoch 992/1000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.3887 - acc: 0.4371 - val_loss: 2.2055 - val_acc: 0.2400\n",
      "Epoch 993/1000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.3885 - acc: 0.4443 - val_loss: 2.2001 - val_acc: 0.2533\n",
      "Epoch 994/1000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.3885 - acc: 0.4371 - val_loss: 2.1866 - val_acc: 0.2333\n",
      "Epoch 995/1000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.3891 - acc: 0.4429 - val_loss: 2.2019 - val_acc: 0.2500\n",
      "Epoch 996/1000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.3878 - acc: 0.4443 - val_loss: 2.2044 - val_acc: 0.2467\n",
      "Epoch 997/1000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 1.3880 - acc: 0.4414 - val_loss: 2.2010 - val_acc: 0.2500\n",
      "Epoch 998/1000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.3885 - acc: 0.4386 - val_loss: 2.2121 - val_acc: 0.2500\n",
      "Epoch 999/1000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.3880 - acc: 0.4386 - val_loss: 2.2013 - val_acc: 0.2500\n",
      "Epoch 1000/1000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.3880 - acc: 0.4400 - val_loss: 2.2123 - val_acc: 0.2500\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from keras.utils import np_utils\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(3)\n",
    "\n",
    "# 1.  \n",
    "\n",
    "#   \n",
    "(X_train, Y_train), (X_test, Y_test) = mnist.load_data()\n",
    "\n",
    "#   \n",
    "X_val = X_train[50000:]\n",
    "Y_val = Y_train[50000:]\n",
    "X_train = X_train[:50000]\n",
    "Y_train = Y_train[:50000]\n",
    "\n",
    "X_train = X_train.reshape(50000, 784).astype('float32') / 255.0\n",
    "X_val = X_val.reshape(10000, 784).astype('float32') / 255.0\n",
    "X_test = X_test.reshape(10000, 784).astype('float32') / 255.0\n",
    "\n",
    "# ,  \n",
    "train_rand_idxs = np.random.choice(50000, 700)\n",
    "val_rand_idxs = np.random.choice(10000, 300)\n",
    "\n",
    "X_train = X_train[train_rand_idxs]\n",
    "Y_train = Y_train[train_rand_idxs]\n",
    "X_val = X_val[val_rand_idxs]\n",
    "Y_val = Y_val[val_rand_idxs]\n",
    "\n",
    "#  \n",
    "Y_train = np_utils.to_categorical(Y_train)\n",
    "Y_val = np_utils.to_categorical(Y_val)\n",
    "Y_test = np_utils.to_categorical(Y_test)\n",
    "\n",
    "# 2.  \n",
    "model = Sequential()\n",
    "model.add(Dense(units=2, input_dim=28*28, activation='relu'))\n",
    "model.add(Dense(units=10, activation='softmax'))\n",
    "\n",
    "# 3.  \n",
    "model.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])\n",
    "\n",
    "# 4.  \n",
    "hist = model.fit(X_train, Y_train, epochs=1000, batch_size=10, validation_data=(X_val, Y_val))\n",
    "\n",
    "# 5.    \n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, loss_ax = plt.subplots()\n",
    "\n",
    "acc_ax = loss_ax.twinx()\n",
    "\n",
    "loss_ax.plot(hist.history['loss'], 'y', label='train loss')\n",
    "loss_ax.plot(hist.history['val_loss'], 'r', label='val loss')\n",
    "\n",
    "acc_ax.plot(hist.history['acc'], 'b', label='train acc')\n",
    "acc_ax.plot(hist.history['val_acc'], 'g', label='val acc')\n",
    "\n",
    "loss_ax.set_xlabel('epoch')\n",
    "loss_ax.set_ylabel('loss')\n",
    "acc_ax.set_ylabel('accuray')\n",
    "\n",
    "loss_ax.legend(loc='upper left')\n",
    "acc_ax.legend(loc='lower left')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1000\n",
      "700/700 [==============================] - 0s 80us/step - loss: 1.3875 - acc: 0.4429 - val_loss: 2.2041 - val_acc: 0.2533\n",
      "Epoch 2/1000\n",
      "700/700 [==============================] - 0s 77us/step - loss: 1.3879 - acc: 0.4414 - val_loss: 2.2115 - val_acc: 0.2533\n",
      "Epoch 3/1000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 1.3874 - acc: 0.4386 - val_loss: 2.2119 - val_acc: 0.2567\n",
      "Epoch 4/1000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.3869 - acc: 0.4486 - val_loss: 2.2168 - val_acc: 0.2467\n",
      "Epoch 5/1000\n",
      "700/700 [==============================] - 0s 92us/step - loss: 1.3867 - acc: 0.4400 - val_loss: 2.2021 - val_acc: 0.2467\n",
      "Epoch 6/1000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3871 - acc: 0.4414 - val_loss: 2.1974 - val_acc: 0.2467\n",
      "Epoch 7/1000\n",
      "700/700 [==============================] - 0s 98us/step - loss: 1.3872 - acc: 0.4414 - val_loss: 2.2049 - val_acc: 0.2500\n",
      "Epoch 8/1000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3864 - acc: 0.4414 - val_loss: 2.2028 - val_acc: 0.2433\n",
      "Epoch 9/1000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.3861 - acc: 0.4471 - val_loss: 2.2131 - val_acc: 0.2567\n",
      "Epoch 10/1000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.3875 - acc: 0.4414 - val_loss: 2.2071 - val_acc: 0.2400\n",
      "Epoch 11/1000\n",
      "700/700 [==============================] - 0s 98us/step - loss: 1.3859 - acc: 0.4400 - val_loss: 2.2012 - val_acc: 0.2400\n",
      "Epoch 12/1000\n",
      "700/700 [==============================] - 0s 98us/step - loss: 1.3859 - acc: 0.4429 - val_loss: 2.2063 - val_acc: 0.2367\n",
      "Epoch 13/1000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 1.3872 - acc: 0.4471 - val_loss: 2.2131 - val_acc: 0.2500\n",
      "Epoch 14/1000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.3858 - acc: 0.4486 - val_loss: 2.2028 - val_acc: 0.2533\n",
      "Epoch 15/1000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.3853 - acc: 0.4486 - val_loss: 2.2152 - val_acc: 0.2567\n",
      "Epoch 16/1000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.3858 - acc: 0.4443 - val_loss: 2.2106 - val_acc: 0.2500\n",
      "Epoch 17/1000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 1.3852 - acc: 0.4371 - val_loss: 2.2189 - val_acc: 0.2500\n",
      "Epoch 18/1000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.3839 - acc: 0.4371 - val_loss: 2.2217 - val_acc: 0.2400\n",
      "Epoch 19/1000\n",
      "700/700 [==============================] - 0s 120us/step - loss: 1.3858 - acc: 0.4400 - val_loss: 2.2038 - val_acc: 0.2500\n",
      "Epoch 20/1000\n",
      "700/700 [==============================] - 0s 117us/step - loss: 1.3858 - acc: 0.4443 - val_loss: 2.2092 - val_acc: 0.2533\n",
      "Epoch 21/1000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 1.3848 - acc: 0.4414 - val_loss: 2.2153 - val_acc: 0.2567\n",
      "Epoch 22/1000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 1.3850 - acc: 0.4414 - val_loss: 2.2091 - val_acc: 0.2533\n",
      "Epoch 23/1000\n",
      "700/700 [==============================] - 0s 108us/step - loss: 1.3848 - acc: 0.4414 - val_loss: 2.2046 - val_acc: 0.2367\n",
      "Epoch 24/1000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.3855 - acc: 0.4457 - val_loss: 2.2142 - val_acc: 0.2533\n",
      "Epoch 25/1000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.3836 - acc: 0.4471 - val_loss: 2.2226 - val_acc: 0.2600\n",
      "Epoch 26/1000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.3851 - acc: 0.4443 - val_loss: 2.2000 - val_acc: 0.2500\n",
      "Epoch 27/1000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.3842 - acc: 0.4429 - val_loss: 2.2188 - val_acc: 0.2567\n",
      "Epoch 28/1000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.3839 - acc: 0.4486 - val_loss: 2.2081 - val_acc: 0.2533\n",
      "Epoch 29/1000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.3850 - acc: 0.4471 - val_loss: 2.2191 - val_acc: 0.2533\n",
      "Epoch 30/1000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.3839 - acc: 0.4386 - val_loss: 2.2185 - val_acc: 0.2400\n",
      "Epoch 31/1000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.3838 - acc: 0.4471 - val_loss: 2.1954 - val_acc: 0.2433\n",
      "Epoch 32/1000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.3842 - acc: 0.4443 - val_loss: 2.2118 - val_acc: 0.2500\n",
      "Epoch 33/1000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.3836 - acc: 0.4457 - val_loss: 2.2206 - val_acc: 0.2533\n",
      "Epoch 34/1000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.3840 - acc: 0.4386 - val_loss: 2.2016 - val_acc: 0.2533\n",
      "Epoch 35/1000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3836 - acc: 0.4429 - val_loss: 2.2103 - val_acc: 0.2500\n",
      "Epoch 36/1000\n",
      "700/700 [==============================] - 0s 98us/step - loss: 1.3820 - acc: 0.4414 - val_loss: 2.2203 - val_acc: 0.2367\n",
      "Epoch 37/1000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 1.3828 - acc: 0.4429 - val_loss: 2.2141 - val_acc: 0.2533\n",
      "Epoch 38/1000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.3828 - acc: 0.4443 - val_loss: 2.2029 - val_acc: 0.2400\n",
      "Epoch 39/1000\n",
      "700/700 [==============================] - 0s 108us/step - loss: 1.3826 - acc: 0.4486 - val_loss: 2.2162 - val_acc: 0.2533\n",
      "Epoch 40/1000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.3823 - acc: 0.4414 - val_loss: 2.2164 - val_acc: 0.2400\n",
      "Epoch 41/1000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.3820 - acc: 0.4414 - val_loss: 2.2060 - val_acc: 0.2400\n",
      "Epoch 42/1000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.3819 - acc: 0.4529 - val_loss: 2.2259 - val_acc: 0.2433\n",
      "Epoch 43/1000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.3826 - acc: 0.4443 - val_loss: 2.2239 - val_acc: 0.2500\n",
      "Epoch 44/1000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.3828 - acc: 0.4414 - val_loss: 2.2315 - val_acc: 0.2533\n",
      "Epoch 45/1000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.3821 - acc: 0.4414 - val_loss: 2.2164 - val_acc: 0.2567\n",
      "Epoch 46/1000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.3816 - acc: 0.4429 - val_loss: 2.2155 - val_acc: 0.2533\n",
      "Epoch 47/1000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.3811 - acc: 0.4414 - val_loss: 2.2114 - val_acc: 0.2533\n",
      "Epoch 48/1000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.3825 - acc: 0.4400 - val_loss: 2.2268 - val_acc: 0.2500\n",
      "Epoch 49/1000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.3815 - acc: 0.4529 - val_loss: 2.2235 - val_acc: 0.2533\n",
      "Epoch 50/1000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.3820 - acc: 0.4471 - val_loss: 2.2170 - val_acc: 0.2400\n",
      "Epoch 51/1000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.3815 - acc: 0.4429 - val_loss: 2.2170 - val_acc: 0.2467\n",
      "Epoch 52/1000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.3803 - acc: 0.4457 - val_loss: 2.2193 - val_acc: 0.2400\n",
      "Epoch 53/1000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.3817 - acc: 0.4414 - val_loss: 2.2178 - val_acc: 0.2500\n",
      "Epoch 54/1000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.3813 - acc: 0.4386 - val_loss: 2.2012 - val_acc: 0.2367\n",
      "Epoch 55/1000\n",
      "700/700 [==============================] - 0s 108us/step - loss: 1.3804 - acc: 0.4471 - val_loss: 2.2186 - val_acc: 0.2533\n",
      "Epoch 56/1000\n",
      "700/700 [==============================] - 0s 98us/step - loss: 1.3807 - acc: 0.4443 - val_loss: 2.2088 - val_acc: 0.2333\n",
      "Epoch 57/1000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.3800 - acc: 0.4514 - val_loss: 2.2336 - val_acc: 0.2533\n",
      "Epoch 58/1000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.3807 - acc: 0.4429 - val_loss: 2.2159 - val_acc: 0.2467\n",
      "Epoch 59/1000\n",
      "700/700 [==============================] - 0s 92us/step - loss: 1.3806 - acc: 0.4457 - val_loss: 2.2180 - val_acc: 0.2533\n",
      "Epoch 60/1000\n",
      "700/700 [==============================] - 0s 92us/step - loss: 1.3808 - acc: 0.4386 - val_loss: 2.2206 - val_acc: 0.2433\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/1000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.3795 - acc: 0.4600 - val_loss: 2.2291 - val_acc: 0.2500\n",
      "Epoch 62/1000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.3816 - acc: 0.4457 - val_loss: 2.2200 - val_acc: 0.2467\n",
      "Epoch 63/1000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.3803 - acc: 0.4414 - val_loss: 2.2284 - val_acc: 0.2467\n",
      "Epoch 64/1000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.3807 - acc: 0.4429 - val_loss: 2.2198 - val_acc: 0.2467\n",
      "Epoch 65/1000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.3797 - acc: 0.4471 - val_loss: 2.2166 - val_acc: 0.2500\n",
      "Epoch 66/1000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.3805 - acc: 0.4386 - val_loss: 2.2414 - val_acc: 0.2467\n",
      "Epoch 67/1000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.3803 - acc: 0.4400 - val_loss: 2.2155 - val_acc: 0.2333\n",
      "Epoch 68/1000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.3791 - acc: 0.4457 - val_loss: 2.2176 - val_acc: 0.2367\n",
      "Epoch 69/1000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.3800 - acc: 0.4443 - val_loss: 2.2293 - val_acc: 0.2467\n",
      "Epoch 70/1000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.3791 - acc: 0.4471 - val_loss: 2.2338 - val_acc: 0.2467\n",
      "Epoch 71/1000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.3790 - acc: 0.4457 - val_loss: 2.2289 - val_acc: 0.2500\n",
      "Epoch 72/1000\n",
      "700/700 [==============================] - 0s 108us/step - loss: 1.3788 - acc: 0.4400 - val_loss: 2.2300 - val_acc: 0.2500\n",
      "Epoch 73/1000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.3796 - acc: 0.4414 - val_loss: 2.2309 - val_acc: 0.2500\n",
      "Epoch 74/1000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.3801 - acc: 0.4400 - val_loss: 2.2203 - val_acc: 0.2500\n",
      "Epoch 75/1000\n",
      "700/700 [==============================] - 0s 98us/step - loss: 1.3785 - acc: 0.4500 - val_loss: 2.2266 - val_acc: 0.2467\n",
      "Epoch 76/1000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.3783 - acc: 0.4543 - val_loss: 2.2013 - val_acc: 0.2367\n",
      "Epoch 77/1000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.3790 - acc: 0.4457 - val_loss: 2.2224 - val_acc: 0.2500\n",
      "Epoch 78/1000\n",
      "700/700 [==============================] - 0s 98us/step - loss: 1.3786 - acc: 0.4429 - val_loss: 2.2312 - val_acc: 0.2433\n",
      "Epoch 79/1000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.3782 - acc: 0.4500 - val_loss: 2.2192 - val_acc: 0.2500\n",
      "Epoch 80/1000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3782 - acc: 0.4543 - val_loss: 2.2346 - val_acc: 0.2533\n",
      "Epoch 81/1000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.3776 - acc: 0.4386 - val_loss: 2.2281 - val_acc: 0.2533\n",
      "Epoch 82/1000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.3778 - acc: 0.4471 - val_loss: 2.2213 - val_acc: 0.2500\n",
      "Epoch 83/1000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.3781 - acc: 0.4414 - val_loss: 2.2378 - val_acc: 0.2400\n",
      "Epoch 84/1000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.3774 - acc: 0.4457 - val_loss: 2.2318 - val_acc: 0.2400\n",
      "Epoch 85/1000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.3766 - acc: 0.4500 - val_loss: 2.2396 - val_acc: 0.2333\n",
      "Epoch 86/1000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.3764 - acc: 0.4500 - val_loss: 2.2295 - val_acc: 0.2467\n",
      "Epoch 87/1000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.3773 - acc: 0.4486 - val_loss: 2.2380 - val_acc: 0.2533\n",
      "Epoch 88/1000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.3785 - acc: 0.4500 - val_loss: 2.2153 - val_acc: 0.2467\n",
      "Epoch 89/1000\n",
      "700/700 [==============================] - 0s 92us/step - loss: 1.3769 - acc: 0.4529 - val_loss: 2.2209 - val_acc: 0.2433\n",
      "Epoch 90/1000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.3772 - acc: 0.4457 - val_loss: 2.2252 - val_acc: 0.2500\n",
      "Epoch 91/1000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.3774 - acc: 0.4486 - val_loss: 2.2255 - val_acc: 0.2500\n",
      "Epoch 92/1000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3775 - acc: 0.4457 - val_loss: 2.2308 - val_acc: 0.2533\n",
      "Epoch 93/1000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.3762 - acc: 0.4457 - val_loss: 2.2215 - val_acc: 0.2467\n",
      "Epoch 94/1000\n",
      "700/700 [==============================] - 0s 76us/step - loss: 1.3773 - acc: 0.4400 - val_loss: 2.2435 - val_acc: 0.2533\n",
      "Epoch 95/1000\n",
      "700/700 [==============================] - 0s 82us/step - loss: 1.3770 - acc: 0.4429 - val_loss: 2.2264 - val_acc: 0.2533\n",
      "Epoch 96/1000\n",
      "700/700 [==============================] - 0s 79us/step - loss: 1.3762 - acc: 0.4486 - val_loss: 2.2340 - val_acc: 0.2467\n",
      "Epoch 97/1000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 1.3753 - acc: 0.4500 - val_loss: 2.2239 - val_acc: 0.2400\n",
      "Epoch 98/1000\n",
      "700/700 [==============================] - 0s 85us/step - loss: 1.3762 - acc: 0.4457 - val_loss: 2.2190 - val_acc: 0.2500\n",
      "Epoch 99/1000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.3764 - acc: 0.4486 - val_loss: 2.2086 - val_acc: 0.2433\n",
      "Epoch 100/1000\n",
      "700/700 [==============================] - 0s 80us/step - loss: 1.3757 - acc: 0.4486 - val_loss: 2.2280 - val_acc: 0.2433\n",
      "Epoch 101/1000\n",
      "700/700 [==============================] - 0s 86us/step - loss: 1.3758 - acc: 0.4500 - val_loss: 2.2280 - val_acc: 0.2367\n",
      "Epoch 102/1000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3744 - acc: 0.4543 - val_loss: 2.2281 - val_acc: 0.2467\n",
      "Epoch 103/1000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.3754 - acc: 0.4486 - val_loss: 2.2252 - val_acc: 0.2467\n",
      "Epoch 104/1000\n",
      "700/700 [==============================] - 0s 135us/step - loss: 1.3757 - acc: 0.4429 - val_loss: 2.2357 - val_acc: 0.2533\n",
      "Epoch 105/1000\n",
      "700/700 [==============================] - 0s 77us/step - loss: 1.3756 - acc: 0.4371 - val_loss: 2.2266 - val_acc: 0.2500\n",
      "Epoch 106/1000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.3759 - acc: 0.4514 - val_loss: 2.2383 - val_acc: 0.2500\n",
      "Epoch 107/1000\n",
      "700/700 [==============================] - 0s 78us/step - loss: 1.3744 - acc: 0.4486 - val_loss: 2.2404 - val_acc: 0.2400\n",
      "Epoch 108/1000\n",
      "700/700 [==============================] - 0s 82us/step - loss: 1.3745 - acc: 0.4457 - val_loss: 2.2301 - val_acc: 0.2367\n",
      "Epoch 109/1000\n",
      "700/700 [==============================] - 0s 84us/step - loss: 1.3748 - acc: 0.4514 - val_loss: 2.2337 - val_acc: 0.2500\n",
      "Epoch 110/1000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.3751 - acc: 0.4443 - val_loss: 2.2445 - val_acc: 0.2433\n",
      "Epoch 111/1000\n",
      "700/700 [==============================] - 0s 79us/step - loss: 1.3745 - acc: 0.4457 - val_loss: 2.2286 - val_acc: 0.2400\n",
      "Epoch 112/1000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.3741 - acc: 0.4514 - val_loss: 2.2350 - val_acc: 0.2500\n",
      "Epoch 113/1000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3745 - acc: 0.4514 - val_loss: 2.2328 - val_acc: 0.2467\n",
      "Epoch 114/1000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.3743 - acc: 0.4471 - val_loss: 2.2465 - val_acc: 0.2433\n",
      "Epoch 115/1000\n",
      "700/700 [==============================] - 0s 88us/step - loss: 1.3748 - acc: 0.4443 - val_loss: 2.2363 - val_acc: 0.2533\n",
      "Epoch 116/1000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.3742 - acc: 0.4471 - val_loss: 2.2373 - val_acc: 0.2533\n",
      "Epoch 117/1000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.3741 - acc: 0.4457 - val_loss: 2.2256 - val_acc: 0.2533\n",
      "Epoch 118/1000\n",
      "700/700 [==============================] - 0s 85us/step - loss: 1.3738 - acc: 0.4543 - val_loss: 2.2189 - val_acc: 0.2467\n",
      "Epoch 119/1000\n",
      "700/700 [==============================] - 0s 87us/step - loss: 1.3743 - acc: 0.4557 - val_loss: 2.2203 - val_acc: 0.2400\n",
      "Epoch 120/1000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.3742 - acc: 0.4443 - val_loss: 2.2281 - val_acc: 0.2500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 121/1000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3737 - acc: 0.4486 - val_loss: 2.2359 - val_acc: 0.2500\n",
      "Epoch 122/1000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.3730 - acc: 0.4443 - val_loss: 2.2103 - val_acc: 0.2500\n",
      "Epoch 123/1000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.3749 - acc: 0.4500 - val_loss: 2.2371 - val_acc: 0.2467\n",
      "Epoch 124/1000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.3739 - acc: 0.4457 - val_loss: 2.2270 - val_acc: 0.2433\n",
      "Epoch 125/1000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3732 - acc: 0.4486 - val_loss: 2.2327 - val_acc: 0.2367\n",
      "Epoch 126/1000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.3736 - acc: 0.4457 - val_loss: 2.2461 - val_acc: 0.2433\n",
      "Epoch 127/1000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.3707 - acc: 0.4443 - val_loss: 2.2485 - val_acc: 0.2300\n",
      "Epoch 128/1000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.3726 - acc: 0.4529 - val_loss: 2.2407 - val_acc: 0.2433\n",
      "Epoch 129/1000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.3730 - acc: 0.4457 - val_loss: 2.2424 - val_acc: 0.2500\n",
      "Epoch 130/1000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.3725 - acc: 0.4486 - val_loss: 2.2415 - val_acc: 0.2367\n",
      "Epoch 131/1000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.3724 - acc: 0.4486 - val_loss: 2.2363 - val_acc: 0.2533\n",
      "Epoch 132/1000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.3724 - acc: 0.4471 - val_loss: 2.2290 - val_acc: 0.2333\n",
      "Epoch 133/1000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.3722 - acc: 0.4514 - val_loss: 2.2305 - val_acc: 0.2433\n",
      "Epoch 134/1000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.3718 - acc: 0.4529 - val_loss: 2.2507 - val_acc: 0.2500\n",
      "Epoch 135/1000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.3718 - acc: 0.4486 - val_loss: 2.2390 - val_acc: 0.2533\n",
      "Epoch 136/1000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 1.3719 - acc: 0.4486 - val_loss: 2.2408 - val_acc: 0.2400\n",
      "Epoch 137/1000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.3720 - acc: 0.4443 - val_loss: 2.2399 - val_acc: 0.2500\n",
      "Epoch 138/1000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.3718 - acc: 0.4543 - val_loss: 2.2338 - val_acc: 0.2500\n",
      "Epoch 139/1000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.3717 - acc: 0.4500 - val_loss: 2.2390 - val_acc: 0.2433\n",
      "Epoch 140/1000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.3715 - acc: 0.4486 - val_loss: 2.2486 - val_acc: 0.2467\n",
      "Epoch 141/1000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3723 - acc: 0.4500 - val_loss: 2.2403 - val_acc: 0.2500\n",
      "Epoch 142/1000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.3709 - acc: 0.4543 - val_loss: 2.2380 - val_acc: 0.2333\n",
      "Epoch 143/1000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.3722 - acc: 0.4543 - val_loss: 2.2221 - val_acc: 0.2500\n",
      "Epoch 144/1000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.3711 - acc: 0.4571 - val_loss: 2.2544 - val_acc: 0.2467\n",
      "Epoch 145/1000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.3718 - acc: 0.4457 - val_loss: 2.2301 - val_acc: 0.2433\n",
      "Epoch 146/1000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.3707 - acc: 0.4486 - val_loss: 2.2539 - val_acc: 0.2500\n",
      "Epoch 147/1000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 1.3703 - acc: 0.4471 - val_loss: 2.2501 - val_acc: 0.2333\n",
      "Epoch 148/1000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.3703 - acc: 0.4471 - val_loss: 2.2304 - val_acc: 0.2500\n",
      "Epoch 149/1000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.3711 - acc: 0.4500 - val_loss: 2.2476 - val_acc: 0.2367\n",
      "Epoch 150/1000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.3701 - acc: 0.4529 - val_loss: 2.2333 - val_acc: 0.2467\n",
      "Epoch 151/1000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.3709 - acc: 0.4514 - val_loss: 2.2285 - val_acc: 0.2467\n",
      "Epoch 152/1000\n",
      "700/700 [==============================] - 0s 108us/step - loss: 1.3710 - acc: 0.4486 - val_loss: 2.2325 - val_acc: 0.2433\n",
      "Epoch 153/1000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.3697 - acc: 0.4486 - val_loss: 2.2504 - val_acc: 0.2333\n",
      "Epoch 154/1000\n",
      "700/700 [==============================] - 0s 88us/step - loss: 1.3706 - acc: 0.4514 - val_loss: 2.2375 - val_acc: 0.2433\n",
      "Epoch 155/1000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.3695 - acc: 0.4571 - val_loss: 2.2372 - val_acc: 0.2333\n",
      "Epoch 156/1000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.3692 - acc: 0.4514 - val_loss: 2.2444 - val_acc: 0.2467\n",
      "Epoch 157/1000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.3709 - acc: 0.4486 - val_loss: 2.2537 - val_acc: 0.2433\n",
      "Epoch 158/1000\n",
      "700/700 [==============================] - 0s 98us/step - loss: 1.3696 - acc: 0.4557 - val_loss: 2.2357 - val_acc: 0.2433\n",
      "Epoch 159/1000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.3694 - acc: 0.4471 - val_loss: 2.2249 - val_acc: 0.2367\n",
      "Epoch 160/1000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.3695 - acc: 0.4586 - val_loss: 2.2562 - val_acc: 0.2500\n",
      "Epoch 161/1000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3690 - acc: 0.4529 - val_loss: 2.2396 - val_acc: 0.2367\n",
      "Epoch 162/1000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.3692 - acc: 0.4500 - val_loss: 2.2403 - val_acc: 0.2433\n",
      "Epoch 163/1000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.3686 - acc: 0.4514 - val_loss: 2.2483 - val_acc: 0.2467\n",
      "Epoch 164/1000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.3692 - acc: 0.4514 - val_loss: 2.2241 - val_acc: 0.2333\n",
      "Epoch 165/1000\n",
      "700/700 [==============================] - 0s 98us/step - loss: 1.3693 - acc: 0.4529 - val_loss: 2.2503 - val_acc: 0.2500\n",
      "Epoch 166/1000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.3682 - acc: 0.4457 - val_loss: 2.2398 - val_acc: 0.2367\n",
      "Epoch 167/1000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.3687 - acc: 0.4486 - val_loss: 2.2488 - val_acc: 0.2433\n",
      "Epoch 168/1000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 1.3686 - acc: 0.4514 - val_loss: 2.2411 - val_acc: 0.2467\n",
      "Epoch 169/1000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.3686 - acc: 0.4500 - val_loss: 2.2470 - val_acc: 0.2467\n",
      "Epoch 170/1000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.3680 - acc: 0.4529 - val_loss: 2.2513 - val_acc: 0.2333\n",
      "Epoch 171/1000\n",
      "700/700 [==============================] - 0s 134us/step - loss: 1.3684 - acc: 0.4514 - val_loss: 2.2579 - val_acc: 0.2467\n",
      "Epoch 172/1000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3683 - acc: 0.4557 - val_loss: 2.2310 - val_acc: 0.2333\n",
      "Epoch 173/1000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3682 - acc: 0.4443 - val_loss: 2.2472 - val_acc: 0.2467\n",
      "Epoch 174/1000\n",
      "700/700 [==============================] - 0s 88us/step - loss: 1.3670 - acc: 0.4629 - val_loss: 2.2496 - val_acc: 0.2467\n",
      "Epoch 175/1000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.3682 - acc: 0.4471 - val_loss: 2.2520 - val_acc: 0.2467\n",
      "Epoch 176/1000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.3681 - acc: 0.4543 - val_loss: 2.2480 - val_acc: 0.2467\n",
      "Epoch 177/1000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.3688 - acc: 0.4500 - val_loss: 2.2329 - val_acc: 0.2400\n",
      "Epoch 178/1000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.3673 - acc: 0.4514 - val_loss: 2.2565 - val_acc: 0.2500\n",
      "Epoch 179/1000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.3675 - acc: 0.4529 - val_loss: 2.2545 - val_acc: 0.2300\n",
      "Epoch 180/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 111us/step - loss: 1.3681 - acc: 0.4514 - val_loss: 2.2473 - val_acc: 0.2300\n",
      "Epoch 181/1000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.3666 - acc: 0.4586 - val_loss: 2.2481 - val_acc: 0.2433\n",
      "Epoch 182/1000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.3667 - acc: 0.4400 - val_loss: 2.2455 - val_acc: 0.2300\n",
      "Epoch 183/1000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 1.3673 - acc: 0.4529 - val_loss: 2.2434 - val_acc: 0.2433\n",
      "Epoch 184/1000\n",
      "700/700 [==============================] - 0s 98us/step - loss: 1.3674 - acc: 0.4514 - val_loss: 2.2391 - val_acc: 0.2467\n",
      "Epoch 185/1000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.3667 - acc: 0.4457 - val_loss: 2.2625 - val_acc: 0.2467\n",
      "Epoch 186/1000\n",
      "700/700 [==============================] - 0s 116us/step - loss: 1.3666 - acc: 0.4529 - val_loss: 2.2463 - val_acc: 0.2467\n",
      "Epoch 187/1000\n",
      "700/700 [==============================] - 0s 119us/step - loss: 1.3667 - acc: 0.4529 - val_loss: 2.2573 - val_acc: 0.2467\n",
      "Epoch 188/1000\n",
      "700/700 [==============================] - 0s 117us/step - loss: 1.3668 - acc: 0.4543 - val_loss: 2.2563 - val_acc: 0.2433\n",
      "Epoch 189/1000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.3654 - acc: 0.4557 - val_loss: 2.2457 - val_acc: 0.2433\n",
      "Epoch 190/1000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.3669 - acc: 0.4614 - val_loss: 2.2320 - val_acc: 0.2400\n",
      "Epoch 191/1000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.3659 - acc: 0.4586 - val_loss: 2.2481 - val_acc: 0.2500\n",
      "Epoch 192/1000\n",
      "700/700 [==============================] - 0s 108us/step - loss: 1.3655 - acc: 0.4600 - val_loss: 2.2582 - val_acc: 0.2267\n",
      "Epoch 193/1000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.3656 - acc: 0.4557 - val_loss: 2.2562 - val_acc: 0.2400\n",
      "Epoch 194/1000\n",
      "700/700 [==============================] - 0s 112us/step - loss: 1.3658 - acc: 0.4600 - val_loss: 2.2372 - val_acc: 0.2333\n",
      "Epoch 195/1000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.3663 - acc: 0.4557 - val_loss: 2.2640 - val_acc: 0.2433\n",
      "Epoch 196/1000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.3660 - acc: 0.4571 - val_loss: 2.2560 - val_acc: 0.2433\n",
      "Epoch 197/1000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.3657 - acc: 0.4543 - val_loss: 2.2487 - val_acc: 0.2333\n",
      "Epoch 198/1000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.3663 - acc: 0.4557 - val_loss: 2.2385 - val_acc: 0.2467\n",
      "Epoch 199/1000\n",
      "700/700 [==============================] - 0s 115us/step - loss: 1.3657 - acc: 0.4543 - val_loss: 2.2496 - val_acc: 0.2433\n",
      "Epoch 200/1000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 1.3656 - acc: 0.4571 - val_loss: 2.2578 - val_acc: 0.2433\n",
      "Epoch 201/1000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.3653 - acc: 0.4557 - val_loss: 2.2655 - val_acc: 0.2433\n",
      "Epoch 202/1000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.3654 - acc: 0.4529 - val_loss: 2.2564 - val_acc: 0.2467\n",
      "Epoch 203/1000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.3647 - acc: 0.4586 - val_loss: 2.2620 - val_acc: 0.2400\n",
      "Epoch 204/1000\n",
      "700/700 [==============================] - 0s 122us/step - loss: 1.3652 - acc: 0.4529 - val_loss: 2.2626 - val_acc: 0.2367\n",
      "Epoch 205/1000\n",
      "700/700 [==============================] - 0s 84us/step - loss: 1.3644 - acc: 0.4557 - val_loss: 2.2646 - val_acc: 0.2333\n",
      "Epoch 206/1000\n",
      "700/700 [==============================] - 0s 81us/step - loss: 1.3644 - acc: 0.4486 - val_loss: 2.2459 - val_acc: 0.2400\n",
      "Epoch 207/1000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.3647 - acc: 0.4557 - val_loss: 2.2732 - val_acc: 0.2467\n",
      "Epoch 208/1000\n",
      "700/700 [==============================] - 0s 79us/step - loss: 1.3648 - acc: 0.4471 - val_loss: 2.2706 - val_acc: 0.2433\n",
      "Epoch 209/1000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3649 - acc: 0.4529 - val_loss: 2.2506 - val_acc: 0.2400\n",
      "Epoch 210/1000\n",
      "700/700 [==============================] - 0s 115us/step - loss: 1.3646 - acc: 0.4500 - val_loss: 2.2512 - val_acc: 0.2400\n",
      "Epoch 211/1000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.3638 - acc: 0.4543 - val_loss: 2.2540 - val_acc: 0.2433\n",
      "Epoch 212/1000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.3639 - acc: 0.4557 - val_loss: 2.2595 - val_acc: 0.2433\n",
      "Epoch 213/1000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.3646 - acc: 0.4543 - val_loss: 2.2673 - val_acc: 0.2433\n",
      "Epoch 214/1000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.3644 - acc: 0.4557 - val_loss: 2.2602 - val_acc: 0.2400\n",
      "Epoch 215/1000\n",
      "700/700 [==============================] - 0s 116us/step - loss: 1.3633 - acc: 0.4571 - val_loss: 2.2550 - val_acc: 0.2467\n",
      "Epoch 216/1000\n",
      "700/700 [==============================] - 0s 118us/step - loss: 1.3622 - acc: 0.4600 - val_loss: 2.2515 - val_acc: 0.2267\n",
      "Epoch 217/1000\n",
      "700/700 [==============================] - 0s 76us/step - loss: 1.3635 - acc: 0.4557 - val_loss: 2.2513 - val_acc: 0.2400\n",
      "Epoch 218/1000\n",
      "700/700 [==============================] - 0s 75us/step - loss: 1.3638 - acc: 0.4486 - val_loss: 2.2471 - val_acc: 0.2433\n",
      "Epoch 219/1000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.3639 - acc: 0.4514 - val_loss: 2.2687 - val_acc: 0.2433\n",
      "Epoch 220/1000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.3629 - acc: 0.4557 - val_loss: 2.2546 - val_acc: 0.2433\n",
      "Epoch 221/1000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.3634 - acc: 0.4557 - val_loss: 2.2632 - val_acc: 0.2500\n",
      "Epoch 222/1000\n",
      "700/700 [==============================] - 0s 120us/step - loss: 1.3629 - acc: 0.4543 - val_loss: 2.2571 - val_acc: 0.2433\n",
      "Epoch 223/1000\n",
      "700/700 [==============================] - 0s 123us/step - loss: 1.3631 - acc: 0.4571 - val_loss: 2.2468 - val_acc: 0.2333\n",
      "Epoch 224/1000\n",
      "700/700 [==============================] - 0s 133us/step - loss: 1.3629 - acc: 0.4529 - val_loss: 2.2584 - val_acc: 0.2300\n",
      "Epoch 225/1000\n",
      "700/700 [==============================] - 0s 121us/step - loss: 1.3628 - acc: 0.4586 - val_loss: 2.2412 - val_acc: 0.2333\n",
      "Epoch 226/1000\n",
      "700/700 [==============================] - 0s 108us/step - loss: 1.3635 - acc: 0.4543 - val_loss: 2.2594 - val_acc: 0.2367\n",
      "Epoch 227/1000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.3625 - acc: 0.4600 - val_loss: 2.2678 - val_acc: 0.2433\n",
      "Epoch 228/1000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.3625 - acc: 0.4657 - val_loss: 2.2586 - val_acc: 0.2367\n",
      "Epoch 229/1000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 1.3625 - acc: 0.4529 - val_loss: 2.2613 - val_acc: 0.2400\n",
      "Epoch 230/1000\n",
      "700/700 [==============================] - 0s 116us/step - loss: 1.3620 - acc: 0.4514 - val_loss: 2.2481 - val_acc: 0.2433\n",
      "Epoch 231/1000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.3628 - acc: 0.4557 - val_loss: 2.2580 - val_acc: 0.2400\n",
      "Epoch 232/1000\n",
      "700/700 [==============================] - 0s 126us/step - loss: 1.3618 - acc: 0.4614 - val_loss: 2.2664 - val_acc: 0.2500\n",
      "Epoch 233/1000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.3612 - acc: 0.4514 - val_loss: 2.2642 - val_acc: 0.2467\n",
      "Epoch 234/1000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.3619 - acc: 0.4557 - val_loss: 2.2634 - val_acc: 0.2400\n",
      "Epoch 235/1000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.3625 - acc: 0.4586 - val_loss: 2.2539 - val_acc: 0.2400\n",
      "Epoch 236/1000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.3621 - acc: 0.4557 - val_loss: 2.2643 - val_acc: 0.2400\n",
      "Epoch 237/1000\n",
      "700/700 [==============================] - 0s 116us/step - loss: 1.3612 - acc: 0.4514 - val_loss: 2.2591 - val_acc: 0.2400\n",
      "Epoch 238/1000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.3618 - acc: 0.4600 - val_loss: 2.2519 - val_acc: 0.2433\n",
      "Epoch 239/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 108us/step - loss: 1.3611 - acc: 0.4600 - val_loss: 2.2591 - val_acc: 0.2433\n",
      "Epoch 240/1000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.3609 - acc: 0.4614 - val_loss: 2.2538 - val_acc: 0.2400\n",
      "Epoch 241/1000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.3615 - acc: 0.4571 - val_loss: 2.2569 - val_acc: 0.2400\n",
      "Epoch 242/1000\n",
      "700/700 [==============================] - 0s 125us/step - loss: 1.3615 - acc: 0.4571 - val_loss: 2.2533 - val_acc: 0.2400\n",
      "Epoch 243/1000\n",
      "700/700 [==============================] - 0s 98us/step - loss: 1.3622 - acc: 0.4600 - val_loss: 2.2506 - val_acc: 0.2300\n",
      "Epoch 244/1000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 1.3610 - acc: 0.4529 - val_loss: 2.2517 - val_acc: 0.2467\n",
      "Epoch 245/1000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.3606 - acc: 0.4643 - val_loss: 2.2666 - val_acc: 0.2433\n",
      "Epoch 246/1000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.3616 - acc: 0.4571 - val_loss: 2.2630 - val_acc: 0.2433\n",
      "Epoch 247/1000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.3606 - acc: 0.4643 - val_loss: 2.2738 - val_acc: 0.2500\n",
      "Epoch 248/1000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.3606 - acc: 0.4600 - val_loss: 2.2596 - val_acc: 0.2433\n",
      "Epoch 249/1000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.3603 - acc: 0.4586 - val_loss: 2.2586 - val_acc: 0.2400\n",
      "Epoch 250/1000\n",
      "700/700 [==============================] - 0s 115us/step - loss: 1.3608 - acc: 0.4586 - val_loss: 2.2615 - val_acc: 0.2433\n",
      "Epoch 251/1000\n",
      "700/700 [==============================] - 0s 117us/step - loss: 1.3604 - acc: 0.4529 - val_loss: 2.2571 - val_acc: 0.2433\n",
      "Epoch 252/1000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.3608 - acc: 0.4657 - val_loss: 2.2542 - val_acc: 0.2400\n",
      "Epoch 253/1000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.3598 - acc: 0.4586 - val_loss: 2.2673 - val_acc: 0.2400\n",
      "Epoch 254/1000\n",
      "700/700 [==============================] - 0s 117us/step - loss: 1.3603 - acc: 0.4543 - val_loss: 2.2638 - val_acc: 0.2433\n",
      "Epoch 255/1000\n",
      "700/700 [==============================] - 0s 119us/step - loss: 1.3602 - acc: 0.4514 - val_loss: 2.2580 - val_acc: 0.2400\n",
      "Epoch 256/1000\n",
      "700/700 [==============================] - 0s 112us/step - loss: 1.3597 - acc: 0.4614 - val_loss: 2.2517 - val_acc: 0.2467\n",
      "Epoch 257/1000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.3600 - acc: 0.4600 - val_loss: 2.2604 - val_acc: 0.2467\n",
      "Epoch 258/1000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3604 - acc: 0.4571 - val_loss: 2.2605 - val_acc: 0.2433\n",
      "Epoch 259/1000\n",
      "700/700 [==============================] - 0s 108us/step - loss: 1.3597 - acc: 0.4557 - val_loss: 2.2558 - val_acc: 0.2400\n",
      "Epoch 260/1000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.3588 - acc: 0.4586 - val_loss: 2.2513 - val_acc: 0.2467\n",
      "Epoch 261/1000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 1.3591 - acc: 0.4629 - val_loss: 2.2792 - val_acc: 0.2433\n",
      "Epoch 262/1000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.3594 - acc: 0.4557 - val_loss: 2.2751 - val_acc: 0.2400\n",
      "Epoch 263/1000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.3593 - acc: 0.4714 - val_loss: 2.2707 - val_acc: 0.2400\n",
      "Epoch 264/1000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.3583 - acc: 0.4557 - val_loss: 2.2764 - val_acc: 0.2333\n",
      "Epoch 265/1000\n",
      "700/700 [==============================] - 0s 116us/step - loss: 1.3593 - acc: 0.4571 - val_loss: 2.2622 - val_acc: 0.2400\n",
      "Epoch 266/1000\n",
      "700/700 [==============================] - 0s 120us/step - loss: 1.3591 - acc: 0.4529 - val_loss: 2.2728 - val_acc: 0.2400\n",
      "Epoch 267/1000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.3592 - acc: 0.4671 - val_loss: 2.2742 - val_acc: 0.2467\n",
      "Epoch 268/1000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.3587 - acc: 0.4600 - val_loss: 2.2603 - val_acc: 0.2433\n",
      "Epoch 269/1000\n",
      "700/700 [==============================] - 0s 92us/step - loss: 1.3588 - acc: 0.4586 - val_loss: 2.2647 - val_acc: 0.2433\n",
      "Epoch 270/1000\n",
      "700/700 [==============================] - 0s 78us/step - loss: 1.3589 - acc: 0.4600 - val_loss: 2.2689 - val_acc: 0.2400\n",
      "Epoch 271/1000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.3575 - acc: 0.4600 - val_loss: 2.2811 - val_acc: 0.2433\n",
      "Epoch 272/1000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.3574 - acc: 0.4614 - val_loss: 2.2523 - val_acc: 0.2467\n",
      "Epoch 273/1000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.3589 - acc: 0.4600 - val_loss: 2.2573 - val_acc: 0.2433\n",
      "Epoch 274/1000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.3584 - acc: 0.4629 - val_loss: 2.2636 - val_acc: 0.2433\n",
      "Epoch 275/1000\n",
      "700/700 [==============================] - 0s 121us/step - loss: 1.3582 - acc: 0.4557 - val_loss: 2.2587 - val_acc: 0.2433\n",
      "Epoch 276/1000\n",
      "700/700 [==============================] - 0s 85us/step - loss: 1.3581 - acc: 0.4643 - val_loss: 2.2821 - val_acc: 0.2467\n",
      "Epoch 277/1000\n",
      "700/700 [==============================] - 0s 85us/step - loss: 1.3581 - acc: 0.4543 - val_loss: 2.2825 - val_acc: 0.2433\n",
      "Epoch 278/1000\n",
      "700/700 [==============================] - 0s 87us/step - loss: 1.3579 - acc: 0.4629 - val_loss: 2.2797 - val_acc: 0.2500\n",
      "Epoch 279/1000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.3573 - acc: 0.4557 - val_loss: 2.2645 - val_acc: 0.2433\n",
      "Epoch 280/1000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.3575 - acc: 0.4643 - val_loss: 2.2775 - val_acc: 0.2467\n",
      "Epoch 281/1000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.3574 - acc: 0.4571 - val_loss: 2.2796 - val_acc: 0.2467\n",
      "Epoch 282/1000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 1.3565 - acc: 0.4614 - val_loss: 2.2658 - val_acc: 0.2400\n",
      "Epoch 283/1000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.3573 - acc: 0.4571 - val_loss: 2.2679 - val_acc: 0.2433\n",
      "Epoch 284/1000\n",
      "700/700 [==============================] - 0s 115us/step - loss: 1.3574 - acc: 0.4586 - val_loss: 2.2690 - val_acc: 0.2400\n",
      "Epoch 285/1000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.3574 - acc: 0.4643 - val_loss: 2.2655 - val_acc: 0.2433\n",
      "Epoch 286/1000\n",
      "700/700 [==============================] - 0s 86us/step - loss: 1.3567 - acc: 0.4586 - val_loss: 2.2874 - val_acc: 0.2500\n",
      "Epoch 287/1000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.3572 - acc: 0.4614 - val_loss: 2.2769 - val_acc: 0.2467\n",
      "Epoch 288/1000\n",
      "700/700 [==============================] - 0s 86us/step - loss: 1.3572 - acc: 0.4629 - val_loss: 2.2624 - val_acc: 0.2433\n",
      "Epoch 289/1000\n",
      "700/700 [==============================] - 0s 80us/step - loss: 1.3575 - acc: 0.4657 - val_loss: 2.2554 - val_acc: 0.2433\n",
      "Epoch 290/1000\n",
      "700/700 [==============================] - 0s 77us/step - loss: 1.3561 - acc: 0.4671 - val_loss: 2.2735 - val_acc: 0.2467\n",
      "Epoch 291/1000\n",
      "700/700 [==============================] - 0s 84us/step - loss: 1.3569 - acc: 0.4643 - val_loss: 2.2695 - val_acc: 0.2267\n",
      "Epoch 292/1000\n",
      "700/700 [==============================] - 0s 76us/step - loss: 1.3562 - acc: 0.4529 - val_loss: 2.2623 - val_acc: 0.2333\n",
      "Epoch 293/1000\n",
      "700/700 [==============================] - 0s 118us/step - loss: 1.3548 - acc: 0.4629 - val_loss: 2.2705 - val_acc: 0.2433\n",
      "Epoch 294/1000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.3566 - acc: 0.4629 - val_loss: 2.2835 - val_acc: 0.2500\n",
      "Epoch 295/1000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.3562 - acc: 0.4629 - val_loss: 2.2607 - val_acc: 0.2400\n",
      "Epoch 296/1000\n",
      "700/700 [==============================] - 0s 112us/step - loss: 1.3564 - acc: 0.4614 - val_loss: 2.2850 - val_acc: 0.2467\n",
      "Epoch 297/1000\n",
      "700/700 [==============================] - 0s 87us/step - loss: 1.3553 - acc: 0.4643 - val_loss: 2.2852 - val_acc: 0.2467\n",
      "Epoch 298/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 82us/step - loss: 1.3567 - acc: 0.4600 - val_loss: 2.2823 - val_acc: 0.2467\n",
      "Epoch 299/1000\n",
      "700/700 [==============================] - 0s 98us/step - loss: 1.3559 - acc: 0.4629 - val_loss: 2.2753 - val_acc: 0.2467\n",
      "Epoch 300/1000\n",
      "700/700 [==============================] - 0s 118us/step - loss: 1.3555 - acc: 0.4671 - val_loss: 2.2861 - val_acc: 0.2500\n",
      "Epoch 301/1000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 1.3555 - acc: 0.4557 - val_loss: 2.2817 - val_acc: 0.2400\n",
      "Epoch 302/1000\n",
      "700/700 [==============================] - 0s 112us/step - loss: 1.3560 - acc: 0.4571 - val_loss: 2.2722 - val_acc: 0.2433\n",
      "Epoch 303/1000\n",
      "700/700 [==============================] - 0s 121us/step - loss: 1.3553 - acc: 0.4614 - val_loss: 2.2750 - val_acc: 0.2467\n",
      "Epoch 304/1000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.3565 - acc: 0.4571 - val_loss: 2.2779 - val_acc: 0.2433\n",
      "Epoch 305/1000\n",
      "700/700 [==============================] - 0s 80us/step - loss: 1.3558 - acc: 0.4643 - val_loss: 2.2827 - val_acc: 0.2467\n",
      "Epoch 306/1000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.3554 - acc: 0.4614 - val_loss: 2.2797 - val_acc: 0.2433\n",
      "Epoch 307/1000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.3552 - acc: 0.4671 - val_loss: 2.2826 - val_acc: 0.2433\n",
      "Epoch 308/1000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.3553 - acc: 0.4671 - val_loss: 2.2646 - val_acc: 0.2400\n",
      "Epoch 309/1000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 1.3546 - acc: 0.4657 - val_loss: 2.2891 - val_acc: 0.2300\n",
      "Epoch 310/1000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.3552 - acc: 0.4586 - val_loss: 2.2775 - val_acc: 0.2367\n",
      "Epoch 311/1000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.3543 - acc: 0.4614 - val_loss: 2.2796 - val_acc: 0.2467\n",
      "Epoch 312/1000\n",
      "700/700 [==============================] - 0s 116us/step - loss: 1.3554 - acc: 0.4657 - val_loss: 2.2776 - val_acc: 0.2433\n",
      "Epoch 313/1000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 1.3537 - acc: 0.4643 - val_loss: 2.2735 - val_acc: 0.2300\n",
      "Epoch 314/1000\n",
      "700/700 [==============================] - 0s 116us/step - loss: 1.3529 - acc: 0.4671 - val_loss: 2.2739 - val_acc: 0.2400\n",
      "Epoch 315/1000\n",
      "700/700 [==============================] - 0s 98us/step - loss: 1.3545 - acc: 0.4643 - val_loss: 2.2707 - val_acc: 0.2433\n",
      "Epoch 316/1000\n",
      "700/700 [==============================] - 0s 117us/step - loss: 1.3548 - acc: 0.4657 - val_loss: 2.2754 - val_acc: 0.2467\n",
      "Epoch 317/1000\n",
      "700/700 [==============================] - 0s 117us/step - loss: 1.3534 - acc: 0.4729 - val_loss: 2.2724 - val_acc: 0.2433\n",
      "Epoch 318/1000\n",
      "700/700 [==============================] - 0s 117us/step - loss: 1.3537 - acc: 0.4657 - val_loss: 2.2794 - val_acc: 0.2300\n",
      "Epoch 319/1000\n",
      "700/700 [==============================] - 0s 112us/step - loss: 1.3545 - acc: 0.4600 - val_loss: 2.2767 - val_acc: 0.2467\n",
      "Epoch 320/1000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.3542 - acc: 0.4600 - val_loss: 2.2726 - val_acc: 0.2400\n",
      "Epoch 321/1000\n",
      "700/700 [==============================] - 0s 115us/step - loss: 1.3538 - acc: 0.4614 - val_loss: 2.2726 - val_acc: 0.2400\n",
      "Epoch 322/1000\n",
      "700/700 [==============================] - 0s 88us/step - loss: 1.3542 - acc: 0.4643 - val_loss: 2.2800 - val_acc: 0.2467\n",
      "Epoch 323/1000\n",
      "700/700 [==============================] - 0s 78us/step - loss: 1.3534 - acc: 0.4657 - val_loss: 2.2935 - val_acc: 0.2433\n",
      "Epoch 324/1000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3551 - acc: 0.4671 - val_loss: 2.2817 - val_acc: 0.2433\n",
      "Epoch 325/1000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.3540 - acc: 0.4600 - val_loss: 2.2826 - val_acc: 0.2433\n",
      "Epoch 326/1000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.3534 - acc: 0.4657 - val_loss: 2.2877 - val_acc: 0.2400\n",
      "Epoch 327/1000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.3517 - acc: 0.4629 - val_loss: 2.2831 - val_acc: 0.2433\n",
      "Epoch 328/1000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.3524 - acc: 0.4671 - val_loss: 2.2795 - val_acc: 0.2367\n",
      "Epoch 329/1000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 1.3534 - acc: 0.4586 - val_loss: 2.2737 - val_acc: 0.2333\n",
      "Epoch 330/1000\n",
      "700/700 [==============================] - 0s 112us/step - loss: 1.3528 - acc: 0.4686 - val_loss: 2.2811 - val_acc: 0.2433\n",
      "Epoch 331/1000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.3516 - acc: 0.4700 - val_loss: 2.3099 - val_acc: 0.2333\n",
      "Epoch 332/1000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.3534 - acc: 0.4700 - val_loss: 2.3043 - val_acc: 0.2367\n",
      "Epoch 333/1000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 1.3529 - acc: 0.4657 - val_loss: 2.2939 - val_acc: 0.2467\n",
      "Epoch 334/1000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.3529 - acc: 0.4629 - val_loss: 2.2836 - val_acc: 0.2433\n",
      "Epoch 335/1000\n",
      "700/700 [==============================] - 0s 116us/step - loss: 1.3528 - acc: 0.4614 - val_loss: 2.2931 - val_acc: 0.2433\n",
      "Epoch 336/1000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.3517 - acc: 0.4671 - val_loss: 2.2952 - val_acc: 0.2500\n",
      "Epoch 337/1000\n",
      "700/700 [==============================] - 0s 119us/step - loss: 1.3525 - acc: 0.4614 - val_loss: 2.2938 - val_acc: 0.2500\n",
      "Epoch 338/1000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.3528 - acc: 0.4657 - val_loss: 2.2916 - val_acc: 0.2433\n",
      "Epoch 339/1000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.3514 - acc: 0.4614 - val_loss: 2.2862 - val_acc: 0.2433\n",
      "Epoch 340/1000\n",
      "700/700 [==============================] - 0s 112us/step - loss: 1.3517 - acc: 0.4657 - val_loss: 2.2912 - val_acc: 0.2500\n",
      "Epoch 341/1000\n",
      "700/700 [==============================] - 0s 108us/step - loss: 1.3533 - acc: 0.4586 - val_loss: 2.2664 - val_acc: 0.2433\n",
      "Epoch 342/1000\n",
      "700/700 [==============================] - 0s 112us/step - loss: 1.3527 - acc: 0.4629 - val_loss: 2.2694 - val_acc: 0.2467\n",
      "Epoch 343/1000\n",
      "700/700 [==============================] - 0s 112us/step - loss: 1.3514 - acc: 0.4700 - val_loss: 2.3170 - val_acc: 0.2467\n",
      "Epoch 344/1000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.3531 - acc: 0.4643 - val_loss: 2.2800 - val_acc: 0.2500\n",
      "Epoch 345/1000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.3518 - acc: 0.4686 - val_loss: 2.3040 - val_acc: 0.2500\n",
      "Epoch 346/1000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.3526 - acc: 0.4700 - val_loss: 2.2942 - val_acc: 0.2500\n",
      "Epoch 347/1000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 1.3514 - acc: 0.4643 - val_loss: 2.2914 - val_acc: 0.2400\n",
      "Epoch 348/1000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 1.3514 - acc: 0.4729 - val_loss: 2.2942 - val_acc: 0.2467\n",
      "Epoch 349/1000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.3515 - acc: 0.4614 - val_loss: 2.3112 - val_acc: 0.2467\n",
      "Epoch 350/1000\n",
      "700/700 [==============================] - 0s 122us/step - loss: 1.3509 - acc: 0.4714 - val_loss: 2.2876 - val_acc: 0.2500\n",
      "Epoch 351/1000\n",
      "700/700 [==============================] - 0s 118us/step - loss: 1.3515 - acc: 0.4657 - val_loss: 2.2767 - val_acc: 0.2433\n",
      "Epoch 352/1000\n",
      "700/700 [==============================] - 0s 117us/step - loss: 1.3510 - acc: 0.4686 - val_loss: 2.2953 - val_acc: 0.2400\n",
      "Epoch 353/1000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.3507 - acc: 0.4586 - val_loss: 2.3090 - val_acc: 0.2500\n",
      "Epoch 354/1000\n",
      "700/700 [==============================] - 0s 115us/step - loss: 1.3511 - acc: 0.4671 - val_loss: 2.3075 - val_acc: 0.2467\n",
      "Epoch 355/1000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.3501 - acc: 0.4686 - val_loss: 2.2863 - val_acc: 0.2467\n",
      "Epoch 356/1000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.3509 - acc: 0.4643 - val_loss: 2.2873 - val_acc: 0.2433\n",
      "Epoch 357/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 109us/step - loss: 1.3508 - acc: 0.4657 - val_loss: 2.2944 - val_acc: 0.2467\n",
      "Epoch 358/1000\n",
      "700/700 [==============================] - 0s 117us/step - loss: 1.3506 - acc: 0.4614 - val_loss: 2.2837 - val_acc: 0.2400\n",
      "Epoch 359/1000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.3507 - acc: 0.4700 - val_loss: 2.3013 - val_acc: 0.2400\n",
      "Epoch 360/1000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.3508 - acc: 0.4671 - val_loss: 2.2934 - val_acc: 0.2400\n",
      "Epoch 361/1000\n",
      "700/700 [==============================] - 0s 108us/step - loss: 1.3500 - acc: 0.4729 - val_loss: 2.2872 - val_acc: 0.2500\n",
      "Epoch 362/1000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 1.3493 - acc: 0.4686 - val_loss: 2.2923 - val_acc: 0.2467\n",
      "Epoch 363/1000\n",
      "700/700 [==============================] - 0s 125us/step - loss: 1.3500 - acc: 0.4629 - val_loss: 2.2941 - val_acc: 0.2433\n",
      "Epoch 364/1000\n",
      "700/700 [==============================] - 0s 108us/step - loss: 1.3500 - acc: 0.4671 - val_loss: 2.2810 - val_acc: 0.2467\n",
      "Epoch 365/1000\n",
      "700/700 [==============================] - 0s 108us/step - loss: 1.3502 - acc: 0.4671 - val_loss: 2.2860 - val_acc: 0.2333\n",
      "Epoch 366/1000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.3496 - acc: 0.4671 - val_loss: 2.2931 - val_acc: 0.2433\n",
      "Epoch 367/1000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.3502 - acc: 0.4643 - val_loss: 2.2884 - val_acc: 0.2533\n",
      "Epoch 368/1000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.3500 - acc: 0.4671 - val_loss: 2.2773 - val_acc: 0.2433\n",
      "Epoch 369/1000\n",
      "700/700 [==============================] - 0s 81us/step - loss: 1.3497 - acc: 0.4629 - val_loss: 2.2841 - val_acc: 0.2400\n",
      "Epoch 370/1000\n",
      "700/700 [==============================] - 0s 85us/step - loss: 1.3500 - acc: 0.4714 - val_loss: 2.2900 - val_acc: 0.2433\n",
      "Epoch 371/1000\n",
      "700/700 [==============================] - 0s 82us/step - loss: 1.3504 - acc: 0.4714 - val_loss: 2.2871 - val_acc: 0.2433\n",
      "Epoch 372/1000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 1.3494 - acc: 0.4700 - val_loss: 2.2957 - val_acc: 0.2433\n",
      "Epoch 373/1000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.3495 - acc: 0.4671 - val_loss: 2.2942 - val_acc: 0.2433\n",
      "Epoch 374/1000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.3488 - acc: 0.4629 - val_loss: 2.2887 - val_acc: 0.2500\n",
      "Epoch 375/1000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 1.3492 - acc: 0.4671 - val_loss: 2.3042 - val_acc: 0.2467\n",
      "Epoch 376/1000\n",
      "700/700 [==============================] - 0s 118us/step - loss: 1.3483 - acc: 0.4643 - val_loss: 2.3032 - val_acc: 0.2500\n",
      "Epoch 377/1000\n",
      "700/700 [==============================] - 0s 112us/step - loss: 1.3491 - acc: 0.4657 - val_loss: 2.3172 - val_acc: 0.2500\n",
      "Epoch 378/1000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.3475 - acc: 0.4671 - val_loss: 2.3016 - val_acc: 0.2533\n",
      "Epoch 379/1000\n",
      "700/700 [==============================] - 0s 112us/step - loss: 1.3491 - acc: 0.4643 - val_loss: 2.3045 - val_acc: 0.2533\n",
      "Epoch 380/1000\n",
      "700/700 [==============================] - 0s 108us/step - loss: 1.3480 - acc: 0.4671 - val_loss: 2.3036 - val_acc: 0.2433\n",
      "Epoch 381/1000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.3483 - acc: 0.4686 - val_loss: 2.3049 - val_acc: 0.2467\n",
      "Epoch 382/1000\n",
      "700/700 [==============================] - 0s 112us/step - loss: 1.3490 - acc: 0.4671 - val_loss: 2.3063 - val_acc: 0.2400\n",
      "Epoch 383/1000\n",
      "700/700 [==============================] - 0s 123us/step - loss: 1.3477 - acc: 0.4757 - val_loss: 2.2930 - val_acc: 0.2467\n",
      "Epoch 384/1000\n",
      "700/700 [==============================] - 0s 125us/step - loss: 1.3486 - acc: 0.4643 - val_loss: 2.2966 - val_acc: 0.2433\n",
      "Epoch 385/1000\n",
      "700/700 [==============================] - 0s 120us/step - loss: 1.3492 - acc: 0.4643 - val_loss: 2.2972 - val_acc: 0.2467\n",
      "Epoch 386/1000\n",
      "700/700 [==============================] - 0s 117us/step - loss: 1.3477 - acc: 0.4629 - val_loss: 2.2928 - val_acc: 0.2433\n",
      "Epoch 387/1000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.3475 - acc: 0.4657 - val_loss: 2.3044 - val_acc: 0.2467\n",
      "Epoch 388/1000\n",
      "700/700 [==============================] - 0s 88us/step - loss: 1.3479 - acc: 0.4686 - val_loss: 2.3010 - val_acc: 0.2400\n",
      "Epoch 389/1000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 1.3463 - acc: 0.4743 - val_loss: 2.3094 - val_acc: 0.2467\n",
      "Epoch 390/1000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.3475 - acc: 0.4714 - val_loss: 2.2899 - val_acc: 0.2467\n",
      "Epoch 391/1000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3485 - acc: 0.4686 - val_loss: 2.3020 - val_acc: 0.2400\n",
      "Epoch 392/1000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.3489 - acc: 0.4729 - val_loss: 2.3112 - val_acc: 0.2400\n",
      "Epoch 393/1000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.3476 - acc: 0.4643 - val_loss: 2.2958 - val_acc: 0.2467\n",
      "Epoch 394/1000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.3477 - acc: 0.4643 - val_loss: 2.3137 - val_acc: 0.2467\n",
      "Epoch 395/1000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.3480 - acc: 0.4686 - val_loss: 2.2910 - val_acc: 0.2467\n",
      "Epoch 396/1000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 1.3479 - acc: 0.4657 - val_loss: 2.3311 - val_acc: 0.2467\n",
      "Epoch 397/1000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.3479 - acc: 0.4686 - val_loss: 2.2972 - val_acc: 0.2433\n",
      "Epoch 398/1000\n",
      "700/700 [==============================] - 0s 112us/step - loss: 1.3476 - acc: 0.4714 - val_loss: 2.3006 - val_acc: 0.2467\n",
      "Epoch 399/1000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.3466 - acc: 0.4600 - val_loss: 2.3034 - val_acc: 0.2300\n",
      "Epoch 400/1000\n",
      "700/700 [==============================] - 0s 126us/step - loss: 1.3468 - acc: 0.4671 - val_loss: 2.3170 - val_acc: 0.2467\n",
      "Epoch 401/1000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.3475 - acc: 0.4571 - val_loss: 2.2999 - val_acc: 0.2433\n",
      "Epoch 402/1000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.3471 - acc: 0.4671 - val_loss: 2.2967 - val_acc: 0.2500\n",
      "Epoch 403/1000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.3470 - acc: 0.4714 - val_loss: 2.2961 - val_acc: 0.2500\n",
      "Epoch 404/1000\n",
      "700/700 [==============================] - 0s 125us/step - loss: 1.3459 - acc: 0.4700 - val_loss: 2.2922 - val_acc: 0.2333\n",
      "Epoch 405/1000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.3468 - acc: 0.4700 - val_loss: 2.2887 - val_acc: 0.2433\n",
      "Epoch 406/1000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.3467 - acc: 0.4657 - val_loss: 2.2901 - val_acc: 0.2433\n",
      "Epoch 407/1000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.3456 - acc: 0.4686 - val_loss: 2.3017 - val_acc: 0.2467\n",
      "Epoch 408/1000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.3474 - acc: 0.4671 - val_loss: 2.2936 - val_acc: 0.2400\n",
      "Epoch 409/1000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.3473 - acc: 0.4657 - val_loss: 2.2964 - val_acc: 0.2433\n",
      "Epoch 410/1000\n",
      "700/700 [==============================] - 0s 124us/step - loss: 1.3459 - acc: 0.4700 - val_loss: 2.2975 - val_acc: 0.2500\n",
      "Epoch 411/1000\n",
      "700/700 [==============================] - 0s 120us/step - loss: 1.3460 - acc: 0.4671 - val_loss: 2.3188 - val_acc: 0.2500\n",
      "Epoch 412/1000\n",
      "700/700 [==============================] - 0s 121us/step - loss: 1.3457 - acc: 0.4657 - val_loss: 2.2965 - val_acc: 0.2467\n",
      "Epoch 413/1000\n",
      "700/700 [==============================] - 0s 119us/step - loss: 1.3466 - acc: 0.4700 - val_loss: 2.3031 - val_acc: 0.2433\n",
      "Epoch 414/1000\n",
      "700/700 [==============================] - 0s 118us/step - loss: 1.3456 - acc: 0.4657 - val_loss: 2.2981 - val_acc: 0.2433\n",
      "Epoch 415/1000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 1.3452 - acc: 0.4771 - val_loss: 2.2997 - val_acc: 0.2333\n",
      "Epoch 416/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 104us/step - loss: 1.3460 - acc: 0.4657 - val_loss: 2.3138 - val_acc: 0.2300\n",
      "Epoch 417/1000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.3461 - acc: 0.4671 - val_loss: 2.3046 - val_acc: 0.2433\n",
      "Epoch 418/1000\n",
      "700/700 [==============================] - 0s 115us/step - loss: 1.3446 - acc: 0.4686 - val_loss: 2.3006 - val_acc: 0.2333\n",
      "Epoch 419/1000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.3460 - acc: 0.4657 - val_loss: 2.3039 - val_acc: 0.2400\n",
      "Epoch 420/1000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.3463 - acc: 0.4757 - val_loss: 2.3087 - val_acc: 0.2433\n",
      "Epoch 421/1000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.3450 - acc: 0.4657 - val_loss: 2.3176 - val_acc: 0.2400\n",
      "Epoch 422/1000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.3446 - acc: 0.4700 - val_loss: 2.3169 - val_acc: 0.2500\n",
      "Epoch 423/1000\n",
      "700/700 [==============================] - 0s 118us/step - loss: 1.3453 - acc: 0.4671 - val_loss: 2.3060 - val_acc: 0.2533\n",
      "Epoch 424/1000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.3450 - acc: 0.4671 - val_loss: 2.2885 - val_acc: 0.2433\n",
      "Epoch 425/1000\n",
      "700/700 [==============================] - 0s 75us/step - loss: 1.3452 - acc: 0.4700 - val_loss: 2.2983 - val_acc: 0.2467\n",
      "Epoch 426/1000\n",
      "700/700 [==============================] - 0s 82us/step - loss: 1.3447 - acc: 0.4686 - val_loss: 2.3008 - val_acc: 0.2500\n",
      "Epoch 427/1000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.3452 - acc: 0.4729 - val_loss: 2.2971 - val_acc: 0.2433\n",
      "Epoch 428/1000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.3450 - acc: 0.4686 - val_loss: 2.3101 - val_acc: 0.2500\n",
      "Epoch 429/1000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.3446 - acc: 0.4729 - val_loss: 2.3025 - val_acc: 0.2500\n",
      "Epoch 430/1000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 1.3428 - acc: 0.4757 - val_loss: 2.3122 - val_acc: 0.2333\n",
      "Epoch 431/1000\n",
      "700/700 [==============================] - 0s 118us/step - loss: 1.3440 - acc: 0.4671 - val_loss: 2.3080 - val_acc: 0.2500\n",
      "Epoch 432/1000\n",
      "700/700 [==============================] - 0s 115us/step - loss: 1.3447 - acc: 0.4729 - val_loss: 2.2975 - val_acc: 0.2433\n",
      "Epoch 433/1000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3442 - acc: 0.4671 - val_loss: 2.3174 - val_acc: 0.2367\n",
      "Epoch 434/1000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.3443 - acc: 0.4671 - val_loss: 2.3131 - val_acc: 0.2433\n",
      "Epoch 435/1000\n",
      "700/700 [==============================] - 0s 81us/step - loss: 1.3448 - acc: 0.4700 - val_loss: 2.3057 - val_acc: 0.2400\n",
      "Epoch 436/1000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 1.3443 - acc: 0.4757 - val_loss: 2.3046 - val_acc: 0.2433\n",
      "Epoch 437/1000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.3430 - acc: 0.4686 - val_loss: 2.3194 - val_acc: 0.2367\n",
      "Epoch 438/1000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 1.3441 - acc: 0.4643 - val_loss: 2.3038 - val_acc: 0.2367\n",
      "Epoch 439/1000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 1.3443 - acc: 0.4729 - val_loss: 2.3041 - val_acc: 0.2367\n",
      "Epoch 440/1000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 1.3429 - acc: 0.4686 - val_loss: 2.3151 - val_acc: 0.2400\n",
      "Epoch 441/1000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.3435 - acc: 0.4686 - val_loss: 2.2969 - val_acc: 0.2467\n",
      "Epoch 442/1000\n",
      "700/700 [==============================] - 0s 126us/step - loss: 1.3435 - acc: 0.4686 - val_loss: 2.3292 - val_acc: 0.2467\n",
      "Epoch 443/1000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.3427 - acc: 0.4714 - val_loss: 2.3163 - val_acc: 0.2467\n",
      "Epoch 444/1000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.3435 - acc: 0.4743 - val_loss: 2.3013 - val_acc: 0.2500\n",
      "Epoch 445/1000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.3434 - acc: 0.4757 - val_loss: 2.2997 - val_acc: 0.2467\n",
      "Epoch 446/1000\n",
      "700/700 [==============================] - 0s 116us/step - loss: 1.3432 - acc: 0.4629 - val_loss: 2.2964 - val_acc: 0.2433\n",
      "Epoch 447/1000\n",
      "700/700 [==============================] - 0s 120us/step - loss: 1.3430 - acc: 0.4643 - val_loss: 2.3069 - val_acc: 0.2500\n",
      "Epoch 448/1000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.3437 - acc: 0.4671 - val_loss: 2.3282 - val_acc: 0.2433\n",
      "Epoch 449/1000\n",
      "700/700 [==============================] - 0s 119us/step - loss: 1.3434 - acc: 0.4629 - val_loss: 2.3056 - val_acc: 0.2467\n",
      "Epoch 450/1000\n",
      "700/700 [==============================] - 0s 118us/step - loss: 1.3427 - acc: 0.4686 - val_loss: 2.3238 - val_acc: 0.2467\n",
      "Epoch 451/1000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.3429 - acc: 0.4671 - val_loss: 2.3122 - val_acc: 0.2433\n",
      "Epoch 452/1000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.3430 - acc: 0.4757 - val_loss: 2.3181 - val_acc: 0.2433\n",
      "Epoch 453/1000\n",
      "700/700 [==============================] - 0s 123us/step - loss: 1.3427 - acc: 0.4686 - val_loss: 2.3067 - val_acc: 0.2433\n",
      "Epoch 454/1000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.3430 - acc: 0.4643 - val_loss: 2.2987 - val_acc: 0.2467\n",
      "Epoch 455/1000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.3422 - acc: 0.4686 - val_loss: 2.3040 - val_acc: 0.2367\n",
      "Epoch 456/1000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.3431 - acc: 0.4771 - val_loss: 2.3099 - val_acc: 0.2467\n",
      "Epoch 457/1000\n",
      "700/700 [==============================] - 0s 98us/step - loss: 1.3429 - acc: 0.4643 - val_loss: 2.3127 - val_acc: 0.2400\n",
      "Epoch 458/1000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 1.3421 - acc: 0.4743 - val_loss: 2.3323 - val_acc: 0.2467\n",
      "Epoch 459/1000\n",
      "700/700 [==============================] - 0s 121us/step - loss: 1.3418 - acc: 0.4757 - val_loss: 2.3359 - val_acc: 0.2433\n",
      "Epoch 460/1000\n",
      "700/700 [==============================] - 0s 128us/step - loss: 1.3421 - acc: 0.4686 - val_loss: 2.3071 - val_acc: 0.2500\n",
      "Epoch 461/1000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.3420 - acc: 0.4700 - val_loss: 2.3118 - val_acc: 0.2467\n",
      "Epoch 462/1000\n",
      "700/700 [==============================] - 0s 116us/step - loss: 1.3414 - acc: 0.4714 - val_loss: 2.3023 - val_acc: 0.2467\n",
      "Epoch 463/1000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.3421 - acc: 0.4729 - val_loss: 2.3134 - val_acc: 0.2500\n",
      "Epoch 464/1000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.3416 - acc: 0.4700 - val_loss: 2.3150 - val_acc: 0.2467\n",
      "Epoch 465/1000\n",
      "700/700 [==============================] - 0s 117us/step - loss: 1.3415 - acc: 0.4686 - val_loss: 2.3276 - val_acc: 0.2467\n",
      "Epoch 466/1000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.3414 - acc: 0.4671 - val_loss: 2.3268 - val_acc: 0.2367\n",
      "Epoch 467/1000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.3425 - acc: 0.4714 - val_loss: 2.3147 - val_acc: 0.2467\n",
      "Epoch 468/1000\n",
      "700/700 [==============================] - 0s 108us/step - loss: 1.3423 - acc: 0.4686 - val_loss: 2.3174 - val_acc: 0.2433\n",
      "Epoch 469/1000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.3412 - acc: 0.4700 - val_loss: 2.3148 - val_acc: 0.2467\n",
      "Epoch 470/1000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.3416 - acc: 0.4729 - val_loss: 2.3104 - val_acc: 0.2433\n",
      "Epoch 471/1000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 1.3406 - acc: 0.4714 - val_loss: 2.3204 - val_acc: 0.2433\n",
      "Epoch 472/1000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.3411 - acc: 0.4686 - val_loss: 2.3158 - val_acc: 0.2500\n",
      "Epoch 473/1000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.3404 - acc: 0.4743 - val_loss: 2.3132 - val_acc: 0.2367\n",
      "Epoch 474/1000\n",
      "700/700 [==============================] - 0s 75us/step - loss: 1.3410 - acc: 0.4657 - val_loss: 2.3077 - val_acc: 0.2467\n",
      "Epoch 475/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 78us/step - loss: 1.3404 - acc: 0.4714 - val_loss: 2.3103 - val_acc: 0.2433\n",
      "Epoch 476/1000\n",
      "700/700 [==============================] - 0s 125us/step - loss: 1.3414 - acc: 0.4743 - val_loss: 2.3242 - val_acc: 0.2400\n",
      "Epoch 477/1000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.3411 - acc: 0.4729 - val_loss: 2.3165 - val_acc: 0.2467\n",
      "Epoch 478/1000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.3410 - acc: 0.4629 - val_loss: 2.3189 - val_acc: 0.2400\n",
      "Epoch 479/1000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.3406 - acc: 0.4729 - val_loss: 2.3084 - val_acc: 0.2467\n",
      "Epoch 480/1000\n",
      "700/700 [==============================] - 0s 123us/step - loss: 1.3398 - acc: 0.4657 - val_loss: 2.3059 - val_acc: 0.2367\n",
      "Epoch 481/1000\n",
      "700/700 [==============================] - 0s 112us/step - loss: 1.3404 - acc: 0.4786 - val_loss: 2.3300 - val_acc: 0.2433\n",
      "Epoch 482/1000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 1.3413 - acc: 0.4686 - val_loss: 2.3290 - val_acc: 0.2467\n",
      "Epoch 483/1000\n",
      "700/700 [==============================] - 0s 112us/step - loss: 1.3404 - acc: 0.4686 - val_loss: 2.3278 - val_acc: 0.2433\n",
      "Epoch 484/1000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.3402 - acc: 0.4686 - val_loss: 2.3069 - val_acc: 0.2433\n",
      "Epoch 485/1000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.3401 - acc: 0.4757 - val_loss: 2.3298 - val_acc: 0.2467\n",
      "Epoch 486/1000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.3403 - acc: 0.4743 - val_loss: 2.3110 - val_acc: 0.2433\n",
      "Epoch 487/1000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.3399 - acc: 0.4657 - val_loss: 2.3365 - val_acc: 0.2467\n",
      "Epoch 488/1000\n",
      "700/700 [==============================] - 0s 112us/step - loss: 1.3393 - acc: 0.4686 - val_loss: 2.3406 - val_acc: 0.2467\n",
      "Epoch 489/1000\n",
      "700/700 [==============================] - 0s 115us/step - loss: 1.3407 - acc: 0.4714 - val_loss: 2.3337 - val_acc: 0.2500\n",
      "Epoch 490/1000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.3396 - acc: 0.4757 - val_loss: 2.3297 - val_acc: 0.2433\n",
      "Epoch 491/1000\n",
      "700/700 [==============================] - 0s 108us/step - loss: 1.3393 - acc: 0.4629 - val_loss: 2.3196 - val_acc: 0.2467\n",
      "Epoch 492/1000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.3387 - acc: 0.4729 - val_loss: 2.3169 - val_acc: 0.2433\n",
      "Epoch 493/1000\n",
      "700/700 [==============================] - 0s 122us/step - loss: 1.3394 - acc: 0.4686 - val_loss: 2.3079 - val_acc: 0.2467\n",
      "Epoch 494/1000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.3394 - acc: 0.4729 - val_loss: 2.3355 - val_acc: 0.2433\n",
      "Epoch 495/1000\n",
      "700/700 [==============================] - 0s 112us/step - loss: 1.3395 - acc: 0.4729 - val_loss: 2.3195 - val_acc: 0.2433\n",
      "Epoch 496/1000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.3395 - acc: 0.4686 - val_loss: 2.3178 - val_acc: 0.2400\n",
      "Epoch 497/1000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.3401 - acc: 0.4729 - val_loss: 2.3112 - val_acc: 0.2433\n",
      "Epoch 498/1000\n",
      "700/700 [==============================] - 0s 129us/step - loss: 1.3391 - acc: 0.4729 - val_loss: 2.3371 - val_acc: 0.2433\n",
      "Epoch 499/1000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 1.3395 - acc: 0.4729 - val_loss: 2.3231 - val_acc: 0.2400\n",
      "Epoch 500/1000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.3383 - acc: 0.4786 - val_loss: 2.3183 - val_acc: 0.2367\n",
      "Epoch 501/1000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.3390 - acc: 0.4714 - val_loss: 2.3027 - val_acc: 0.2433\n",
      "Epoch 502/1000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.3390 - acc: 0.4743 - val_loss: 2.3287 - val_acc: 0.2467\n",
      "Epoch 503/1000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.3386 - acc: 0.4671 - val_loss: 2.3207 - val_acc: 0.2467\n",
      "Epoch 504/1000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.3379 - acc: 0.4757 - val_loss: 2.3190 - val_acc: 0.2367\n",
      "Epoch 505/1000\n",
      "700/700 [==============================] - 0s 122us/step - loss: 1.3387 - acc: 0.4700 - val_loss: 2.3268 - val_acc: 0.2400\n",
      "Epoch 506/1000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.3387 - acc: 0.4714 - val_loss: 2.3252 - val_acc: 0.2433\n",
      "Epoch 507/1000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.3389 - acc: 0.4686 - val_loss: 2.3253 - val_acc: 0.2433\n",
      "Epoch 508/1000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.3379 - acc: 0.4700 - val_loss: 2.3154 - val_acc: 0.2433\n",
      "Epoch 509/1000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.3383 - acc: 0.4671 - val_loss: 2.3104 - val_acc: 0.2500\n",
      "Epoch 510/1000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.3378 - acc: 0.4700 - val_loss: 2.3214 - val_acc: 0.2400\n",
      "Epoch 511/1000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 1.3383 - acc: 0.4643 - val_loss: 2.3203 - val_acc: 0.2367\n",
      "Epoch 512/1000\n",
      "700/700 [==============================] - 0s 92us/step - loss: 1.3374 - acc: 0.4757 - val_loss: 2.3444 - val_acc: 0.2433\n",
      "Epoch 513/1000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.3385 - acc: 0.4714 - val_loss: 2.3286 - val_acc: 0.2400\n",
      "Epoch 514/1000\n",
      "700/700 [==============================] - 0s 120us/step - loss: 1.3381 - acc: 0.4743 - val_loss: 2.3265 - val_acc: 0.2433\n",
      "Epoch 515/1000\n",
      "700/700 [==============================] - 0s 120us/step - loss: 1.3370 - acc: 0.4729 - val_loss: 2.3375 - val_acc: 0.2433\n",
      "Epoch 516/1000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.3379 - acc: 0.4686 - val_loss: 2.3471 - val_acc: 0.2467\n",
      "Epoch 517/1000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.3372 - acc: 0.4743 - val_loss: 2.3182 - val_acc: 0.2500\n",
      "Epoch 518/1000\n",
      "700/700 [==============================] - 0s 108us/step - loss: 1.3393 - acc: 0.4657 - val_loss: 2.3030 - val_acc: 0.2467\n",
      "Epoch 519/1000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.3371 - acc: 0.4786 - val_loss: 2.3260 - val_acc: 0.2433\n",
      "Epoch 520/1000\n",
      "700/700 [==============================] - 0s 115us/step - loss: 1.3383 - acc: 0.4729 - val_loss: 2.3401 - val_acc: 0.2433\n",
      "Epoch 521/1000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 1.3369 - acc: 0.4757 - val_loss: 2.3555 - val_acc: 0.2467\n",
      "Epoch 522/1000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.3382 - acc: 0.4714 - val_loss: 2.3268 - val_acc: 0.2433\n",
      "Epoch 523/1000\n",
      "700/700 [==============================] - 0s 117us/step - loss: 1.3370 - acc: 0.4757 - val_loss: 2.3472 - val_acc: 0.2500\n",
      "Epoch 524/1000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.3371 - acc: 0.4700 - val_loss: 2.3419 - val_acc: 0.2500\n",
      "Epoch 525/1000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.3362 - acc: 0.4857 - val_loss: 2.3242 - val_acc: 0.2333\n",
      "Epoch 526/1000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.3377 - acc: 0.4686 - val_loss: 2.3295 - val_acc: 0.2433\n",
      "Epoch 527/1000\n",
      "700/700 [==============================] - 0s 118us/step - loss: 1.3369 - acc: 0.4729 - val_loss: 2.3201 - val_acc: 0.2500\n",
      "Epoch 528/1000\n",
      "700/700 [==============================] - 0s 112us/step - loss: 1.3365 - acc: 0.4686 - val_loss: 2.3386 - val_acc: 0.2433\n",
      "Epoch 529/1000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.3367 - acc: 0.4729 - val_loss: 2.3425 - val_acc: 0.2467\n",
      "Epoch 530/1000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 1.3361 - acc: 0.4714 - val_loss: 2.3341 - val_acc: 0.2433\n",
      "Epoch 531/1000\n",
      "700/700 [==============================] - 0s 117us/step - loss: 1.3364 - acc: 0.4714 - val_loss: 2.3284 - val_acc: 0.2433\n",
      "Epoch 532/1000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.3371 - acc: 0.4729 - val_loss: 2.3329 - val_acc: 0.2367\n",
      "Epoch 533/1000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.3370 - acc: 0.4757 - val_loss: 2.3409 - val_acc: 0.2400\n",
      "Epoch 534/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 106us/step - loss: 1.3365 - acc: 0.4714 - val_loss: 2.3349 - val_acc: 0.2433\n",
      "Epoch 535/1000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.3368 - acc: 0.4729 - val_loss: 2.3339 - val_acc: 0.2467\n",
      "Epoch 536/1000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 1.3364 - acc: 0.4714 - val_loss: 2.3584 - val_acc: 0.2433\n",
      "Epoch 537/1000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.3365 - acc: 0.4714 - val_loss: 2.3419 - val_acc: 0.2500\n",
      "Epoch 538/1000\n",
      "700/700 [==============================] - 0s 108us/step - loss: 1.3349 - acc: 0.4686 - val_loss: 2.3467 - val_acc: 0.2500\n",
      "Epoch 539/1000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.3359 - acc: 0.4657 - val_loss: 2.3343 - val_acc: 0.2500\n",
      "Epoch 540/1000\n",
      "700/700 [==============================] - 0s 120us/step - loss: 1.3353 - acc: 0.4729 - val_loss: 2.3391 - val_acc: 0.2467\n",
      "Epoch 541/1000\n",
      "700/700 [==============================] - 0s 121us/step - loss: 1.3360 - acc: 0.4743 - val_loss: 2.3294 - val_acc: 0.2433\n",
      "Epoch 542/1000\n",
      "700/700 [==============================] - 0s 123us/step - loss: 1.3352 - acc: 0.4743 - val_loss: 2.3437 - val_acc: 0.2433\n",
      "Epoch 543/1000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.3355 - acc: 0.4714 - val_loss: 2.3242 - val_acc: 0.2433\n",
      "Epoch 544/1000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.3356 - acc: 0.4714 - val_loss: 2.3341 - val_acc: 0.2400\n",
      "Epoch 545/1000\n",
      "700/700 [==============================] - 0s 78us/step - loss: 1.3360 - acc: 0.4743 - val_loss: 2.3243 - val_acc: 0.2433\n",
      "Epoch 546/1000\n",
      "700/700 [==============================] - 0s 76us/step - loss: 1.3355 - acc: 0.4757 - val_loss: 2.3488 - val_acc: 0.2467\n",
      "Epoch 547/1000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.3350 - acc: 0.4743 - val_loss: 2.3345 - val_acc: 0.2433\n",
      "Epoch 548/1000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.3349 - acc: 0.4743 - val_loss: 2.3560 - val_acc: 0.2467\n",
      "Epoch 549/1000\n",
      "700/700 [==============================] - 0s 108us/step - loss: 1.3345 - acc: 0.4700 - val_loss: 2.3477 - val_acc: 0.2467\n",
      "Epoch 550/1000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.3351 - acc: 0.4657 - val_loss: 2.3265 - val_acc: 0.2367\n",
      "Epoch 551/1000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.3350 - acc: 0.4714 - val_loss: 2.3316 - val_acc: 0.2433\n",
      "Epoch 552/1000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.3359 - acc: 0.4700 - val_loss: 2.3359 - val_acc: 0.2433\n",
      "Epoch 553/1000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.3355 - acc: 0.4714 - val_loss: 2.3430 - val_acc: 0.2467\n",
      "Epoch 554/1000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.3336 - acc: 0.4786 - val_loss: 2.3388 - val_acc: 0.2500\n",
      "Epoch 555/1000\n",
      "700/700 [==============================] - 0s 116us/step - loss: 1.3340 - acc: 0.4729 - val_loss: 2.3367 - val_acc: 0.2433\n",
      "Epoch 556/1000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 1.3337 - acc: 0.4757 - val_loss: 2.3530 - val_acc: 0.2467\n",
      "Epoch 557/1000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3357 - acc: 0.4743 - val_loss: 2.3387 - val_acc: 0.2433\n",
      "Epoch 558/1000\n",
      "700/700 [==============================] - 0s 78us/step - loss: 1.3346 - acc: 0.4757 - val_loss: 2.3374 - val_acc: 0.2433\n",
      "Epoch 559/1000\n",
      "700/700 [==============================] - 0s 84us/step - loss: 1.3337 - acc: 0.4743 - val_loss: 2.3333 - val_acc: 0.2433\n",
      "Epoch 560/1000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.3346 - acc: 0.4829 - val_loss: 2.3368 - val_acc: 0.2367\n",
      "Epoch 561/1000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.3338 - acc: 0.4771 - val_loss: 2.3526 - val_acc: 0.2467\n",
      "Epoch 562/1000\n",
      "700/700 [==============================] - 0s 108us/step - loss: 1.3341 - acc: 0.4671 - val_loss: 2.3405 - val_acc: 0.2500\n",
      "Epoch 563/1000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 1.3342 - acc: 0.4657 - val_loss: 2.3467 - val_acc: 0.2433\n",
      "Epoch 564/1000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.3320 - acc: 0.4771 - val_loss: 2.3516 - val_acc: 0.2500\n",
      "Epoch 565/1000\n",
      "700/700 [==============================] - 0s 92us/step - loss: 1.3346 - acc: 0.4714 - val_loss: 2.3254 - val_acc: 0.2400\n",
      "Epoch 566/1000\n",
      "700/700 [==============================] - 0s 78us/step - loss: 1.3337 - acc: 0.4786 - val_loss: 2.3394 - val_acc: 0.2467\n",
      "Epoch 567/1000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.3343 - acc: 0.4714 - val_loss: 2.3549 - val_acc: 0.2467\n",
      "Epoch 568/1000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.3338 - acc: 0.4743 - val_loss: 2.3466 - val_acc: 0.2400\n",
      "Epoch 569/1000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.3326 - acc: 0.4743 - val_loss: 2.3396 - val_acc: 0.2467\n",
      "Epoch 570/1000\n",
      "700/700 [==============================] - 0s 117us/step - loss: 1.3344 - acc: 0.4757 - val_loss: 2.3426 - val_acc: 0.2433\n",
      "Epoch 571/1000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.3343 - acc: 0.4757 - val_loss: 2.3343 - val_acc: 0.2500\n",
      "Epoch 572/1000\n",
      "700/700 [==============================] - 0s 112us/step - loss: 1.3334 - acc: 0.4729 - val_loss: 2.3615 - val_acc: 0.2500\n",
      "Epoch 573/1000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 1.3326 - acc: 0.4714 - val_loss: 2.3422 - val_acc: 0.2367\n",
      "Epoch 574/1000\n",
      "700/700 [==============================] - 0s 116us/step - loss: 1.3335 - acc: 0.4800 - val_loss: 2.3598 - val_acc: 0.2467\n",
      "Epoch 575/1000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.3332 - acc: 0.4714 - val_loss: 2.3551 - val_acc: 0.2467\n",
      "Epoch 576/1000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.3327 - acc: 0.4757 - val_loss: 2.3446 - val_acc: 0.2433\n",
      "Epoch 577/1000\n",
      "700/700 [==============================] - 0s 116us/step - loss: 1.3332 - acc: 0.4714 - val_loss: 2.3477 - val_acc: 0.2467\n",
      "Epoch 578/1000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.3301 - acc: 0.4743 - val_loss: 2.3360 - val_acc: 0.2367\n",
      "Epoch 579/1000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.3323 - acc: 0.4757 - val_loss: 2.3696 - val_acc: 0.2467\n",
      "Epoch 580/1000\n",
      "700/700 [==============================] - 0s 108us/step - loss: 1.3334 - acc: 0.4729 - val_loss: 2.3365 - val_acc: 0.2433\n",
      "Epoch 581/1000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 1.3319 - acc: 0.4800 - val_loss: 2.3576 - val_acc: 0.2533\n",
      "Epoch 582/1000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.3331 - acc: 0.4771 - val_loss: 2.3355 - val_acc: 0.2433\n",
      "Epoch 583/1000\n",
      "700/700 [==============================] - 0s 115us/step - loss: 1.3338 - acc: 0.4757 - val_loss: 2.3489 - val_acc: 0.2433\n",
      "Epoch 584/1000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.3331 - acc: 0.4786 - val_loss: 2.3505 - val_acc: 0.2433\n",
      "Epoch 585/1000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.3311 - acc: 0.4657 - val_loss: 2.3301 - val_acc: 0.2433\n",
      "Epoch 586/1000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 1.3322 - acc: 0.4714 - val_loss: 2.3325 - val_acc: 0.2433\n",
      "Epoch 587/1000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.3324 - acc: 0.4757 - val_loss: 2.3391 - val_acc: 0.2433\n",
      "Epoch 588/1000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.3324 - acc: 0.4743 - val_loss: 2.3826 - val_acc: 0.2567\n",
      "Epoch 589/1000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.3322 - acc: 0.4729 - val_loss: 2.3592 - val_acc: 0.2500\n",
      "Epoch 590/1000\n",
      "700/700 [==============================] - 0s 78us/step - loss: 1.3325 - acc: 0.4729 - val_loss: 2.3491 - val_acc: 0.2433\n",
      "Epoch 591/1000\n",
      "700/700 [==============================] - 0s 79us/step - loss: 1.3315 - acc: 0.4714 - val_loss: 2.3594 - val_acc: 0.2467\n",
      "Epoch 592/1000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.3305 - acc: 0.4829 - val_loss: 2.3574 - val_acc: 0.2433\n",
      "Epoch 593/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 108us/step - loss: 1.3330 - acc: 0.4771 - val_loss: 2.3542 - val_acc: 0.2433\n",
      "Epoch 594/1000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 1.3321 - acc: 0.4786 - val_loss: 2.3408 - val_acc: 0.2467\n",
      "Epoch 595/1000\n",
      "700/700 [==============================] - 0s 126us/step - loss: 1.3313 - acc: 0.4800 - val_loss: 2.3576 - val_acc: 0.2500\n",
      "Epoch 596/1000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.3316 - acc: 0.4729 - val_loss: 2.3632 - val_acc: 0.2400\n",
      "Epoch 597/1000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.3322 - acc: 0.4743 - val_loss: 2.3583 - val_acc: 0.2400\n",
      "Epoch 598/1000\n",
      "700/700 [==============================] - 0s 115us/step - loss: 1.3315 - acc: 0.4700 - val_loss: 2.3482 - val_acc: 0.2433\n",
      "Epoch 599/1000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 1.3317 - acc: 0.4729 - val_loss: 2.3457 - val_acc: 0.2400\n",
      "Epoch 600/1000\n",
      "700/700 [==============================] - 0s 108us/step - loss: 1.3307 - acc: 0.4729 - val_loss: 2.3556 - val_acc: 0.2433\n",
      "Epoch 601/1000\n",
      "700/700 [==============================] - 0s 122us/step - loss: 1.3312 - acc: 0.4729 - val_loss: 2.3408 - val_acc: 0.2433\n",
      "Epoch 602/1000\n",
      "700/700 [==============================] - 0s 118us/step - loss: 1.3302 - acc: 0.4729 - val_loss: 2.3724 - val_acc: 0.2467\n",
      "Epoch 603/1000\n",
      "700/700 [==============================] - 0s 116us/step - loss: 1.3312 - acc: 0.4686 - val_loss: 2.3276 - val_acc: 0.2367\n",
      "Epoch 604/1000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 1.3308 - acc: 0.4743 - val_loss: 2.3500 - val_acc: 0.2433\n",
      "Epoch 605/1000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.3315 - acc: 0.4757 - val_loss: 2.3600 - val_acc: 0.2467\n",
      "Epoch 606/1000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.3307 - acc: 0.4714 - val_loss: 2.3618 - val_acc: 0.2433\n",
      "Epoch 607/1000\n",
      "700/700 [==============================] - 0s 112us/step - loss: 1.3308 - acc: 0.4657 - val_loss: 2.3357 - val_acc: 0.2433\n",
      "Epoch 608/1000\n",
      "700/700 [==============================] - 0s 119us/step - loss: 1.3296 - acc: 0.4671 - val_loss: 2.3484 - val_acc: 0.2400\n",
      "Epoch 609/1000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.3319 - acc: 0.4800 - val_loss: 2.3516 - val_acc: 0.2400\n",
      "Epoch 610/1000\n",
      "700/700 [==============================] - 0s 115us/step - loss: 1.3299 - acc: 0.4800 - val_loss: 2.3577 - val_acc: 0.2400\n",
      "Epoch 611/1000\n",
      "700/700 [==============================] - 0s 128us/step - loss: 1.3298 - acc: 0.4700 - val_loss: 2.3411 - val_acc: 0.2533\n",
      "Epoch 612/1000\n",
      "700/700 [==============================] - 0s 115us/step - loss: 1.3319 - acc: 0.4729 - val_loss: 2.3396 - val_acc: 0.2500\n",
      "Epoch 613/1000\n",
      "700/700 [==============================] - 0s 120us/step - loss: 1.3306 - acc: 0.4800 - val_loss: 2.3490 - val_acc: 0.2400\n",
      "Epoch 614/1000\n",
      "700/700 [==============================] - 0s 130us/step - loss: 1.3299 - acc: 0.4714 - val_loss: 2.3419 - val_acc: 0.2367\n",
      "Epoch 615/1000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.3304 - acc: 0.4700 - val_loss: 2.3340 - val_acc: 0.2433\n",
      "Epoch 616/1000\n",
      "700/700 [==============================] - 0s 112us/step - loss: 1.3295 - acc: 0.4771 - val_loss: 2.3558 - val_acc: 0.2400\n",
      "Epoch 617/1000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.3299 - acc: 0.4729 - val_loss: 2.3560 - val_acc: 0.2400\n",
      "Epoch 618/1000\n",
      "700/700 [==============================] - 0s 119us/step - loss: 1.3300 - acc: 0.4771 - val_loss: 2.3501 - val_acc: 0.2400\n",
      "Epoch 619/1000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.3295 - acc: 0.4800 - val_loss: 2.3270 - val_acc: 0.2500\n",
      "Epoch 620/1000\n",
      "700/700 [==============================] - 0s 125us/step - loss: 1.3302 - acc: 0.4786 - val_loss: 2.3694 - val_acc: 0.2467\n",
      "Epoch 621/1000\n",
      "700/700 [==============================] - 0s 119us/step - loss: 1.3304 - acc: 0.4771 - val_loss: 2.3515 - val_acc: 0.2433\n",
      "Epoch 622/1000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.3295 - acc: 0.4771 - val_loss: 2.3550 - val_acc: 0.2467\n",
      "Epoch 623/1000\n",
      "700/700 [==============================] - 0s 116us/step - loss: 1.3296 - acc: 0.4743 - val_loss: 2.3607 - val_acc: 0.2467\n",
      "Epoch 624/1000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.3300 - acc: 0.4743 - val_loss: 2.3602 - val_acc: 0.2400\n",
      "Epoch 625/1000\n",
      "700/700 [==============================] - 0s 119us/step - loss: 1.3298 - acc: 0.4757 - val_loss: 2.3573 - val_acc: 0.2400\n",
      "Epoch 626/1000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.3294 - acc: 0.4743 - val_loss: 2.3933 - val_acc: 0.2467\n",
      "Epoch 627/1000\n",
      "700/700 [==============================] - 0s 116us/step - loss: 1.3296 - acc: 0.4714 - val_loss: 2.3814 - val_acc: 0.2433\n",
      "Epoch 628/1000\n",
      "700/700 [==============================] - 0s 118us/step - loss: 1.3299 - acc: 0.4686 - val_loss: 2.3634 - val_acc: 0.2467\n",
      "Epoch 629/1000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.3284 - acc: 0.4743 - val_loss: 2.3598 - val_acc: 0.2433\n",
      "Epoch 630/1000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.3296 - acc: 0.4700 - val_loss: 2.3747 - val_acc: 0.2500\n",
      "Epoch 631/1000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.3288 - acc: 0.4743 - val_loss: 2.3735 - val_acc: 0.2533\n",
      "Epoch 632/1000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3292 - acc: 0.4743 - val_loss: 2.3392 - val_acc: 0.2500\n",
      "Epoch 633/1000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.3292 - acc: 0.4757 - val_loss: 2.3467 - val_acc: 0.2467\n",
      "Epoch 634/1000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.3287 - acc: 0.4700 - val_loss: 2.3467 - val_acc: 0.2367\n",
      "Epoch 635/1000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 1.3290 - acc: 0.4686 - val_loss: 2.3560 - val_acc: 0.2433\n",
      "Epoch 636/1000\n",
      "700/700 [==============================] - 0s 118us/step - loss: 1.3285 - acc: 0.4800 - val_loss: 2.3395 - val_acc: 0.2400\n",
      "Epoch 637/1000\n",
      "700/700 [==============================] - 0s 112us/step - loss: 1.3280 - acc: 0.4771 - val_loss: 2.3716 - val_acc: 0.2500\n",
      "Epoch 638/1000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 1.3283 - acc: 0.4757 - val_loss: 2.3642 - val_acc: 0.2500\n",
      "Epoch 639/1000\n",
      "700/700 [==============================] - 0s 117us/step - loss: 1.3291 - acc: 0.4829 - val_loss: 2.3669 - val_acc: 0.2467\n",
      "Epoch 640/1000\n",
      "700/700 [==============================] - 0s 115us/step - loss: 1.3286 - acc: 0.4757 - val_loss: 2.3531 - val_acc: 0.2467\n",
      "Epoch 641/1000\n",
      "700/700 [==============================] - 0s 80us/step - loss: 1.3282 - acc: 0.4786 - val_loss: 2.3467 - val_acc: 0.2467\n",
      "Epoch 642/1000\n",
      "700/700 [==============================] - 0s 79us/step - loss: 1.3290 - acc: 0.4800 - val_loss: 2.3669 - val_acc: 0.2433\n",
      "Epoch 643/1000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.3284 - acc: 0.4743 - val_loss: 2.3377 - val_acc: 0.2533\n",
      "Epoch 644/1000\n",
      "700/700 [==============================] - 0s 108us/step - loss: 1.3290 - acc: 0.4771 - val_loss: 2.3668 - val_acc: 0.2433\n",
      "Epoch 645/1000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.3274 - acc: 0.4743 - val_loss: 2.3633 - val_acc: 0.2500\n",
      "Epoch 646/1000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.3278 - acc: 0.4829 - val_loss: 2.3523 - val_acc: 0.2467\n",
      "Epoch 647/1000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.3280 - acc: 0.4786 - val_loss: 2.3758 - val_acc: 0.2367\n",
      "Epoch 648/1000\n",
      "700/700 [==============================] - 0s 116us/step - loss: 1.3288 - acc: 0.4814 - val_loss: 2.3650 - val_acc: 0.2400\n",
      "Epoch 649/1000\n",
      "700/700 [==============================] - 0s 115us/step - loss: 1.3277 - acc: 0.4743 - val_loss: 2.3524 - val_acc: 0.2433\n",
      "Epoch 650/1000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.3276 - acc: 0.4771 - val_loss: 2.3780 - val_acc: 0.2467\n",
      "Epoch 651/1000\n",
      "700/700 [==============================] - 0s 108us/step - loss: 1.3272 - acc: 0.4786 - val_loss: 2.3561 - val_acc: 0.2367\n",
      "Epoch 652/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 113us/step - loss: 1.3281 - acc: 0.4800 - val_loss: 2.3444 - val_acc: 0.2500\n",
      "Epoch 653/1000\n",
      "700/700 [==============================] - 0s 116us/step - loss: 1.3275 - acc: 0.4800 - val_loss: 2.3650 - val_acc: 0.2433\n",
      "Epoch 654/1000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.3269 - acc: 0.4786 - val_loss: 2.3463 - val_acc: 0.2400\n",
      "Epoch 655/1000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.3272 - acc: 0.4771 - val_loss: 2.3437 - val_acc: 0.2367\n",
      "Epoch 656/1000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.3265 - acc: 0.4700 - val_loss: 2.3613 - val_acc: 0.2433\n",
      "Epoch 657/1000\n",
      "700/700 [==============================] - 0s 115us/step - loss: 1.3269 - acc: 0.4786 - val_loss: 2.3756 - val_acc: 0.2467\n",
      "Epoch 658/1000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.3282 - acc: 0.4771 - val_loss: 2.3783 - val_acc: 0.2500\n",
      "Epoch 659/1000\n",
      "700/700 [==============================] - 0s 115us/step - loss: 1.3270 - acc: 0.4743 - val_loss: 2.3506 - val_acc: 0.2467\n",
      "Epoch 660/1000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.3264 - acc: 0.4786 - val_loss: 2.3656 - val_acc: 0.2400\n",
      "Epoch 661/1000\n",
      "700/700 [==============================] - 0s 117us/step - loss: 1.3263 - acc: 0.4714 - val_loss: 2.3564 - val_acc: 0.2500\n",
      "Epoch 662/1000\n",
      "700/700 [==============================] - 0s 116us/step - loss: 1.3257 - acc: 0.4757 - val_loss: 2.3661 - val_acc: 0.2467\n",
      "Epoch 663/1000\n",
      "700/700 [==============================] - 0s 120us/step - loss: 1.3263 - acc: 0.4771 - val_loss: 2.3540 - val_acc: 0.2367\n",
      "Epoch 664/1000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.3261 - acc: 0.4786 - val_loss: 2.3780 - val_acc: 0.2467\n",
      "Epoch 665/1000\n",
      "700/700 [==============================] - 0s 112us/step - loss: 1.3268 - acc: 0.4757 - val_loss: 2.3742 - val_acc: 0.2400\n",
      "Epoch 666/1000\n",
      "700/700 [==============================] - 0s 112us/step - loss: 1.3260 - acc: 0.4757 - val_loss: 2.3962 - val_acc: 0.2433\n",
      "Epoch 667/1000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.3261 - acc: 0.4829 - val_loss: 2.3880 - val_acc: 0.2400\n",
      "Epoch 668/1000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.3263 - acc: 0.4800 - val_loss: 2.3632 - val_acc: 0.2433\n",
      "Epoch 669/1000\n",
      "700/700 [==============================] - 0s 108us/step - loss: 1.3247 - acc: 0.4800 - val_loss: 2.3792 - val_acc: 0.2467\n",
      "Epoch 670/1000\n",
      "700/700 [==============================] - 0s 121us/step - loss: 1.3259 - acc: 0.4757 - val_loss: 2.3710 - val_acc: 0.2400\n",
      "Epoch 671/1000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.3261 - acc: 0.4786 - val_loss: 2.3775 - val_acc: 0.2400\n",
      "Epoch 672/1000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.3256 - acc: 0.4786 - val_loss: 2.3740 - val_acc: 0.2467\n",
      "Epoch 673/1000\n",
      "700/700 [==============================] - 0s 118us/step - loss: 1.3253 - acc: 0.4743 - val_loss: 2.3619 - val_acc: 0.2400\n",
      "Epoch 674/1000\n",
      "700/700 [==============================] - 0s 115us/step - loss: 1.3249 - acc: 0.4786 - val_loss: 2.3786 - val_acc: 0.2433\n",
      "Epoch 675/1000\n",
      "700/700 [==============================] - 0s 123us/step - loss: 1.3260 - acc: 0.4757 - val_loss: 2.3980 - val_acc: 0.2567\n",
      "Epoch 676/1000\n",
      "700/700 [==============================] - 0s 112us/step - loss: 1.3244 - acc: 0.4786 - val_loss: 2.3809 - val_acc: 0.2400\n",
      "Epoch 677/1000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.3241 - acc: 0.4700 - val_loss: 2.3600 - val_acc: 0.2433\n",
      "Epoch 678/1000\n",
      "700/700 [==============================] - 0s 132us/step - loss: 1.3253 - acc: 0.4786 - val_loss: 2.3854 - val_acc: 0.2433\n",
      "Epoch 679/1000\n",
      "700/700 [==============================] - 0s 112us/step - loss: 1.3250 - acc: 0.4757 - val_loss: 2.3658 - val_acc: 0.2400\n",
      "Epoch 680/1000\n",
      "700/700 [==============================] - 0s 117us/step - loss: 1.3244 - acc: 0.4757 - val_loss: 2.3576 - val_acc: 0.2433\n",
      "Epoch 681/1000\n",
      "700/700 [==============================] - 0s 116us/step - loss: 1.3242 - acc: 0.4757 - val_loss: 2.3729 - val_acc: 0.2467\n",
      "Epoch 682/1000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.3242 - acc: 0.4814 - val_loss: 2.3750 - val_acc: 0.2333\n",
      "Epoch 683/1000\n",
      "700/700 [==============================] - 0s 112us/step - loss: 1.3250 - acc: 0.4743 - val_loss: 2.3767 - val_acc: 0.2433\n",
      "Epoch 684/1000\n",
      "700/700 [==============================] - 0s 124us/step - loss: 1.3249 - acc: 0.4714 - val_loss: 2.3788 - val_acc: 0.2433\n",
      "Epoch 685/1000\n",
      "700/700 [==============================] - 0s 115us/step - loss: 1.3243 - acc: 0.4771 - val_loss: 2.3785 - val_acc: 0.2433\n",
      "Epoch 686/1000\n",
      "700/700 [==============================] - 0s 108us/step - loss: 1.3244 - acc: 0.4757 - val_loss: 2.3750 - val_acc: 0.2367\n",
      "Epoch 687/1000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 1.3237 - acc: 0.4843 - val_loss: 2.3574 - val_acc: 0.2467\n",
      "Epoch 688/1000\n",
      "700/700 [==============================] - 0s 112us/step - loss: 1.3242 - acc: 0.4786 - val_loss: 2.3724 - val_acc: 0.2400\n",
      "Epoch 689/1000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.3241 - acc: 0.4786 - val_loss: 2.3680 - val_acc: 0.2400\n",
      "Epoch 690/1000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.3240 - acc: 0.4786 - val_loss: 2.3927 - val_acc: 0.2433\n",
      "Epoch 691/1000\n",
      "700/700 [==============================] - 0s 123us/step - loss: 1.3240 - acc: 0.4729 - val_loss: 2.3798 - val_acc: 0.2400\n",
      "Epoch 692/1000\n",
      "700/700 [==============================] - 0s 112us/step - loss: 1.3247 - acc: 0.4771 - val_loss: 2.3617 - val_acc: 0.2433\n",
      "Epoch 693/1000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.3241 - acc: 0.4814 - val_loss: 2.4098 - val_acc: 0.2500\n",
      "Epoch 694/1000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.3239 - acc: 0.4829 - val_loss: 2.3827 - val_acc: 0.2433\n",
      "Epoch 695/1000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 1.3237 - acc: 0.4757 - val_loss: 2.3899 - val_acc: 0.2433\n",
      "Epoch 696/1000\n",
      "700/700 [==============================] - 0s 115us/step - loss: 1.3239 - acc: 0.4771 - val_loss: 2.3882 - val_acc: 0.2467\n",
      "Epoch 697/1000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.3230 - acc: 0.4729 - val_loss: 2.3741 - val_acc: 0.2367\n",
      "Epoch 698/1000\n",
      "700/700 [==============================] - 0s 120us/step - loss: 1.3237 - acc: 0.4814 - val_loss: 2.3761 - val_acc: 0.2433\n",
      "Epoch 699/1000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 1.3228 - acc: 0.4771 - val_loss: 2.3911 - val_acc: 0.2400\n",
      "Epoch 700/1000\n",
      "700/700 [==============================] - 0s 135us/step - loss: 1.3238 - acc: 0.4743 - val_loss: 2.3889 - val_acc: 0.2467\n",
      "Epoch 701/1000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.3224 - acc: 0.4743 - val_loss: 2.3794 - val_acc: 0.2433\n",
      "Epoch 702/1000\n",
      "700/700 [==============================] - 0s 108us/step - loss: 1.3222 - acc: 0.4786 - val_loss: 2.3980 - val_acc: 0.2433\n",
      "Epoch 703/1000\n",
      "700/700 [==============================] - 0s 123us/step - loss: 1.3228 - acc: 0.4843 - val_loss: 2.3777 - val_acc: 0.2400\n",
      "Epoch 704/1000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.3230 - acc: 0.4843 - val_loss: 2.4072 - val_acc: 0.2500\n",
      "Epoch 705/1000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 1.3223 - acc: 0.4829 - val_loss: 2.3969 - val_acc: 0.2467\n",
      "Epoch 706/1000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.3232 - acc: 0.4814 - val_loss: 2.3886 - val_acc: 0.2433\n",
      "Epoch 707/1000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.3229 - acc: 0.4843 - val_loss: 2.3848 - val_acc: 0.2433\n",
      "Epoch 708/1000\n",
      "700/700 [==============================] - 0s 112us/step - loss: 1.3217 - acc: 0.4857 - val_loss: 2.3805 - val_acc: 0.2400\n",
      "Epoch 709/1000\n",
      "700/700 [==============================] - 0s 112us/step - loss: 1.3228 - acc: 0.4814 - val_loss: 2.3639 - val_acc: 0.2367\n",
      "Epoch 710/1000\n",
      "700/700 [==============================] - 0s 118us/step - loss: 1.3208 - acc: 0.4786 - val_loss: 2.4006 - val_acc: 0.2467\n",
      "Epoch 711/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 106us/step - loss: 1.3222 - acc: 0.4843 - val_loss: 2.3842 - val_acc: 0.2400\n",
      "Epoch 712/1000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.3232 - acc: 0.4800 - val_loss: 2.4043 - val_acc: 0.2467\n",
      "Epoch 713/1000\n",
      "700/700 [==============================] - 0s 112us/step - loss: 1.3222 - acc: 0.4857 - val_loss: 2.3818 - val_acc: 0.2433\n",
      "Epoch 714/1000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.3226 - acc: 0.4814 - val_loss: 2.3971 - val_acc: 0.2467\n",
      "Epoch 715/1000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.3221 - acc: 0.4857 - val_loss: 2.3958 - val_acc: 0.2467\n",
      "Epoch 716/1000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.3227 - acc: 0.4814 - val_loss: 2.3729 - val_acc: 0.2433\n",
      "Epoch 717/1000\n",
      "700/700 [==============================] - 0s 98us/step - loss: 1.3221 - acc: 0.4829 - val_loss: 2.3702 - val_acc: 0.2400\n",
      "Epoch 718/1000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.3220 - acc: 0.4829 - val_loss: 2.3857 - val_acc: 0.2467\n",
      "Epoch 719/1000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.3223 - acc: 0.4786 - val_loss: 2.3964 - val_acc: 0.2500\n",
      "Epoch 720/1000\n",
      "700/700 [==============================] - 0s 116us/step - loss: 1.3220 - acc: 0.4800 - val_loss: 2.3710 - val_acc: 0.2400\n",
      "Epoch 721/1000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 1.3217 - acc: 0.4871 - val_loss: 2.3905 - val_acc: 0.2400\n",
      "Epoch 722/1000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 1.3217 - acc: 0.4814 - val_loss: 2.3879 - val_acc: 0.2433\n",
      "Epoch 723/1000\n",
      "700/700 [==============================] - 0s 87us/step - loss: 1.3223 - acc: 0.4800 - val_loss: 2.3651 - val_acc: 0.2400\n",
      "Epoch 724/1000\n",
      "700/700 [==============================] - 0s 77us/step - loss: 1.3221 - acc: 0.4829 - val_loss: 2.3972 - val_acc: 0.2433\n",
      "Epoch 725/1000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.3220 - acc: 0.4771 - val_loss: 2.3904 - val_acc: 0.2467\n",
      "Epoch 726/1000\n",
      "700/700 [==============================] - 0s 120us/step - loss: 1.3212 - acc: 0.4857 - val_loss: 2.3835 - val_acc: 0.2400\n",
      "Epoch 727/1000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.3218 - acc: 0.4771 - val_loss: 2.3833 - val_acc: 0.2400\n",
      "Epoch 728/1000\n",
      "700/700 [==============================] - 0s 117us/step - loss: 1.3212 - acc: 0.4786 - val_loss: 2.3852 - val_acc: 0.2367\n",
      "Epoch 729/1000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.3216 - acc: 0.4829 - val_loss: 2.3799 - val_acc: 0.2400\n",
      "Epoch 730/1000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.3216 - acc: 0.4857 - val_loss: 2.3825 - val_acc: 0.2433\n",
      "Epoch 731/1000\n",
      "700/700 [==============================] - 0s 108us/step - loss: 1.3219 - acc: 0.4814 - val_loss: 2.4012 - val_acc: 0.2500\n",
      "Epoch 732/1000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.3217 - acc: 0.4786 - val_loss: 2.3862 - val_acc: 0.2433\n",
      "Epoch 733/1000\n",
      "700/700 [==============================] - 0s 120us/step - loss: 1.3209 - acc: 0.4771 - val_loss: 2.3871 - val_acc: 0.2433\n",
      "Epoch 734/1000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.3218 - acc: 0.4771 - val_loss: 2.3676 - val_acc: 0.2400\n",
      "Epoch 735/1000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.3212 - acc: 0.4814 - val_loss: 2.3700 - val_acc: 0.2400\n",
      "Epoch 736/1000\n",
      "700/700 [==============================] - 0s 123us/step - loss: 1.3206 - acc: 0.4771 - val_loss: 2.3899 - val_acc: 0.2400\n",
      "Epoch 737/1000\n",
      "700/700 [==============================] - 0s 121us/step - loss: 1.3207 - acc: 0.4829 - val_loss: 2.3576 - val_acc: 0.2400\n",
      "Epoch 738/1000\n",
      "700/700 [==============================] - 0s 115us/step - loss: 1.3218 - acc: 0.4829 - val_loss: 2.3768 - val_acc: 0.2433\n",
      "Epoch 739/1000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 1.3206 - acc: 0.4829 - val_loss: 2.4065 - val_acc: 0.2467\n",
      "Epoch 740/1000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.3200 - acc: 0.4843 - val_loss: 2.3927 - val_acc: 0.2467\n",
      "Epoch 741/1000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.3205 - acc: 0.4843 - val_loss: 2.3875 - val_acc: 0.2400\n",
      "Epoch 742/1000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.3202 - acc: 0.4886 - val_loss: 2.3816 - val_acc: 0.2400\n",
      "Epoch 743/1000\n",
      "700/700 [==============================] - 0s 115us/step - loss: 1.3201 - acc: 0.4814 - val_loss: 2.3989 - val_acc: 0.2467\n",
      "Epoch 744/1000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.3208 - acc: 0.4814 - val_loss: 2.3824 - val_acc: 0.2400\n",
      "Epoch 745/1000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.3214 - acc: 0.4814 - val_loss: 2.3803 - val_acc: 0.2367\n",
      "Epoch 746/1000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.3203 - acc: 0.4800 - val_loss: 2.4043 - val_acc: 0.2467\n",
      "Epoch 747/1000\n",
      "700/700 [==============================] - 0s 112us/step - loss: 1.3204 - acc: 0.4757 - val_loss: 2.3746 - val_acc: 0.2333\n",
      "Epoch 748/1000\n",
      "700/700 [==============================] - 0s 116us/step - loss: 1.3207 - acc: 0.4757 - val_loss: 2.3948 - val_acc: 0.2467\n",
      "Epoch 749/1000\n",
      "700/700 [==============================] - 0s 120us/step - loss: 1.3200 - acc: 0.4757 - val_loss: 2.3917 - val_acc: 0.2400\n",
      "Epoch 750/1000\n",
      "700/700 [==============================] - 0s 117us/step - loss: 1.3191 - acc: 0.4857 - val_loss: 2.3969 - val_acc: 0.2467\n",
      "Epoch 751/1000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.3205 - acc: 0.4800 - val_loss: 2.3885 - val_acc: 0.2433\n",
      "Epoch 752/1000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.3198 - acc: 0.4814 - val_loss: 2.3889 - val_acc: 0.2433\n",
      "Epoch 753/1000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.3197 - acc: 0.4829 - val_loss: 2.3890 - val_acc: 0.2467\n",
      "Epoch 754/1000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.3199 - acc: 0.4871 - val_loss: 2.3690 - val_acc: 0.2400\n",
      "Epoch 755/1000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.3197 - acc: 0.4814 - val_loss: 2.3749 - val_acc: 0.2500\n",
      "Epoch 756/1000\n",
      "700/700 [==============================] - 0s 133us/step - loss: 1.3199 - acc: 0.4843 - val_loss: 2.3836 - val_acc: 0.2433\n",
      "Epoch 757/1000\n",
      "700/700 [==============================] - 0s 119us/step - loss: 1.3190 - acc: 0.4871 - val_loss: 2.4138 - val_acc: 0.2500\n",
      "Epoch 758/1000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.3207 - acc: 0.4800 - val_loss: 2.3844 - val_acc: 0.2433\n",
      "Epoch 759/1000\n",
      "700/700 [==============================] - 0s 78us/step - loss: 1.3201 - acc: 0.4829 - val_loss: 2.3918 - val_acc: 0.2400\n",
      "Epoch 760/1000\n",
      "700/700 [==============================] - 0s 75us/step - loss: 1.3193 - acc: 0.4800 - val_loss: 2.3934 - val_acc: 0.2433\n",
      "Epoch 761/1000\n",
      "700/700 [==============================] - 0s 78us/step - loss: 1.3180 - acc: 0.4843 - val_loss: 2.3851 - val_acc: 0.2400\n",
      "Epoch 762/1000\n",
      "700/700 [==============================] - 0s 108us/step - loss: 1.3195 - acc: 0.4800 - val_loss: 2.3812 - val_acc: 0.2400\n",
      "Epoch 763/1000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.3189 - acc: 0.4857 - val_loss: 2.4090 - val_acc: 0.2467\n",
      "Epoch 764/1000\n",
      "700/700 [==============================] - 0s 83us/step - loss: 1.3190 - acc: 0.4771 - val_loss: 2.4073 - val_acc: 0.2433\n",
      "Epoch 765/1000\n",
      "700/700 [==============================] - 0s 143us/step - loss: 1.3201 - acc: 0.4829 - val_loss: 2.4063 - val_acc: 0.2467\n",
      "Epoch 766/1000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.3184 - acc: 0.4857 - val_loss: 2.4011 - val_acc: 0.2433\n",
      "Epoch 767/1000\n",
      "700/700 [==============================] - 0s 79us/step - loss: 1.3192 - acc: 0.4814 - val_loss: 2.3818 - val_acc: 0.2433\n",
      "Epoch 768/1000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.3182 - acc: 0.4800 - val_loss: 2.4074 - val_acc: 0.2500\n",
      "Epoch 769/1000\n",
      "700/700 [==============================] - 0s 79us/step - loss: 1.3188 - acc: 0.4814 - val_loss: 2.3951 - val_acc: 0.2433\n",
      "Epoch 770/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 77us/step - loss: 1.3184 - acc: 0.4857 - val_loss: 2.3830 - val_acc: 0.2433\n",
      "Epoch 771/1000\n",
      "700/700 [==============================] - 0s 79us/step - loss: 1.3179 - acc: 0.4829 - val_loss: 2.4057 - val_acc: 0.2433\n",
      "Epoch 772/1000\n",
      "700/700 [==============================] - 0s 77us/step - loss: 1.3184 - acc: 0.4871 - val_loss: 2.4075 - val_acc: 0.2433\n",
      "Epoch 773/1000\n",
      "700/700 [==============================] - 0s 78us/step - loss: 1.3193 - acc: 0.4871 - val_loss: 2.3649 - val_acc: 0.2400\n",
      "Epoch 774/1000\n",
      "700/700 [==============================] - 0s 78us/step - loss: 1.3179 - acc: 0.4871 - val_loss: 2.4125 - val_acc: 0.2500\n",
      "Epoch 775/1000\n",
      "700/700 [==============================] - 0s 76us/step - loss: 1.3170 - acc: 0.4814 - val_loss: 2.4010 - val_acc: 0.2467\n",
      "Epoch 776/1000\n",
      "700/700 [==============================] - 0s 78us/step - loss: 1.3176 - acc: 0.4786 - val_loss: 2.3930 - val_acc: 0.2433\n",
      "Epoch 777/1000\n",
      "700/700 [==============================] - 0s 77us/step - loss: 1.3179 - acc: 0.4814 - val_loss: 2.3832 - val_acc: 0.2367\n",
      "Epoch 778/1000\n",
      "700/700 [==============================] - 0s 76us/step - loss: 1.3171 - acc: 0.4771 - val_loss: 2.3963 - val_acc: 0.2367\n",
      "Epoch 779/1000\n",
      "700/700 [==============================] - 0s 78us/step - loss: 1.3177 - acc: 0.4800 - val_loss: 2.3679 - val_acc: 0.2433\n",
      "Epoch 780/1000\n",
      "700/700 [==============================] - 0s 78us/step - loss: 1.3169 - acc: 0.4829 - val_loss: 2.3860 - val_acc: 0.2433\n",
      "Epoch 781/1000\n",
      "700/700 [==============================] - 0s 78us/step - loss: 1.3177 - acc: 0.4857 - val_loss: 2.3931 - val_acc: 0.2433\n",
      "Epoch 782/1000\n",
      "700/700 [==============================] - 0s 78us/step - loss: 1.3171 - acc: 0.4814 - val_loss: 2.3903 - val_acc: 0.2400\n",
      "Epoch 783/1000\n",
      "700/700 [==============================] - 0s 78us/step - loss: 1.3175 - acc: 0.4771 - val_loss: 2.3763 - val_acc: 0.2433\n",
      "Epoch 784/1000\n",
      "700/700 [==============================] - 0s 75us/step - loss: 1.3171 - acc: 0.4771 - val_loss: 2.3993 - val_acc: 0.2433\n",
      "Epoch 785/1000\n",
      "700/700 [==============================] - 0s 162us/step - loss: 1.3164 - acc: 0.4800 - val_loss: 2.3881 - val_acc: 0.2400\n",
      "Epoch 786/1000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3169 - acc: 0.4829 - val_loss: 2.4023 - val_acc: 0.2400\n",
      "Epoch 787/1000\n",
      "700/700 [==============================] - 0s 75us/step - loss: 1.3167 - acc: 0.4814 - val_loss: 2.3897 - val_acc: 0.2433\n",
      "Epoch 788/1000\n",
      "700/700 [==============================] - 0s 77us/step - loss: 1.3164 - acc: 0.4843 - val_loss: 2.3859 - val_acc: 0.2467\n",
      "Epoch 789/1000\n",
      "700/700 [==============================] - 0s 76us/step - loss: 1.3164 - acc: 0.4886 - val_loss: 2.3827 - val_acc: 0.2433\n",
      "Epoch 790/1000\n",
      "700/700 [==============================] - 0s 81us/step - loss: 1.3164 - acc: 0.4800 - val_loss: 2.3695 - val_acc: 0.2433\n",
      "Epoch 791/1000\n",
      "700/700 [==============================] - 0s 78us/step - loss: 1.3164 - acc: 0.4814 - val_loss: 2.4090 - val_acc: 0.2433\n",
      "Epoch 792/1000\n",
      "700/700 [==============================] - 0s 77us/step - loss: 1.3159 - acc: 0.4871 - val_loss: 2.4033 - val_acc: 0.2433\n",
      "Epoch 793/1000\n",
      "700/700 [==============================] - 0s 78us/step - loss: 1.3165 - acc: 0.4871 - val_loss: 2.3757 - val_acc: 0.2400\n",
      "Epoch 794/1000\n",
      "700/700 [==============================] - 0s 80us/step - loss: 1.3172 - acc: 0.4814 - val_loss: 2.3847 - val_acc: 0.2433\n",
      "Epoch 795/1000\n",
      "700/700 [==============================] - 0s 78us/step - loss: 1.3162 - acc: 0.4929 - val_loss: 2.3995 - val_acc: 0.2433\n",
      "Epoch 796/1000\n",
      "700/700 [==============================] - 0s 78us/step - loss: 1.3161 - acc: 0.4800 - val_loss: 2.4006 - val_acc: 0.2467\n",
      "Epoch 797/1000\n",
      "700/700 [==============================] - 0s 78us/step - loss: 1.3161 - acc: 0.4871 - val_loss: 2.4019 - val_acc: 0.2367\n",
      "Epoch 798/1000\n",
      "700/700 [==============================] - 0s 78us/step - loss: 1.3141 - acc: 0.4871 - val_loss: 2.4272 - val_acc: 0.2433\n",
      "Epoch 799/1000\n",
      "700/700 [==============================] - 0s 81us/step - loss: 1.3158 - acc: 0.4857 - val_loss: 2.3814 - val_acc: 0.2433\n",
      "Epoch 800/1000\n",
      "700/700 [==============================] - 0s 81us/step - loss: 1.3157 - acc: 0.4843 - val_loss: 2.4132 - val_acc: 0.2400\n",
      "Epoch 801/1000\n",
      "700/700 [==============================] - 0s 86us/step - loss: 1.3153 - acc: 0.4871 - val_loss: 2.4166 - val_acc: 0.2433\n",
      "Epoch 802/1000\n",
      "700/700 [==============================] - 0s 86us/step - loss: 1.3155 - acc: 0.4857 - val_loss: 2.4007 - val_acc: 0.2400\n",
      "Epoch 803/1000\n",
      "700/700 [==============================] - 0s 85us/step - loss: 1.3147 - acc: 0.4771 - val_loss: 2.4096 - val_acc: 0.2433\n",
      "Epoch 804/1000\n",
      "700/700 [==============================] - 0s 84us/step - loss: 1.3160 - acc: 0.4843 - val_loss: 2.4026 - val_acc: 0.2433\n",
      "Epoch 805/1000\n",
      "700/700 [==============================] - 0s 79us/step - loss: 1.3156 - acc: 0.4843 - val_loss: 2.3948 - val_acc: 0.2500\n",
      "Epoch 806/1000\n",
      "700/700 [==============================] - 0s 83us/step - loss: 1.3165 - acc: 0.4843 - val_loss: 2.3929 - val_acc: 0.2400\n",
      "Epoch 807/1000\n",
      "700/700 [==============================] - 0s 120us/step - loss: 1.3150 - acc: 0.4871 - val_loss: 2.3854 - val_acc: 0.2433\n",
      "Epoch 808/1000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.3150 - acc: 0.4814 - val_loss: 2.4280 - val_acc: 0.2467\n",
      "Epoch 809/1000\n",
      "700/700 [==============================] - 0s 120us/step - loss: 1.3151 - acc: 0.4900 - val_loss: 2.4083 - val_acc: 0.2467\n",
      "Epoch 810/1000\n",
      "700/700 [==============================] - 0s 115us/step - loss: 1.3157 - acc: 0.4871 - val_loss: 2.4016 - val_acc: 0.2433\n",
      "Epoch 811/1000\n",
      "700/700 [==============================] - 0s 115us/step - loss: 1.3153 - acc: 0.4900 - val_loss: 2.4013 - val_acc: 0.2467\n",
      "Epoch 812/1000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 1.3149 - acc: 0.4871 - val_loss: 2.3676 - val_acc: 0.2433\n",
      "Epoch 813/1000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.3146 - acc: 0.4886 - val_loss: 2.3993 - val_acc: 0.2467\n",
      "Epoch 814/1000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.3153 - acc: 0.4829 - val_loss: 2.4074 - val_acc: 0.2467\n",
      "Epoch 815/1000\n",
      "700/700 [==============================] - 0s 117us/step - loss: 1.3144 - acc: 0.4843 - val_loss: 2.4038 - val_acc: 0.2400\n",
      "Epoch 816/1000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 1.3142 - acc: 0.4857 - val_loss: 2.4043 - val_acc: 0.2467\n",
      "Epoch 817/1000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 1.3149 - acc: 0.4814 - val_loss: 2.4145 - val_acc: 0.2500\n",
      "Epoch 818/1000\n",
      "700/700 [==============================] - 0s 75us/step - loss: 1.3153 - acc: 0.4886 - val_loss: 2.4026 - val_acc: 0.2433\n",
      "Epoch 819/1000\n",
      "700/700 [==============================] - 0s 88us/step - loss: 1.3142 - acc: 0.4843 - val_loss: 2.4188 - val_acc: 0.2467\n",
      "Epoch 820/1000\n",
      "700/700 [==============================] - 0s 120us/step - loss: 1.3144 - acc: 0.4829 - val_loss: 2.4052 - val_acc: 0.2433\n",
      "Epoch 821/1000\n",
      "700/700 [==============================] - 0s 122us/step - loss: 1.3143 - acc: 0.4929 - val_loss: 2.4222 - val_acc: 0.2467\n",
      "Epoch 822/1000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.3144 - acc: 0.4829 - val_loss: 2.4115 - val_acc: 0.2467\n",
      "Epoch 823/1000\n",
      "700/700 [==============================] - 0s 118us/step - loss: 1.3145 - acc: 0.4829 - val_loss: 2.3983 - val_acc: 0.2533\n",
      "Epoch 824/1000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.3143 - acc: 0.4829 - val_loss: 2.4067 - val_acc: 0.2500\n",
      "Epoch 825/1000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.3151 - acc: 0.4871 - val_loss: 2.3951 - val_acc: 0.2500\n",
      "Epoch 826/1000\n",
      "700/700 [==============================] - 0s 118us/step - loss: 1.3139 - acc: 0.4857 - val_loss: 2.3958 - val_acc: 0.2433\n",
      "Epoch 827/1000\n",
      "700/700 [==============================] - 0s 115us/step - loss: 1.3139 - acc: 0.4857 - val_loss: 2.3939 - val_acc: 0.2433\n",
      "Epoch 828/1000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.3141 - acc: 0.4829 - val_loss: 2.4282 - val_acc: 0.2467\n",
      "Epoch 829/1000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.3139 - acc: 0.4900 - val_loss: 2.3979 - val_acc: 0.2400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 830/1000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 1.3139 - acc: 0.4843 - val_loss: 2.4138 - val_acc: 0.2467\n",
      "Epoch 831/1000\n",
      "700/700 [==============================] - 0s 108us/step - loss: 1.3136 - acc: 0.4843 - val_loss: 2.4074 - val_acc: 0.2433\n",
      "Epoch 832/1000\n",
      "700/700 [==============================] - 0s 112us/step - loss: 1.3135 - acc: 0.4871 - val_loss: 2.4160 - val_acc: 0.2467\n",
      "Epoch 833/1000\n",
      "700/700 [==============================] - 0s 112us/step - loss: 1.3135 - acc: 0.4814 - val_loss: 2.4154 - val_acc: 0.2467\n",
      "Epoch 834/1000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.3145 - acc: 0.4843 - val_loss: 2.3812 - val_acc: 0.2400\n",
      "Epoch 835/1000\n",
      "700/700 [==============================] - 0s 108us/step - loss: 1.3139 - acc: 0.4857 - val_loss: 2.4167 - val_acc: 0.2467\n",
      "Epoch 836/1000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 1.3128 - acc: 0.4914 - val_loss: 2.4166 - val_acc: 0.2467\n",
      "Epoch 837/1000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.3136 - acc: 0.4843 - val_loss: 2.4158 - val_acc: 0.2433\n",
      "Epoch 838/1000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.3134 - acc: 0.4771 - val_loss: 2.4065 - val_acc: 0.2433\n",
      "Epoch 839/1000\n",
      "700/700 [==============================] - 0s 108us/step - loss: 1.3137 - acc: 0.4929 - val_loss: 2.4289 - val_acc: 0.2500\n",
      "Epoch 840/1000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.3134 - acc: 0.4829 - val_loss: 2.4174 - val_acc: 0.2433\n",
      "Epoch 841/1000\n",
      "700/700 [==============================] - 0s 112us/step - loss: 1.3133 - acc: 0.4871 - val_loss: 2.4067 - val_acc: 0.2433\n",
      "Epoch 842/1000\n",
      "700/700 [==============================] - 0s 112us/step - loss: 1.3132 - acc: 0.4914 - val_loss: 2.3973 - val_acc: 0.2400\n",
      "Epoch 843/1000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 1.3137 - acc: 0.4843 - val_loss: 2.4086 - val_acc: 0.2400\n",
      "Epoch 844/1000\n",
      "700/700 [==============================] - 0s 108us/step - loss: 1.3130 - acc: 0.4886 - val_loss: 2.4116 - val_acc: 0.2533\n",
      "Epoch 845/1000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.3126 - acc: 0.4900 - val_loss: 2.4075 - val_acc: 0.2433\n",
      "Epoch 846/1000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.3121 - acc: 0.4814 - val_loss: 2.4034 - val_acc: 0.2433\n",
      "Epoch 847/1000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.3133 - acc: 0.4886 - val_loss: 2.4123 - val_acc: 0.2367\n",
      "Epoch 848/1000\n",
      "700/700 [==============================] - 0s 117us/step - loss: 1.3123 - acc: 0.4886 - val_loss: 2.4096 - val_acc: 0.2433\n",
      "Epoch 849/1000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.3126 - acc: 0.4843 - val_loss: 2.3959 - val_acc: 0.2433\n",
      "Epoch 850/1000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 1.3125 - acc: 0.4829 - val_loss: 2.4071 - val_acc: 0.2433\n",
      "Epoch 851/1000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.3126 - acc: 0.4857 - val_loss: 2.4026 - val_acc: 0.2433\n",
      "Epoch 852/1000\n",
      "700/700 [==============================] - 0s 123us/step - loss: 1.3128 - acc: 0.4814 - val_loss: 2.3927 - val_acc: 0.2400\n",
      "Epoch 853/1000\n",
      "700/700 [==============================] - 0s 120us/step - loss: 1.3120 - acc: 0.4886 - val_loss: 2.4191 - val_acc: 0.2467\n",
      "Epoch 854/1000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.3130 - acc: 0.4771 - val_loss: 2.3954 - val_acc: 0.2400\n",
      "Epoch 855/1000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.3123 - acc: 0.4914 - val_loss: 2.4001 - val_acc: 0.2533\n",
      "Epoch 856/1000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.3117 - acc: 0.4857 - val_loss: 2.4203 - val_acc: 0.2467\n",
      "Epoch 857/1000\n",
      "700/700 [==============================] - 0s 117us/step - loss: 1.3127 - acc: 0.4900 - val_loss: 2.4028 - val_acc: 0.2533\n",
      "Epoch 858/1000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.3114 - acc: 0.4886 - val_loss: 2.4156 - val_acc: 0.2467\n",
      "Epoch 859/1000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.3106 - acc: 0.4943 - val_loss: 2.4257 - val_acc: 0.2433\n",
      "Epoch 860/1000\n",
      "700/700 [==============================] - 0s 118us/step - loss: 1.3128 - acc: 0.4843 - val_loss: 2.4191 - val_acc: 0.2400\n",
      "Epoch 861/1000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.3113 - acc: 0.4943 - val_loss: 2.4194 - val_acc: 0.2467\n",
      "Epoch 862/1000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 1.3107 - acc: 0.4914 - val_loss: 2.4098 - val_acc: 0.2433\n",
      "Epoch 863/1000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.3117 - acc: 0.4857 - val_loss: 2.4218 - val_acc: 0.2433\n",
      "Epoch 864/1000\n",
      "700/700 [==============================] - 0s 123us/step - loss: 1.3105 - acc: 0.4800 - val_loss: 2.4147 - val_acc: 0.2467\n",
      "Epoch 865/1000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.3118 - acc: 0.4857 - val_loss: 2.4076 - val_acc: 0.2467\n",
      "Epoch 866/1000\n",
      "700/700 [==============================] - 0s 112us/step - loss: 1.3124 - acc: 0.4800 - val_loss: 2.4112 - val_acc: 0.2533\n",
      "Epoch 867/1000\n",
      "700/700 [==============================] - 0s 116us/step - loss: 1.3110 - acc: 0.4871 - val_loss: 2.4245 - val_acc: 0.2467\n",
      "Epoch 868/1000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.3101 - acc: 0.4843 - val_loss: 2.4147 - val_acc: 0.2467\n",
      "Epoch 869/1000\n",
      "700/700 [==============================] - 0s 112us/step - loss: 1.3111 - acc: 0.4871 - val_loss: 2.4126 - val_acc: 0.2400\n",
      "Epoch 870/1000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.3106 - acc: 0.4843 - val_loss: 2.4266 - val_acc: 0.2433\n",
      "Epoch 871/1000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.3107 - acc: 0.4843 - val_loss: 2.4186 - val_acc: 0.2433\n",
      "Epoch 872/1000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.3114 - acc: 0.4843 - val_loss: 2.4108 - val_acc: 0.2433\n",
      "Epoch 873/1000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.3102 - acc: 0.4929 - val_loss: 2.4037 - val_acc: 0.2467\n",
      "Epoch 874/1000\n",
      "700/700 [==============================] - 0s 82us/step - loss: 1.3109 - acc: 0.4871 - val_loss: 2.4180 - val_acc: 0.2433\n",
      "Epoch 875/1000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.3101 - acc: 0.4871 - val_loss: 2.4121 - val_acc: 0.2467\n",
      "Epoch 876/1000\n",
      "700/700 [==============================] - 0s 88us/step - loss: 1.3114 - acc: 0.4857 - val_loss: 2.4062 - val_acc: 0.2467\n",
      "Epoch 877/1000\n",
      "700/700 [==============================] - 0s 112us/step - loss: 1.3108 - acc: 0.4857 - val_loss: 2.4214 - val_acc: 0.2467\n",
      "Epoch 878/1000\n",
      "700/700 [==============================] - 0s 143us/step - loss: 1.3109 - acc: 0.4871 - val_loss: 2.4066 - val_acc: 0.2433\n",
      "Epoch 879/1000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.3099 - acc: 0.4914 - val_loss: 2.4115 - val_acc: 0.2533\n",
      "Epoch 880/1000\n",
      "700/700 [==============================] - 0s 92us/step - loss: 1.3094 - acc: 0.4943 - val_loss: 2.4312 - val_acc: 0.2433\n",
      "Epoch 881/1000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3106 - acc: 0.4871 - val_loss: 2.3838 - val_acc: 0.2467\n",
      "Epoch 882/1000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.3105 - acc: 0.4829 - val_loss: 2.4165 - val_acc: 0.2467\n",
      "Epoch 883/1000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.3104 - acc: 0.4871 - val_loss: 2.4043 - val_acc: 0.2400\n",
      "Epoch 884/1000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3107 - acc: 0.4871 - val_loss: 2.4280 - val_acc: 0.2467\n",
      "Epoch 885/1000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.3103 - acc: 0.4857 - val_loss: 2.4143 - val_acc: 0.2400\n",
      "Epoch 886/1000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.3095 - acc: 0.4886 - val_loss: 2.3936 - val_acc: 0.2400\n",
      "Epoch 887/1000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.3094 - acc: 0.4857 - val_loss: 2.3983 - val_acc: 0.2467\n",
      "Epoch 888/1000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.3099 - acc: 0.4914 - val_loss: 2.4136 - val_acc: 0.2467\n",
      "Epoch 889/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 99us/step - loss: 1.3106 - acc: 0.4843 - val_loss: 2.4261 - val_acc: 0.2467\n",
      "Epoch 890/1000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3103 - acc: 0.4857 - val_loss: 2.4234 - val_acc: 0.2400\n",
      "Epoch 891/1000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.3097 - acc: 0.4886 - val_loss: 2.4165 - val_acc: 0.2500\n",
      "Epoch 892/1000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.3092 - acc: 0.4900 - val_loss: 2.4116 - val_acc: 0.2400\n",
      "Epoch 893/1000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.3083 - acc: 0.4957 - val_loss: 2.4245 - val_acc: 0.2467\n",
      "Epoch 894/1000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.3098 - acc: 0.4857 - val_loss: 2.4247 - val_acc: 0.2467\n",
      "Epoch 895/1000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.3098 - acc: 0.4829 - val_loss: 2.4288 - val_acc: 0.2467\n",
      "Epoch 896/1000\n",
      "700/700 [==============================] - 0s 115us/step - loss: 1.3098 - acc: 0.4900 - val_loss: 2.4317 - val_acc: 0.2467\n",
      "Epoch 897/1000\n",
      "700/700 [==============================] - 0s 162us/step - loss: 1.3099 - acc: 0.4829 - val_loss: 2.4155 - val_acc: 0.2433\n",
      "Epoch 898/1000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.3090 - acc: 0.4900 - val_loss: 2.4054 - val_acc: 0.2433\n",
      "Epoch 899/1000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.3093 - acc: 0.4900 - val_loss: 2.4085 - val_acc: 0.2500\n",
      "Epoch 900/1000\n",
      "700/700 [==============================] - 0s 124us/step - loss: 1.3092 - acc: 0.4829 - val_loss: 2.4193 - val_acc: 0.2500\n",
      "Epoch 901/1000\n",
      "700/700 [==============================] - 0s 133us/step - loss: 1.3097 - acc: 0.4857 - val_loss: 2.4103 - val_acc: 0.2467\n",
      "Epoch 902/1000\n",
      "700/700 [==============================] - 0s 143us/step - loss: 1.3086 - acc: 0.4871 - val_loss: 2.4396 - val_acc: 0.2533\n",
      "Epoch 903/1000\n",
      "700/700 [==============================] - 0s 131us/step - loss: 1.3081 - acc: 0.4843 - val_loss: 2.4300 - val_acc: 0.2467\n",
      "Epoch 904/1000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.3091 - acc: 0.4900 - val_loss: 2.4251 - val_acc: 0.2400\n",
      "Epoch 905/1000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3089 - acc: 0.4929 - val_loss: 2.4108 - val_acc: 0.2533\n",
      "Epoch 906/1000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 1.3100 - acc: 0.4843 - val_loss: 2.4140 - val_acc: 0.2500\n",
      "Epoch 907/1000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.3086 - acc: 0.4871 - val_loss: 2.4197 - val_acc: 0.2467\n",
      "Epoch 908/1000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.3086 - acc: 0.4843 - val_loss: 2.4122 - val_acc: 0.2500\n",
      "Epoch 909/1000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.3085 - acc: 0.4900 - val_loss: 2.4308 - val_acc: 0.2467\n",
      "Epoch 910/1000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.3082 - acc: 0.4929 - val_loss: 2.4388 - val_acc: 0.2467\n",
      "Epoch 911/1000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.3087 - acc: 0.4829 - val_loss: 2.4458 - val_acc: 0.2533\n",
      "Epoch 912/1000\n",
      "700/700 [==============================] - 0s 84us/step - loss: 1.3089 - acc: 0.4929 - val_loss: 2.3889 - val_acc: 0.2433\n",
      "Epoch 913/1000\n",
      "700/700 [==============================] - 0s 92us/step - loss: 1.3090 - acc: 0.4900 - val_loss: 2.4270 - val_acc: 0.2400\n",
      "Epoch 914/1000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.3088 - acc: 0.4871 - val_loss: 2.4220 - val_acc: 0.2433\n",
      "Epoch 915/1000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.3087 - acc: 0.4886 - val_loss: 2.4268 - val_acc: 0.2467\n",
      "Epoch 916/1000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3089 - acc: 0.4900 - val_loss: 2.4461 - val_acc: 0.2467\n",
      "Epoch 917/1000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 1.3085 - acc: 0.4900 - val_loss: 2.4225 - val_acc: 0.2400\n",
      "Epoch 918/1000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.3078 - acc: 0.4900 - val_loss: 2.4168 - val_acc: 0.2500\n",
      "Epoch 919/1000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.3082 - acc: 0.4857 - val_loss: 2.4034 - val_acc: 0.2433\n",
      "Epoch 920/1000\n",
      "700/700 [==============================] - 0s 98us/step - loss: 1.3090 - acc: 0.4814 - val_loss: 2.4143 - val_acc: 0.2400\n",
      "Epoch 921/1000\n",
      "700/700 [==============================] - 0s 98us/step - loss: 1.3078 - acc: 0.4914 - val_loss: 2.4275 - val_acc: 0.2400\n",
      "Epoch 922/1000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.3075 - acc: 0.4871 - val_loss: 2.4181 - val_acc: 0.2467\n",
      "Epoch 923/1000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3080 - acc: 0.4943 - val_loss: 2.4364 - val_acc: 0.2533\n",
      "Epoch 924/1000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.3074 - acc: 0.4886 - val_loss: 2.3985 - val_acc: 0.2400\n",
      "Epoch 925/1000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.3077 - acc: 0.4929 - val_loss: 2.4384 - val_acc: 0.2467\n",
      "Epoch 926/1000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 1.3081 - acc: 0.4886 - val_loss: 2.4432 - val_acc: 0.2467\n",
      "Epoch 927/1000\n",
      "700/700 [==============================] - 0s 125us/step - loss: 1.3071 - acc: 0.4900 - val_loss: 2.4260 - val_acc: 0.2467\n",
      "Epoch 928/1000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.3078 - acc: 0.4829 - val_loss: 2.4384 - val_acc: 0.2533\n",
      "Epoch 929/1000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3072 - acc: 0.4914 - val_loss: 2.4203 - val_acc: 0.2467\n",
      "Epoch 930/1000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.3073 - acc: 0.4914 - val_loss: 2.4330 - val_acc: 0.2467\n",
      "Epoch 931/1000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.3076 - acc: 0.4871 - val_loss: 2.4300 - val_acc: 0.2467\n",
      "Epoch 932/1000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.3071 - acc: 0.4914 - val_loss: 2.4340 - val_acc: 0.2433\n",
      "Epoch 933/1000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.3078 - acc: 0.4957 - val_loss: 2.4455 - val_acc: 0.2533\n",
      "Epoch 934/1000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3074 - acc: 0.4814 - val_loss: 2.4191 - val_acc: 0.2467\n",
      "Epoch 935/1000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.3069 - acc: 0.4957 - val_loss: 2.4236 - val_acc: 0.2433\n",
      "Epoch 936/1000\n",
      "700/700 [==============================] - 0s 92us/step - loss: 1.3056 - acc: 0.4843 - val_loss: 2.4373 - val_acc: 0.2467\n",
      "Epoch 937/1000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.3089 - acc: 0.4914 - val_loss: 2.4213 - val_acc: 0.2433\n",
      "Epoch 938/1000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 1.3074 - acc: 0.4929 - val_loss: 2.4408 - val_acc: 0.2433\n",
      "Epoch 939/1000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.3075 - acc: 0.4886 - val_loss: 2.4356 - val_acc: 0.2433\n",
      "Epoch 940/1000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.3068 - acc: 0.4900 - val_loss: 2.4405 - val_acc: 0.2467\n",
      "Epoch 941/1000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.3072 - acc: 0.4914 - val_loss: 2.4102 - val_acc: 0.2400\n",
      "Epoch 942/1000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3069 - acc: 0.4900 - val_loss: 2.4285 - val_acc: 0.2400\n",
      "Epoch 943/1000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.3066 - acc: 0.4871 - val_loss: 2.4217 - val_acc: 0.2433\n",
      "Epoch 944/1000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.3068 - acc: 0.4914 - val_loss: 2.4314 - val_acc: 0.2433\n",
      "Epoch 945/1000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.3067 - acc: 0.4914 - val_loss: 2.4185 - val_acc: 0.2433\n",
      "Epoch 946/1000\n",
      "700/700 [==============================] - 0s 115us/step - loss: 1.3071 - acc: 0.4886 - val_loss: 2.4276 - val_acc: 0.2433\n",
      "Epoch 947/1000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.3063 - acc: 0.4900 - val_loss: 2.4261 - val_acc: 0.2433\n",
      "Epoch 948/1000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.3065 - acc: 0.4886 - val_loss: 2.4266 - val_acc: 0.2467\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 949/1000\n",
      "700/700 [==============================] - 0s 85us/step - loss: 1.3060 - acc: 0.4914 - val_loss: 2.4347 - val_acc: 0.2400\n",
      "Epoch 950/1000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.3057 - acc: 0.4886 - val_loss: 2.4101 - val_acc: 0.2433\n",
      "Epoch 951/1000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.3067 - acc: 0.4900 - val_loss: 2.4198 - val_acc: 0.2467\n",
      "Epoch 952/1000\n",
      "700/700 [==============================] - 0s 118us/step - loss: 1.3061 - acc: 0.4914 - val_loss: 2.4107 - val_acc: 0.2467\n",
      "Epoch 953/1000\n",
      "700/700 [==============================] - 0s 108us/step - loss: 1.3066 - acc: 0.4914 - val_loss: 2.4262 - val_acc: 0.2500\n",
      "Epoch 954/1000\n",
      "700/700 [==============================] - 0s 75us/step - loss: 1.3059 - acc: 0.4886 - val_loss: 2.4264 - val_acc: 0.2467\n",
      "Epoch 955/1000\n",
      "700/700 [==============================] - 0s 76us/step - loss: 1.3059 - acc: 0.4886 - val_loss: 2.4350 - val_acc: 0.2467\n",
      "Epoch 956/1000\n",
      "700/700 [==============================] - 0s 88us/step - loss: 1.3065 - acc: 0.4871 - val_loss: 2.4471 - val_acc: 0.2467\n",
      "Epoch 957/1000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.3055 - acc: 0.4943 - val_loss: 2.4417 - val_acc: 0.2467\n",
      "Epoch 958/1000\n",
      "700/700 [==============================] - 0s 117us/step - loss: 1.3063 - acc: 0.4857 - val_loss: 2.4327 - val_acc: 0.2433\n",
      "Epoch 959/1000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.3053 - acc: 0.4871 - val_loss: 2.4262 - val_acc: 0.2533\n",
      "Epoch 960/1000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3062 - acc: 0.4943 - val_loss: 2.4238 - val_acc: 0.2400\n",
      "Epoch 961/1000\n",
      "700/700 [==============================] - 0s 98us/step - loss: 1.3061 - acc: 0.4871 - val_loss: 2.4354 - val_acc: 0.2400\n",
      "Epoch 962/1000\n",
      "700/700 [==============================] - 0s 92us/step - loss: 1.3053 - acc: 0.4943 - val_loss: 2.4418 - val_acc: 0.2467\n",
      "Epoch 963/1000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.3058 - acc: 0.4857 - val_loss: 2.4339 - val_acc: 0.2433\n",
      "Epoch 964/1000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 1.3055 - acc: 0.4871 - val_loss: 2.4182 - val_acc: 0.2367\n",
      "Epoch 965/1000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3052 - acc: 0.4829 - val_loss: 2.4189 - val_acc: 0.2400\n",
      "Epoch 966/1000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.3051 - acc: 0.4943 - val_loss: 2.4371 - val_acc: 0.2467\n",
      "Epoch 967/1000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.3053 - acc: 0.4971 - val_loss: 2.4434 - val_acc: 0.2400\n",
      "Epoch 968/1000\n",
      "700/700 [==============================] - 0s 170us/step - loss: 1.3050 - acc: 0.4914 - val_loss: 2.4300 - val_acc: 0.2400\n",
      "Epoch 969/1000\n",
      "700/700 [==============================] - 0s 124us/step - loss: 1.3048 - acc: 0.4943 - val_loss: 2.4452 - val_acc: 0.2433\n",
      "Epoch 970/1000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.3052 - acc: 0.4843 - val_loss: 2.4469 - val_acc: 0.2433\n",
      "Epoch 971/1000\n",
      "700/700 [==============================] - 0s 86us/step - loss: 1.3050 - acc: 0.4957 - val_loss: 2.4475 - val_acc: 0.2433\n",
      "Epoch 972/1000\n",
      "700/700 [==============================] - 0s 88us/step - loss: 1.3049 - acc: 0.4943 - val_loss: 2.4072 - val_acc: 0.2433\n",
      "Epoch 973/1000\n",
      "700/700 [==============================] - 0s 80us/step - loss: 1.3048 - acc: 0.4914 - val_loss: 2.4368 - val_acc: 0.2433\n",
      "Epoch 974/1000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3050 - acc: 0.4900 - val_loss: 2.4477 - val_acc: 0.2433\n",
      "Epoch 975/1000\n",
      "700/700 [==============================] - 0s 92us/step - loss: 1.3055 - acc: 0.4929 - val_loss: 2.4379 - val_acc: 0.2467\n",
      "Epoch 976/1000\n",
      "700/700 [==============================] - 0s 98us/step - loss: 1.3047 - acc: 0.4857 - val_loss: 2.4458 - val_acc: 0.2467\n",
      "Epoch 977/1000\n",
      "700/700 [==============================] - 0s 117us/step - loss: 1.3045 - acc: 0.4914 - val_loss: 2.4092 - val_acc: 0.2400\n",
      "Epoch 978/1000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.3037 - acc: 0.4929 - val_loss: 2.4262 - val_acc: 0.2433\n",
      "Epoch 979/1000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.3050 - acc: 0.4929 - val_loss: 2.4196 - val_acc: 0.2333\n",
      "Epoch 980/1000\n",
      "700/700 [==============================] - 0s 151us/step - loss: 1.3050 - acc: 0.4886 - val_loss: 2.4184 - val_acc: 0.2433\n",
      "Epoch 981/1000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.3046 - acc: 0.4957 - val_loss: 2.4222 - val_acc: 0.2467\n",
      "Epoch 982/1000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.3042 - acc: 0.4914 - val_loss: 2.4331 - val_acc: 0.2400\n",
      "Epoch 983/1000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.3038 - acc: 0.4929 - val_loss: 2.4273 - val_acc: 0.2433\n",
      "Epoch 984/1000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.3045 - acc: 0.4886 - val_loss: 2.4425 - val_acc: 0.2400\n",
      "Epoch 985/1000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.3041 - acc: 0.4914 - val_loss: 2.4334 - val_acc: 0.2467\n",
      "Epoch 986/1000\n",
      "700/700 [==============================] - 0s 127us/step - loss: 1.3037 - acc: 0.4971 - val_loss: 2.4295 - val_acc: 0.2367\n",
      "Epoch 987/1000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.3041 - acc: 0.4929 - val_loss: 2.4401 - val_acc: 0.2433\n",
      "Epoch 988/1000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.3036 - acc: 0.4971 - val_loss: 2.4342 - val_acc: 0.2433\n",
      "Epoch 989/1000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.3041 - acc: 0.4900 - val_loss: 2.4382 - val_acc: 0.2467\n",
      "Epoch 990/1000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.3037 - acc: 0.4929 - val_loss: 2.4346 - val_acc: 0.2467\n",
      "Epoch 991/1000\n",
      "700/700 [==============================] - 0s 126us/step - loss: 1.3036 - acc: 0.4914 - val_loss: 2.4382 - val_acc: 0.2400\n",
      "Epoch 992/1000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3040 - acc: 0.4886 - val_loss: 2.4419 - val_acc: 0.2400\n",
      "Epoch 993/1000\n",
      "700/700 [==============================] - 0s 98us/step - loss: 1.3040 - acc: 0.4929 - val_loss: 2.4266 - val_acc: 0.2433\n",
      "Epoch 994/1000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.3029 - acc: 0.4957 - val_loss: 2.4310 - val_acc: 0.2500\n",
      "Epoch 995/1000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.3038 - acc: 0.4900 - val_loss: 2.4430 - val_acc: 0.2467\n",
      "Epoch 996/1000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.3035 - acc: 0.4929 - val_loss: 2.4206 - val_acc: 0.2400\n",
      "Epoch 997/1000\n",
      "700/700 [==============================] - 0s 98us/step - loss: 1.3040 - acc: 0.4914 - val_loss: 2.4260 - val_acc: 0.2400\n",
      "Epoch 998/1000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.3037 - acc: 0.4900 - val_loss: 2.4439 - val_acc: 0.2433\n",
      "Epoch 999/1000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.3033 - acc: 0.4929 - val_loss: 2.4492 - val_acc: 0.2433\n",
      "Epoch 1000/1000\n",
      "700/700 [==============================] - 0s 82us/step - loss: 1.3034 - acc: 0.4900 - val_loss: 2.4432 - val_acc: 0.2400\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f8104298cf8>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## add tensorboard for log\n",
    "## check the result via: tensorboard --logdir=~/Projects/Keras/_writing/graph(absolute path)\n",
    "import keras\n",
    "# 4.  \n",
    "tb_hist = keras.callbacks.TensorBoard(log_dir='./graph', histogram_freq=0, write_graph=True, write_images=True)\n",
    "model.fit(X_train, Y_train, epochs=1000, batch_size=10, validation_data=(X_val, Y_val), callbacks=[tb_hist])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
