{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0. 사용할 패키지 불러오기\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "width = 16\n",
    "height = 16\n",
    "\n",
    "def generate_dataset(samples):\n",
    "\n",
    "    ds_x = []\n",
    "    ds_y = []\n",
    "    \n",
    "    for it in range(samples):\n",
    "        \n",
    "        num_pt = np.random.randint(0, width * height)\n",
    "        img = generate_image(num_pt)\n",
    "        \n",
    "        ds_y.append(num_pt)\n",
    "        ds_x.append(img)\n",
    "    \n",
    "    return np.array(ds_x), np.array(ds_y).reshape(samples, 1)\n",
    "    \n",
    "def generate_image(points):\n",
    "    \n",
    "    img = np.zeros((width, height))\n",
    "    pts = np.random.random((points, 2))\n",
    "    \n",
    "    for ipt in pts:\n",
    "        img[int(ipt[0] * width), int(ipt[1] * height)] = 1\n",
    "    \n",
    "    return img.reshape(width, height, 1)\n",
    "\n",
    "# 1. 데이터셋 생성하기\n",
    "x_train, y_train = generate_dataset(1500)\n",
    "x_val, y_val = generate_dataset(300)\n",
    "x_test, y_test = generate_dataset(100)\n",
    "\n",
    "## flatten - 4 dense layer\n",
    "x_train_1d = x_train.reshape(x_train.shape[0], width*height)\n",
    "x_val_1d = x_val.reshape(x_val.shape[0], width*height)\n",
    "x_test_1d = x_test.reshape(x_test.shape[0], width*height)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1500 samples, validate on 300 samples\n",
      "Epoch 1/1000\n",
      "1500/1500 [==============================] - 1s 393us/step - loss: 4350.9521 - val_loss: 411.3909\n",
      "Epoch 2/1000\n",
      "1500/1500 [==============================] - 0s 135us/step - loss: 263.9700 - val_loss: 209.5471\n",
      "Epoch 3/1000\n",
      "1500/1500 [==============================] - 0s 135us/step - loss: 195.2146 - val_loss: 173.3117\n",
      "Epoch 4/1000\n",
      "1500/1500 [==============================] - 0s 135us/step - loss: 145.1568 - val_loss: 144.8355\n",
      "Epoch 5/1000\n",
      "1500/1500 [==============================] - 0s 144us/step - loss: 109.5698 - val_loss: 163.7816\n",
      "Epoch 6/1000\n",
      "1500/1500 [==============================] - 0s 181us/step - loss: 89.2491 - val_loss: 134.8121\n",
      "Epoch 7/1000\n",
      "1500/1500 [==============================] - 0s 140us/step - loss: 68.3135 - val_loss: 115.5831\n",
      "Epoch 8/1000\n",
      "1500/1500 [==============================] - 0s 138us/step - loss: 57.5167 - val_loss: 116.2626\n",
      "Epoch 9/1000\n",
      "1500/1500 [==============================] - 0s 132us/step - loss: 48.8068 - val_loss: 120.0838\n",
      "Epoch 10/1000\n",
      "1500/1500 [==============================] - 0s 148us/step - loss: 36.3617 - val_loss: 102.9721\n",
      "Epoch 11/1000\n",
      "1500/1500 [==============================] - 0s 135us/step - loss: 30.8099 - val_loss: 125.6278\n",
      "Epoch 12/1000\n",
      "1500/1500 [==============================] - 0s 136us/step - loss: 30.1888 - val_loss: 109.0662\n",
      "Epoch 13/1000\n",
      "1500/1500 [==============================] - 0s 133us/step - loss: 18.5743 - val_loss: 106.6783\n",
      "Epoch 14/1000\n",
      "1500/1500 [==============================] - 0s 137us/step - loss: 14.7573 - val_loss: 105.8088\n",
      "Epoch 15/1000\n",
      "1500/1500 [==============================] - 0s 172us/step - loss: 12.1506 - val_loss: 102.0294\n",
      "Epoch 16/1000\n",
      "1500/1500 [==============================] - 0s 166us/step - loss: 8.5385 - val_loss: 103.3337\n",
      "Epoch 17/1000\n",
      "1500/1500 [==============================] - 0s 132us/step - loss: 5.6979 - val_loss: 98.5728\n",
      "Epoch 18/1000\n",
      "1500/1500 [==============================] - 0s 157us/step - loss: 4.5870 - val_loss: 103.2749\n",
      "Epoch 19/1000\n",
      "1500/1500 [==============================] - 0s 156us/step - loss: 3.7321 - val_loss: 101.3987\n",
      "Epoch 20/1000\n",
      "1500/1500 [==============================] - 0s 132us/step - loss: 2.2045 - val_loss: 102.4847\n",
      "Epoch 21/1000\n",
      "1500/1500 [==============================] - 0s 144us/step - loss: 2.2991 - val_loss: 99.8888\n",
      "Epoch 22/1000\n",
      "1500/1500 [==============================] - 0s 169us/step - loss: 1.8758 - val_loss: 100.0222\n",
      "Epoch 23/1000\n",
      "1500/1500 [==============================] - 0s 134us/step - loss: 1.0590 - val_loss: 99.1476\n",
      "Epoch 24/1000\n",
      "1500/1500 [==============================] - 0s 178us/step - loss: 0.8145 - val_loss: 100.0409\n",
      "Epoch 25/1000\n",
      "1500/1500 [==============================] - 0s 137us/step - loss: 0.4850 - val_loss: 100.1802\n",
      "Epoch 26/1000\n",
      "1500/1500 [==============================] - 0s 135us/step - loss: 0.3243 - val_loss: 99.6798\n",
      "Epoch 27/1000\n",
      "1500/1500 [==============================] - 0s 136us/step - loss: 0.2704 - val_loss: 99.6023\n",
      "Epoch 28/1000\n",
      "1500/1500 [==============================] - 0s 132us/step - loss: 0.2121 - val_loss: 99.9387\n",
      "Epoch 29/1000\n",
      "1500/1500 [==============================] - 0s 137us/step - loss: 0.1473 - val_loss: 99.1924\n",
      "Epoch 30/1000\n",
      "1500/1500 [==============================] - 0s 133us/step - loss: 0.1413 - val_loss: 99.5761\n",
      "Epoch 31/1000\n",
      "1500/1500 [==============================] - 0s 136us/step - loss: 0.1229 - val_loss: 99.4747\n",
      "Epoch 32/1000\n",
      "1500/1500 [==============================] - 0s 137us/step - loss: 0.1476 - val_loss: 100.7239\n",
      "Epoch 33/1000\n",
      "1500/1500 [==============================] - 0s 134us/step - loss: 0.4914 - val_loss: 99.4535\n",
      "Epoch 34/1000\n",
      "1500/1500 [==============================] - 0s 137us/step - loss: 1.2252 - val_loss: 98.9824\n",
      "Epoch 35/1000\n",
      "1500/1500 [==============================] - 0s 134us/step - loss: 1.3378 - val_loss: 98.6046\n",
      "Epoch 36/1000\n",
      "1500/1500 [==============================] - 0s 133us/step - loss: 1.2133 - val_loss: 102.9950\n",
      "Epoch 37/1000\n",
      "1500/1500 [==============================] - 0s 137us/step - loss: 1.6297 - val_loss: 99.8127\n",
      "Epoch 38/1000\n",
      "1500/1500 [==============================] - 0s 136us/step - loss: 1.8274 - val_loss: 97.8246\n",
      "Epoch 39/1000\n",
      "1500/1500 [==============================] - 0s 139us/step - loss: 1.6263 - val_loss: 101.9097\n",
      "Epoch 40/1000\n",
      "1500/1500 [==============================] - 0s 134us/step - loss: 2.4422 - val_loss: 101.8152\n",
      "Epoch 41/1000\n",
      "1500/1500 [==============================] - 0s 134us/step - loss: 2.5969 - val_loss: 99.7396\n",
      "Epoch 42/1000\n",
      "1500/1500 [==============================] - 0s 137us/step - loss: 2.3702 - val_loss: 101.4185\n",
      "Epoch 43/1000\n",
      "1500/1500 [==============================] - 0s 137us/step - loss: 1.7696 - val_loss: 100.2919\n",
      "Epoch 44/1000\n",
      "1500/1500 [==============================] - 0s 140us/step - loss: 1.6850 - val_loss: 100.4736\n",
      "Epoch 45/1000\n",
      "1500/1500 [==============================] - 0s 135us/step - loss: 2.3217 - val_loss: 100.2023\n",
      "Epoch 46/1000\n",
      "1500/1500 [==============================] - 0s 137us/step - loss: 6.1732 - val_loss: 104.6739\n",
      "Epoch 47/1000\n",
      "1500/1500 [==============================] - 0s 135us/step - loss: 5.4083 - val_loss: 98.8598\n",
      "Epoch 48/1000\n",
      "1500/1500 [==============================] - 0s 136us/step - loss: 3.2366 - val_loss: 102.9163\n",
      "Epoch 49/1000\n",
      "1500/1500 [==============================] - 0s 133us/step - loss: 2.7648 - val_loss: 97.8078\n",
      "Epoch 50/1000\n",
      "1500/1500 [==============================] - 0s 137us/step - loss: 2.1527 - val_loss: 101.0465\n",
      "Epoch 51/1000\n",
      "1500/1500 [==============================] - 0s 132us/step - loss: 1.2988 - val_loss: 96.8957\n",
      "Epoch 52/1000\n",
      "1500/1500 [==============================] - 0s 141us/step - loss: 1.4725 - val_loss: 100.9749\n",
      "Epoch 53/1000\n",
      "1500/1500 [==============================] - 0s 134us/step - loss: 2.8376 - val_loss: 95.5998\n",
      "Epoch 54/1000\n",
      "1500/1500 [==============================] - 0s 137us/step - loss: 3.1397 - val_loss: 109.5535\n",
      "Epoch 55/1000\n",
      "1500/1500 [==============================] - 0s 129us/step - loss: 5.1341 - val_loss: 99.8179\n",
      "Epoch 56/1000\n",
      "1500/1500 [==============================] - 0s 128us/step - loss: 5.7388 - val_loss: 108.0255\n",
      "Epoch 57/1000\n",
      "1500/1500 [==============================] - 0s 128us/step - loss: 6.0146 - val_loss: 109.0381\n",
      "Epoch 58/1000\n",
      "1500/1500 [==============================] - 0s 127us/step - loss: 8.0637 - val_loss: 106.2365\n",
      "Epoch 59/1000\n",
      "1500/1500 [==============================] - 0s 127us/step - loss: 13.4856 - val_loss: 101.1687\n",
      "Epoch 60/1000\n",
      "1500/1500 [==============================] - 0s 125us/step - loss: 9.6179 - val_loss: 102.7553\n",
      "Epoch 61/1000\n",
      "1500/1500 [==============================] - 0s 131us/step - loss: 10.7263 - val_loss: 113.8816\n",
      "Epoch 62/1000\n",
      "1500/1500 [==============================] - 0s 122us/step - loss: 13.0108 - val_loss: 105.2551\n",
      "Epoch 63/1000\n",
      "1500/1500 [==============================] - 0s 126us/step - loss: 14.5522 - val_loss: 99.6265\n",
      "Epoch 64/1000\n",
      "1500/1500 [==============================] - 0s 129us/step - loss: 7.5269 - val_loss: 99.8937\n",
      "Epoch 65/1000\n",
      "1500/1500 [==============================] - 0s 128us/step - loss: 8.7979 - val_loss: 100.1174\n",
      "Epoch 66/1000\n",
      "1500/1500 [==============================] - 0s 129us/step - loss: 4.1768 - val_loss: 98.3755\n",
      "Epoch 67/1000\n",
      "1500/1500 [==============================] - 0s 125us/step - loss: 2.1853 - val_loss: 99.8530\n",
      "Epoch 68/1000\n",
      "1500/1500 [==============================] - 0s 128us/step - loss: 1.2286 - val_loss: 96.8380\n",
      "Epoch 69/1000\n",
      "1500/1500 [==============================] - 0s 127us/step - loss: 0.6888 - val_loss: 97.6639\n",
      "Epoch 70/1000\n",
      "1500/1500 [==============================] - 0s 127us/step - loss: 0.5575 - val_loss: 98.5343\n",
      "Epoch 71/1000\n",
      "1500/1500 [==============================] - 0s 125us/step - loss: 0.4825 - val_loss: 97.9217\n",
      "Epoch 72/1000\n",
      "1500/1500 [==============================] - 0s 127us/step - loss: 0.2817 - val_loss: 97.4862\n",
      "Epoch 73/1000\n",
      "1500/1500 [==============================] - 0s 125us/step - loss: 0.3199 - val_loss: 97.1908\n",
      "Epoch 74/1000\n",
      "1500/1500 [==============================] - 0s 123us/step - loss: 0.3764 - val_loss: 97.9401\n",
      "Epoch 75/1000\n",
      "1500/1500 [==============================] - 0s 131us/step - loss: 0.3180 - val_loss: 98.5914\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 76/1000\n",
      "1500/1500 [==============================] - 0s 128us/step - loss: 0.2430 - val_loss: 99.6320\n",
      "Epoch 77/1000\n",
      "1500/1500 [==============================] - 0s 125us/step - loss: 0.3538 - val_loss: 97.5189\n",
      "Epoch 78/1000\n",
      "1500/1500 [==============================] - 0s 126us/step - loss: 0.2404 - val_loss: 97.6584\n",
      "Epoch 79/1000\n",
      "1500/1500 [==============================] - 0s 125us/step - loss: 0.2682 - val_loss: 97.9694\n",
      "Epoch 80/1000\n",
      "1500/1500 [==============================] - 0s 127us/step - loss: 0.3665 - val_loss: 98.7744\n",
      "Epoch 81/1000\n",
      "1500/1500 [==============================] - 0s 145us/step - loss: 0.3611 - val_loss: 98.2269\n",
      "Epoch 82/1000\n",
      "1500/1500 [==============================] - 0s 140us/step - loss: 0.3756 - val_loss: 98.4161\n",
      "Epoch 83/1000\n",
      "1500/1500 [==============================] - 0s 120us/step - loss: 0.7855 - val_loss: 97.2895\n",
      "Epoch 84/1000\n",
      "1500/1500 [==============================] - 0s 131us/step - loss: 0.7317 - val_loss: 98.2828\n",
      "Epoch 85/1000\n",
      "1500/1500 [==============================] - 0s 130us/step - loss: 11.5432 - val_loss: 102.0178\n",
      "Epoch 86/1000\n",
      "1500/1500 [==============================] - 0s 124us/step - loss: 10.5307 - val_loss: 100.4839\n",
      "Epoch 87/1000\n",
      "1500/1500 [==============================] - 0s 136us/step - loss: 9.2660 - val_loss: 118.0260\n",
      "Epoch 88/1000\n",
      "1500/1500 [==============================] - 0s 125us/step - loss: 38.6241 - val_loss: 196.0293\n",
      "Epoch 89/1000\n",
      "1500/1500 [==============================] - 0s 132us/step - loss: 22.8950 - val_loss: 112.9562\n",
      "Epoch 90/1000\n",
      "1500/1500 [==============================] - 0s 136us/step - loss: 5.9411 - val_loss: 100.2140\n",
      "Epoch 91/1000\n",
      "1500/1500 [==============================] - 0s 126us/step - loss: 4.6064 - val_loss: 101.5182\n",
      "Epoch 92/1000\n",
      "1500/1500 [==============================] - 0s 137us/step - loss: 2.9578 - val_loss: 96.1400\n",
      "Epoch 93/1000\n",
      "1500/1500 [==============================] - 0s 124us/step - loss: 1.3741 - val_loss: 100.3707\n",
      "Epoch 94/1000\n",
      "1500/1500 [==============================] - 0s 129us/step - loss: 1.3983 - val_loss: 96.1109\n",
      "Epoch 95/1000\n",
      "1500/1500 [==============================] - 0s 133us/step - loss: 0.8418 - val_loss: 97.4154\n",
      "Epoch 96/1000\n",
      "1500/1500 [==============================] - 0s 127us/step - loss: 0.4333 - val_loss: 97.9850\n",
      "Epoch 97/1000\n",
      "1500/1500 [==============================] - 0s 130us/step - loss: 0.6485 - val_loss: 98.9752\n",
      "Epoch 98/1000\n",
      "1500/1500 [==============================] - 0s 126us/step - loss: 0.5566 - val_loss: 97.1302\n",
      "Epoch 99/1000\n",
      "1500/1500 [==============================] - 0s 134us/step - loss: 1.0011 - val_loss: 96.6999\n",
      "Epoch 100/1000\n",
      "1500/1500 [==============================] - 0s 132us/step - loss: 0.6854 - val_loss: 98.7164\n",
      "Epoch 101/1000\n",
      "1500/1500 [==============================] - 0s 123us/step - loss: 0.3794 - val_loss: 97.2989\n",
      "Epoch 102/1000\n",
      "1500/1500 [==============================] - 0s 132us/step - loss: 0.4384 - val_loss: 98.3884\n",
      "Epoch 103/1000\n",
      "1500/1500 [==============================] - 0s 134us/step - loss: 0.3691 - val_loss: 96.4248\n",
      "Epoch 104/1000\n",
      "1500/1500 [==============================] - 0s 124us/step - loss: 0.7784 - val_loss: 97.6341\n",
      "Epoch 105/1000\n",
      "1500/1500 [==============================] - 0s 125us/step - loss: 0.5295 - val_loss: 96.6509\n",
      "Epoch 106/1000\n",
      "1500/1500 [==============================] - 0s 125us/step - loss: 0.8853 - val_loss: 100.9797\n",
      "Epoch 107/1000\n",
      "1500/1500 [==============================] - 0s 123us/step - loss: 0.7834 - val_loss: 97.2216\n",
      "Epoch 108/1000\n",
      "1500/1500 [==============================] - 0s 124us/step - loss: 0.5695 - val_loss: 96.7271\n",
      "Epoch 109/1000\n",
      "1500/1500 [==============================] - 0s 124us/step - loss: 0.7401 - val_loss: 96.6302\n",
      "Epoch 110/1000\n",
      "1500/1500 [==============================] - 0s 124us/step - loss: 1.5413 - val_loss: 98.0009\n",
      "Epoch 111/1000\n",
      "1500/1500 [==============================] - 0s 130us/step - loss: 1.8850 - val_loss: 105.9965\n",
      "Epoch 112/1000\n",
      "1500/1500 [==============================] - 0s 126us/step - loss: 11.8071 - val_loss: 101.6433\n",
      "Epoch 113/1000\n",
      "1500/1500 [==============================] - 0s 120us/step - loss: 7.9541 - val_loss: 96.3523\n",
      "Epoch 114/1000\n",
      "1500/1500 [==============================] - 0s 124us/step - loss: 5.5149 - val_loss: 98.7720\n",
      "Epoch 115/1000\n",
      "1500/1500 [==============================] - 0s 128us/step - loss: 5.9040 - val_loss: 102.7802\n",
      "Epoch 116/1000\n",
      "1500/1500 [==============================] - 0s 122us/step - loss: 7.0923 - val_loss: 99.8261\n",
      "Epoch 117/1000\n",
      "1500/1500 [==============================] - 0s 126us/step - loss: 4.9739 - val_loss: 101.2804\n",
      "Epoch 118/1000\n",
      "1500/1500 [==============================] - 0s 124us/step - loss: 3.6251 - val_loss: 102.6991\n",
      "Epoch 119/1000\n",
      "1500/1500 [==============================] - 0s 124us/step - loss: 4.3817 - val_loss: 107.6847\n",
      "Epoch 120/1000\n",
      "1500/1500 [==============================] - 0s 125us/step - loss: 9.1545 - val_loss: 105.4711\n",
      "Epoch 121/1000\n",
      "1500/1500 [==============================] - 0s 124us/step - loss: 8.7116 - val_loss: 99.4847\n",
      "Epoch 122/1000\n",
      "1500/1500 [==============================] - 0s 125us/step - loss: 4.7576 - val_loss: 95.5322\n",
      "Epoch 123/1000\n",
      "1500/1500 [==============================] - 0s 123us/step - loss: 1.9809 - val_loss: 96.0010\n",
      "Epoch 124/1000\n",
      "1500/1500 [==============================] - 0s 125us/step - loss: 0.9667 - val_loss: 96.4165\n",
      "Epoch 125/1000\n",
      "1500/1500 [==============================] - 0s 125us/step - loss: 0.6029 - val_loss: 97.2631\n",
      "Epoch 126/1000\n",
      "1500/1500 [==============================] - 0s 122us/step - loss: 0.3769 - val_loss: 97.1082\n",
      "Epoch 127/1000\n",
      "1500/1500 [==============================] - 0s 125us/step - loss: 0.2176 - val_loss: 96.5221\n",
      "Epoch 128/1000\n",
      "1500/1500 [==============================] - 0s 124us/step - loss: 0.3427 - val_loss: 95.8776\n",
      "Epoch 129/1000\n",
      "1500/1500 [==============================] - 0s 124us/step - loss: 0.4464 - val_loss: 97.1095\n",
      "Epoch 130/1000\n",
      "1500/1500 [==============================] - 0s 123us/step - loss: 2.0459 - val_loss: 96.9005\n",
      "Epoch 131/1000\n",
      "1500/1500 [==============================] - 0s 124us/step - loss: 1.1999 - val_loss: 100.7639\n",
      "Epoch 132/1000\n",
      "1500/1500 [==============================] - 0s 126us/step - loss: 1.1942 - val_loss: 98.3052\n",
      "Epoch 133/1000\n",
      "1500/1500 [==============================] - 0s 122us/step - loss: 1.7460 - val_loss: 96.2226\n",
      "Epoch 134/1000\n",
      "1500/1500 [==============================] - 0s 122us/step - loss: 2.8820 - val_loss: 99.4764\n",
      "Epoch 135/1000\n",
      "1500/1500 [==============================] - 0s 126us/step - loss: 26.7654 - val_loss: 101.7583\n",
      "Epoch 136/1000\n",
      "1500/1500 [==============================] - 0s 123us/step - loss: 11.1604 - val_loss: 99.5605\n",
      "Epoch 137/1000\n",
      "1500/1500 [==============================] - 0s 121us/step - loss: 7.7539 - val_loss: 94.9475\n",
      "Epoch 138/1000\n",
      "1500/1500 [==============================] - 0s 124us/step - loss: 8.4272 - val_loss: 95.4193\n",
      "Epoch 139/1000\n",
      "1500/1500 [==============================] - 0s 125us/step - loss: 2.8930 - val_loss: 95.8749\n",
      "Epoch 140/1000\n",
      "1500/1500 [==============================] - 0s 122us/step - loss: 1.5167 - val_loss: 97.8055\n",
      "Epoch 141/1000\n",
      "1500/1500 [==============================] - 0s 127us/step - loss: 0.9385 - val_loss: 97.2896\n",
      "Epoch 142/1000\n",
      "1500/1500 [==============================] - 0s 121us/step - loss: 0.7699 - val_loss: 95.6603\n",
      "Epoch 143/1000\n",
      "1500/1500 [==============================] - 0s 125us/step - loss: 0.3917 - val_loss: 96.0884\n",
      "Epoch 144/1000\n",
      "1500/1500 [==============================] - 0s 125us/step - loss: 0.2132 - val_loss: 96.2551\n",
      "Epoch 145/1000\n",
      "1500/1500 [==============================] - 0s 125us/step - loss: 0.6243 - val_loss: 95.4098\n",
      "Epoch 146/1000\n",
      "1500/1500 [==============================] - 0s 129us/step - loss: 0.3431 - val_loss: 95.7991\n",
      "Epoch 147/1000\n",
      "1500/1500 [==============================] - 0s 127us/step - loss: 0.2043 - val_loss: 97.5709\n",
      "Epoch 148/1000\n",
      "1500/1500 [==============================] - 0s 122us/step - loss: 0.2754 - val_loss: 95.5283\n",
      "Epoch 149/1000\n",
      "1500/1500 [==============================] - 0s 129us/step - loss: 0.2244 - val_loss: 95.3272\n",
      "Epoch 150/1000\n",
      "1500/1500 [==============================] - 0s 132us/step - loss: 0.3868 - val_loss: 98.9002\n",
      "Epoch 151/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1500/1500 [==============================] - 0s 126us/step - loss: 0.2541 - val_loss: 96.3676\n",
      "Epoch 152/1000\n",
      "1500/1500 [==============================] - 0s 124us/step - loss: 0.1905 - val_loss: 94.8575\n",
      "Epoch 153/1000\n",
      "1500/1500 [==============================] - 0s 125us/step - loss: 0.2594 - val_loss: 95.3573\n",
      "Epoch 154/1000\n",
      "1500/1500 [==============================] - 0s 126us/step - loss: 0.2269 - val_loss: 96.1664\n",
      "Epoch 155/1000\n",
      "1500/1500 [==============================] - 0s 121us/step - loss: 0.3434 - val_loss: 95.3446\n",
      "Epoch 156/1000\n",
      "1500/1500 [==============================] - 0s 121us/step - loss: 0.7243 - val_loss: 95.0643\n",
      "Epoch 157/1000\n",
      "1500/1500 [==============================] - 0s 122us/step - loss: 0.8773 - val_loss: 97.9172\n",
      "Epoch 158/1000\n",
      "1500/1500 [==============================] - 0s 121us/step - loss: 1.7264 - val_loss: 97.8098\n",
      "Epoch 159/1000\n",
      "1500/1500 [==============================] - 0s 125us/step - loss: 1.1305 - val_loss: 95.4112\n",
      "Epoch 160/1000\n",
      "1500/1500 [==============================] - 0s 120us/step - loss: 1.0269 - val_loss: 97.8410\n",
      "Epoch 161/1000\n",
      "1500/1500 [==============================] - 0s 125us/step - loss: 3.7473 - val_loss: 99.9530\n",
      "Epoch 162/1000\n",
      "1500/1500 [==============================] - 0s 125us/step - loss: 10.7213 - val_loss: 102.5196\n",
      "Epoch 163/1000\n",
      "1500/1500 [==============================] - 0s 125us/step - loss: 16.2209 - val_loss: 98.5576\n",
      "Epoch 164/1000\n",
      "1500/1500 [==============================] - 0s 121us/step - loss: 6.4029 - val_loss: 98.9235\n",
      "Epoch 165/1000\n",
      "1500/1500 [==============================] - 0s 125us/step - loss: 7.8910 - val_loss: 99.3623\n",
      "Epoch 166/1000\n",
      "1500/1500 [==============================] - 0s 122us/step - loss: 2.4558 - val_loss: 98.0427\n",
      "Epoch 167/1000\n",
      "1500/1500 [==============================] - 0s 120us/step - loss: 1.6104 - val_loss: 98.6712\n",
      "Epoch 168/1000\n",
      "1500/1500 [==============================] - 0s 122us/step - loss: 3.6641 - val_loss: 101.1230\n",
      "Epoch 169/1000\n",
      "1500/1500 [==============================] - 0s 125us/step - loss: 2.5942 - val_loss: 97.4408\n",
      "Epoch 170/1000\n",
      "1500/1500 [==============================] - 0s 125us/step - loss: 1.3983 - val_loss: 95.4369\n",
      "Epoch 171/1000\n",
      "1500/1500 [==============================] - 0s 125us/step - loss: 0.9601 - val_loss: 95.1611\n",
      "Epoch 172/1000\n",
      "1500/1500 [==============================] - 0s 126us/step - loss: 1.0193 - val_loss: 96.8692\n",
      "Epoch 173/1000\n",
      "1500/1500 [==============================] - 0s 124us/step - loss: 0.5563 - val_loss: 98.7623\n",
      "Epoch 174/1000\n",
      "1500/1500 [==============================] - 0s 124us/step - loss: 0.7126 - val_loss: 96.2454\n",
      "Epoch 175/1000\n",
      "1500/1500 [==============================] - 0s 123us/step - loss: 0.5633 - val_loss: 99.7681\n",
      "Epoch 176/1000\n",
      "1500/1500 [==============================] - 0s 125us/step - loss: 2.2654 - val_loss: 96.4908\n",
      "Epoch 177/1000\n",
      "1500/1500 [==============================] - 0s 125us/step - loss: 5.0374 - val_loss: 101.3675\n",
      "Epoch 178/1000\n",
      "1500/1500 [==============================] - 0s 125us/step - loss: 5.6435 - val_loss: 96.0126\n",
      "Epoch 179/1000\n",
      "1500/1500 [==============================] - 0s 121us/step - loss: 2.4674 - val_loss: 96.7429\n",
      "Epoch 180/1000\n",
      "1500/1500 [==============================] - 0s 123us/step - loss: 3.4400 - val_loss: 95.5621\n",
      "Epoch 181/1000\n",
      "1500/1500 [==============================] - 0s 125us/step - loss: 1.6296 - val_loss: 97.7411\n",
      "Epoch 182/1000\n",
      "1500/1500 [==============================] - 0s 125us/step - loss: 2.6003 - val_loss: 99.0479\n",
      "Epoch 183/1000\n",
      "1500/1500 [==============================] - 0s 123us/step - loss: 1.0525 - val_loss: 95.3546\n",
      "Epoch 184/1000\n",
      "1500/1500 [==============================] - 0s 124us/step - loss: 0.7286 - val_loss: 97.0816\n",
      "Epoch 185/1000\n",
      "1500/1500 [==============================] - 0s 122us/step - loss: 1.2568 - val_loss: 99.0095\n",
      "Epoch 186/1000\n",
      "1500/1500 [==============================] - 0s 124us/step - loss: 1.7233 - val_loss: 97.2083\n",
      "Epoch 187/1000\n",
      "1500/1500 [==============================] - 0s 125us/step - loss: 0.7494 - val_loss: 94.3055\n",
      "Epoch 188/1000\n",
      "1500/1500 [==============================] - 0s 125us/step - loss: 2.2433 - val_loss: 123.0978\n",
      "Epoch 189/1000\n",
      "1500/1500 [==============================] - 0s 121us/step - loss: 7.6550 - val_loss: 96.9507\n",
      "Epoch 190/1000\n",
      "1500/1500 [==============================] - 0s 126us/step - loss: 3.0238 - val_loss: 92.9291\n",
      "Epoch 191/1000\n",
      "1500/1500 [==============================] - 0s 125us/step - loss: 5.1870 - val_loss: 101.0363\n",
      "Epoch 192/1000\n",
      "1500/1500 [==============================] - 0s 126us/step - loss: 4.0661 - val_loss: 106.1094\n",
      "Epoch 193/1000\n",
      "1500/1500 [==============================] - 0s 129us/step - loss: 2.4855 - val_loss: 99.7135\n",
      "Epoch 194/1000\n",
      "1500/1500 [==============================] - 0s 125us/step - loss: 5.4141 - val_loss: 101.5830\n",
      "Epoch 195/1000\n",
      "1500/1500 [==============================] - 0s 122us/step - loss: 6.7699 - val_loss: 102.2551\n",
      "Epoch 196/1000\n",
      "1500/1500 [==============================] - 0s 123us/step - loss: 3.1999 - val_loss: 97.3478\n",
      "Epoch 197/1000\n",
      "1500/1500 [==============================] - 0s 124us/step - loss: 1.3464 - val_loss: 97.0443\n",
      "Epoch 198/1000\n",
      "1500/1500 [==============================] - 0s 127us/step - loss: 1.3397 - val_loss: 97.4970\n",
      "Epoch 199/1000\n",
      "1500/1500 [==============================] - 0s 122us/step - loss: 1.0124 - val_loss: 97.0596\n",
      "Epoch 200/1000\n",
      "1500/1500 [==============================] - 0s 125us/step - loss: 0.8578 - val_loss: 97.5305\n",
      "Epoch 201/1000\n",
      "1500/1500 [==============================] - 0s 124us/step - loss: 0.4174 - val_loss: 98.0069\n",
      "Epoch 202/1000\n",
      "1500/1500 [==============================] - 0s 124us/step - loss: 0.5855 - val_loss: 96.3117\n",
      "Epoch 203/1000\n",
      "1500/1500 [==============================] - 0s 127us/step - loss: 0.3230 - val_loss: 95.9089\n",
      "Epoch 204/1000\n",
      "1500/1500 [==============================] - 0s 123us/step - loss: 0.4986 - val_loss: 97.0134\n",
      "Epoch 205/1000\n",
      "1500/1500 [==============================] - 0s 122us/step - loss: 0.5852 - val_loss: 96.8200\n",
      "Epoch 206/1000\n",
      "1500/1500 [==============================] - 0s 124us/step - loss: 0.4314 - val_loss: 95.2503\n",
      "Epoch 207/1000\n",
      "1500/1500 [==============================] - 0s 124us/step - loss: 0.2581 - val_loss: 96.3706\n",
      "Epoch 208/1000\n",
      "1500/1500 [==============================] - 0s 126us/step - loss: 0.4588 - val_loss: 95.5460\n",
      "Epoch 209/1000\n",
      "1500/1500 [==============================] - 0s 123us/step - loss: 0.3339 - val_loss: 96.5373\n",
      "Epoch 210/1000\n",
      "1500/1500 [==============================] - 0s 125us/step - loss: 0.3781 - val_loss: 96.3145\n",
      "Epoch 211/1000\n",
      "1500/1500 [==============================] - 0s 122us/step - loss: 0.6201 - val_loss: 97.0022\n",
      "Epoch 212/1000\n",
      "1500/1500 [==============================] - 0s 122us/step - loss: 2.0578 - val_loss: 98.1263\n",
      "Epoch 213/1000\n",
      "1500/1500 [==============================] - 0s 126us/step - loss: 1.5719 - val_loss: 98.8635\n",
      "Epoch 214/1000\n",
      "1500/1500 [==============================] - 0s 123us/step - loss: 2.7542 - val_loss: 96.8274\n",
      "Epoch 215/1000\n",
      "1500/1500 [==============================] - 0s 128us/step - loss: 1.9266 - val_loss: 99.4189\n",
      "Epoch 216/1000\n",
      "1500/1500 [==============================] - 0s 126us/step - loss: 1.3587 - val_loss: 100.3439\n",
      "Epoch 217/1000\n",
      "1500/1500 [==============================] - 0s 123us/step - loss: 1.1592 - val_loss: 95.9629\n",
      "Epoch 218/1000\n",
      "1500/1500 [==============================] - 0s 122us/step - loss: 6.3735 - val_loss: 118.0673\n",
      "Epoch 219/1000\n",
      "1500/1500 [==============================] - 0s 124us/step - loss: 12.5142 - val_loss: 93.0713\n",
      "Epoch 220/1000\n",
      "1500/1500 [==============================] - 0s 124us/step - loss: 10.1149 - val_loss: 96.3200\n",
      "Epoch 221/1000\n",
      "1500/1500 [==============================] - 0s 122us/step - loss: 4.9235 - val_loss: 110.1570\n",
      "Epoch 222/1000\n",
      "1500/1500 [==============================] - 0s 123us/step - loss: 2.5675 - val_loss: 94.3148\n",
      "Epoch 223/1000\n",
      "1500/1500 [==============================] - 0s 122us/step - loss: 1.1591 - val_loss: 93.2487\n",
      "Epoch 224/1000\n",
      "1500/1500 [==============================] - 0s 128us/step - loss: 0.9816 - val_loss: 95.9017\n",
      "Epoch 225/1000\n",
      "1500/1500 [==============================] - 0s 123us/step - loss: 0.5353 - val_loss: 95.2344\n",
      "Epoch 226/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1500/1500 [==============================] - 0s 124us/step - loss: 0.6601 - val_loss: 96.5119\n",
      "Epoch 227/1000\n",
      "1500/1500 [==============================] - 0s 123us/step - loss: 0.9696 - val_loss: 96.0822\n",
      "Epoch 228/1000\n",
      "1500/1500 [==============================] - 0s 124us/step - loss: 0.7937 - val_loss: 95.4687\n",
      "Epoch 229/1000\n",
      "1500/1500 [==============================] - 0s 125us/step - loss: 0.7054 - val_loss: 95.6710\n",
      "Epoch 230/1000\n",
      "1500/1500 [==============================] - 0s 125us/step - loss: 0.8539 - val_loss: 100.5345\n",
      "Epoch 231/1000\n",
      "1500/1500 [==============================] - 0s 124us/step - loss: 1.9187 - val_loss: 99.4532\n",
      "Epoch 232/1000\n",
      "1500/1500 [==============================] - 0s 122us/step - loss: 1.3497 - val_loss: 100.3760\n",
      "Epoch 233/1000\n",
      "1500/1500 [==============================] - 0s 123us/step - loss: 1.4265 - val_loss: 96.8382\n",
      "Epoch 234/1000\n",
      "1500/1500 [==============================] - 0s 124us/step - loss: 1.0489 - val_loss: 95.1169\n",
      "Epoch 235/1000\n",
      "1500/1500 [==============================] - 0s 126us/step - loss: 1.4291 - val_loss: 97.9825\n",
      "Epoch 236/1000\n",
      "1500/1500 [==============================] - 0s 122us/step - loss: 0.7616 - val_loss: 100.5628\n",
      "Epoch 237/1000\n",
      "1500/1500 [==============================] - 0s 123us/step - loss: 1.1780 - val_loss: 95.9840\n",
      "Epoch 238/1000\n",
      "1500/1500 [==============================] - 0s 120us/step - loss: 1.2176 - val_loss: 98.9734\n",
      "Epoch 239/1000\n",
      "1500/1500 [==============================] - 0s 125us/step - loss: 1.4096 - val_loss: 95.7682\n",
      "Epoch 240/1000\n",
      "1500/1500 [==============================] - 0s 124us/step - loss: 1.2323 - val_loss: 98.3792\n",
      "Epoch 241/1000\n",
      "1500/1500 [==============================] - 0s 123us/step - loss: 1.8142 - val_loss: 97.1821\n",
      "Epoch 242/1000\n",
      "1500/1500 [==============================] - 0s 122us/step - loss: 7.3620 - val_loss: 120.8579\n",
      "Epoch 243/1000\n",
      "1500/1500 [==============================] - 0s 121us/step - loss: 7.3792 - val_loss: 96.7752\n",
      "Epoch 244/1000\n",
      "1500/1500 [==============================] - 0s 128us/step - loss: 2.9143 - val_loss: 95.9990\n",
      "Epoch 245/1000\n",
      "1500/1500 [==============================] - 0s 125us/step - loss: 3.7071 - val_loss: 98.5750\n",
      "Epoch 246/1000\n",
      "1500/1500 [==============================] - 0s 126us/step - loss: 5.2818 - val_loss: 99.5065\n",
      "Epoch 247/1000\n",
      "1500/1500 [==============================] - 0s 125us/step - loss: 2.1858 - val_loss: 105.2602\n",
      "Epoch 248/1000\n",
      "1500/1500 [==============================] - 0s 123us/step - loss: 5.0325 - val_loss: 97.4996\n",
      "Epoch 249/1000\n",
      "1500/1500 [==============================] - 0s 123us/step - loss: 2.2237 - val_loss: 94.9102\n",
      "Epoch 250/1000\n",
      "1500/1500 [==============================] - 0s 121us/step - loss: 1.1089 - val_loss: 99.9240\n",
      "Epoch 251/1000\n",
      "1500/1500 [==============================] - 0s 127us/step - loss: 0.9002 - val_loss: 102.4363\n",
      "Epoch 252/1000\n",
      "1500/1500 [==============================] - 0s 125us/step - loss: 0.8559 - val_loss: 98.1426\n",
      "Epoch 253/1000\n",
      "1500/1500 [==============================] - 0s 127us/step - loss: 0.5050 - val_loss: 97.0979\n",
      "Epoch 254/1000\n",
      "1500/1500 [==============================] - 0s 125us/step - loss: 0.5790 - val_loss: 97.6683\n",
      "Epoch 255/1000\n",
      "1500/1500 [==============================] - 0s 127us/step - loss: 0.4064 - val_loss: 99.1315\n",
      "Epoch 256/1000\n",
      "1500/1500 [==============================] - 0s 125us/step - loss: 1.3133 - val_loss: 102.1094\n",
      "Epoch 257/1000\n",
      "1500/1500 [==============================] - 0s 124us/step - loss: 0.8049 - val_loss: 96.2584\n",
      "Epoch 258/1000\n",
      "1500/1500 [==============================] - 0s 126us/step - loss: 0.9420 - val_loss: 95.4329\n",
      "Epoch 259/1000\n",
      "1500/1500 [==============================] - 0s 121us/step - loss: 1.6539 - val_loss: 101.5108\n",
      "Epoch 260/1000\n",
      "1500/1500 [==============================] - 0s 126us/step - loss: 1.2400 - val_loss: 96.7491\n",
      "Epoch 261/1000\n",
      "1500/1500 [==============================] - 0s 125us/step - loss: 2.4775 - val_loss: 111.0755\n",
      "Epoch 262/1000\n",
      "1500/1500 [==============================] - 0s 130us/step - loss: 5.7423 - val_loss: 107.8110\n",
      "Epoch 263/1000\n",
      "1500/1500 [==============================] - 0s 124us/step - loss: 6.0071 - val_loss: 97.9122\n",
      "Epoch 264/1000\n",
      "1500/1500 [==============================] - 0s 126us/step - loss: 2.0210 - val_loss: 96.7839\n",
      "Epoch 265/1000\n",
      "1500/1500 [==============================] - 0s 123us/step - loss: 1.4706 - val_loss: 96.8287\n",
      "Epoch 266/1000\n",
      "1500/1500 [==============================] - 0s 124us/step - loss: 1.7577 - val_loss: 96.3606\n",
      "Epoch 267/1000\n",
      "1500/1500 [==============================] - 0s 126us/step - loss: 1.0457 - val_loss: 97.9763\n",
      "Epoch 268/1000\n",
      "1500/1500 [==============================] - 0s 128us/step - loss: 4.2015 - val_loss: 94.6847\n",
      "Epoch 269/1000\n",
      "1500/1500 [==============================] - 0s 124us/step - loss: 4.1066 - val_loss: 99.6126\n",
      "Epoch 270/1000\n",
      "1500/1500 [==============================] - 0s 123us/step - loss: 1.6872 - val_loss: 98.5318\n",
      "Epoch 271/1000\n",
      "1500/1500 [==============================] - 0s 126us/step - loss: 3.6419 - val_loss: 102.4888\n",
      "Epoch 272/1000\n",
      "1500/1500 [==============================] - 0s 124us/step - loss: 1.3774 - val_loss: 96.0117\n",
      "Epoch 273/1000\n",
      "1500/1500 [==============================] - 0s 125us/step - loss: 0.7072 - val_loss: 95.9459\n",
      "Epoch 274/1000\n",
      "1500/1500 [==============================] - 0s 123us/step - loss: 0.4042 - val_loss: 97.1957\n",
      "Epoch 275/1000\n",
      "1500/1500 [==============================] - 0s 122us/step - loss: 0.3998 - val_loss: 97.5690\n",
      "Epoch 276/1000\n",
      "1500/1500 [==============================] - 0s 123us/step - loss: 0.3411 - val_loss: 97.3640\n",
      "Epoch 277/1000\n",
      "1500/1500 [==============================] - 0s 123us/step - loss: 0.6753 - val_loss: 96.7585\n",
      "Epoch 278/1000\n",
      "1500/1500 [==============================] - 0s 125us/step - loss: 0.7507 - val_loss: 97.8348\n",
      "Epoch 279/1000\n",
      "1500/1500 [==============================] - 0s 122us/step - loss: 0.6982 - val_loss: 95.9455\n",
      "Epoch 280/1000\n",
      "1500/1500 [==============================] - 0s 123us/step - loss: 0.7072 - val_loss: 98.8138\n",
      "Epoch 281/1000\n",
      "1500/1500 [==============================] - 0s 124us/step - loss: 0.7565 - val_loss: 98.3968\n",
      "Epoch 282/1000\n",
      "1500/1500 [==============================] - 0s 127us/step - loss: 2.1270 - val_loss: 97.0447\n",
      "Epoch 283/1000\n",
      "1500/1500 [==============================] - 0s 124us/step - loss: 1.9096 - val_loss: 99.3699\n",
      "Epoch 284/1000\n",
      "1500/1500 [==============================] - 0s 124us/step - loss: 5.2993 - val_loss: 100.1993\n",
      "Epoch 285/1000\n",
      "1500/1500 [==============================] - 0s 122us/step - loss: 10.6450 - val_loss: 109.4600\n",
      "Epoch 286/1000\n",
      "1500/1500 [==============================] - 0s 122us/step - loss: 4.5333 - val_loss: 97.2316\n",
      "Epoch 287/1000\n",
      "1500/1500 [==============================] - 0s 123us/step - loss: 3.5994 - val_loss: 103.6506\n",
      "Epoch 288/1000\n",
      "1500/1500 [==============================] - 0s 123us/step - loss: 2.0926 - val_loss: 98.4373\n",
      "Epoch 289/1000\n",
      "1500/1500 [==============================] - 0s 127us/step - loss: 1.4813 - val_loss: 100.3749\n",
      "Epoch 290/1000\n",
      "1500/1500 [==============================] - 0s 127us/step - loss: 0.9012 - val_loss: 97.9172\n",
      "Epoch 291/1000\n",
      "1500/1500 [==============================] - 0s 127us/step - loss: 1.1559 - val_loss: 97.5437\n",
      "Epoch 292/1000\n",
      "1500/1500 [==============================] - 0s 120us/step - loss: 0.9230 - val_loss: 97.5089\n",
      "Epoch 293/1000\n",
      "1500/1500 [==============================] - 0s 129us/step - loss: 0.3895 - val_loss: 97.3212\n",
      "Epoch 294/1000\n",
      "1500/1500 [==============================] - 0s 133us/step - loss: 0.3969 - val_loss: 97.8349\n",
      "Epoch 295/1000\n",
      "1500/1500 [==============================] - 0s 129us/step - loss: 0.2306 - val_loss: 97.9176\n",
      "Epoch 296/1000\n",
      "1500/1500 [==============================] - 0s 127us/step - loss: 0.1977 - val_loss: 97.1968\n",
      "Epoch 297/1000\n",
      "1500/1500 [==============================] - 0s 127us/step - loss: 0.2866 - val_loss: 96.8641\n",
      "Epoch 298/1000\n",
      "1500/1500 [==============================] - 0s 123us/step - loss: 0.2359 - val_loss: 98.3061\n",
      "Epoch 299/1000\n",
      "1500/1500 [==============================] - 0s 125us/step - loss: 0.5498 - val_loss: 98.4788\n",
      "Epoch 300/1000\n",
      "1500/1500 [==============================] - 0s 127us/step - loss: 0.3242 - val_loss: 96.9036\n",
      "Epoch 301/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1500/1500 [==============================] - 0s 125us/step - loss: 0.3584 - val_loss: 98.0525\n",
      "Epoch 302/1000\n",
      "1500/1500 [==============================] - 0s 121us/step - loss: 0.4079 - val_loss: 97.6378\n",
      "Epoch 303/1000\n",
      "1500/1500 [==============================] - 0s 123us/step - loss: 0.2531 - val_loss: 97.6673\n",
      "Epoch 304/1000\n",
      "1500/1500 [==============================] - 0s 121us/step - loss: 0.8325 - val_loss: 99.2205\n",
      "Epoch 305/1000\n",
      "1500/1500 [==============================] - 0s 129us/step - loss: 0.6292 - val_loss: 100.1608\n",
      "Epoch 306/1000\n",
      "1500/1500 [==============================] - 0s 124us/step - loss: 2.5247 - val_loss: 100.4364\n",
      "Epoch 307/1000\n",
      "1500/1500 [==============================] - 0s 119us/step - loss: 3.0900 - val_loss: 98.2140\n",
      "Epoch 308/1000\n",
      "1500/1500 [==============================] - 0s 125us/step - loss: 1.1750 - val_loss: 97.9922\n",
      "Epoch 309/1000\n",
      "1500/1500 [==============================] - 0s 123us/step - loss: 1.2133 - val_loss: 98.7349\n",
      "Epoch 310/1000\n",
      "1500/1500 [==============================] - 0s 124us/step - loss: 2.4027 - val_loss: 97.3214\n",
      "Epoch 311/1000\n",
      "1500/1500 [==============================] - 0s 120us/step - loss: 2.5171 - val_loss: 98.7437\n",
      "Epoch 312/1000\n",
      "1500/1500 [==============================] - 0s 125us/step - loss: 1.9225 - val_loss: 97.4595\n",
      "Epoch 313/1000\n",
      "1500/1500 [==============================] - 0s 121us/step - loss: 1.7086 - val_loss: 100.2682\n",
      "Epoch 314/1000\n",
      "1500/1500 [==============================] - 0s 122us/step - loss: 4.2673 - val_loss: 102.7006\n",
      "Epoch 315/1000\n",
      "1500/1500 [==============================] - 0s 125us/step - loss: 1.7836 - val_loss: 97.0341\n",
      "Epoch 316/1000\n",
      "1500/1500 [==============================] - 0s 125us/step - loss: 1.8287 - val_loss: 102.1037\n",
      "Epoch 317/1000\n",
      "1500/1500 [==============================] - 0s 125us/step - loss: 2.9724 - val_loss: 100.5546\n",
      "Epoch 318/1000\n",
      "1500/1500 [==============================] - 0s 123us/step - loss: 1.5917 - val_loss: 97.6538\n",
      "Epoch 319/1000\n",
      "1500/1500 [==============================] - 0s 123us/step - loss: 1.0918 - val_loss: 96.9776\n",
      "Epoch 320/1000\n",
      "1500/1500 [==============================] - 0s 123us/step - loss: 0.6517 - val_loss: 98.4948\n",
      "Epoch 321/1000\n",
      "1500/1500 [==============================] - 0s 126us/step - loss: 0.6843 - val_loss: 99.2626\n",
      "Epoch 322/1000\n",
      "1500/1500 [==============================] - 0s 124us/step - loss: 0.7266 - val_loss: 97.7791\n",
      "Epoch 323/1000\n",
      "1500/1500 [==============================] - 0s 125us/step - loss: 0.4045 - val_loss: 100.2826\n",
      "Epoch 324/1000\n",
      "1500/1500 [==============================] - 0s 121us/step - loss: 0.3531 - val_loss: 100.5824\n",
      "Epoch 325/1000\n",
      "1500/1500 [==============================] - 0s 125us/step - loss: 0.3864 - val_loss: 98.2246\n",
      "Epoch 326/1000\n",
      "1500/1500 [==============================] - 0s 124us/step - loss: 0.3893 - val_loss: 96.6145\n",
      "Epoch 327/1000\n",
      "1500/1500 [==============================] - 0s 125us/step - loss: 0.8184 - val_loss: 97.9411\n",
      "Epoch 328/1000\n",
      "1500/1500 [==============================] - 0s 125us/step - loss: 1.4513 - val_loss: 102.6405\n",
      "Epoch 329/1000\n",
      "1500/1500 [==============================] - 0s 120us/step - loss: 2.2883 - val_loss: 95.0397\n",
      "Epoch 330/1000\n",
      "1500/1500 [==============================] - 0s 127us/step - loss: 4.4143 - val_loss: 101.3695\n",
      "Epoch 331/1000\n",
      "1500/1500 [==============================] - 0s 122us/step - loss: 6.6557 - val_loss: 98.5611\n",
      "Epoch 332/1000\n",
      "1500/1500 [==============================] - 0s 124us/step - loss: 6.1804 - val_loss: 99.3124\n",
      "Epoch 333/1000\n",
      "1500/1500 [==============================] - 0s 124us/step - loss: 3.6648 - val_loss: 100.6206\n",
      "Epoch 334/1000\n",
      "1500/1500 [==============================] - 0s 126us/step - loss: 2.7238 - val_loss: 101.2135\n",
      "Epoch 335/1000\n",
      "1500/1500 [==============================] - 0s 124us/step - loss: 1.8473 - val_loss: 98.8105\n",
      "Epoch 336/1000\n",
      "1500/1500 [==============================] - 0s 123us/step - loss: 0.9513 - val_loss: 98.0523\n",
      "Epoch 337/1000\n",
      "1500/1500 [==============================] - 0s 124us/step - loss: 1.4306 - val_loss: 102.6798\n",
      "Epoch 338/1000\n",
      "1500/1500 [==============================] - 0s 124us/step - loss: 1.1564 - val_loss: 98.2033\n",
      "Epoch 339/1000\n",
      "1500/1500 [==============================] - 0s 122us/step - loss: 0.8475 - val_loss: 98.6797\n",
      "Epoch 340/1000\n",
      "1500/1500 [==============================] - 0s 125us/step - loss: 0.5047 - val_loss: 97.2531\n",
      "Epoch 341/1000\n",
      "1500/1500 [==============================] - 0s 137us/step - loss: 0.5147 - val_loss: 100.4329\n",
      "Epoch 342/1000\n",
      "1500/1500 [==============================] - 0s 130us/step - loss: 1.1211 - val_loss: 98.8792\n",
      "Epoch 343/1000\n",
      "1500/1500 [==============================] - 0s 125us/step - loss: 1.6488 - val_loss: 97.3439\n",
      "Epoch 344/1000\n",
      "1500/1500 [==============================] - 0s 125us/step - loss: 2.5979 - val_loss: 97.9872\n",
      "Epoch 345/1000\n",
      "1500/1500 [==============================] - 0s 126us/step - loss: 1.1998 - val_loss: 99.1415\n",
      "Epoch 346/1000\n",
      "1500/1500 [==============================] - 0s 125us/step - loss: 0.7052 - val_loss: 98.7550\n",
      "Epoch 347/1000\n",
      "1500/1500 [==============================] - 0s 123us/step - loss: 0.4576 - val_loss: 99.1675\n",
      "Epoch 348/1000\n",
      "1500/1500 [==============================] - 0s 127us/step - loss: 0.7178 - val_loss: 99.4690\n",
      "Epoch 349/1000\n",
      "1500/1500 [==============================] - 0s 126us/step - loss: 2.0852 - val_loss: 98.7776\n",
      "Epoch 350/1000\n",
      "1500/1500 [==============================] - 0s 123us/step - loss: 3.0230 - val_loss: 99.3611\n",
      "Epoch 351/1000\n",
      "1500/1500 [==============================] - 0s 126us/step - loss: 1.9773 - val_loss: 101.1430\n",
      "Epoch 352/1000\n",
      "1500/1500 [==============================] - 0s 128us/step - loss: 1.2466 - val_loss: 100.9600\n",
      "Epoch 353/1000\n",
      "1500/1500 [==============================] - 0s 128us/step - loss: 1.1367 - val_loss: 98.9841\n",
      "Epoch 354/1000\n",
      "1500/1500 [==============================] - 0s 120us/step - loss: 0.6580 - val_loss: 102.2194\n",
      "Epoch 355/1000\n",
      "1500/1500 [==============================] - 0s 123us/step - loss: 0.5856 - val_loss: 101.3079\n",
      "Epoch 356/1000\n",
      "1500/1500 [==============================] - 0s 123us/step - loss: 0.5088 - val_loss: 98.4028\n",
      "Epoch 357/1000\n",
      "1500/1500 [==============================] - 0s 136us/step - loss: 0.5087 - val_loss: 98.8610\n",
      "Epoch 358/1000\n",
      "1500/1500 [==============================] - 0s 128us/step - loss: 0.9883 - val_loss: 98.5769\n",
      "Epoch 359/1000\n",
      "1500/1500 [==============================] - 0s 127us/step - loss: 0.6060 - val_loss: 101.1932\n",
      "Epoch 360/1000\n",
      "1500/1500 [==============================] - 0s 128us/step - loss: 0.7788 - val_loss: 103.1677\n",
      "Epoch 361/1000\n",
      "1500/1500 [==============================] - 0s 133us/step - loss: 0.5871 - val_loss: 98.1308\n",
      "Epoch 362/1000\n",
      "1500/1500 [==============================] - 0s 128us/step - loss: 0.6738 - val_loss: 98.9774\n",
      "Epoch 363/1000\n",
      "1500/1500 [==============================] - 0s 125us/step - loss: 0.4413 - val_loss: 99.7503\n",
      "Epoch 364/1000\n",
      "1500/1500 [==============================] - 0s 128us/step - loss: 0.8956 - val_loss: 97.9595\n",
      "Epoch 365/1000\n",
      "1500/1500 [==============================] - 0s 124us/step - loss: 2.5059 - val_loss: 99.9173\n",
      "Epoch 366/1000\n",
      "1500/1500 [==============================] - 0s 123us/step - loss: 2.9008 - val_loss: 99.9088\n",
      "Epoch 367/1000\n",
      "1500/1500 [==============================] - 0s 122us/step - loss: 2.8425 - val_loss: 102.0322\n",
      "Epoch 368/1000\n",
      "1500/1500 [==============================] - 0s 123us/step - loss: 5.1656 - val_loss: 105.9069\n",
      "Epoch 369/1000\n",
      "1500/1500 [==============================] - 0s 125us/step - loss: 5.6670 - val_loss: 102.8032\n",
      "Epoch 370/1000\n",
      "1500/1500 [==============================] - 0s 121us/step - loss: 2.1395 - val_loss: 102.9765\n",
      "Epoch 371/1000\n",
      "1500/1500 [==============================] - 0s 124us/step - loss: 1.0123 - val_loss: 99.9933\n",
      "Epoch 372/1000\n",
      "1500/1500 [==============================] - 0s 126us/step - loss: 0.8773 - val_loss: 100.0916\n",
      "Epoch 373/1000\n",
      "1500/1500 [==============================] - 0s 126us/step - loss: 0.4330 - val_loss: 98.7877\n",
      "Epoch 374/1000\n",
      "1500/1500 [==============================] - 0s 127us/step - loss: 0.3522 - val_loss: 100.2142\n",
      "Epoch 375/1000\n",
      "1500/1500 [==============================] - 0s 128us/step - loss: 0.3246 - val_loss: 98.0723\n",
      "Epoch 376/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1500/1500 [==============================] - 0s 126us/step - loss: 0.4122 - val_loss: 100.8050\n",
      "Epoch 377/1000\n",
      "1500/1500 [==============================] - 0s 125us/step - loss: 0.2622 - val_loss: 100.1529\n",
      "Epoch 378/1000\n",
      "1500/1500 [==============================] - 0s 123us/step - loss: 0.2813 - val_loss: 101.3741\n",
      "Epoch 379/1000\n",
      "1500/1500 [==============================] - 0s 123us/step - loss: 0.3467 - val_loss: 99.3335\n",
      "Epoch 380/1000\n",
      "1500/1500 [==============================] - 0s 122us/step - loss: 0.5417 - val_loss: 100.3837\n",
      "Epoch 381/1000\n",
      "1500/1500 [==============================] - 0s 122us/step - loss: 0.2990 - val_loss: 98.6689\n",
      "Epoch 382/1000\n",
      "1500/1500 [==============================] - 0s 125us/step - loss: 0.2162 - val_loss: 99.6483\n",
      "Epoch 383/1000\n",
      "1500/1500 [==============================] - 0s 125us/step - loss: 0.1838 - val_loss: 99.9389\n",
      "Epoch 384/1000\n",
      "1500/1500 [==============================] - 0s 124us/step - loss: 0.1378 - val_loss: 99.3359\n",
      "Epoch 385/1000\n",
      "1500/1500 [==============================] - 0s 127us/step - loss: 0.3712 - val_loss: 102.3989\n",
      "Epoch 386/1000\n",
      "1500/1500 [==============================] - 0s 127us/step - loss: 1.5137 - val_loss: 100.2435\n",
      "Epoch 387/1000\n",
      "1500/1500 [==============================] - 0s 126us/step - loss: 10.5685 - val_loss: 105.4880\n",
      "Epoch 388/1000\n",
      "1500/1500 [==============================] - 0s 126us/step - loss: 19.8569 - val_loss: 98.5275\n",
      "Epoch 389/1000\n",
      "1500/1500 [==============================] - 0s 121us/step - loss: 5.2006 - val_loss: 98.3219\n",
      "Epoch 390/1000\n",
      "1500/1500 [==============================] - 0s 128us/step - loss: 1.8038 - val_loss: 99.1686\n",
      "Epoch 391/1000\n",
      "1500/1500 [==============================] - 0s 130us/step - loss: 1.6068 - val_loss: 99.2275\n",
      "Epoch 392/1000\n",
      "1500/1500 [==============================] - 0s 124us/step - loss: 1.5062 - val_loss: 105.5594\n",
      "Epoch 393/1000\n",
      "1500/1500 [==============================] - 0s 123us/step - loss: 0.8982 - val_loss: 99.3414\n",
      "Epoch 394/1000\n",
      "1500/1500 [==============================] - 0s 121us/step - loss: 0.4461 - val_loss: 99.7363\n",
      "Epoch 395/1000\n",
      "1500/1500 [==============================] - 0s 122us/step - loss: 0.2723 - val_loss: 99.7494\n",
      "Epoch 396/1000\n",
      "1500/1500 [==============================] - 0s 123us/step - loss: 0.1670 - val_loss: 100.0271\n",
      "Epoch 397/1000\n",
      "1500/1500 [==============================] - 0s 122us/step - loss: 0.1106 - val_loss: 99.9268\n",
      "Epoch 398/1000\n",
      "1500/1500 [==============================] - 0s 121us/step - loss: 0.0658 - val_loss: 99.1917\n",
      "Epoch 399/1000\n",
      "1500/1500 [==============================] - 0s 123us/step - loss: 0.0476 - val_loss: 99.1060\n",
      "Epoch 400/1000\n",
      "1500/1500 [==============================] - 0s 122us/step - loss: 0.0682 - val_loss: 100.0443\n",
      "Epoch 401/1000\n",
      "1500/1500 [==============================] - 0s 124us/step - loss: 0.0768 - val_loss: 99.4590\n",
      "Epoch 402/1000\n",
      "1500/1500 [==============================] - 0s 122us/step - loss: 0.0477 - val_loss: 99.4151\n",
      "Epoch 403/1000\n",
      "1500/1500 [==============================] - 0s 121us/step - loss: 0.0447 - val_loss: 99.3381\n",
      "Epoch 404/1000\n",
      "1500/1500 [==============================] - 0s 124us/step - loss: 0.0335 - val_loss: 99.8100\n",
      "Epoch 405/1000\n",
      "1500/1500 [==============================] - 0s 123us/step - loss: 0.0226 - val_loss: 99.6926\n",
      "Epoch 406/1000\n",
      "1500/1500 [==============================] - 0s 123us/step - loss: 0.0208 - val_loss: 99.5381\n",
      "Epoch 407/1000\n",
      "1500/1500 [==============================] - 0s 124us/step - loss: 0.0203 - val_loss: 99.5073\n",
      "Epoch 408/1000\n",
      "1500/1500 [==============================] - 0s 122us/step - loss: 0.0249 - val_loss: 99.7083\n",
      "Epoch 409/1000\n",
      "1500/1500 [==============================] - 0s 125us/step - loss: 0.0363 - val_loss: 99.7550\n",
      "Epoch 410/1000\n",
      "1500/1500 [==============================] - 0s 122us/step - loss: 0.0934 - val_loss: 99.8436\n",
      "Epoch 411/1000\n",
      "1500/1500 [==============================] - 0s 125us/step - loss: 0.0698 - val_loss: 100.1564\n",
      "Epoch 412/1000\n",
      "1500/1500 [==============================] - 0s 123us/step - loss: 0.1007 - val_loss: 99.4681\n",
      "Epoch 413/1000\n",
      "1500/1500 [==============================] - 0s 125us/step - loss: 0.1732 - val_loss: 99.6116\n",
      "Epoch 414/1000\n",
      "1500/1500 [==============================] - 0s 126us/step - loss: 0.4627 - val_loss: 99.6262\n",
      "Epoch 415/1000\n",
      "1500/1500 [==============================] - 0s 123us/step - loss: 0.6626 - val_loss: 99.6622\n",
      "Epoch 416/1000\n",
      "1500/1500 [==============================] - 0s 123us/step - loss: 1.0855 - val_loss: 102.0427\n",
      "Epoch 417/1000\n",
      "1500/1500 [==============================] - 0s 125us/step - loss: 3.0305 - val_loss: 116.0757\n",
      "Epoch 418/1000\n",
      "1500/1500 [==============================] - 0s 122us/step - loss: 3.8840 - val_loss: 100.5114\n",
      "Epoch 419/1000\n",
      "1500/1500 [==============================] - 0s 123us/step - loss: 4.6543 - val_loss: 124.3473\n",
      "Epoch 420/1000\n",
      "1500/1500 [==============================] - 0s 124us/step - loss: 16.7169 - val_loss: 99.7190\n",
      "Epoch 421/1000\n",
      "1500/1500 [==============================] - 0s 127us/step - loss: 3.9088 - val_loss: 99.9386\n",
      "Epoch 422/1000\n",
      "1500/1500 [==============================] - 0s 140us/step - loss: 1.9769 - val_loss: 97.2987\n",
      "Epoch 423/1000\n",
      "1500/1500 [==============================] - 0s 126us/step - loss: 1.2019 - val_loss: 100.2670\n",
      "Epoch 424/1000\n",
      "1500/1500 [==============================] - 0s 124us/step - loss: 1.1470 - val_loss: 99.6554\n",
      "Epoch 425/1000\n",
      "1500/1500 [==============================] - 0s 126us/step - loss: 0.6215 - val_loss: 101.4913\n",
      "Epoch 426/1000\n",
      "1500/1500 [==============================] - 0s 127us/step - loss: 0.4646 - val_loss: 100.3411\n",
      "Epoch 427/1000\n",
      "1500/1500 [==============================] - 0s 124us/step - loss: 0.3671 - val_loss: 99.4297\n",
      "Epoch 428/1000\n",
      "1500/1500 [==============================] - 0s 127us/step - loss: 0.1730 - val_loss: 98.9281\n",
      "Epoch 429/1000\n",
      "1500/1500 [==============================] - 0s 124us/step - loss: 0.1083 - val_loss: 99.6930\n",
      "Epoch 430/1000\n",
      "1500/1500 [==============================] - 0s 121us/step - loss: 0.0811 - val_loss: 100.2444\n",
      "Epoch 431/1000\n",
      "1500/1500 [==============================] - 0s 127us/step - loss: 0.1077 - val_loss: 99.6784\n",
      "Epoch 432/1000\n",
      "1500/1500 [==============================] - 0s 124us/step - loss: 0.0899 - val_loss: 100.4278\n",
      "Epoch 433/1000\n",
      "1500/1500 [==============================] - 0s 126us/step - loss: 0.0670 - val_loss: 99.3853\n",
      "Epoch 434/1000\n",
      "1500/1500 [==============================] - 0s 124us/step - loss: 0.0666 - val_loss: 99.7811\n",
      "Epoch 435/1000\n",
      "1500/1500 [==============================] - 0s 122us/step - loss: 0.0511 - val_loss: 100.0788\n",
      "Epoch 436/1000\n",
      "1500/1500 [==============================] - 0s 121us/step - loss: 0.0579 - val_loss: 99.6658\n",
      "Epoch 437/1000\n",
      "1500/1500 [==============================] - 0s 127us/step - loss: 0.0803 - val_loss: 99.9412\n",
      "Epoch 438/1000\n",
      "1500/1500 [==============================] - 0s 122us/step - loss: 0.1079 - val_loss: 99.9430\n",
      "Epoch 439/1000\n",
      "1500/1500 [==============================] - 0s 126us/step - loss: 0.1465 - val_loss: 100.6507\n",
      "Epoch 440/1000\n",
      "1500/1500 [==============================] - 0s 126us/step - loss: 0.2665 - val_loss: 100.9505\n",
      "Epoch 441/1000\n",
      "1500/1500 [==============================] - 0s 124us/step - loss: 0.4794 - val_loss: 100.3904\n",
      "Epoch 442/1000\n",
      "1500/1500 [==============================] - 0s 124us/step - loss: 0.2774 - val_loss: 99.0911\n",
      "Epoch 443/1000\n",
      "1500/1500 [==============================] - 0s 122us/step - loss: 0.3099 - val_loss: 98.7141\n",
      "Epoch 444/1000\n",
      "1500/1500 [==============================] - 0s 125us/step - loss: 0.2629 - val_loss: 99.6110\n",
      "Epoch 445/1000\n",
      "1500/1500 [==============================] - 0s 123us/step - loss: 0.2600 - val_loss: 102.5096\n",
      "Epoch 446/1000\n",
      "1500/1500 [==============================] - 0s 126us/step - loss: 0.4220 - val_loss: 100.1101\n",
      "Epoch 447/1000\n",
      "1500/1500 [==============================] - 0s 124us/step - loss: 0.6654 - val_loss: 100.8588\n",
      "Epoch 448/1000\n",
      "1500/1500 [==============================] - 0s 121us/step - loss: 1.0480 - val_loss: 101.0955\n",
      "Epoch 449/1000\n",
      "1500/1500 [==============================] - 0s 129us/step - loss: 2.2188 - val_loss: 116.7345\n",
      "Epoch 450/1000\n",
      "1500/1500 [==============================] - 0s 124us/step - loss: 4.5845 - val_loss: 107.6000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 451/1000\n",
      "1500/1500 [==============================] - 0s 123us/step - loss: 6.2157 - val_loss: 105.7797\n",
      "Epoch 452/1000\n",
      "1500/1500 [==============================] - 0s 122us/step - loss: 3.0057 - val_loss: 106.8064\n",
      "Epoch 453/1000\n",
      "1500/1500 [==============================] - 0s 122us/step - loss: 2.2714 - val_loss: 100.4402\n",
      "Epoch 454/1000\n",
      "1500/1500 [==============================] - 0s 121us/step - loss: 1.2229 - val_loss: 100.4655\n",
      "Epoch 455/1000\n",
      "1500/1500 [==============================] - 0s 125us/step - loss: 1.3212 - val_loss: 100.4899\n",
      "Epoch 456/1000\n",
      "1500/1500 [==============================] - 0s 126us/step - loss: 1.2057 - val_loss: 99.7724\n",
      "Epoch 457/1000\n",
      "1500/1500 [==============================] - 0s 123us/step - loss: 1.1952 - val_loss: 103.0291\n",
      "Epoch 458/1000\n",
      "1500/1500 [==============================] - 0s 124us/step - loss: 0.6995 - val_loss: 100.7564\n",
      "Epoch 459/1000\n",
      "1500/1500 [==============================] - 0s 122us/step - loss: 0.9705 - val_loss: 103.1385\n",
      "Epoch 460/1000\n",
      "1500/1500 [==============================] - 0s 123us/step - loss: 1.2708 - val_loss: 102.9650\n",
      "Epoch 461/1000\n",
      "1500/1500 [==============================] - 0s 125us/step - loss: 4.8169 - val_loss: 112.4654\n",
      "Epoch 462/1000\n",
      "1500/1500 [==============================] - 0s 121us/step - loss: 8.8727 - val_loss: 102.2674\n",
      "Epoch 463/1000\n",
      "1500/1500 [==============================] - 0s 125us/step - loss: 4.0776 - val_loss: 98.7557\n",
      "Epoch 464/1000\n",
      "1500/1500 [==============================] - 0s 123us/step - loss: 2.3500 - val_loss: 100.5999\n",
      "Epoch 465/1000\n",
      "1500/1500 [==============================] - 0s 124us/step - loss: 1.0542 - val_loss: 100.6187\n",
      "Epoch 466/1000\n",
      "1500/1500 [==============================] - 0s 132us/step - loss: 0.5551 - val_loss: 99.9589\n",
      "Epoch 467/1000\n",
      "1500/1500 [==============================] - 0s 123us/step - loss: 0.4303 - val_loss: 99.6088\n",
      "Epoch 468/1000\n",
      "1500/1500 [==============================] - 0s 123us/step - loss: 0.3105 - val_loss: 101.0331\n",
      "Epoch 469/1000\n",
      "1500/1500 [==============================] - 0s 123us/step - loss: 0.1687 - val_loss: 100.1375\n",
      "Epoch 470/1000\n",
      "1500/1500 [==============================] - 0s 120us/step - loss: 0.0963 - val_loss: 99.8032\n",
      "Epoch 471/1000\n",
      "1500/1500 [==============================] - 0s 129us/step - loss: 0.0896 - val_loss: 99.8807\n",
      "Epoch 472/1000\n",
      "1500/1500 [==============================] - 0s 123us/step - loss: 0.0710 - val_loss: 100.2750\n",
      "Epoch 473/1000\n",
      "1500/1500 [==============================] - 0s 129us/step - loss: 0.1461 - val_loss: 99.9284\n",
      "Epoch 474/1000\n",
      "1500/1500 [==============================] - 0s 124us/step - loss: 0.2132 - val_loss: 101.4378\n",
      "Epoch 475/1000\n",
      "1500/1500 [==============================] - 0s 123us/step - loss: 0.8083 - val_loss: 106.3278\n",
      "Epoch 476/1000\n",
      "1500/1500 [==============================] - 0s 122us/step - loss: 2.6149 - val_loss: 104.8388\n",
      "Epoch 477/1000\n",
      "1500/1500 [==============================] - 0s 125us/step - loss: 3.0004 - val_loss: 104.1331\n",
      "Epoch 478/1000\n",
      "1500/1500 [==============================] - 0s 125us/step - loss: 1.8528 - val_loss: 101.6091\n",
      "Epoch 479/1000\n",
      "1500/1500 [==============================] - 0s 123us/step - loss: 1.2364 - val_loss: 101.1830\n",
      "Epoch 480/1000\n",
      "1500/1500 [==============================] - 0s 123us/step - loss: 1.0226 - val_loss: 102.1465\n",
      "Epoch 481/1000\n",
      "1500/1500 [==============================] - 0s 122us/step - loss: 0.5056 - val_loss: 101.7619\n",
      "Epoch 482/1000\n",
      "1500/1500 [==============================] - 0s 124us/step - loss: 0.4223 - val_loss: 100.0028\n",
      "Epoch 483/1000\n",
      "1500/1500 [==============================] - 0s 127us/step - loss: 0.2849 - val_loss: 100.8857\n",
      "Epoch 484/1000\n",
      "1500/1500 [==============================] - 0s 123us/step - loss: 0.2724 - val_loss: 102.3112\n",
      "Epoch 485/1000\n",
      "1500/1500 [==============================] - 0s 123us/step - loss: 0.3203 - val_loss: 100.9675\n",
      "Epoch 486/1000\n",
      "1500/1500 [==============================] - 0s 123us/step - loss: 0.1727 - val_loss: 99.8667\n",
      "Epoch 487/1000\n",
      "1500/1500 [==============================] - 0s 123us/step - loss: 0.1660 - val_loss: 100.3135\n",
      "Epoch 488/1000\n",
      "1500/1500 [==============================] - 0s 121us/step - loss: 0.5093 - val_loss: 100.7983\n",
      "Epoch 489/1000\n",
      "1500/1500 [==============================] - 0s 121us/step - loss: 1.3621 - val_loss: 99.9092\n",
      "Epoch 490/1000\n",
      "1500/1500 [==============================] - 0s 126us/step - loss: 1.5613 - val_loss: 98.6386\n",
      "Epoch 491/1000\n",
      "1500/1500 [==============================] - 0s 121us/step - loss: 2.9337 - val_loss: 109.9036\n",
      "Epoch 492/1000\n",
      "1500/1500 [==============================] - 0s 125us/step - loss: 2.4482 - val_loss: 104.0797\n",
      "Epoch 493/1000\n",
      "1500/1500 [==============================] - 0s 126us/step - loss: 1.3300 - val_loss: 103.1133\n",
      "Epoch 494/1000\n",
      "1500/1500 [==============================] - 0s 123us/step - loss: 1.6587 - val_loss: 98.5827\n",
      "Epoch 495/1000\n",
      "1500/1500 [==============================] - 0s 130us/step - loss: 4.3497 - val_loss: 116.2735\n",
      "Epoch 496/1000\n",
      "1500/1500 [==============================] - 0s 122us/step - loss: 6.2726 - val_loss: 109.6141\n",
      "Epoch 497/1000\n",
      "1500/1500 [==============================] - 0s 125us/step - loss: 3.6604 - val_loss: 106.1528\n",
      "Epoch 498/1000\n",
      "1500/1500 [==============================] - 0s 124us/step - loss: 4.7619 - val_loss: 105.2750\n",
      "Epoch 499/1000\n",
      "1500/1500 [==============================] - 0s 125us/step - loss: 1.8426 - val_loss: 102.3311\n",
      "Epoch 500/1000\n",
      "1500/1500 [==============================] - 0s 125us/step - loss: 0.8212 - val_loss: 101.6691\n",
      "Epoch 501/1000\n",
      "1500/1500 [==============================] - 0s 125us/step - loss: 0.4175 - val_loss: 101.2511\n",
      "Epoch 502/1000\n",
      "1500/1500 [==============================] - 0s 124us/step - loss: 0.2624 - val_loss: 102.0583\n",
      "Epoch 503/1000\n",
      "1500/1500 [==============================] - 0s 127us/step - loss: 0.2552 - val_loss: 102.0795\n",
      "Epoch 504/1000\n",
      "1500/1500 [==============================] - 0s 123us/step - loss: 0.2373 - val_loss: 101.7844\n",
      "Epoch 505/1000\n",
      "1500/1500 [==============================] - 0s 123us/step - loss: 0.1143 - val_loss: 101.2694\n",
      "Epoch 506/1000\n",
      "1500/1500 [==============================] - 0s 126us/step - loss: 0.0686 - val_loss: 101.4166\n",
      "Epoch 507/1000\n",
      "1500/1500 [==============================] - 0s 127us/step - loss: 0.0754 - val_loss: 100.7345\n",
      "Epoch 508/1000\n",
      "1500/1500 [==============================] - 0s 124us/step - loss: 0.0839 - val_loss: 102.8440\n",
      "Epoch 509/1000\n",
      "1500/1500 [==============================] - 0s 125us/step - loss: 0.0634 - val_loss: 102.6046\n",
      "Epoch 510/1000\n",
      "1500/1500 [==============================] - 0s 123us/step - loss: 0.0610 - val_loss: 101.8190\n",
      "Epoch 511/1000\n",
      "1500/1500 [==============================] - 0s 121us/step - loss: 0.0352 - val_loss: 101.1475\n",
      "Epoch 512/1000\n",
      "1500/1500 [==============================] - 0s 126us/step - loss: 0.0368 - val_loss: 101.8515\n",
      "Epoch 513/1000\n",
      "1500/1500 [==============================] - 0s 127us/step - loss: 0.0292 - val_loss: 102.1561\n",
      "Epoch 514/1000\n",
      "1500/1500 [==============================] - 0s 126us/step - loss: 0.0366 - val_loss: 101.5430\n",
      "Epoch 515/1000\n",
      "1500/1500 [==============================] - 0s 126us/step - loss: 0.1644 - val_loss: 103.0514\n",
      "Epoch 516/1000\n",
      "1500/1500 [==============================] - 0s 126us/step - loss: 0.3826 - val_loss: 100.6120\n",
      "Epoch 517/1000\n",
      "1500/1500 [==============================] - 0s 124us/step - loss: 0.4385 - val_loss: 102.0174\n",
      "Epoch 518/1000\n",
      "1500/1500 [==============================] - 0s 123us/step - loss: 0.4758 - val_loss: 102.8779\n",
      "Epoch 519/1000\n",
      "1500/1500 [==============================] - 0s 122us/step - loss: 0.4454 - val_loss: 104.6114\n",
      "Epoch 520/1000\n",
      "1500/1500 [==============================] - 0s 125us/step - loss: 0.6560 - val_loss: 102.6660\n",
      "Epoch 521/1000\n",
      "1500/1500 [==============================] - 0s 122us/step - loss: 1.3855 - val_loss: 104.9072\n",
      "Epoch 522/1000\n",
      "1500/1500 [==============================] - 0s 123us/step - loss: 1.4311 - val_loss: 107.1791\n",
      "Epoch 523/1000\n",
      "1500/1500 [==============================] - 0s 123us/step - loss: 1.6269 - val_loss: 104.6445\n",
      "Epoch 524/1000\n",
      "1500/1500 [==============================] - 0s 124us/step - loss: 1.4237 - val_loss: 99.8663\n",
      "Epoch 525/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1500/1500 [==============================] - 0s 123us/step - loss: 2.1588 - val_loss: 101.6665\n",
      "Epoch 526/1000\n",
      "1500/1500 [==============================] - 0s 125us/step - loss: 1.4500 - val_loss: 101.3213\n",
      "Epoch 527/1000\n",
      "1500/1500 [==============================] - 0s 123us/step - loss: 1.3207 - val_loss: 107.5883\n",
      "Epoch 528/1000\n",
      "1500/1500 [==============================] - 0s 126us/step - loss: 1.4212 - val_loss: 103.7424\n",
      "Epoch 529/1000\n",
      "1500/1500 [==============================] - 0s 125us/step - loss: 0.9759 - val_loss: 101.4012\n",
      "Epoch 530/1000\n",
      "1500/1500 [==============================] - 0s 121us/step - loss: 0.6156 - val_loss: 99.9857\n",
      "Epoch 531/1000\n",
      "1500/1500 [==============================] - 0s 126us/step - loss: 1.9445 - val_loss: 101.7514\n",
      "Epoch 532/1000\n",
      "1500/1500 [==============================] - 0s 126us/step - loss: 1.3089 - val_loss: 102.1173\n",
      "Epoch 533/1000\n",
      "1500/1500 [==============================] - 0s 122us/step - loss: 1.3612 - val_loss: 110.7871\n",
      "Epoch 534/1000\n",
      "1500/1500 [==============================] - 0s 127us/step - loss: 5.6014 - val_loss: 102.6003\n",
      "Epoch 535/1000\n",
      "1500/1500 [==============================] - 0s 126us/step - loss: 3.1147 - val_loss: 101.9029\n",
      "Epoch 536/1000\n",
      "1500/1500 [==============================] - 0s 124us/step - loss: 1.2255 - val_loss: 104.7472\n",
      "Epoch 537/1000\n",
      "1500/1500 [==============================] - 0s 121us/step - loss: 2.2398 - val_loss: 104.5627\n",
      "Epoch 538/1000\n",
      "1500/1500 [==============================] - 0s 123us/step - loss: 1.6637 - val_loss: 100.4371\n",
      "Epoch 539/1000\n",
      "1500/1500 [==============================] - 0s 127us/step - loss: 0.8424 - val_loss: 100.1731\n",
      "Epoch 540/1000\n",
      "1500/1500 [==============================] - 0s 120us/step - loss: 0.4551 - val_loss: 101.8461\n",
      "Epoch 541/1000\n",
      "1500/1500 [==============================] - 0s 125us/step - loss: 0.5024 - val_loss: 101.0137\n",
      "Epoch 542/1000\n",
      "1500/1500 [==============================] - 0s 122us/step - loss: 0.6483 - val_loss: 106.0296\n",
      "Epoch 543/1000\n",
      "1500/1500 [==============================] - 0s 122us/step - loss: 0.5333 - val_loss: 102.2781\n",
      "Epoch 544/1000\n",
      "1500/1500 [==============================] - 0s 120us/step - loss: 0.5495 - val_loss: 102.1218\n",
      "Epoch 545/1000\n",
      "1500/1500 [==============================] - 0s 123us/step - loss: 0.2886 - val_loss: 100.9282\n",
      "Epoch 546/1000\n",
      "1500/1500 [==============================] - 0s 124us/step - loss: 0.3319 - val_loss: 101.9656\n",
      "Epoch 547/1000\n",
      "1500/1500 [==============================] - 0s 123us/step - loss: 0.1652 - val_loss: 101.2447\n",
      "Epoch 548/1000\n",
      "1500/1500 [==============================] - 0s 120us/step - loss: 0.1057 - val_loss: 101.3636\n",
      "Epoch 549/1000\n",
      "1500/1500 [==============================] - 0s 121us/step - loss: 0.0794 - val_loss: 101.0203\n",
      "Epoch 550/1000\n",
      "1500/1500 [==============================] - 0s 129us/step - loss: 0.0656 - val_loss: 101.2346\n",
      "Epoch 551/1000\n",
      "1500/1500 [==============================] - 0s 125us/step - loss: 0.1345 - val_loss: 101.8255\n",
      "Epoch 552/1000\n",
      "1500/1500 [==============================] - 0s 124us/step - loss: 0.1482 - val_loss: 102.1409\n",
      "Epoch 553/1000\n",
      "1500/1500 [==============================] - 0s 121us/step - loss: 0.1782 - val_loss: 101.5788\n",
      "Epoch 554/1000\n",
      "1500/1500 [==============================] - 0s 122us/step - loss: 0.1660 - val_loss: 102.4377\n",
      "Epoch 555/1000\n",
      "1500/1500 [==============================] - 0s 123us/step - loss: 0.4067 - val_loss: 101.8120\n",
      "Epoch 556/1000\n",
      "1500/1500 [==============================] - 0s 121us/step - loss: 0.3826 - val_loss: 101.3782\n",
      "Epoch 557/1000\n",
      "1500/1500 [==============================] - 0s 127us/step - loss: 0.6154 - val_loss: 102.2366\n",
      "Epoch 558/1000\n",
      "1500/1500 [==============================] - 0s 125us/step - loss: 1.6270 - val_loss: 101.8882\n",
      "Epoch 559/1000\n",
      "1500/1500 [==============================] - 0s 124us/step - loss: 3.3758 - val_loss: 101.1454\n",
      "Epoch 560/1000\n",
      "1500/1500 [==============================] - 0s 122us/step - loss: 2.5127 - val_loss: 100.7371\n",
      "Epoch 561/1000\n",
      "1500/1500 [==============================] - 0s 125us/step - loss: 2.6567 - val_loss: 103.7960\n",
      "Epoch 562/1000\n",
      "1500/1500 [==============================] - 0s 128us/step - loss: 1.7629 - val_loss: 101.0443\n",
      "Epoch 563/1000\n",
      "1500/1500 [==============================] - 0s 123us/step - loss: 1.6267 - val_loss: 104.7113\n",
      "Epoch 564/1000\n",
      "1500/1500 [==============================] - 0s 123us/step - loss: 3.0507 - val_loss: 115.2563\n",
      "Epoch 565/1000\n",
      "1500/1500 [==============================] - 0s 125us/step - loss: 8.2315 - val_loss: 109.9418\n",
      "Epoch 566/1000\n",
      "1500/1500 [==============================] - 0s 127us/step - loss: 3.8766 - val_loss: 104.2882\n",
      "Epoch 567/1000\n",
      "1500/1500 [==============================] - 0s 122us/step - loss: 2.8612 - val_loss: 110.8871\n",
      "Epoch 568/1000\n",
      "1500/1500 [==============================] - 0s 124us/step - loss: 1.3154 - val_loss: 102.1075\n",
      "Epoch 569/1000\n",
      "1500/1500 [==============================] - 0s 125us/step - loss: 1.5305 - val_loss: 100.5590\n",
      "Epoch 570/1000\n",
      "1500/1500 [==============================] - 0s 122us/step - loss: 0.7467 - val_loss: 102.4969\n",
      "Epoch 571/1000\n",
      "1500/1500 [==============================] - 0s 123us/step - loss: 0.3018 - val_loss: 101.0571\n",
      "Epoch 572/1000\n",
      "1500/1500 [==============================] - 0s 126us/step - loss: 0.2612 - val_loss: 101.3650\n",
      "Epoch 573/1000\n",
      "1500/1500 [==============================] - 0s 128us/step - loss: 0.1562 - val_loss: 101.1931\n",
      "Epoch 574/1000\n",
      "1500/1500 [==============================] - 0s 129us/step - loss: 0.0826 - val_loss: 102.0591\n",
      "Epoch 575/1000\n",
      "1500/1500 [==============================] - 0s 124us/step - loss: 0.0809 - val_loss: 101.4714\n",
      "Epoch 576/1000\n",
      "1500/1500 [==============================] - 0s 128us/step - loss: 0.1261 - val_loss: 101.1631\n",
      "Epoch 577/1000\n",
      "1500/1500 [==============================] - 0s 123us/step - loss: 0.2600 - val_loss: 101.4084\n",
      "Epoch 578/1000\n",
      "1500/1500 [==============================] - 0s 129us/step - loss: 0.2760 - val_loss: 101.5226\n",
      "Epoch 579/1000\n",
      "1500/1500 [==============================] - 0s 128us/step - loss: 0.1030 - val_loss: 101.8157\n",
      "Epoch 580/1000\n",
      "1500/1500 [==============================] - 0s 124us/step - loss: 0.0822 - val_loss: 101.2802\n",
      "Epoch 581/1000\n",
      "1500/1500 [==============================] - 0s 125us/step - loss: 0.0523 - val_loss: 101.3485\n",
      "Epoch 582/1000\n",
      "1500/1500 [==============================] - 0s 126us/step - loss: 0.0969 - val_loss: 102.1227\n",
      "Epoch 583/1000\n",
      "1500/1500 [==============================] - 0s 125us/step - loss: 0.0801 - val_loss: 101.5123\n",
      "Epoch 584/1000\n",
      "1500/1500 [==============================] - 0s 125us/step - loss: 0.1990 - val_loss: 101.3271\n",
      "Epoch 585/1000\n",
      "1500/1500 [==============================] - 0s 126us/step - loss: 0.1333 - val_loss: 101.0414\n",
      "Epoch 586/1000\n",
      "1500/1500 [==============================] - 0s 123us/step - loss: 0.3421 - val_loss: 104.1104\n",
      "Epoch 587/1000\n",
      "1500/1500 [==============================] - 0s 123us/step - loss: 1.1817 - val_loss: 105.2730\n",
      "Epoch 588/1000\n",
      "1500/1500 [==============================] - 0s 125us/step - loss: 6.5556 - val_loss: 101.9902\n",
      "Epoch 589/1000\n",
      "1500/1500 [==============================] - 0s 128us/step - loss: 4.1604 - val_loss: 103.9331\n",
      "Epoch 590/1000\n",
      "1500/1500 [==============================] - 0s 122us/step - loss: 8.2559 - val_loss: 99.5595\n",
      "Epoch 591/1000\n",
      "1500/1500 [==============================] - 0s 125us/step - loss: 3.8113 - val_loss: 108.9045\n",
      "Epoch 592/1000\n",
      "1500/1500 [==============================] - 0s 129us/step - loss: 2.7942 - val_loss: 101.4488\n",
      "Epoch 593/1000\n",
      "1500/1500 [==============================] - 0s 126us/step - loss: 1.2298 - val_loss: 101.7350\n",
      "Epoch 594/1000\n",
      "1500/1500 [==============================] - 0s 124us/step - loss: 0.4584 - val_loss: 102.1320\n",
      "Epoch 595/1000\n",
      "1500/1500 [==============================] - 0s 122us/step - loss: 0.3472 - val_loss: 100.9936\n",
      "Epoch 596/1000\n",
      "1500/1500 [==============================] - 0s 123us/step - loss: 0.1764 - val_loss: 102.0952\n",
      "Epoch 597/1000\n",
      "1500/1500 [==============================] - 0s 126us/step - loss: 0.1773 - val_loss: 101.8250\n",
      "Epoch 598/1000\n",
      "1500/1500 [==============================] - 0s 126us/step - loss: 0.1194 - val_loss: 100.1215\n",
      "Epoch 599/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1500/1500 [==============================] - 0s 125us/step - loss: 0.0866 - val_loss: 100.4542\n",
      "Epoch 600/1000\n",
      "1500/1500 [==============================] - 0s 124us/step - loss: 0.0595 - val_loss: 100.4421\n",
      "Epoch 601/1000\n",
      "1500/1500 [==============================] - 0s 128us/step - loss: 0.0480 - val_loss: 101.3187\n",
      "Epoch 602/1000\n",
      "1500/1500 [==============================] - 0s 122us/step - loss: 0.0391 - val_loss: 100.2968\n",
      "Epoch 603/1000\n",
      "1500/1500 [==============================] - 0s 124us/step - loss: 0.0511 - val_loss: 100.2831\n",
      "Epoch 604/1000\n",
      "1500/1500 [==============================] - 0s 123us/step - loss: 0.0851 - val_loss: 101.3665\n",
      "Epoch 605/1000\n",
      "1500/1500 [==============================] - 0s 124us/step - loss: 0.0668 - val_loss: 100.9211\n",
      "Epoch 606/1000\n",
      "1500/1500 [==============================] - 0s 124us/step - loss: 0.0464 - val_loss: 101.2999\n",
      "Epoch 607/1000\n",
      "1500/1500 [==============================] - 0s 123us/step - loss: 0.0603 - val_loss: 100.6867\n",
      "Epoch 608/1000\n",
      "1500/1500 [==============================] - 0s 123us/step - loss: 0.0594 - val_loss: 101.1102\n",
      "Epoch 609/1000\n",
      "1500/1500 [==============================] - 0s 125us/step - loss: 0.1599 - val_loss: 100.4359\n",
      "Epoch 610/1000\n",
      "1500/1500 [==============================] - 0s 122us/step - loss: 0.1352 - val_loss: 100.1553\n",
      "Epoch 611/1000\n",
      "1500/1500 [==============================] - 0s 130us/step - loss: 0.1048 - val_loss: 100.2738\n",
      "Epoch 612/1000\n",
      "1500/1500 [==============================] - 0s 123us/step - loss: 0.7233 - val_loss: 100.1050\n",
      "Epoch 613/1000\n",
      "1500/1500 [==============================] - 0s 131us/step - loss: 2.2696 - val_loss: 105.3235\n",
      "Epoch 614/1000\n",
      "1500/1500 [==============================] - 0s 124us/step - loss: 1.7749 - val_loss: 102.6994\n",
      "Epoch 615/1000\n",
      "1500/1500 [==============================] - 0s 124us/step - loss: 1.1306 - val_loss: 104.5360\n",
      "Epoch 616/1000\n",
      "1500/1500 [==============================] - 0s 122us/step - loss: 0.7388 - val_loss: 101.6789\n",
      "Epoch 617/1000\n",
      "1500/1500 [==============================] - 0s 127us/step - loss: 1.3282 - val_loss: 98.6742\n",
      "Epoch 618/1000\n",
      "1500/1500 [==============================] - 0s 122us/step - loss: 0.8477 - val_loss: 102.9240\n",
      "Epoch 619/1000\n",
      "1500/1500 [==============================] - 0s 124us/step - loss: 0.9051 - val_loss: 107.5388\n",
      "Epoch 620/1000\n",
      "1500/1500 [==============================] - 0s 133us/step - loss: 1.3977 - val_loss: 101.8650\n",
      "Epoch 621/1000\n",
      "1500/1500 [==============================] - 0s 130us/step - loss: 1.0386 - val_loss: 100.4769\n",
      "Epoch 622/1000\n",
      "1500/1500 [==============================] - 0s 125us/step - loss: 0.5777 - val_loss: 102.0456\n",
      "Epoch 623/1000\n",
      "1500/1500 [==============================] - 0s 125us/step - loss: 1.2996 - val_loss: 100.2309\n",
      "Epoch 624/1000\n",
      "1500/1500 [==============================] - 0s 123us/step - loss: 0.9552 - val_loss: 100.4206\n",
      "Epoch 625/1000\n",
      "1500/1500 [==============================] - 0s 128us/step - loss: 0.7578 - val_loss: 102.5457\n",
      "Epoch 626/1000\n",
      "1500/1500 [==============================] - 0s 125us/step - loss: 1.3533 - val_loss: 101.8563\n",
      "Epoch 627/1000\n",
      "1500/1500 [==============================] - 0s 123us/step - loss: 0.9717 - val_loss: 102.3054\n",
      "Epoch 628/1000\n",
      "1500/1500 [==============================] - 0s 122us/step - loss: 0.7442 - val_loss: 101.8325\n",
      "Epoch 629/1000\n",
      "1500/1500 [==============================] - 0s 123us/step - loss: 0.3882 - val_loss: 100.8073\n",
      "Epoch 630/1000\n",
      "1500/1500 [==============================] - 0s 125us/step - loss: 0.4052 - val_loss: 101.9815\n",
      "Epoch 631/1000\n",
      "1500/1500 [==============================] - 0s 126us/step - loss: 0.2796 - val_loss: 100.4528\n",
      "Epoch 632/1000\n",
      "1500/1500 [==============================] - 0s 124us/step - loss: 0.2309 - val_loss: 99.4999\n",
      "Epoch 633/1000\n",
      "1500/1500 [==============================] - 0s 125us/step - loss: 0.2846 - val_loss: 101.0800\n",
      "Epoch 634/1000\n",
      "1500/1500 [==============================] - 0s 127us/step - loss: 0.1453 - val_loss: 101.2629\n",
      "Epoch 635/1000\n",
      "1500/1500 [==============================] - 0s 121us/step - loss: 0.3303 - val_loss: 103.4820\n",
      "Epoch 636/1000\n",
      "1500/1500 [==============================] - 0s 123us/step - loss: 0.2659 - val_loss: 99.9935\n",
      "Epoch 637/1000\n",
      "1500/1500 [==============================] - 0s 126us/step - loss: 0.2472 - val_loss: 100.4813\n",
      "Epoch 638/1000\n",
      "1500/1500 [==============================] - 0s 121us/step - loss: 0.4431 - val_loss: 102.0152\n",
      "Epoch 639/1000\n",
      "1500/1500 [==============================] - 0s 121us/step - loss: 1.0962 - val_loss: 100.6699\n",
      "Epoch 640/1000\n",
      "1500/1500 [==============================] - 0s 122us/step - loss: 4.8084 - val_loss: 111.6722\n",
      "Epoch 641/1000\n",
      "1500/1500 [==============================] - 0s 125us/step - loss: 10.3553 - val_loss: 117.9405\n",
      "Epoch 642/1000\n",
      "1500/1500 [==============================] - 0s 126us/step - loss: 6.1956 - val_loss: 104.5195\n",
      "Epoch 643/1000\n",
      "1500/1500 [==============================] - 0s 125us/step - loss: 3.4149 - val_loss: 103.1516\n",
      "Epoch 644/1000\n",
      "1500/1500 [==============================] - 0s 122us/step - loss: 1.3514 - val_loss: 102.4094\n",
      "Epoch 645/1000\n",
      "1500/1500 [==============================] - 0s 124us/step - loss: 0.8190 - val_loss: 102.7234\n",
      "Epoch 646/1000\n",
      "1500/1500 [==============================] - 0s 125us/step - loss: 0.6628 - val_loss: 101.7694\n",
      "Epoch 647/1000\n",
      "1500/1500 [==============================] - 0s 126us/step - loss: 0.3941 - val_loss: 102.1409\n",
      "Epoch 648/1000\n",
      "1500/1500 [==============================] - 0s 126us/step - loss: 0.2265 - val_loss: 101.5455\n",
      "Epoch 649/1000\n",
      "1500/1500 [==============================] - 0s 122us/step - loss: 0.1203 - val_loss: 101.5437\n",
      "Epoch 650/1000\n",
      "1500/1500 [==============================] - 0s 122us/step - loss: 0.0772 - val_loss: 101.7206\n",
      "Epoch 651/1000\n",
      "1500/1500 [==============================] - 0s 123us/step - loss: 0.0508 - val_loss: 101.7749\n",
      "Epoch 652/1000\n",
      "1500/1500 [==============================] - 0s 131us/step - loss: 0.0589 - val_loss: 101.2305\n",
      "Epoch 653/1000\n",
      "1500/1500 [==============================] - 0s 126us/step - loss: 0.0478 - val_loss: 101.5883\n",
      "Epoch 654/1000\n",
      "1500/1500 [==============================] - 0s 122us/step - loss: 0.0336 - val_loss: 101.1450\n",
      "Epoch 655/1000\n",
      "1500/1500 [==============================] - 0s 125us/step - loss: 0.0254 - val_loss: 101.5858\n",
      "Epoch 656/1000\n",
      "1500/1500 [==============================] - 0s 125us/step - loss: 0.0177 - val_loss: 101.6860\n",
      "Epoch 657/1000\n",
      "1500/1500 [==============================] - 0s 123us/step - loss: 0.0171 - val_loss: 101.3587\n",
      "Epoch 658/1000\n",
      "1500/1500 [==============================] - 0s 126us/step - loss: 0.0212 - val_loss: 101.6665\n",
      "Epoch 659/1000\n",
      "1500/1500 [==============================] - 0s 123us/step - loss: 0.0194 - val_loss: 101.4220\n",
      "Epoch 660/1000\n",
      "1500/1500 [==============================] - 0s 126us/step - loss: 0.0238 - val_loss: 101.6403\n",
      "Epoch 661/1000\n",
      "1500/1500 [==============================] - 0s 124us/step - loss: 0.0310 - val_loss: 101.4438\n",
      "Epoch 662/1000\n",
      "1500/1500 [==============================] - 0s 127us/step - loss: 0.0593 - val_loss: 101.0857\n",
      "Epoch 663/1000\n",
      "1500/1500 [==============================] - 0s 125us/step - loss: 0.1887 - val_loss: 100.8930\n",
      "Epoch 664/1000\n",
      "1500/1500 [==============================] - 0s 124us/step - loss: 0.1589 - val_loss: 102.5827\n",
      "Epoch 665/1000\n",
      "1500/1500 [==============================] - 0s 126us/step - loss: 0.7033 - val_loss: 102.5211\n",
      "Epoch 666/1000\n",
      "1500/1500 [==============================] - 0s 128us/step - loss: 1.3468 - val_loss: 102.8429\n",
      "Epoch 667/1000\n",
      "1500/1500 [==============================] - 0s 123us/step - loss: 1.5515 - val_loss: 105.5462\n",
      "Epoch 668/1000\n",
      "1500/1500 [==============================] - 0s 126us/step - loss: 5.1229 - val_loss: 103.5911\n",
      "Epoch 669/1000\n",
      "1500/1500 [==============================] - 0s 128us/step - loss: 2.5484 - val_loss: 101.7613\n",
      "Epoch 670/1000\n",
      "1500/1500 [==============================] - 0s 122us/step - loss: 1.9909 - val_loss: 102.3126\n",
      "Epoch 671/1000\n",
      "1500/1500 [==============================] - 0s 126us/step - loss: 2.2149 - val_loss: 103.7158\n",
      "Epoch 672/1000\n",
      "1500/1500 [==============================] - 0s 125us/step - loss: 1.1805 - val_loss: 104.6482\n",
      "Epoch 673/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1500/1500 [==============================] - 0s 125us/step - loss: 0.6124 - val_loss: 101.4411\n",
      "Epoch 674/1000\n",
      "1500/1500 [==============================] - 0s 124us/step - loss: 0.3619 - val_loss: 100.8328\n",
      "Epoch 675/1000\n",
      "1500/1500 [==============================] - 0s 123us/step - loss: 0.4771 - val_loss: 102.5888\n",
      "Epoch 676/1000\n",
      "1500/1500 [==============================] - 0s 125us/step - loss: 0.2161 - val_loss: 102.2507\n",
      "Epoch 677/1000\n",
      "1500/1500 [==============================] - 0s 121us/step - loss: 0.2428 - val_loss: 103.4417\n",
      "Epoch 678/1000\n",
      "1500/1500 [==============================] - 0s 126us/step - loss: 0.1680 - val_loss: 101.2472\n",
      "Epoch 679/1000\n",
      "1500/1500 [==============================] - 0s 123us/step - loss: 0.1254 - val_loss: 101.6974\n",
      "Epoch 680/1000\n",
      "1500/1500 [==============================] - 0s 125us/step - loss: 0.0946 - val_loss: 101.4272\n",
      "Epoch 681/1000\n",
      "1500/1500 [==============================] - 0s 125us/step - loss: 0.1952 - val_loss: 102.3499\n",
      "Epoch 682/1000\n",
      "1500/1500 [==============================] - 0s 124us/step - loss: 0.1573 - val_loss: 100.2619\n",
      "Epoch 683/1000\n",
      "1500/1500 [==============================] - 0s 125us/step - loss: 0.3032 - val_loss: 99.8460\n",
      "Epoch 684/1000\n",
      "1500/1500 [==============================] - 0s 124us/step - loss: 0.7958 - val_loss: 101.4579\n",
      "Epoch 685/1000\n",
      "1500/1500 [==============================] - 0s 122us/step - loss: 1.6005 - val_loss: 104.5151\n",
      "Epoch 686/1000\n",
      "1500/1500 [==============================] - 0s 122us/step - loss: 1.7167 - val_loss: 104.5431\n",
      "Epoch 687/1000\n",
      "1500/1500 [==============================] - 0s 125us/step - loss: 1.0335 - val_loss: 103.9272\n",
      "Epoch 688/1000\n",
      "1500/1500 [==============================] - 0s 125us/step - loss: 0.5751 - val_loss: 100.4858\n",
      "Epoch 689/1000\n",
      "1500/1500 [==============================] - 0s 121us/step - loss: 0.5239 - val_loss: 100.7192\n",
      "Epoch 690/1000\n",
      "1500/1500 [==============================] - 0s 123us/step - loss: 0.5874 - val_loss: 100.6071\n",
      "Epoch 691/1000\n",
      "1500/1500 [==============================] - 0s 125us/step - loss: 1.0502 - val_loss: 100.2300\n",
      "Epoch 692/1000\n",
      "1500/1500 [==============================] - 0s 124us/step - loss: 0.5582 - val_loss: 101.8419\n",
      "Epoch 693/1000\n",
      "1500/1500 [==============================] - 0s 122us/step - loss: 1.0068 - val_loss: 102.1129\n",
      "Epoch 694/1000\n",
      "1500/1500 [==============================] - 0s 128us/step - loss: 0.5680 - val_loss: 102.1808\n",
      "Epoch 695/1000\n",
      "1500/1500 [==============================] - 0s 127us/step - loss: 0.7267 - val_loss: 102.2046\n",
      "Epoch 696/1000\n",
      "1500/1500 [==============================] - 0s 127us/step - loss: 0.8905 - val_loss: 101.7314\n",
      "Epoch 697/1000\n",
      "1500/1500 [==============================] - 0s 124us/step - loss: 0.6226 - val_loss: 101.2713\n",
      "Epoch 698/1000\n",
      "1500/1500 [==============================] - 0s 121us/step - loss: 1.1414 - val_loss: 101.0068\n",
      "Epoch 699/1000\n",
      "1500/1500 [==============================] - 0s 123us/step - loss: 3.0387 - val_loss: 112.9993\n",
      "Epoch 700/1000\n",
      "1500/1500 [==============================] - 0s 122us/step - loss: 2.7804 - val_loss: 102.5190\n",
      "Epoch 701/1000\n",
      "1500/1500 [==============================] - 0s 124us/step - loss: 2.5748 - val_loss: 100.0906\n",
      "Epoch 702/1000\n",
      "1500/1500 [==============================] - 0s 122us/step - loss: 1.6198 - val_loss: 102.3819\n",
      "Epoch 703/1000\n",
      "1500/1500 [==============================] - 0s 124us/step - loss: 1.4734 - val_loss: 101.8092\n",
      "Epoch 704/1000\n",
      "1500/1500 [==============================] - 0s 128us/step - loss: 0.6065 - val_loss: 99.8697\n",
      "Epoch 705/1000\n",
      "1500/1500 [==============================] - 0s 126us/step - loss: 0.5303 - val_loss: 101.9913\n",
      "Epoch 706/1000\n",
      "1500/1500 [==============================] - 0s 124us/step - loss: 0.7664 - val_loss: 104.1528\n",
      "Epoch 707/1000\n",
      "1500/1500 [==============================] - 0s 123us/step - loss: 1.7650 - val_loss: 104.5433\n",
      "Epoch 708/1000\n",
      "1500/1500 [==============================] - 0s 126us/step - loss: 1.6830 - val_loss: 102.4857\n",
      "Epoch 709/1000\n",
      "1500/1500 [==============================] - 0s 125us/step - loss: 0.7176 - val_loss: 101.1989\n",
      "Epoch 710/1000\n",
      "1500/1500 [==============================] - 0s 125us/step - loss: 0.3348 - val_loss: 101.1445\n",
      "Epoch 711/1000\n",
      "1500/1500 [==============================] - 0s 125us/step - loss: 0.2211 - val_loss: 100.3701\n",
      "Epoch 712/1000\n",
      "1500/1500 [==============================] - 0s 126us/step - loss: 0.1375 - val_loss: 100.8781\n",
      "Epoch 713/1000\n",
      "1500/1500 [==============================] - 0s 124us/step - loss: 0.1410 - val_loss: 100.7462\n",
      "Epoch 714/1000\n",
      "1500/1500 [==============================] - 0s 123us/step - loss: 0.1700 - val_loss: 102.4812\n",
      "Epoch 715/1000\n",
      "1500/1500 [==============================] - 0s 122us/step - loss: 0.1451 - val_loss: 100.8426\n",
      "Epoch 716/1000\n",
      "1500/1500 [==============================] - 0s 124us/step - loss: 0.2930 - val_loss: 100.4883\n",
      "Epoch 717/1000\n",
      "1500/1500 [==============================] - 0s 122us/step - loss: 0.5205 - val_loss: 101.9264\n",
      "Epoch 718/1000\n",
      "1500/1500 [==============================] - 0s 124us/step - loss: 1.9235 - val_loss: 103.4713\n",
      "Epoch 719/1000\n",
      "1500/1500 [==============================] - 0s 126us/step - loss: 2.3073 - val_loss: 108.4760\n",
      "Epoch 720/1000\n",
      "1500/1500 [==============================] - 0s 126us/step - loss: 1.7192 - val_loss: 105.7651\n",
      "Epoch 721/1000\n",
      "1500/1500 [==============================] - 0s 126us/step - loss: 1.9539 - val_loss: 103.8488\n",
      "Epoch 722/1000\n",
      "1500/1500 [==============================] - 0s 121us/step - loss: 1.0234 - val_loss: 102.4846\n",
      "Epoch 723/1000\n",
      "1500/1500 [==============================] - 0s 120us/step - loss: 0.6541 - val_loss: 100.4882\n",
      "Epoch 724/1000\n",
      "1500/1500 [==============================] - 0s 125us/step - loss: 0.5297 - val_loss: 102.0005\n",
      "Epoch 725/1000\n",
      "1500/1500 [==============================] - 0s 125us/step - loss: 0.2681 - val_loss: 101.0130\n",
      "Epoch 726/1000\n",
      "1500/1500 [==============================] - 0s 124us/step - loss: 0.4188 - val_loss: 100.8873\n",
      "Epoch 727/1000\n",
      "1500/1500 [==============================] - 0s 122us/step - loss: 0.2172 - val_loss: 101.1445\n",
      "Epoch 728/1000\n",
      "1500/1500 [==============================] - 0s 128us/step - loss: 0.1547 - val_loss: 100.9314\n",
      "Epoch 729/1000\n",
      "1500/1500 [==============================] - 0s 127us/step - loss: 0.1887 - val_loss: 103.5727\n",
      "Epoch 730/1000\n",
      "1500/1500 [==============================] - 0s 125us/step - loss: 0.7173 - val_loss: 101.8244\n",
      "Epoch 731/1000\n",
      "1500/1500 [==============================] - 0s 124us/step - loss: 1.2279 - val_loss: 100.5978\n",
      "Epoch 732/1000\n",
      "1500/1500 [==============================] - 0s 127us/step - loss: 0.7167 - val_loss: 101.1649\n",
      "Epoch 733/1000\n",
      "1500/1500 [==============================] - 0s 125us/step - loss: 0.9040 - val_loss: 100.7453\n",
      "Epoch 734/1000\n",
      "1500/1500 [==============================] - 0s 124us/step - loss: 0.8404 - val_loss: 102.7685\n",
      "Epoch 735/1000\n",
      "1500/1500 [==============================] - 0s 124us/step - loss: 0.5062 - val_loss: 99.3536\n",
      "Epoch 736/1000\n",
      "1500/1500 [==============================] - 0s 127us/step - loss: 0.2886 - val_loss: 101.0754\n",
      "Epoch 737/1000\n",
      "1500/1500 [==============================] - 0s 123us/step - loss: 0.5573 - val_loss: 99.4172\n",
      "Epoch 738/1000\n",
      "1500/1500 [==============================] - 0s 124us/step - loss: 0.3008 - val_loss: 101.3935\n",
      "Epoch 739/1000\n",
      "1500/1500 [==============================] - 0s 125us/step - loss: 0.5688 - val_loss: 102.2487\n",
      "Epoch 740/1000\n",
      "1500/1500 [==============================] - 0s 124us/step - loss: 0.6809 - val_loss: 106.9339\n",
      "Epoch 741/1000\n",
      "1500/1500 [==============================] - 0s 122us/step - loss: 2.8242 - val_loss: 102.5118\n",
      "Epoch 742/1000\n",
      "1500/1500 [==============================] - 0s 130us/step - loss: 3.6875 - val_loss: 101.9309\n",
      "Epoch 743/1000\n",
      "1500/1500 [==============================] - 0s 126us/step - loss: 1.4897 - val_loss: 102.2134\n",
      "Epoch 744/1000\n",
      "1500/1500 [==============================] - 0s 132us/step - loss: 0.9573 - val_loss: 101.5529\n",
      "Epoch 745/1000\n",
      "1500/1500 [==============================] - 0s 134us/step - loss: 0.6712 - val_loss: 103.7817\n",
      "Epoch 746/1000\n",
      "1500/1500 [==============================] - 0s 130us/step - loss: 0.4199 - val_loss: 101.0458\n",
      "Epoch 747/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1500/1500 [==============================] - 0s 126us/step - loss: 0.7002 - val_loss: 99.7649\n",
      "Epoch 748/1000\n",
      "1500/1500 [==============================] - 0s 127us/step - loss: 0.4562 - val_loss: 101.6635\n",
      "Epoch 749/1000\n",
      "1500/1500 [==============================] - 0s 125us/step - loss: 0.2120 - val_loss: 100.5166\n",
      "Epoch 750/1000\n",
      "1500/1500 [==============================] - 0s 126us/step - loss: 0.4638 - val_loss: 101.2575\n",
      "Epoch 751/1000\n",
      "1500/1500 [==============================] - 0s 125us/step - loss: 0.3349 - val_loss: 101.2016\n",
      "Epoch 752/1000\n",
      "1500/1500 [==============================] - 0s 123us/step - loss: 0.2768 - val_loss: 101.2570\n",
      "Epoch 753/1000\n",
      "1500/1500 [==============================] - 0s 124us/step - loss: 0.4247 - val_loss: 101.0165\n",
      "Epoch 754/1000\n",
      "1500/1500 [==============================] - 0s 125us/step - loss: 0.4985 - val_loss: 100.3203\n",
      "Epoch 755/1000\n",
      "1500/1500 [==============================] - 0s 124us/step - loss: 0.5500 - val_loss: 100.2437\n",
      "Epoch 756/1000\n",
      "1500/1500 [==============================] - 0s 121us/step - loss: 0.7190 - val_loss: 102.5320\n",
      "Epoch 757/1000\n",
      "1500/1500 [==============================] - 0s 121us/step - loss: 0.4652 - val_loss: 101.8327\n",
      "Epoch 758/1000\n",
      "1500/1500 [==============================] - 0s 120us/step - loss: 0.4521 - val_loss: 101.7518\n",
      "Epoch 759/1000\n",
      "1500/1500 [==============================] - 0s 124us/step - loss: 0.2607 - val_loss: 101.3364\n",
      "Epoch 760/1000\n",
      "1500/1500 [==============================] - 0s 124us/step - loss: 0.2330 - val_loss: 101.5561\n",
      "Epoch 761/1000\n",
      "1500/1500 [==============================] - 0s 127us/step - loss: 0.3747 - val_loss: 102.9845\n",
      "Epoch 762/1000\n",
      "1500/1500 [==============================] - 0s 126us/step - loss: 0.2762 - val_loss: 101.9389\n",
      "Epoch 763/1000\n",
      "1500/1500 [==============================] - 0s 125us/step - loss: 0.2893 - val_loss: 101.6588\n",
      "Epoch 764/1000\n",
      "1500/1500 [==============================] - 0s 125us/step - loss: 0.3446 - val_loss: 101.7009\n",
      "Epoch 765/1000\n",
      "1500/1500 [==============================] - 0s 124us/step - loss: 0.4626 - val_loss: 101.3503\n",
      "Epoch 766/1000\n",
      "1500/1500 [==============================] - 0s 128us/step - loss: 0.5041 - val_loss: 100.9641\n",
      "Epoch 767/1000\n",
      "1500/1500 [==============================] - 0s 123us/step - loss: 1.1342 - val_loss: 102.4264\n",
      "Epoch 768/1000\n",
      "1500/1500 [==============================] - 0s 123us/step - loss: 2.5469 - val_loss: 104.6608\n",
      "Epoch 769/1000\n",
      "1500/1500 [==============================] - 0s 124us/step - loss: 1.5893 - val_loss: 101.1205\n",
      "Epoch 770/1000\n",
      "1500/1500 [==============================] - 0s 127us/step - loss: 1.1920 - val_loss: 102.6448\n",
      "Epoch 771/1000\n",
      "1500/1500 [==============================] - 0s 128us/step - loss: 2.1178 - val_loss: 104.0469\n",
      "Epoch 772/1000\n",
      "1500/1500 [==============================] - 0s 127us/step - loss: 2.1243 - val_loss: 105.6048\n",
      "Epoch 773/1000\n",
      "1500/1500 [==============================] - 0s 125us/step - loss: 2.0201 - val_loss: 102.2195\n",
      "Epoch 774/1000\n",
      "1500/1500 [==============================] - 0s 126us/step - loss: 1.4368 - val_loss: 101.1585\n",
      "Epoch 775/1000\n",
      "1500/1500 [==============================] - 0s 120us/step - loss: 1.2172 - val_loss: 100.4485\n",
      "Epoch 776/1000\n",
      "1500/1500 [==============================] - 0s 124us/step - loss: 0.9233 - val_loss: 103.1016\n",
      "Epoch 777/1000\n",
      "1500/1500 [==============================] - 0s 126us/step - loss: 0.8790 - val_loss: 101.8536\n",
      "Epoch 778/1000\n",
      "1500/1500 [==============================] - 0s 122us/step - loss: 0.6242 - val_loss: 100.6284\n",
      "Epoch 779/1000\n",
      "1500/1500 [==============================] - 0s 125us/step - loss: 0.2992 - val_loss: 101.7842\n",
      "Epoch 780/1000\n",
      "1500/1500 [==============================] - 0s 127us/step - loss: 0.2189 - val_loss: 100.6725\n",
      "Epoch 781/1000\n",
      "1500/1500 [==============================] - 0s 124us/step - loss: 0.2661 - val_loss: 101.3992\n",
      "Epoch 782/1000\n",
      "1500/1500 [==============================] - 0s 124us/step - loss: 0.1706 - val_loss: 101.9286\n",
      "Epoch 783/1000\n",
      "1500/1500 [==============================] - 0s 125us/step - loss: 0.1707 - val_loss: 102.0547\n",
      "Epoch 784/1000\n",
      "1500/1500 [==============================] - 0s 125us/step - loss: 0.1852 - val_loss: 101.0743\n",
      "Epoch 785/1000\n",
      "1500/1500 [==============================] - 0s 133us/step - loss: 0.2412 - val_loss: 101.6333\n",
      "Epoch 786/1000\n",
      "1500/1500 [==============================] - 0s 124us/step - loss: 0.1494 - val_loss: 100.9144\n",
      "Epoch 787/1000\n",
      "1500/1500 [==============================] - 0s 128us/step - loss: 0.1048 - val_loss: 100.9410\n",
      "Epoch 788/1000\n",
      "1500/1500 [==============================] - 0s 127us/step - loss: 0.1156 - val_loss: 101.3734\n",
      "Epoch 789/1000\n",
      "1500/1500 [==============================] - 0s 122us/step - loss: 0.1449 - val_loss: 102.6010\n",
      "Epoch 790/1000\n",
      "1500/1500 [==============================] - 0s 133us/step - loss: 0.2778 - val_loss: 102.0649\n",
      "Epoch 791/1000\n",
      "1500/1500 [==============================] - 0s 125us/step - loss: 0.4734 - val_loss: 102.5488\n",
      "Epoch 792/1000\n",
      "1500/1500 [==============================] - 0s 127us/step - loss: 0.4372 - val_loss: 101.0964\n",
      "Epoch 793/1000\n",
      "1500/1500 [==============================] - 0s 124us/step - loss: 0.8099 - val_loss: 103.3687\n",
      "Epoch 794/1000\n",
      "1500/1500 [==============================] - 0s 122us/step - loss: 1.3721 - val_loss: 103.7061\n",
      "Epoch 795/1000\n",
      "1500/1500 [==============================] - 0s 120us/step - loss: 2.8236 - val_loss: 104.3245\n",
      "Epoch 796/1000\n",
      "1500/1500 [==============================] - 0s 123us/step - loss: 3.1821 - val_loss: 103.5232\n",
      "Epoch 797/1000\n",
      "1500/1500 [==============================] - 0s 121us/step - loss: 2.1063 - val_loss: 99.5556\n",
      "Epoch 798/1000\n",
      "1500/1500 [==============================] - 0s 127us/step - loss: 1.0629 - val_loss: 102.0286\n",
      "Epoch 799/1000\n",
      "1500/1500 [==============================] - 0s 124us/step - loss: 0.4855 - val_loss: 101.5432\n",
      "Epoch 800/1000\n",
      "1500/1500 [==============================] - 0s 124us/step - loss: 0.5963 - val_loss: 102.1695\n",
      "Epoch 801/1000\n",
      "1500/1500 [==============================] - 0s 124us/step - loss: 0.6539 - val_loss: 101.3190\n",
      "Epoch 802/1000\n",
      "1500/1500 [==============================] - 0s 123us/step - loss: 0.4023 - val_loss: 103.4181\n",
      "Epoch 803/1000\n",
      "1500/1500 [==============================] - 0s 123us/step - loss: 0.3995 - val_loss: 101.0578\n",
      "Epoch 804/1000\n",
      "1500/1500 [==============================] - 0s 124us/step - loss: 0.2261 - val_loss: 100.8203\n",
      "Epoch 805/1000\n",
      "1500/1500 [==============================] - 0s 126us/step - loss: 0.3274 - val_loss: 100.4286\n",
      "Epoch 806/1000\n",
      "1500/1500 [==============================] - 0s 123us/step - loss: 1.0116 - val_loss: 101.4069\n",
      "Epoch 807/1000\n",
      "1500/1500 [==============================] - 0s 127us/step - loss: 3.6244 - val_loss: 98.9199\n",
      "Epoch 808/1000\n",
      "1500/1500 [==============================] - 0s 125us/step - loss: 6.0045 - val_loss: 105.2510\n",
      "Epoch 809/1000\n",
      "1500/1500 [==============================] - 0s 126us/step - loss: 2.0984 - val_loss: 109.6850\n",
      "Epoch 810/1000\n",
      "1500/1500 [==============================] - 0s 130us/step - loss: 1.7304 - val_loss: 105.4804\n",
      "Epoch 811/1000\n",
      "1500/1500 [==============================] - 0s 125us/step - loss: 2.0666 - val_loss: 101.1278\n",
      "Epoch 812/1000\n",
      "1500/1500 [==============================] - 0s 123us/step - loss: 0.9041 - val_loss: 106.2856\n",
      "Epoch 813/1000\n",
      "1500/1500 [==============================] - 0s 124us/step - loss: 0.5334 - val_loss: 103.1655\n",
      "Epoch 814/1000\n",
      "1500/1500 [==============================] - 0s 129us/step - loss: 1.1239 - val_loss: 102.8797\n",
      "Epoch 815/1000\n",
      "1500/1500 [==============================] - 0s 128us/step - loss: 0.4950 - val_loss: 102.5194\n",
      "Epoch 816/1000\n",
      "1500/1500 [==============================] - 0s 125us/step - loss: 0.2223 - val_loss: 100.8694\n",
      "Epoch 817/1000\n",
      "1500/1500 [==============================] - 0s 126us/step - loss: 0.1241 - val_loss: 101.2343\n",
      "Epoch 818/1000\n",
      "1500/1500 [==============================] - 0s 129us/step - loss: 0.0965 - val_loss: 100.6070\n",
      "Epoch 819/1000\n",
      "1500/1500 [==============================] - 0s 129us/step - loss: 0.0944 - val_loss: 101.1231\n",
      "Epoch 820/1000\n",
      "1500/1500 [==============================] - 0s 124us/step - loss: 0.1132 - val_loss: 100.8565\n",
      "Epoch 821/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1500/1500 [==============================] - 0s 126us/step - loss: 0.0604 - val_loss: 101.2921\n",
      "Epoch 822/1000\n",
      "1500/1500 [==============================] - 0s 126us/step - loss: 0.0255 - val_loss: 101.1658\n",
      "Epoch 823/1000\n",
      "1500/1500 [==============================] - 0s 125us/step - loss: 0.0334 - val_loss: 101.1521\n",
      "Epoch 824/1000\n",
      "1500/1500 [==============================] - 0s 126us/step - loss: 0.0253 - val_loss: 101.0838\n",
      "Epoch 825/1000\n",
      "1500/1500 [==============================] - 0s 125us/step - loss: 0.0257 - val_loss: 101.5748\n",
      "Epoch 826/1000\n",
      "1500/1500 [==============================] - 0s 127us/step - loss: 0.0169 - val_loss: 101.6147\n",
      "Epoch 827/1000\n",
      "1500/1500 [==============================] - 0s 123us/step - loss: 0.0219 - val_loss: 101.2320\n",
      "Epoch 828/1000\n",
      "1500/1500 [==============================] - 0s 124us/step - loss: 0.0222 - val_loss: 101.4201\n",
      "Epoch 829/1000\n",
      "1500/1500 [==============================] - 0s 128us/step - loss: 0.0385 - val_loss: 101.1834\n",
      "Epoch 830/1000\n",
      "1500/1500 [==============================] - 0s 124us/step - loss: 0.0251 - val_loss: 101.4119\n",
      "Epoch 831/1000\n",
      "1500/1500 [==============================] - 0s 124us/step - loss: 0.0207 - val_loss: 101.1288\n",
      "Epoch 832/1000\n",
      "1500/1500 [==============================] - 0s 124us/step - loss: 0.0276 - val_loss: 101.3393\n",
      "Epoch 833/1000\n",
      "1500/1500 [==============================] - 0s 125us/step - loss: 0.0289 - val_loss: 100.7997\n",
      "Epoch 834/1000\n",
      "1500/1500 [==============================] - 0s 124us/step - loss: 0.0621 - val_loss: 101.2235\n",
      "Epoch 835/1000\n",
      "1500/1500 [==============================] - 0s 125us/step - loss: 0.1184 - val_loss: 100.1144\n",
      "Epoch 836/1000\n",
      "1500/1500 [==============================] - 0s 125us/step - loss: 0.6359 - val_loss: 101.8640\n",
      "Epoch 837/1000\n",
      "1500/1500 [==============================] - 0s 126us/step - loss: 0.7809 - val_loss: 100.9124\n",
      "Epoch 838/1000\n",
      "1500/1500 [==============================] - 0s 128us/step - loss: 3.9467 - val_loss: 107.7708\n",
      "Epoch 839/1000\n",
      "1500/1500 [==============================] - 0s 122us/step - loss: 3.9369 - val_loss: 106.8320\n",
      "Epoch 840/1000\n",
      "1500/1500 [==============================] - 0s 125us/step - loss: 4.8579 - val_loss: 98.4358\n",
      "Epoch 841/1000\n",
      "1500/1500 [==============================] - 0s 126us/step - loss: 1.9707 - val_loss: 102.6509\n",
      "Epoch 842/1000\n",
      "1500/1500 [==============================] - 0s 125us/step - loss: 0.7585 - val_loss: 101.2412\n",
      "Epoch 843/1000\n",
      "1500/1500 [==============================] - 0s 127us/step - loss: 0.5351 - val_loss: 101.8343\n",
      "Epoch 844/1000\n",
      "1500/1500 [==============================] - 0s 125us/step - loss: 0.8284 - val_loss: 102.1081\n",
      "Epoch 845/1000\n",
      "1500/1500 [==============================] - 0s 127us/step - loss: 1.3282 - val_loss: 106.7507\n",
      "Epoch 846/1000\n",
      "1500/1500 [==============================] - 0s 129us/step - loss: 0.7629 - val_loss: 103.6800\n",
      "Epoch 847/1000\n",
      "1500/1500 [==============================] - 0s 123us/step - loss: 0.5090 - val_loss: 103.5995\n",
      "Epoch 848/1000\n",
      "1500/1500 [==============================] - 0s 126us/step - loss: 0.2586 - val_loss: 101.7927\n",
      "Epoch 849/1000\n",
      "1500/1500 [==============================] - 0s 123us/step - loss: 0.1816 - val_loss: 102.4910\n",
      "Epoch 850/1000\n",
      "1500/1500 [==============================] - 0s 125us/step - loss: 0.1401 - val_loss: 101.6545\n",
      "Epoch 851/1000\n",
      "1500/1500 [==============================] - 0s 127us/step - loss: 0.0751 - val_loss: 102.0603\n",
      "Epoch 852/1000\n",
      "1500/1500 [==============================] - 0s 122us/step - loss: 0.0433 - val_loss: 102.3535\n",
      "Epoch 853/1000\n",
      "1500/1500 [==============================] - 0s 124us/step - loss: 0.0329 - val_loss: 101.8601\n",
      "Epoch 854/1000\n",
      "1500/1500 [==============================] - 0s 125us/step - loss: 0.0416 - val_loss: 102.6805\n",
      "Epoch 855/1000\n",
      "1500/1500 [==============================] - 0s 123us/step - loss: 0.0945 - val_loss: 101.4875\n",
      "Epoch 856/1000\n",
      "1500/1500 [==============================] - 0s 122us/step - loss: 0.0809 - val_loss: 102.5831\n",
      "Epoch 857/1000\n",
      "1500/1500 [==============================] - 0s 124us/step - loss: 0.0868 - val_loss: 101.8084\n",
      "Epoch 858/1000\n",
      "1500/1500 [==============================] - 0s 123us/step - loss: 0.2496 - val_loss: 103.1830\n",
      "Epoch 859/1000\n",
      "1500/1500 [==============================] - 0s 123us/step - loss: 0.1201 - val_loss: 102.6673\n",
      "Epoch 860/1000\n",
      "1500/1500 [==============================] - 0s 122us/step - loss: 0.0873 - val_loss: 102.5150\n",
      "Epoch 861/1000\n",
      "1500/1500 [==============================] - 0s 125us/step - loss: 0.1773 - val_loss: 102.3347\n",
      "Epoch 862/1000\n",
      "1500/1500 [==============================] - 0s 125us/step - loss: 0.2121 - val_loss: 100.6795\n",
      "Epoch 863/1000\n",
      "1500/1500 [==============================] - 0s 122us/step - loss: 1.5560 - val_loss: 101.1896\n",
      "Epoch 864/1000\n",
      "1500/1500 [==============================] - 0s 124us/step - loss: 3.5661 - val_loss: 112.6504\n",
      "Epoch 865/1000\n",
      "1500/1500 [==============================] - 0s 124us/step - loss: 1.6105 - val_loss: 103.1834\n",
      "Epoch 866/1000\n",
      "1500/1500 [==============================] - 0s 126us/step - loss: 0.7738 - val_loss: 102.7710\n",
      "Epoch 867/1000\n",
      "1500/1500 [==============================] - 0s 128us/step - loss: 0.8518 - val_loss: 101.8480\n",
      "Epoch 868/1000\n",
      "1500/1500 [==============================] - 0s 124us/step - loss: 0.4674 - val_loss: 103.0176\n",
      "Epoch 869/1000\n",
      "1500/1500 [==============================] - 0s 127us/step - loss: 0.3150 - val_loss: 102.7976\n",
      "Epoch 870/1000\n",
      "1500/1500 [==============================] - 0s 125us/step - loss: 0.2999 - val_loss: 102.0658\n",
      "Epoch 871/1000\n",
      "1500/1500 [==============================] - 0s 126us/step - loss: 0.3000 - val_loss: 101.7157\n",
      "Epoch 872/1000\n",
      "1500/1500 [==============================] - 0s 122us/step - loss: 1.2233 - val_loss: 101.0061\n",
      "Epoch 873/1000\n",
      "1500/1500 [==============================] - 0s 125us/step - loss: 1.1189 - val_loss: 103.9183\n",
      "Epoch 874/1000\n",
      "1500/1500 [==============================] - 0s 126us/step - loss: 0.4900 - val_loss: 102.9647\n",
      "Epoch 875/1000\n",
      "1500/1500 [==============================] - 0s 126us/step - loss: 0.9325 - val_loss: 106.0841\n",
      "Epoch 876/1000\n",
      "1500/1500 [==============================] - 0s 122us/step - loss: 0.9826 - val_loss: 102.9597\n",
      "Epoch 877/1000\n",
      "1500/1500 [==============================] - 0s 122us/step - loss: 1.0080 - val_loss: 101.3664\n",
      "Epoch 878/1000\n",
      "1500/1500 [==============================] - 0s 124us/step - loss: 0.7897 - val_loss: 100.5294\n",
      "Epoch 879/1000\n",
      "1500/1500 [==============================] - 0s 126us/step - loss: 0.6317 - val_loss: 102.0639\n",
      "Epoch 880/1000\n",
      "1500/1500 [==============================] - 0s 124us/step - loss: 0.4464 - val_loss: 102.9859\n",
      "Epoch 881/1000\n",
      "1500/1500 [==============================] - 0s 124us/step - loss: 0.2564 - val_loss: 101.6776\n",
      "Epoch 882/1000\n",
      "1500/1500 [==============================] - 0s 124us/step - loss: 0.1837 - val_loss: 103.1019\n",
      "Epoch 883/1000\n",
      "1500/1500 [==============================] - 0s 124us/step - loss: 0.2865 - val_loss: 102.0249\n",
      "Epoch 884/1000\n",
      "1500/1500 [==============================] - 0s 123us/step - loss: 0.3913 - val_loss: 103.3677\n",
      "Epoch 885/1000\n",
      "1500/1500 [==============================] - 0s 125us/step - loss: 0.4072 - val_loss: 103.5664\n",
      "Epoch 886/1000\n",
      "1500/1500 [==============================] - 0s 123us/step - loss: 0.5119 - val_loss: 102.8716\n",
      "Epoch 887/1000\n",
      "1500/1500 [==============================] - 0s 125us/step - loss: 0.5499 - val_loss: 102.8035\n",
      "Epoch 888/1000\n",
      "1500/1500 [==============================] - 0s 123us/step - loss: 0.3923 - val_loss: 102.7999\n",
      "Epoch 889/1000\n",
      "1500/1500 [==============================] - 0s 128us/step - loss: 0.3679 - val_loss: 103.2431\n",
      "Epoch 890/1000\n",
      "1500/1500 [==============================] - 0s 126us/step - loss: 0.5275 - val_loss: 101.3418\n",
      "Epoch 891/1000\n",
      "1500/1500 [==============================] - 0s 127us/step - loss: 0.3444 - val_loss: 102.4228\n",
      "Epoch 892/1000\n",
      "1500/1500 [==============================] - 0s 125us/step - loss: 0.2372 - val_loss: 101.1021\n",
      "Epoch 893/1000\n",
      "1500/1500 [==============================] - 0s 124us/step - loss: 0.3108 - val_loss: 101.2037\n",
      "Epoch 894/1000\n",
      "1500/1500 [==============================] - 0s 125us/step - loss: 0.3719 - val_loss: 103.2969\n",
      "Epoch 895/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1500/1500 [==============================] - 0s 125us/step - loss: 0.2967 - val_loss: 102.4873\n",
      "Epoch 896/1000\n",
      "1500/1500 [==============================] - 0s 127us/step - loss: 0.6093 - val_loss: 104.7323\n",
      "Epoch 897/1000\n",
      "1500/1500 [==============================] - 0s 127us/step - loss: 0.5749 - val_loss: 113.5074\n",
      "Epoch 898/1000\n",
      "1500/1500 [==============================] - 0s 121us/step - loss: 2.6894 - val_loss: 103.6660\n",
      "Epoch 899/1000\n",
      "1500/1500 [==============================] - 0s 123us/step - loss: 2.8226 - val_loss: 113.8877\n",
      "Epoch 900/1000\n",
      "1500/1500 [==============================] - 0s 122us/step - loss: 6.5579 - val_loss: 107.5047\n",
      "Epoch 901/1000\n",
      "1500/1500 [==============================] - 0s 123us/step - loss: 2.8589 - val_loss: 101.6955\n",
      "Epoch 902/1000\n",
      "1500/1500 [==============================] - 0s 127us/step - loss: 1.3433 - val_loss: 101.1427\n",
      "Epoch 903/1000\n",
      "1500/1500 [==============================] - 0s 124us/step - loss: 0.6147 - val_loss: 103.1360\n",
      "Epoch 904/1000\n",
      "1500/1500 [==============================] - 0s 123us/step - loss: 0.2708 - val_loss: 104.0411\n",
      "Epoch 905/1000\n",
      "1500/1500 [==============================] - 0s 125us/step - loss: 0.2464 - val_loss: 102.7600\n",
      "Epoch 906/1000\n",
      "1500/1500 [==============================] - 0s 122us/step - loss: 0.1691 - val_loss: 102.6005\n",
      "Epoch 907/1000\n",
      "1500/1500 [==============================] - 0s 124us/step - loss: 0.1485 - val_loss: 103.9318\n",
      "Epoch 908/1000\n",
      "1500/1500 [==============================] - 0s 128us/step - loss: 0.2780 - val_loss: 101.9934\n",
      "Epoch 909/1000\n",
      "1500/1500 [==============================] - 0s 125us/step - loss: 0.2564 - val_loss: 102.9641\n",
      "Epoch 910/1000\n",
      "1500/1500 [==============================] - 0s 125us/step - loss: 0.1822 - val_loss: 103.2525\n",
      "Epoch 911/1000\n",
      "1500/1500 [==============================] - 0s 123us/step - loss: 0.0753 - val_loss: 102.4877\n",
      "Epoch 912/1000\n",
      "1500/1500 [==============================] - 0s 125us/step - loss: 0.0540 - val_loss: 103.2028\n",
      "Epoch 913/1000\n",
      "1500/1500 [==============================] - 0s 123us/step - loss: 0.0403 - val_loss: 102.5305\n",
      "Epoch 914/1000\n",
      "1500/1500 [==============================] - 0s 123us/step - loss: 0.0245 - val_loss: 102.6050\n",
      "Epoch 915/1000\n",
      "1500/1500 [==============================] - 0s 122us/step - loss: 0.0177 - val_loss: 102.8286\n",
      "Epoch 916/1000\n",
      "1500/1500 [==============================] - 0s 122us/step - loss: 0.0112 - val_loss: 102.6989\n",
      "Epoch 917/1000\n",
      "1500/1500 [==============================] - 0s 123us/step - loss: 0.0077 - val_loss: 102.6501\n",
      "Epoch 918/1000\n",
      "1500/1500 [==============================] - 0s 125us/step - loss: 0.0079 - val_loss: 102.5566\n",
      "Epoch 919/1000\n",
      "1500/1500 [==============================] - 0s 123us/step - loss: 0.0073 - val_loss: 102.7098\n",
      "Epoch 920/1000\n",
      "1500/1500 [==============================] - 0s 126us/step - loss: 0.0084 - val_loss: 102.5019\n",
      "Epoch 921/1000\n",
      "1500/1500 [==============================] - 0s 123us/step - loss: 0.0198 - val_loss: 103.1282\n",
      "Epoch 922/1000\n",
      "1500/1500 [==============================] - 0s 126us/step - loss: 0.1052 - val_loss: 101.8224\n",
      "Epoch 923/1000\n",
      "1500/1500 [==============================] - 0s 122us/step - loss: 0.1248 - val_loss: 103.1634\n",
      "Epoch 924/1000\n",
      "1500/1500 [==============================] - 0s 123us/step - loss: 0.1778 - val_loss: 102.9215\n",
      "Epoch 925/1000\n",
      "1500/1500 [==============================] - 0s 122us/step - loss: 1.1652 - val_loss: 101.4504\n",
      "Epoch 926/1000\n",
      "1500/1500 [==============================] - 0s 129us/step - loss: 2.1825 - val_loss: 102.1886\n",
      "Epoch 927/1000\n",
      "1500/1500 [==============================] - 0s 120us/step - loss: 1.1737 - val_loss: 100.5904\n",
      "Epoch 928/1000\n",
      "1500/1500 [==============================] - 0s 124us/step - loss: 0.7819 - val_loss: 104.7392\n",
      "Epoch 929/1000\n",
      "1500/1500 [==============================] - 0s 121us/step - loss: 2.4889 - val_loss: 105.1550\n",
      "Epoch 930/1000\n",
      "1500/1500 [==============================] - 0s 123us/step - loss: 4.0388 - val_loss: 101.6523\n",
      "Epoch 931/1000\n",
      "1500/1500 [==============================] - 0s 120us/step - loss: 3.5846 - val_loss: 108.5161\n",
      "Epoch 932/1000\n",
      "1500/1500 [==============================] - 0s 134us/step - loss: 2.3950 - val_loss: 104.1347\n",
      "Epoch 933/1000\n",
      "1500/1500 [==============================] - 0s 124us/step - loss: 0.8683 - val_loss: 103.3499\n",
      "Epoch 934/1000\n",
      "1500/1500 [==============================] - 0s 128us/step - loss: 0.4293 - val_loss: 102.6926\n",
      "Epoch 935/1000\n",
      "1500/1500 [==============================] - 0s 125us/step - loss: 0.4727 - val_loss: 104.0057\n",
      "Epoch 936/1000\n",
      "1500/1500 [==============================] - 0s 126us/step - loss: 0.2176 - val_loss: 103.4784\n",
      "Epoch 937/1000\n",
      "1500/1500 [==============================] - 0s 130us/step - loss: 0.1106 - val_loss: 102.8957\n",
      "Epoch 938/1000\n",
      "1500/1500 [==============================] - 0s 123us/step - loss: 0.1724 - val_loss: 103.1724\n",
      "Epoch 939/1000\n",
      "1500/1500 [==============================] - 0s 126us/step - loss: 0.1261 - val_loss: 103.7526\n",
      "Epoch 940/1000\n",
      "1500/1500 [==============================] - 0s 124us/step - loss: 0.1033 - val_loss: 103.2727\n",
      "Epoch 941/1000\n",
      "1500/1500 [==============================] - 0s 123us/step - loss: 0.2304 - val_loss: 102.8267\n",
      "Epoch 942/1000\n",
      "1500/1500 [==============================] - 0s 125us/step - loss: 0.2235 - val_loss: 103.1782\n",
      "Epoch 943/1000\n",
      "1500/1500 [==============================] - 0s 133us/step - loss: 0.1379 - val_loss: 103.7682\n",
      "Epoch 944/1000\n",
      "1500/1500 [==============================] - 0s 128us/step - loss: 0.1014 - val_loss: 104.6800\n",
      "Epoch 945/1000\n",
      "1500/1500 [==============================] - 0s 124us/step - loss: 0.0723 - val_loss: 102.9986\n",
      "Epoch 946/1000\n",
      "1500/1500 [==============================] - 0s 121us/step - loss: 0.1429 - val_loss: 106.1993\n",
      "Epoch 947/1000\n",
      "1500/1500 [==============================] - 0s 122us/step - loss: 0.9181 - val_loss: 102.1781\n",
      "Epoch 948/1000\n",
      "1500/1500 [==============================] - 0s 123us/step - loss: 0.8897 - val_loss: 102.9760\n",
      "Epoch 949/1000\n",
      "1500/1500 [==============================] - 0s 124us/step - loss: 0.9219 - val_loss: 104.9612\n",
      "Epoch 950/1000\n",
      "1500/1500 [==============================] - 0s 125us/step - loss: 0.6356 - val_loss: 103.0573\n",
      "Epoch 951/1000\n",
      "1500/1500 [==============================] - 0s 125us/step - loss: 0.4039 - val_loss: 103.4643\n",
      "Epoch 952/1000\n",
      "1500/1500 [==============================] - 0s 123us/step - loss: 0.2015 - val_loss: 102.0938\n",
      "Epoch 953/1000\n",
      "1500/1500 [==============================] - 0s 126us/step - loss: 0.1613 - val_loss: 103.2906\n",
      "Epoch 954/1000\n",
      "1500/1500 [==============================] - 0s 125us/step - loss: 0.1048 - val_loss: 103.4094\n",
      "Epoch 955/1000\n",
      "1500/1500 [==============================] - 0s 123us/step - loss: 0.2052 - val_loss: 102.3114\n",
      "Epoch 956/1000\n",
      "1500/1500 [==============================] - 0s 123us/step - loss: 0.2504 - val_loss: 104.3426\n",
      "Epoch 957/1000\n",
      "1500/1500 [==============================] - 0s 122us/step - loss: 0.2468 - val_loss: 103.8559\n",
      "Epoch 958/1000\n",
      "1500/1500 [==============================] - 0s 122us/step - loss: 0.3774 - val_loss: 102.8220\n",
      "Epoch 959/1000\n",
      "1500/1500 [==============================] - 0s 125us/step - loss: 0.5492 - val_loss: 103.4976\n",
      "Epoch 960/1000\n",
      "1500/1500 [==============================] - 0s 123us/step - loss: 1.6831 - val_loss: 100.1510\n",
      "Epoch 961/1000\n",
      "1500/1500 [==============================] - 0s 124us/step - loss: 1.5476 - val_loss: 101.7821\n",
      "Epoch 962/1000\n",
      "1500/1500 [==============================] - 0s 123us/step - loss: 0.7336 - val_loss: 102.8692\n",
      "Epoch 963/1000\n",
      "1500/1500 [==============================] - 0s 120us/step - loss: 0.6232 - val_loss: 102.3742\n",
      "Epoch 964/1000\n",
      "1500/1500 [==============================] - 0s 124us/step - loss: 0.3612 - val_loss: 104.1907\n",
      "Epoch 965/1000\n",
      "1500/1500 [==============================] - 0s 125us/step - loss: 0.3320 - val_loss: 101.3045\n",
      "Epoch 966/1000\n",
      "1500/1500 [==============================] - 0s 125us/step - loss: 0.2391 - val_loss: 102.2377\n",
      "Epoch 967/1000\n",
      "1500/1500 [==============================] - 0s 125us/step - loss: 1.1047 - val_loss: 103.0012\n",
      "Epoch 968/1000\n",
      "1500/1500 [==============================] - 0s 124us/step - loss: 1.3882 - val_loss: 101.9379\n",
      "Epoch 969/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1500/1500 [==============================] - 0s 126us/step - loss: 3.6780 - val_loss: 102.5428\n",
      "Epoch 970/1000\n",
      "1500/1500 [==============================] - 0s 123us/step - loss: 1.4277 - val_loss: 101.5142\n",
      "Epoch 971/1000\n",
      "1500/1500 [==============================] - 0s 124us/step - loss: 1.2694 - val_loss: 102.4378\n",
      "Epoch 972/1000\n",
      "1500/1500 [==============================] - 0s 127us/step - loss: 0.5537 - val_loss: 104.2587\n",
      "Epoch 973/1000\n",
      "1500/1500 [==============================] - 0s 123us/step - loss: 0.3322 - val_loss: 103.0583\n",
      "Epoch 974/1000\n",
      "1500/1500 [==============================] - 0s 123us/step - loss: 0.1804 - val_loss: 103.5028\n",
      "Epoch 975/1000\n",
      "1500/1500 [==============================] - 0s 122us/step - loss: 0.0869 - val_loss: 103.1841\n",
      "Epoch 976/1000\n",
      "1500/1500 [==============================] - 0s 126us/step - loss: 0.0601 - val_loss: 103.3210\n",
      "Epoch 977/1000\n",
      "1500/1500 [==============================] - 0s 126us/step - loss: 0.1273 - val_loss: 104.3320\n",
      "Epoch 978/1000\n",
      "1500/1500 [==============================] - 0s 121us/step - loss: 0.1459 - val_loss: 104.0009\n",
      "Epoch 979/1000\n",
      "1500/1500 [==============================] - 0s 131us/step - loss: 0.1255 - val_loss: 102.7436\n",
      "Epoch 980/1000\n",
      "1500/1500 [==============================] - 0s 131us/step - loss: 0.0720 - val_loss: 102.9099\n",
      "Epoch 981/1000\n",
      "1500/1500 [==============================] - 0s 123us/step - loss: 0.0814 - val_loss: 103.8192\n",
      "Epoch 982/1000\n",
      "1500/1500 [==============================] - 0s 127us/step - loss: 0.0668 - val_loss: 102.8841\n",
      "Epoch 983/1000\n",
      "1500/1500 [==============================] - 0s 122us/step - loss: 0.0488 - val_loss: 103.2695\n",
      "Epoch 984/1000\n",
      "1500/1500 [==============================] - 0s 125us/step - loss: 0.0469 - val_loss: 102.6598\n",
      "Epoch 985/1000\n",
      "1500/1500 [==============================] - 0s 125us/step - loss: 0.0447 - val_loss: 103.1940\n",
      "Epoch 986/1000\n",
      "1500/1500 [==============================] - 0s 124us/step - loss: 0.0670 - val_loss: 102.9686\n",
      "Epoch 987/1000\n",
      "1500/1500 [==============================] - 0s 123us/step - loss: 0.2675 - val_loss: 102.4612\n",
      "Epoch 988/1000\n",
      "1500/1500 [==============================] - 0s 124us/step - loss: 0.4643 - val_loss: 103.8322\n",
      "Epoch 989/1000\n",
      "1500/1500 [==============================] - 0s 121us/step - loss: 1.0705 - val_loss: 101.6422\n",
      "Epoch 990/1000\n",
      "1500/1500 [==============================] - 0s 135us/step - loss: 0.5651 - val_loss: 101.3320\n",
      "Epoch 991/1000\n",
      "1500/1500 [==============================] - 0s 128us/step - loss: 0.6671 - val_loss: 103.2881\n",
      "Epoch 992/1000\n",
      "1500/1500 [==============================] - 0s 128us/step - loss: 0.9287 - val_loss: 101.9148\n",
      "Epoch 993/1000\n",
      "1500/1500 [==============================] - 0s 125us/step - loss: 1.0008 - val_loss: 101.1013\n",
      "Epoch 994/1000\n",
      "1500/1500 [==============================] - 0s 125us/step - loss: 1.5028 - val_loss: 101.7580\n",
      "Epoch 995/1000\n",
      "1500/1500 [==============================] - 0s 127us/step - loss: 1.5265 - val_loss: 103.1383\n",
      "Epoch 996/1000\n",
      "1500/1500 [==============================] - 0s 127us/step - loss: 0.8029 - val_loss: 103.1333\n",
      "Epoch 997/1000\n",
      "1500/1500 [==============================] - 0s 123us/step - loss: 0.9930 - val_loss: 103.9070\n",
      "Epoch 998/1000\n",
      "1500/1500 [==============================] - 0s 127us/step - loss: 0.6148 - val_loss: 104.4478\n",
      "Epoch 999/1000\n",
      "1500/1500 [==============================] - 0s 124us/step - loss: 0.3563 - val_loss: 102.6275\n",
      "Epoch 1000/1000\n",
      "1500/1500 [==============================] - 0s 125us/step - loss: 0.9106 - val_loss: 103.8698\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 0s 63us/step\n",
      "110.16749847412109\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 25 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 2. 모델 구성하기\n",
    "model = Sequential()\n",
    "model.add(Dense(256, activation='relu', input_dim = width*height))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(256))\n",
    "model.add(Dense(1))\n",
    "\n",
    "# 3. 모델 학습과정 설정하기\n",
    "model.compile(loss='mse', optimizer='adam')\n",
    "\n",
    "# 4. 모델 학습시키기\n",
    "hist = model.fit(x_train_1d, y_train, batch_size=32, epochs=1000, validation_data=(x_val_1d, y_val))\n",
    "\n",
    "# 5. 학습과정 살펴보기\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(hist.history['loss'])\n",
    "plt.plot(hist.history['val_loss'])\n",
    "plt.ylim(0.0, 300.0)\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# 6. 모델 평가하기\n",
    "score = model.evaluate(x_test_1d, y_test, batch_size=32)\n",
    "\n",
    "print(score)\n",
    "\n",
    "# 7. 모델 사용하기\n",
    "yhat_test = model.predict(x_test_1d, batch_size=32)\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt_row = 5\n",
    "plt_col = 5\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (10,10)\n",
    "\n",
    "f, axarr = plt.subplots(plt_row, plt_col)\n",
    "\n",
    "for i in range(plt_row*plt_col):\n",
    "    sub_plt = axarr[i//plt_row, i%plt_col]\n",
    "    sub_plt.axis('off')\n",
    "    sub_plt.imshow(x_test[i].reshape(width, height))\n",
    "    sub_plt.set_title('R %d P %.1f' % (y_test[i][0], yhat_test[i][0]))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1500 samples, validate on 300 samples\n",
      "Epoch 1/1000\n",
      "1500/1500 [==============================] - 1s 670us/step - loss: 12857.0731 - val_loss: 2017.7996\n",
      "Epoch 2/1000\n",
      "1500/1500 [==============================] - 0s 201us/step - loss: 1406.1266 - val_loss: 1167.9825\n",
      "Epoch 3/1000\n",
      "1500/1500 [==============================] - 0s 203us/step - loss: 1047.2953 - val_loss: 890.2905\n",
      "Epoch 4/1000\n",
      "1500/1500 [==============================] - 0s 205us/step - loss: 721.6227 - val_loss: 531.5177\n",
      "Epoch 5/1000\n",
      "1500/1500 [==============================] - 0s 203us/step - loss: 408.4009 - val_loss: 326.4112\n",
      "Epoch 6/1000\n",
      "1500/1500 [==============================] - 0s 205us/step - loss: 284.0582 - val_loss: 304.5983\n",
      "Epoch 7/1000\n",
      "1500/1500 [==============================] - 0s 200us/step - loss: 273.1558 - val_loss: 309.0818\n",
      "Epoch 8/1000\n",
      "1500/1500 [==============================] - 0s 204us/step - loss: 267.0610 - val_loss: 351.0140\n",
      "Epoch 9/1000\n",
      "1500/1500 [==============================] - 0s 208us/step - loss: 252.0313 - val_loss: 293.0945\n",
      "Epoch 10/1000\n",
      "1500/1500 [==============================] - 0s 202us/step - loss: 239.7273 - val_loss: 268.9177\n",
      "Epoch 11/1000\n",
      "1500/1500 [==============================] - 0s 204us/step - loss: 226.5089 - val_loss: 265.2003\n",
      "Epoch 12/1000\n",
      "1500/1500 [==============================] - 0s 205us/step - loss: 230.8242 - val_loss: 258.0690\n",
      "Epoch 13/1000\n",
      "1500/1500 [==============================] - 0s 205us/step - loss: 226.0275 - val_loss: 259.7909\n",
      "Epoch 14/1000\n",
      "1500/1500 [==============================] - 0s 207us/step - loss: 219.2099 - val_loss: 249.3436\n",
      "Epoch 15/1000\n",
      "1500/1500 [==============================] - 0s 202us/step - loss: 225.5974 - val_loss: 246.9667\n",
      "Epoch 16/1000\n",
      "1500/1500 [==============================] - 0s 204us/step - loss: 209.7286 - val_loss: 268.0155\n",
      "Epoch 17/1000\n",
      "1500/1500 [==============================] - 0s 209us/step - loss: 206.4975 - val_loss: 244.3496\n",
      "Epoch 18/1000\n",
      "1500/1500 [==============================] - 0s 208us/step - loss: 215.1271 - val_loss: 225.4728\n",
      "Epoch 19/1000\n",
      "1500/1500 [==============================] - 0s 205us/step - loss: 198.2430 - val_loss: 243.5499\n",
      "Epoch 20/1000\n",
      "1500/1500 [==============================] - 0s 205us/step - loss: 191.8352 - val_loss: 220.9395\n",
      "Epoch 21/1000\n",
      "1500/1500 [==============================] - 0s 207us/step - loss: 185.7704 - val_loss: 224.0145\n",
      "Epoch 22/1000\n",
      "1500/1500 [==============================] - 0s 203us/step - loss: 178.8749 - val_loss: 221.6464\n",
      "Epoch 23/1000\n",
      "1500/1500 [==============================] - 0s 204us/step - loss: 180.4048 - val_loss: 214.2519\n",
      "Epoch 24/1000\n",
      "1500/1500 [==============================] - 0s 210us/step - loss: 173.5244 - val_loss: 211.3445\n",
      "Epoch 25/1000\n",
      "1500/1500 [==============================] - 0s 201us/step - loss: 185.6626 - val_loss: 255.7149\n",
      "Epoch 26/1000\n",
      "1500/1500 [==============================] - 0s 211us/step - loss: 216.3224 - val_loss: 201.4376\n",
      "Epoch 27/1000\n",
      "1500/1500 [==============================] - 0s 209us/step - loss: 172.0105 - val_loss: 201.4142\n",
      "Epoch 28/1000\n",
      "1500/1500 [==============================] - 0s 210us/step - loss: 170.0298 - val_loss: 200.2871\n",
      "Epoch 29/1000\n",
      "1500/1500 [==============================] - 0s 203us/step - loss: 169.3715 - val_loss: 204.9707\n",
      "Epoch 30/1000\n",
      "1500/1500 [==============================] - 0s 204us/step - loss: 170.4995 - val_loss: 193.7566\n",
      "Epoch 31/1000\n",
      "1500/1500 [==============================] - 0s 210us/step - loss: 163.3995 - val_loss: 205.1144\n",
      "Epoch 32/1000\n",
      "1500/1500 [==============================] - 0s 207us/step - loss: 160.3774 - val_loss: 208.0651\n",
      "Epoch 33/1000\n",
      "1500/1500 [==============================] - 0s 206us/step - loss: 162.9931 - val_loss: 189.5013\n",
      "Epoch 34/1000\n",
      "1500/1500 [==============================] - 0s 207us/step - loss: 170.2697 - val_loss: 185.8471\n",
      "Epoch 35/1000\n",
      "1500/1500 [==============================] - 0s 212us/step - loss: 154.0704 - val_loss: 190.5653\n",
      "Epoch 36/1000\n",
      "1500/1500 [==============================] - 0s 219us/step - loss: 150.9202 - val_loss: 219.8640\n",
      "Epoch 37/1000\n",
      "1500/1500 [==============================] - 0s 209us/step - loss: 150.8849 - val_loss: 182.3015\n",
      "Epoch 38/1000\n",
      "1500/1500 [==============================] - 0s 211us/step - loss: 149.6475 - val_loss: 184.8840\n",
      "Epoch 39/1000\n",
      "1500/1500 [==============================] - 0s 207us/step - loss: 148.3999 - val_loss: 185.9878\n",
      "Epoch 40/1000\n",
      "1500/1500 [==============================] - 0s 212us/step - loss: 149.8669 - val_loss: 181.0249\n",
      "Epoch 41/1000\n",
      "1500/1500 [==============================] - 0s 203us/step - loss: 143.6941 - val_loss: 178.4231\n",
      "Epoch 42/1000\n",
      "1500/1500 [==============================] - 0s 208us/step - loss: 142.8820 - val_loss: 181.1374\n",
      "Epoch 43/1000\n",
      "1500/1500 [==============================] - 0s 209us/step - loss: 148.6090 - val_loss: 198.7528\n",
      "Epoch 44/1000\n",
      "1500/1500 [==============================] - 0s 207us/step - loss: 143.9001 - val_loss: 181.2969\n",
      "Epoch 45/1000\n",
      "1500/1500 [==============================] - 0s 204us/step - loss: 146.8099 - val_loss: 199.7160\n",
      "Epoch 46/1000\n",
      "1500/1500 [==============================] - 0s 204us/step - loss: 143.1918 - val_loss: 178.8443\n",
      "Epoch 47/1000\n",
      "1500/1500 [==============================] - 0s 203us/step - loss: 148.4769 - val_loss: 176.9591\n",
      "Epoch 48/1000\n",
      "1500/1500 [==============================] - 0s 204us/step - loss: 145.6962 - val_loss: 177.0345\n",
      "Epoch 49/1000\n",
      "1500/1500 [==============================] - 0s 209us/step - loss: 146.8969 - val_loss: 175.3916\n",
      "Epoch 50/1000\n",
      "1500/1500 [==============================] - 0s 206us/step - loss: 134.0684 - val_loss: 172.3086\n",
      "Epoch 51/1000\n",
      "1500/1500 [==============================] - 0s 212us/step - loss: 133.2371 - val_loss: 194.1999\n",
      "Epoch 52/1000\n",
      "1500/1500 [==============================] - 0s 210us/step - loss: 131.5938 - val_loss: 177.2628\n",
      "Epoch 53/1000\n",
      "1500/1500 [==============================] - 0s 208us/step - loss: 154.9887 - val_loss: 247.6237\n",
      "Epoch 54/1000\n",
      "1500/1500 [==============================] - 0s 204us/step - loss: 145.7951 - val_loss: 180.4045\n",
      "Epoch 55/1000\n",
      "1500/1500 [==============================] - 0s 207us/step - loss: 127.8488 - val_loss: 180.8177\n",
      "Epoch 56/1000\n",
      "1500/1500 [==============================] - 0s 207us/step - loss: 127.7763 - val_loss: 181.7373\n",
      "Epoch 57/1000\n",
      "1500/1500 [==============================] - 0s 202us/step - loss: 128.1867 - val_loss: 179.1237\n",
      "Epoch 58/1000\n",
      "1500/1500 [==============================] - 0s 203us/step - loss: 156.4936 - val_loss: 209.0670\n",
      "Epoch 59/1000\n",
      "1500/1500 [==============================] - 0s 198us/step - loss: 142.0024 - val_loss: 185.6925\n",
      "Epoch 60/1000\n",
      "1500/1500 [==============================] - 0s 201us/step - loss: 129.8869 - val_loss: 173.3995\n",
      "Epoch 61/1000\n",
      "1500/1500 [==============================] - 0s 206us/step - loss: 127.3635 - val_loss: 179.0892\n",
      "Epoch 62/1000\n",
      "1500/1500 [==============================] - 0s 203us/step - loss: 131.4418 - val_loss: 173.3183\n",
      "Epoch 63/1000\n",
      "1500/1500 [==============================] - 0s 208us/step - loss: 119.8433 - val_loss: 168.7260\n",
      "Epoch 64/1000\n",
      "1500/1500 [==============================] - 0s 207us/step - loss: 120.0812 - val_loss: 188.3815\n",
      "Epoch 65/1000\n",
      "1500/1500 [==============================] - 0s 207us/step - loss: 115.5704 - val_loss: 179.6276\n",
      "Epoch 66/1000\n",
      "1500/1500 [==============================] - 0s 202us/step - loss: 126.4383 - val_loss: 195.4276\n",
      "Epoch 67/1000\n",
      "1500/1500 [==============================] - 0s 204us/step - loss: 117.7890 - val_loss: 174.8295\n",
      "Epoch 68/1000\n",
      "1500/1500 [==============================] - 0s 204us/step - loss: 114.7083 - val_loss: 166.3175\n",
      "Epoch 69/1000\n",
      "1500/1500 [==============================] - 0s 198us/step - loss: 115.6995 - val_loss: 172.1804\n",
      "Epoch 70/1000\n",
      "1500/1500 [==============================] - 0s 200us/step - loss: 112.1974 - val_loss: 166.1694\n",
      "Epoch 71/1000\n",
      "1500/1500 [==============================] - 0s 217us/step - loss: 112.9033 - val_loss: 170.7510\n",
      "Epoch 72/1000\n",
      "1500/1500 [==============================] - 0s 213us/step - loss: 108.7529 - val_loss: 167.1015\n",
      "Epoch 73/1000\n",
      "1500/1500 [==============================] - 0s 204us/step - loss: 108.2299 - val_loss: 174.9923\n",
      "Epoch 74/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1500/1500 [==============================] - 0s 204us/step - loss: 105.5976 - val_loss: 164.9012\n",
      "Epoch 75/1000\n",
      "1500/1500 [==============================] - 0s 199us/step - loss: 113.2992 - val_loss: 165.1396\n",
      "Epoch 76/1000\n",
      "1500/1500 [==============================] - 0s 202us/step - loss: 108.5516 - val_loss: 164.8301\n",
      "Epoch 77/1000\n",
      "1500/1500 [==============================] - 0s 202us/step - loss: 113.0981 - val_loss: 164.4829\n",
      "Epoch 78/1000\n",
      "1500/1500 [==============================] - 0s 198us/step - loss: 117.7269 - val_loss: 166.3238\n",
      "Epoch 79/1000\n",
      "1500/1500 [==============================] - 0s 201us/step - loss: 113.1583 - val_loss: 172.4885\n",
      "Epoch 80/1000\n",
      "1500/1500 [==============================] - 0s 204us/step - loss: 98.2174 - val_loss: 167.0448\n",
      "Epoch 81/1000\n",
      "1500/1500 [==============================] - 0s 206us/step - loss: 98.4102 - val_loss: 163.1886\n",
      "Epoch 82/1000\n",
      "1500/1500 [==============================] - 0s 196us/step - loss: 111.4630 - val_loss: 216.2098\n",
      "Epoch 83/1000\n",
      "1500/1500 [==============================] - 0s 203us/step - loss: 110.3084 - val_loss: 218.5865\n",
      "Epoch 84/1000\n",
      "1500/1500 [==============================] - 0s 203us/step - loss: 100.6340 - val_loss: 167.0890\n",
      "Epoch 85/1000\n",
      "1500/1500 [==============================] - 0s 200us/step - loss: 103.0487 - val_loss: 167.9423\n",
      "Epoch 86/1000\n",
      "1500/1500 [==============================] - 0s 205us/step - loss: 99.3386 - val_loss: 188.2387\n",
      "Epoch 87/1000\n",
      "1500/1500 [==============================] - 0s 203us/step - loss: 96.5084 - val_loss: 179.1434\n",
      "Epoch 88/1000\n",
      "1500/1500 [==============================] - 0s 202us/step - loss: 93.8155 - val_loss: 163.0059\n",
      "Epoch 89/1000\n",
      "1500/1500 [==============================] - 0s 201us/step - loss: 100.3648 - val_loss: 161.7568\n",
      "Epoch 90/1000\n",
      "1500/1500 [==============================] - 0s 205us/step - loss: 95.0060 - val_loss: 160.8629\n",
      "Epoch 91/1000\n",
      "1500/1500 [==============================] - 0s 207us/step - loss: 92.8906 - val_loss: 173.8214\n",
      "Epoch 92/1000\n",
      "1500/1500 [==============================] - 0s 201us/step - loss: 95.0703 - val_loss: 161.4216\n",
      "Epoch 93/1000\n",
      "1500/1500 [==============================] - 0s 199us/step - loss: 90.3291 - val_loss: 168.3395\n",
      "Epoch 94/1000\n",
      "1500/1500 [==============================] - 0s 201us/step - loss: 86.1394 - val_loss: 161.1865\n",
      "Epoch 95/1000\n",
      "1500/1500 [==============================] - 0s 202us/step - loss: 81.8075 - val_loss: 161.8132\n",
      "Epoch 96/1000\n",
      "1500/1500 [==============================] - 0s 203us/step - loss: 86.7230 - val_loss: 172.4662\n",
      "Epoch 97/1000\n",
      "1500/1500 [==============================] - 0s 190us/step - loss: 83.0060 - val_loss: 163.1186\n",
      "Epoch 98/1000\n",
      "1500/1500 [==============================] - 0s 205us/step - loss: 79.6387 - val_loss: 164.8620\n",
      "Epoch 99/1000\n",
      "1500/1500 [==============================] - 0s 198us/step - loss: 87.5846 - val_loss: 166.3633\n",
      "Epoch 100/1000\n",
      "1500/1500 [==============================] - 0s 205us/step - loss: 79.3901 - val_loss: 161.8759\n",
      "Epoch 101/1000\n",
      "1500/1500 [==============================] - 0s 201us/step - loss: 83.4655 - val_loss: 163.6355\n",
      "Epoch 102/1000\n",
      "1500/1500 [==============================] - 0s 206us/step - loss: 77.0629 - val_loss: 161.5960\n",
      "Epoch 103/1000\n",
      "1500/1500 [==============================] - 0s 203us/step - loss: 74.7619 - val_loss: 164.3063\n",
      "Epoch 104/1000\n",
      "1500/1500 [==============================] - 0s 201us/step - loss: 76.6151 - val_loss: 173.5957\n",
      "Epoch 105/1000\n",
      "1500/1500 [==============================] - 0s 196us/step - loss: 78.4933 - val_loss: 185.4152\n",
      "Epoch 106/1000\n",
      "1500/1500 [==============================] - 0s 197us/step - loss: 81.5314 - val_loss: 163.8760\n",
      "Epoch 107/1000\n",
      "1500/1500 [==============================] - 0s 204us/step - loss: 76.4127 - val_loss: 167.9876\n",
      "Epoch 108/1000\n",
      "1500/1500 [==============================] - 0s 200us/step - loss: 69.2172 - val_loss: 164.5654\n",
      "Epoch 109/1000\n",
      "1500/1500 [==============================] - 0s 201us/step - loss: 70.0379 - val_loss: 165.3024\n",
      "Epoch 110/1000\n",
      "1500/1500 [==============================] - 0s 202us/step - loss: 69.3857 - val_loss: 166.1319\n",
      "Epoch 111/1000\n",
      "1500/1500 [==============================] - 0s 206us/step - loss: 85.2027 - val_loss: 168.1814\n",
      "Epoch 112/1000\n",
      "1500/1500 [==============================] - 0s 203us/step - loss: 69.6780 - val_loss: 180.9326\n",
      "Epoch 113/1000\n",
      "1500/1500 [==============================] - 0s 207us/step - loss: 71.5889 - val_loss: 163.4706\n",
      "Epoch 114/1000\n",
      "1500/1500 [==============================] - 0s 204us/step - loss: 66.9879 - val_loss: 167.9088\n",
      "Epoch 115/1000\n",
      "1500/1500 [==============================] - 0s 209us/step - loss: 64.0995 - val_loss: 165.1429\n",
      "Epoch 116/1000\n",
      "1500/1500 [==============================] - 0s 204us/step - loss: 65.0084 - val_loss: 166.5577\n",
      "Epoch 117/1000\n",
      "1500/1500 [==============================] - 0s 201us/step - loss: 60.3331 - val_loss: 166.6448\n",
      "Epoch 118/1000\n",
      "1500/1500 [==============================] - 0s 202us/step - loss: 66.4026 - val_loss: 170.7424\n",
      "Epoch 119/1000\n",
      "1500/1500 [==============================] - 0s 200us/step - loss: 60.4550 - val_loss: 171.4224\n",
      "Epoch 120/1000\n",
      "1500/1500 [==============================] - 0s 203us/step - loss: 58.2033 - val_loss: 173.5431\n",
      "Epoch 121/1000\n",
      "1500/1500 [==============================] - 0s 199us/step - loss: 61.8400 - val_loss: 170.5615\n",
      "Epoch 122/1000\n",
      "1500/1500 [==============================] - 0s 203us/step - loss: 61.2949 - val_loss: 167.0847\n",
      "Epoch 123/1000\n",
      "1500/1500 [==============================] - 0s 205us/step - loss: 58.7882 - val_loss: 181.0691\n",
      "Epoch 124/1000\n",
      "1500/1500 [==============================] - 0s 198us/step - loss: 56.8993 - val_loss: 198.0174\n",
      "Epoch 125/1000\n",
      "1500/1500 [==============================] - 0s 202us/step - loss: 55.4061 - val_loss: 173.2156\n",
      "Epoch 126/1000\n",
      "1500/1500 [==============================] - 0s 204us/step - loss: 53.6477 - val_loss: 169.4315\n",
      "Epoch 127/1000\n",
      "1500/1500 [==============================] - 0s 203us/step - loss: 54.0880 - val_loss: 180.2886\n",
      "Epoch 128/1000\n",
      "1500/1500 [==============================] - 0s 198us/step - loss: 54.8219 - val_loss: 171.0400\n",
      "Epoch 129/1000\n",
      "1500/1500 [==============================] - 0s 209us/step - loss: 52.2130 - val_loss: 179.6396\n",
      "Epoch 130/1000\n",
      "1500/1500 [==============================] - 0s 203us/step - loss: 48.1064 - val_loss: 169.8611\n",
      "Epoch 131/1000\n",
      "1500/1500 [==============================] - 0s 203us/step - loss: 50.7980 - val_loss: 172.8961\n",
      "Epoch 132/1000\n",
      "1500/1500 [==============================] - 0s 198us/step - loss: 51.8112 - val_loss: 185.0121\n",
      "Epoch 133/1000\n",
      "1500/1500 [==============================] - 0s 202us/step - loss: 62.7112 - val_loss: 174.9364\n",
      "Epoch 134/1000\n",
      "1500/1500 [==============================] - 0s 202us/step - loss: 48.3975 - val_loss: 173.5285\n",
      "Epoch 135/1000\n",
      "1500/1500 [==============================] - 0s 204us/step - loss: 42.5790 - val_loss: 178.8672\n",
      "Epoch 136/1000\n",
      "1500/1500 [==============================] - 0s 206us/step - loss: 42.9254 - val_loss: 184.6181\n",
      "Epoch 137/1000\n",
      "1500/1500 [==============================] - 0s 205us/step - loss: 44.2110 - val_loss: 181.5125\n",
      "Epoch 138/1000\n",
      "1500/1500 [==============================] - 0s 206us/step - loss: 49.1893 - val_loss: 182.3460\n",
      "Epoch 139/1000\n",
      "1500/1500 [==============================] - 0s 198us/step - loss: 41.2140 - val_loss: 180.3518\n",
      "Epoch 140/1000\n",
      "1500/1500 [==============================] - 0s 197us/step - loss: 45.3735 - val_loss: 184.8999\n",
      "Epoch 141/1000\n",
      "1500/1500 [==============================] - 0s 200us/step - loss: 45.4781 - val_loss: 183.3773\n",
      "Epoch 142/1000\n",
      "1500/1500 [==============================] - 0s 201us/step - loss: 44.0345 - val_loss: 175.1080\n",
      "Epoch 143/1000\n",
      "1500/1500 [==============================] - 0s 200us/step - loss: 37.3972 - val_loss: 176.8371\n",
      "Epoch 144/1000\n",
      "1500/1500 [==============================] - 0s 197us/step - loss: 40.7105 - val_loss: 180.1817\n",
      "Epoch 145/1000\n",
      "1500/1500 [==============================] - 0s 196us/step - loss: 36.0329 - val_loss: 176.1163\n",
      "Epoch 146/1000\n",
      "1500/1500 [==============================] - 0s 205us/step - loss: 37.8764 - val_loss: 175.5087\n",
      "Epoch 147/1000\n",
      "1500/1500 [==============================] - 0s 200us/step - loss: 35.2351 - val_loss: 175.5231\n",
      "Epoch 148/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1500/1500 [==============================] - 0s 195us/step - loss: 32.5092 - val_loss: 176.2798\n",
      "Epoch 149/1000\n",
      "1500/1500 [==============================] - 0s 201us/step - loss: 31.9521 - val_loss: 191.2167\n",
      "Epoch 150/1000\n",
      "1500/1500 [==============================] - 0s 201us/step - loss: 30.3640 - val_loss: 179.7702\n",
      "Epoch 151/1000\n",
      "1500/1500 [==============================] - 0s 201us/step - loss: 34.0922 - val_loss: 186.0629\n",
      "Epoch 152/1000\n",
      "1500/1500 [==============================] - 0s 199us/step - loss: 30.6033 - val_loss: 179.9938\n",
      "Epoch 153/1000\n",
      "1500/1500 [==============================] - 0s 198us/step - loss: 37.3309 - val_loss: 195.4206\n",
      "Epoch 154/1000\n",
      "1500/1500 [==============================] - 0s 199us/step - loss: 36.6627 - val_loss: 179.8385\n",
      "Epoch 155/1000\n",
      "1500/1500 [==============================] - 0s 200us/step - loss: 29.1587 - val_loss: 180.7695\n",
      "Epoch 156/1000\n",
      "1500/1500 [==============================] - 0s 199us/step - loss: 26.7144 - val_loss: 205.7733\n",
      "Epoch 157/1000\n",
      "1500/1500 [==============================] - 0s 206us/step - loss: 31.7379 - val_loss: 185.0543\n",
      "Epoch 158/1000\n",
      "1500/1500 [==============================] - 0s 206us/step - loss: 26.2130 - val_loss: 187.9788\n",
      "Epoch 159/1000\n",
      "1500/1500 [==============================] - 0s 203us/step - loss: 30.0462 - val_loss: 187.0693\n",
      "Epoch 160/1000\n",
      "1500/1500 [==============================] - 0s 205us/step - loss: 26.9603 - val_loss: 181.1939\n",
      "Epoch 161/1000\n",
      "1500/1500 [==============================] - 0s 202us/step - loss: 23.9317 - val_loss: 187.7725\n",
      "Epoch 162/1000\n",
      "1500/1500 [==============================] - 0s 206us/step - loss: 27.3501 - val_loss: 185.5777\n",
      "Epoch 163/1000\n",
      "1500/1500 [==============================] - 0s 198us/step - loss: 21.2748 - val_loss: 183.1066\n",
      "Epoch 164/1000\n",
      "1500/1500 [==============================] - 0s 203us/step - loss: 22.8568 - val_loss: 183.2152\n",
      "Epoch 165/1000\n",
      "1500/1500 [==============================] - 0s 204us/step - loss: 25.8995 - val_loss: 189.2864\n",
      "Epoch 166/1000\n",
      "1500/1500 [==============================] - 0s 204us/step - loss: 23.1558 - val_loss: 181.7799\n",
      "Epoch 167/1000\n",
      "1500/1500 [==============================] - 0s 201us/step - loss: 19.6979 - val_loss: 189.1039\n",
      "Epoch 168/1000\n",
      "1500/1500 [==============================] - 0s 203us/step - loss: 19.2169 - val_loss: 187.6099\n",
      "Epoch 169/1000\n",
      "1500/1500 [==============================] - 0s 199us/step - loss: 19.0212 - val_loss: 186.5293\n",
      "Epoch 170/1000\n",
      "1500/1500 [==============================] - 0s 200us/step - loss: 18.5404 - val_loss: 184.6074\n",
      "Epoch 171/1000\n",
      "1500/1500 [==============================] - 0s 203us/step - loss: 17.7979 - val_loss: 186.5488\n",
      "Epoch 172/1000\n",
      "1500/1500 [==============================] - 0s 201us/step - loss: 18.8023 - val_loss: 192.0873\n",
      "Epoch 173/1000\n",
      "1500/1500 [==============================] - 0s 203us/step - loss: 16.1554 - val_loss: 186.8996\n",
      "Epoch 174/1000\n",
      "1500/1500 [==============================] - 0s 201us/step - loss: 15.9872 - val_loss: 187.0859\n",
      "Epoch 175/1000\n",
      "1500/1500 [==============================] - 0s 199us/step - loss: 15.8696 - val_loss: 190.6923\n",
      "Epoch 176/1000\n",
      "1500/1500 [==============================] - 0s 200us/step - loss: 17.1627 - val_loss: 188.8692\n",
      "Epoch 177/1000\n",
      "1500/1500 [==============================] - 0s 202us/step - loss: 15.2116 - val_loss: 191.8492\n",
      "Epoch 178/1000\n",
      "1500/1500 [==============================] - 0s 206us/step - loss: 14.1339 - val_loss: 191.4893\n",
      "Epoch 179/1000\n",
      "1500/1500 [==============================] - 0s 201us/step - loss: 16.1649 - val_loss: 190.2457\n",
      "Epoch 180/1000\n",
      "1500/1500 [==============================] - 0s 198us/step - loss: 12.1935 - val_loss: 209.3894\n",
      "Epoch 181/1000\n",
      "1500/1500 [==============================] - 0s 198us/step - loss: 14.7964 - val_loss: 190.1943\n",
      "Epoch 182/1000\n",
      "1500/1500 [==============================] - 0s 201us/step - loss: 12.6036 - val_loss: 196.8912\n",
      "Epoch 183/1000\n",
      "1500/1500 [==============================] - 0s 197us/step - loss: 12.0243 - val_loss: 192.3560\n",
      "Epoch 184/1000\n",
      "1500/1500 [==============================] - 0s 198us/step - loss: 12.0684 - val_loss: 201.7403\n",
      "Epoch 185/1000\n",
      "1500/1500 [==============================] - 0s 200us/step - loss: 10.5075 - val_loss: 197.1863\n",
      "Epoch 186/1000\n",
      "1500/1500 [==============================] - 0s 204us/step - loss: 12.8577 - val_loss: 192.7386\n",
      "Epoch 187/1000\n",
      "1500/1500 [==============================] - 0s 200us/step - loss: 9.1270 - val_loss: 194.4522\n",
      "Epoch 188/1000\n",
      "1500/1500 [==============================] - 0s 203us/step - loss: 10.1334 - val_loss: 193.2526\n",
      "Epoch 189/1000\n",
      "1500/1500 [==============================] - 0s 199us/step - loss: 9.8238 - val_loss: 196.0003\n",
      "Epoch 190/1000\n",
      "1500/1500 [==============================] - 0s 199us/step - loss: 11.3662 - val_loss: 195.3832\n",
      "Epoch 191/1000\n",
      "1500/1500 [==============================] - 0s 201us/step - loss: 15.3789 - val_loss: 194.1514\n",
      "Epoch 192/1000\n",
      "1500/1500 [==============================] - 0s 202us/step - loss: 12.9275 - val_loss: 195.6404\n",
      "Epoch 193/1000\n",
      "1500/1500 [==============================] - 0s 200us/step - loss: 8.7189 - val_loss: 196.3581\n",
      "Epoch 194/1000\n",
      "1500/1500 [==============================] - 0s 197us/step - loss: 7.6230 - val_loss: 203.9167\n",
      "Epoch 195/1000\n",
      "1500/1500 [==============================] - 0s 198us/step - loss: 8.7903 - val_loss: 195.6902\n",
      "Epoch 196/1000\n",
      "1500/1500 [==============================] - 0s 202us/step - loss: 6.8374 - val_loss: 198.8419\n",
      "Epoch 197/1000\n",
      "1500/1500 [==============================] - 0s 202us/step - loss: 6.9625 - val_loss: 200.1068\n",
      "Epoch 198/1000\n",
      "1500/1500 [==============================] - 0s 201us/step - loss: 7.3026 - val_loss: 198.7551\n",
      "Epoch 199/1000\n",
      "1500/1500 [==============================] - 0s 198us/step - loss: 6.5947 - val_loss: 198.7403\n",
      "Epoch 200/1000\n",
      "1500/1500 [==============================] - 0s 203us/step - loss: 7.4942 - val_loss: 197.7483\n",
      "Epoch 201/1000\n",
      "1500/1500 [==============================] - 0s 197us/step - loss: 9.6460 - val_loss: 196.9538\n",
      "Epoch 202/1000\n",
      "1500/1500 [==============================] - 0s 201us/step - loss: 6.8379 - val_loss: 200.4435\n",
      "Epoch 203/1000\n",
      "1500/1500 [==============================] - 0s 200us/step - loss: 6.7685 - val_loss: 197.2972\n",
      "Epoch 204/1000\n",
      "1500/1500 [==============================] - 0s 199us/step - loss: 4.9055 - val_loss: 198.1452\n",
      "Epoch 205/1000\n",
      "1500/1500 [==============================] - 0s 199us/step - loss: 4.7344 - val_loss: 198.7235\n",
      "Epoch 206/1000\n",
      "1500/1500 [==============================] - 0s 200us/step - loss: 5.0902 - val_loss: 206.0720\n",
      "Epoch 207/1000\n",
      "1500/1500 [==============================] - 0s 201us/step - loss: 5.4489 - val_loss: 200.0320\n",
      "Epoch 208/1000\n",
      "1500/1500 [==============================] - 0s 203us/step - loss: 4.9218 - val_loss: 200.8559\n",
      "Epoch 209/1000\n",
      "1500/1500 [==============================] - 0s 200us/step - loss: 6.9811 - val_loss: 199.5490\n",
      "Epoch 210/1000\n",
      "1500/1500 [==============================] - 0s 199us/step - loss: 3.5686 - val_loss: 199.6517\n",
      "Epoch 211/1000\n",
      "1500/1500 [==============================] - 0s 199us/step - loss: 3.7864 - val_loss: 200.3416\n",
      "Epoch 212/1000\n",
      "1500/1500 [==============================] - 0s 199us/step - loss: 4.5910 - val_loss: 202.6481\n",
      "Epoch 213/1000\n",
      "1500/1500 [==============================] - 0s 203us/step - loss: 3.1726 - val_loss: 203.0278\n",
      "Epoch 214/1000\n",
      "1500/1500 [==============================] - 0s 201us/step - loss: 3.6215 - val_loss: 199.5714\n",
      "Epoch 215/1000\n",
      "1500/1500 [==============================] - 0s 200us/step - loss: 3.4650 - val_loss: 199.4993\n",
      "Epoch 216/1000\n",
      "1500/1500 [==============================] - 0s 204us/step - loss: 3.2780 - val_loss: 201.7588\n",
      "Epoch 217/1000\n",
      "1500/1500 [==============================] - 0s 199us/step - loss: 3.3433 - val_loss: 201.1244\n",
      "Epoch 218/1000\n",
      "1500/1500 [==============================] - 0s 199us/step - loss: 3.2864 - val_loss: 200.8290\n",
      "Epoch 219/1000\n",
      "1500/1500 [==============================] - 0s 199us/step - loss: 2.7312 - val_loss: 202.4327\n",
      "Epoch 220/1000\n",
      "1500/1500 [==============================] - 0s 207us/step - loss: 3.8771 - val_loss: 202.2468\n",
      "Epoch 221/1000\n",
      "1500/1500 [==============================] - 0s 202us/step - loss: 2.8446 - val_loss: 204.8964\n",
      "Epoch 222/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1500/1500 [==============================] - 0s 202us/step - loss: 2.2872 - val_loss: 201.7752\n",
      "Epoch 223/1000\n",
      "1500/1500 [==============================] - 0s 198us/step - loss: 2.6572 - val_loss: 203.6658\n",
      "Epoch 224/1000\n",
      "1500/1500 [==============================] - 0s 199us/step - loss: 2.2413 - val_loss: 200.9259\n",
      "Epoch 225/1000\n",
      "1500/1500 [==============================] - 0s 199us/step - loss: 1.8193 - val_loss: 201.6672\n",
      "Epoch 226/1000\n",
      "1500/1500 [==============================] - 0s 204us/step - loss: 2.2354 - val_loss: 201.1528\n",
      "Epoch 227/1000\n",
      "1500/1500 [==============================] - 0s 202us/step - loss: 1.6080 - val_loss: 201.5585\n",
      "Epoch 228/1000\n",
      "1500/1500 [==============================] - 0s 199us/step - loss: 1.6543 - val_loss: 205.1796\n",
      "Epoch 229/1000\n",
      "1500/1500 [==============================] - 0s 201us/step - loss: 2.4352 - val_loss: 201.7945\n",
      "Epoch 230/1000\n",
      "1500/1500 [==============================] - 0s 202us/step - loss: 1.9239 - val_loss: 202.9126\n",
      "Epoch 231/1000\n",
      "1500/1500 [==============================] - 0s 204us/step - loss: 1.4095 - val_loss: 202.7571\n",
      "Epoch 232/1000\n",
      "1500/1500 [==============================] - 0s 195us/step - loss: 1.1953 - val_loss: 202.9814\n",
      "Epoch 233/1000\n",
      "1500/1500 [==============================] - 0s 200us/step - loss: 1.1380 - val_loss: 203.6991\n",
      "Epoch 234/1000\n",
      "1500/1500 [==============================] - 0s 201us/step - loss: 1.4063 - val_loss: 205.9395\n",
      "Epoch 235/1000\n",
      "1500/1500 [==============================] - 0s 208us/step - loss: 2.0705 - val_loss: 204.4541\n",
      "Epoch 236/1000\n",
      "1500/1500 [==============================] - 0s 200us/step - loss: 1.3514 - val_loss: 206.4388\n",
      "Epoch 237/1000\n",
      "1500/1500 [==============================] - 0s 205us/step - loss: 1.3418 - val_loss: 203.7088\n",
      "Epoch 238/1000\n",
      "1500/1500 [==============================] - 0s 203us/step - loss: 1.1804 - val_loss: 207.2496\n",
      "Epoch 239/1000\n",
      "1500/1500 [==============================] - 0s 199us/step - loss: 1.5054 - val_loss: 203.1891\n",
      "Epoch 240/1000\n",
      "1500/1500 [==============================] - 0s 204us/step - loss: 1.0866 - val_loss: 204.3051\n",
      "Epoch 241/1000\n",
      "1500/1500 [==============================] - 0s 201us/step - loss: 0.9594 - val_loss: 202.8432\n",
      "Epoch 242/1000\n",
      "1500/1500 [==============================] - 0s 198us/step - loss: 0.7370 - val_loss: 204.4282\n",
      "Epoch 243/1000\n",
      "1500/1500 [==============================] - 0s 202us/step - loss: 1.0778 - val_loss: 204.5504\n",
      "Epoch 244/1000\n",
      "1500/1500 [==============================] - 0s 200us/step - loss: 0.8699 - val_loss: 203.6752\n",
      "Epoch 245/1000\n",
      "1500/1500 [==============================] - 0s 201us/step - loss: 1.4382 - val_loss: 202.5460\n",
      "Epoch 246/1000\n",
      "1500/1500 [==============================] - 0s 200us/step - loss: 1.0043 - val_loss: 202.6705\n",
      "Epoch 247/1000\n",
      "1500/1500 [==============================] - 0s 205us/step - loss: 0.8638 - val_loss: 204.4330\n",
      "Epoch 248/1000\n",
      "1500/1500 [==============================] - 0s 202us/step - loss: 1.1906 - val_loss: 203.2328\n",
      "Epoch 249/1000\n",
      "1500/1500 [==============================] - 0s 200us/step - loss: 0.8641 - val_loss: 206.0025\n",
      "Epoch 250/1000\n",
      "1500/1500 [==============================] - 0s 201us/step - loss: 0.9942 - val_loss: 203.2303\n",
      "Epoch 251/1000\n",
      "1500/1500 [==============================] - 0s 199us/step - loss: 0.8152 - val_loss: 204.3424\n",
      "Epoch 252/1000\n",
      "1500/1500 [==============================] - 0s 202us/step - loss: 0.8811 - val_loss: 205.2213\n",
      "Epoch 253/1000\n",
      "1500/1500 [==============================] - 0s 206us/step - loss: 1.1076 - val_loss: 204.6197\n",
      "Epoch 254/1000\n",
      "1500/1500 [==============================] - 0s 198us/step - loss: 1.0261 - val_loss: 203.0346\n",
      "Epoch 255/1000\n",
      "1500/1500 [==============================] - 0s 200us/step - loss: 1.0755 - val_loss: 202.4594\n",
      "Epoch 256/1000\n",
      "1500/1500 [==============================] - 0s 204us/step - loss: 0.6906 - val_loss: 205.0027\n",
      "Epoch 257/1000\n",
      "1500/1500 [==============================] - 0s 206us/step - loss: 0.6254 - val_loss: 211.5730\n",
      "Epoch 258/1000\n",
      "1500/1500 [==============================] - 0s 207us/step - loss: 3.5289 - val_loss: 204.0748\n",
      "Epoch 259/1000\n",
      "1500/1500 [==============================] - 0s 199us/step - loss: 2.7177 - val_loss: 203.5977\n",
      "Epoch 260/1000\n",
      "1500/1500 [==============================] - 0s 203us/step - loss: 1.7373 - val_loss: 205.2003\n",
      "Epoch 261/1000\n",
      "1500/1500 [==============================] - 0s 202us/step - loss: 3.2742 - val_loss: 204.3163\n",
      "Epoch 262/1000\n",
      "1500/1500 [==============================] - 0s 202us/step - loss: 1.3913 - val_loss: 202.7651\n",
      "Epoch 263/1000\n",
      "1500/1500 [==============================] - 0s 201us/step - loss: 1.9459 - val_loss: 203.9785\n",
      "Epoch 264/1000\n",
      "1500/1500 [==============================] - 0s 200us/step - loss: 0.9157 - val_loss: 203.9836\n",
      "Epoch 265/1000\n",
      "1500/1500 [==============================] - 0s 203us/step - loss: 1.6219 - val_loss: 206.4805\n",
      "Epoch 266/1000\n",
      "1500/1500 [==============================] - 0s 204us/step - loss: 0.8090 - val_loss: 203.4056\n",
      "Epoch 267/1000\n",
      "1500/1500 [==============================] - 0s 206us/step - loss: 0.4385 - val_loss: 201.6369\n",
      "Epoch 268/1000\n",
      "1500/1500 [==============================] - 0s 203us/step - loss: 0.6651 - val_loss: 203.1246\n",
      "Epoch 269/1000\n",
      "1500/1500 [==============================] - 0s 205us/step - loss: 0.6503 - val_loss: 202.2226\n",
      "Epoch 270/1000\n",
      "1500/1500 [==============================] - 0s 205us/step - loss: 0.3686 - val_loss: 203.5357\n",
      "Epoch 271/1000\n",
      "1500/1500 [==============================] - 0s 206us/step - loss: 0.4243 - val_loss: 203.4737\n",
      "Epoch 272/1000\n",
      "1500/1500 [==============================] - 0s 198us/step - loss: 0.3899 - val_loss: 205.0341\n",
      "Epoch 273/1000\n",
      "1500/1500 [==============================] - 0s 198us/step - loss: 0.9876 - val_loss: 203.2706\n",
      "Epoch 274/1000\n",
      "1500/1500 [==============================] - 0s 206us/step - loss: 0.4795 - val_loss: 201.9090\n",
      "Epoch 275/1000\n",
      "1500/1500 [==============================] - 0s 201us/step - loss: 0.4699 - val_loss: 203.1931\n",
      "Epoch 276/1000\n",
      "1500/1500 [==============================] - 0s 203us/step - loss: 0.4414 - val_loss: 203.4723\n",
      "Epoch 277/1000\n",
      "1500/1500 [==============================] - 0s 198us/step - loss: 0.5252 - val_loss: 203.0202\n",
      "Epoch 278/1000\n",
      "1500/1500 [==============================] - 0s 203us/step - loss: 1.8128 - val_loss: 202.5318\n",
      "Epoch 279/1000\n",
      "1500/1500 [==============================] - 0s 204us/step - loss: 1.5421 - val_loss: 208.1056\n",
      "Epoch 280/1000\n",
      "1500/1500 [==============================] - 0s 199us/step - loss: 0.7823 - val_loss: 203.3444\n",
      "Epoch 281/1000\n",
      "1500/1500 [==============================] - 0s 198us/step - loss: 0.4562 - val_loss: 202.1603\n",
      "Epoch 282/1000\n",
      "1500/1500 [==============================] - 0s 204us/step - loss: 0.4478 - val_loss: 202.3203\n",
      "Epoch 283/1000\n",
      "1500/1500 [==============================] - 0s 200us/step - loss: 0.8066 - val_loss: 206.3357\n",
      "Epoch 284/1000\n",
      "1500/1500 [==============================] - 0s 202us/step - loss: 1.2274 - val_loss: 202.5365\n",
      "Epoch 285/1000\n",
      "1500/1500 [==============================] - 0s 200us/step - loss: 1.2476 - val_loss: 205.6552\n",
      "Epoch 286/1000\n",
      "1500/1500 [==============================] - 0s 201us/step - loss: 1.3155 - val_loss: 204.2183\n",
      "Epoch 287/1000\n",
      "1500/1500 [==============================] - 0s 203us/step - loss: 2.0508 - val_loss: 203.6035\n",
      "Epoch 288/1000\n",
      "1500/1500 [==============================] - 0s 199us/step - loss: 2.0535 - val_loss: 202.0421\n",
      "Epoch 289/1000\n",
      "1500/1500 [==============================] - 0s 198us/step - loss: 1.4517 - val_loss: 202.9539\n",
      "Epoch 290/1000\n",
      "1500/1500 [==============================] - 0s 206us/step - loss: 0.8772 - val_loss: 202.9880\n",
      "Epoch 291/1000\n",
      "1500/1500 [==============================] - 0s 203us/step - loss: 0.4393 - val_loss: 205.6575\n",
      "Epoch 292/1000\n",
      "1500/1500 [==============================] - 0s 198us/step - loss: 0.4465 - val_loss: 204.6778\n",
      "Epoch 293/1000\n",
      "1500/1500 [==============================] - 0s 200us/step - loss: 1.2078 - val_loss: 201.3919\n",
      "Epoch 294/1000\n",
      "1500/1500 [==============================] - 0s 196us/step - loss: 0.4718 - val_loss: 203.7301\n",
      "Epoch 295/1000\n",
      "1500/1500 [==============================] - 0s 201us/step - loss: 0.3288 - val_loss: 201.6419\n",
      "Epoch 296/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1500/1500 [==============================] - 0s 200us/step - loss: 0.3666 - val_loss: 202.2304\n",
      "Epoch 297/1000\n",
      "1500/1500 [==============================] - 0s 198us/step - loss: 0.3976 - val_loss: 201.7291\n",
      "Epoch 298/1000\n",
      "1500/1500 [==============================] - 0s 199us/step - loss: 0.2414 - val_loss: 200.8108\n",
      "Epoch 299/1000\n",
      "1500/1500 [==============================] - 0s 200us/step - loss: 0.2089 - val_loss: 201.7501\n",
      "Epoch 300/1000\n",
      "1500/1500 [==============================] - 0s 197us/step - loss: 2.2747 - val_loss: 208.4951\n",
      "Epoch 301/1000\n",
      "1500/1500 [==============================] - 0s 198us/step - loss: 2.1400 - val_loss: 200.9949\n",
      "Epoch 302/1000\n",
      "1500/1500 [==============================] - 0s 205us/step - loss: 0.9016 - val_loss: 200.6697\n",
      "Epoch 303/1000\n",
      "1500/1500 [==============================] - 0s 199us/step - loss: 0.6375 - val_loss: 203.4609\n",
      "Epoch 304/1000\n",
      "1500/1500 [==============================] - 0s 202us/step - loss: 1.3252 - val_loss: 202.8205\n",
      "Epoch 305/1000\n",
      "1500/1500 [==============================] - 0s 205us/step - loss: 1.0417 - val_loss: 202.7905\n",
      "Epoch 306/1000\n",
      "1500/1500 [==============================] - 0s 198us/step - loss: 0.5025 - val_loss: 202.4270\n",
      "Epoch 307/1000\n",
      "1500/1500 [==============================] - 0s 200us/step - loss: 0.4028 - val_loss: 205.7859\n",
      "Epoch 308/1000\n",
      "1500/1500 [==============================] - 0s 199us/step - loss: 1.1380 - val_loss: 203.5012\n",
      "Epoch 309/1000\n",
      "1500/1500 [==============================] - 0s 199us/step - loss: 2.2699 - val_loss: 200.9078\n",
      "Epoch 310/1000\n",
      "1500/1500 [==============================] - 0s 201us/step - loss: 1.4029 - val_loss: 199.5882\n",
      "Epoch 311/1000\n",
      "1500/1500 [==============================] - 0s 204us/step - loss: 2.3840 - val_loss: 201.7964\n",
      "Epoch 312/1000\n",
      "1500/1500 [==============================] - 0s 201us/step - loss: 0.8191 - val_loss: 201.5318\n",
      "Epoch 313/1000\n",
      "1500/1500 [==============================] - 0s 195us/step - loss: 0.7880 - val_loss: 202.0967\n",
      "Epoch 314/1000\n",
      "1500/1500 [==============================] - 0s 202us/step - loss: 0.6331 - val_loss: 201.0386\n",
      "Epoch 315/1000\n",
      "1500/1500 [==============================] - 0s 205us/step - loss: 0.5894 - val_loss: 203.4557\n",
      "Epoch 316/1000\n",
      "1500/1500 [==============================] - 0s 202us/step - loss: 0.4959 - val_loss: 201.6023\n",
      "Epoch 317/1000\n",
      "1500/1500 [==============================] - 0s 200us/step - loss: 0.5924 - val_loss: 201.1132\n",
      "Epoch 318/1000\n",
      "1500/1500 [==============================] - 0s 199us/step - loss: 0.4315 - val_loss: 201.0826\n",
      "Epoch 319/1000\n",
      "1500/1500 [==============================] - 0s 196us/step - loss: 0.3632 - val_loss: 201.2803\n",
      "Epoch 320/1000\n",
      "1500/1500 [==============================] - 0s 201us/step - loss: 0.4452 - val_loss: 201.5284\n",
      "Epoch 321/1000\n",
      "1500/1500 [==============================] - 0s 200us/step - loss: 1.0287 - val_loss: 201.0044\n",
      "Epoch 322/1000\n",
      "1500/1500 [==============================] - 0s 199us/step - loss: 0.7804 - val_loss: 200.2782\n",
      "Epoch 323/1000\n",
      "1500/1500 [==============================] - 0s 199us/step - loss: 0.5538 - val_loss: 201.4085\n",
      "Epoch 324/1000\n",
      "1500/1500 [==============================] - 0s 197us/step - loss: 1.0371 - val_loss: 201.4257\n",
      "Epoch 325/1000\n",
      "1500/1500 [==============================] - 0s 199us/step - loss: 0.8852 - val_loss: 201.2963\n",
      "Epoch 326/1000\n",
      "1500/1500 [==============================] - 0s 201us/step - loss: 1.7135 - val_loss: 205.4639\n",
      "Epoch 327/1000\n",
      "1500/1500 [==============================] - 0s 198us/step - loss: 0.9916 - val_loss: 200.2320\n",
      "Epoch 328/1000\n",
      "1500/1500 [==============================] - 0s 203us/step - loss: 1.5969 - val_loss: 201.1659\n",
      "Epoch 329/1000\n",
      "1500/1500 [==============================] - 0s 199us/step - loss: 0.9228 - val_loss: 197.7432\n",
      "Epoch 330/1000\n",
      "1500/1500 [==============================] - 0s 198us/step - loss: 1.4356 - val_loss: 202.4686\n",
      "Epoch 331/1000\n",
      "1500/1500 [==============================] - 0s 200us/step - loss: 0.8335 - val_loss: 198.8996\n",
      "Epoch 332/1000\n",
      "1500/1500 [==============================] - 0s 203us/step - loss: 0.6441 - val_loss: 201.4190\n",
      "Epoch 333/1000\n",
      "1500/1500 [==============================] - 0s 202us/step - loss: 0.4907 - val_loss: 199.7123\n",
      "Epoch 334/1000\n",
      "1500/1500 [==============================] - 0s 198us/step - loss: 0.2892 - val_loss: 200.6272\n",
      "Epoch 335/1000\n",
      "1500/1500 [==============================] - 0s 198us/step - loss: 0.7934 - val_loss: 198.8190\n",
      "Epoch 336/1000\n",
      "1500/1500 [==============================] - 0s 201us/step - loss: 1.2659 - val_loss: 199.2663\n",
      "Epoch 337/1000\n",
      "1500/1500 [==============================] - 0s 206us/step - loss: 0.5640 - val_loss: 199.4269\n",
      "Epoch 338/1000\n",
      "1500/1500 [==============================] - 0s 202us/step - loss: 1.0332 - val_loss: 201.1187\n",
      "Epoch 339/1000\n",
      "1500/1500 [==============================] - 0s 201us/step - loss: 2.2115 - val_loss: 199.8508\n",
      "Epoch 340/1000\n",
      "1500/1500 [==============================] - 0s 201us/step - loss: 1.5243 - val_loss: 200.1833\n",
      "Epoch 341/1000\n",
      "1500/1500 [==============================] - 0s 196us/step - loss: 1.5521 - val_loss: 199.2253\n",
      "Epoch 342/1000\n",
      "1500/1500 [==============================] - 0s 200us/step - loss: 0.8093 - val_loss: 200.1721\n",
      "Epoch 343/1000\n",
      "1500/1500 [==============================] - 0s 203us/step - loss: 1.1853 - val_loss: 202.6751\n",
      "Epoch 344/1000\n",
      "1500/1500 [==============================] - 0s 194us/step - loss: 0.9038 - val_loss: 198.0100\n",
      "Epoch 345/1000\n",
      "1500/1500 [==============================] - 0s 202us/step - loss: 0.3467 - val_loss: 199.3338\n",
      "Epoch 346/1000\n",
      "1500/1500 [==============================] - 0s 200us/step - loss: 0.2475 - val_loss: 199.6809\n",
      "Epoch 347/1000\n",
      "1500/1500 [==============================] - 0s 199us/step - loss: 0.4061 - val_loss: 198.7073\n",
      "Epoch 348/1000\n",
      "1500/1500 [==============================] - 0s 198us/step - loss: 0.3437 - val_loss: 200.3390\n",
      "Epoch 349/1000\n",
      "1500/1500 [==============================] - 0s 199us/step - loss: 0.1858 - val_loss: 198.9514\n",
      "Epoch 350/1000\n",
      "1500/1500 [==============================] - 0s 199us/step - loss: 0.2359 - val_loss: 199.4045\n",
      "Epoch 351/1000\n",
      "1500/1500 [==============================] - 0s 200us/step - loss: 0.1864 - val_loss: 200.4718\n",
      "Epoch 352/1000\n",
      "1500/1500 [==============================] - 0s 202us/step - loss: 0.1996 - val_loss: 200.0248\n",
      "Epoch 353/1000\n",
      "1500/1500 [==============================] - 0s 197us/step - loss: 0.3969 - val_loss: 198.6082\n",
      "Epoch 354/1000\n",
      "1500/1500 [==============================] - 0s 198us/step - loss: 0.3527 - val_loss: 200.4361\n",
      "Epoch 355/1000\n",
      "1500/1500 [==============================] - 0s 202us/step - loss: 0.2378 - val_loss: 200.4787\n",
      "Epoch 356/1000\n",
      "1500/1500 [==============================] - 0s 199us/step - loss: 0.3523 - val_loss: 200.2653\n",
      "Epoch 357/1000\n",
      "1500/1500 [==============================] - 0s 199us/step - loss: 1.4081 - val_loss: 199.9163\n",
      "Epoch 358/1000\n",
      "1500/1500 [==============================] - 0s 197us/step - loss: 4.5160 - val_loss: 199.0510\n",
      "Epoch 359/1000\n",
      "1500/1500 [==============================] - 0s 198us/step - loss: 8.0856 - val_loss: 206.4856\n",
      "Epoch 360/1000\n",
      "1500/1500 [==============================] - 0s 202us/step - loss: 5.7902 - val_loss: 199.7198\n",
      "Epoch 361/1000\n",
      "1500/1500 [==============================] - 0s 200us/step - loss: 2.1420 - val_loss: 201.4545\n",
      "Epoch 362/1000\n",
      "1500/1500 [==============================] - 0s 202us/step - loss: 0.9381 - val_loss: 200.8553\n",
      "Epoch 363/1000\n",
      "1500/1500 [==============================] - 0s 202us/step - loss: 0.3982 - val_loss: 199.3193\n",
      "Epoch 364/1000\n",
      "1500/1500 [==============================] - 0s 200us/step - loss: 0.3885 - val_loss: 199.8255\n",
      "Epoch 365/1000\n",
      "1500/1500 [==============================] - 0s 201us/step - loss: 0.3811 - val_loss: 198.2491\n",
      "Epoch 366/1000\n",
      "1500/1500 [==============================] - 0s 202us/step - loss: 0.2443 - val_loss: 199.0089\n",
      "Epoch 367/1000\n",
      "1500/1500 [==============================] - 0s 195us/step - loss: 0.2494 - val_loss: 198.9081\n",
      "Epoch 368/1000\n",
      "1500/1500 [==============================] - 0s 202us/step - loss: 0.2051 - val_loss: 198.6955\n",
      "Epoch 369/1000\n",
      "1500/1500 [==============================] - 0s 203us/step - loss: 0.1618 - val_loss: 199.1168\n",
      "Epoch 370/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1500/1500 [==============================] - 0s 199us/step - loss: 0.2715 - val_loss: 198.6764\n",
      "Epoch 371/1000\n",
      "1500/1500 [==============================] - 0s 201us/step - loss: 0.2598 - val_loss: 199.9688\n",
      "Epoch 372/1000\n",
      "1500/1500 [==============================] - 0s 202us/step - loss: 0.1829 - val_loss: 200.5155\n",
      "Epoch 373/1000\n",
      "1500/1500 [==============================] - 0s 202us/step - loss: 0.2177 - val_loss: 198.8658\n",
      "Epoch 374/1000\n",
      "1500/1500 [==============================] - 0s 199us/step - loss: 0.1850 - val_loss: 199.2040\n",
      "Epoch 375/1000\n",
      "1500/1500 [==============================] - 0s 200us/step - loss: 0.1572 - val_loss: 199.9282\n",
      "Epoch 376/1000\n",
      "1500/1500 [==============================] - 0s 201us/step - loss: 0.1219 - val_loss: 199.4878\n",
      "Epoch 377/1000\n",
      "1500/1500 [==============================] - 0s 202us/step - loss: 0.1416 - val_loss: 198.2128\n",
      "Epoch 378/1000\n",
      "1500/1500 [==============================] - 0s 203us/step - loss: 0.2741 - val_loss: 198.2120\n",
      "Epoch 379/1000\n",
      "1500/1500 [==============================] - 0s 202us/step - loss: 0.5455 - val_loss: 198.9776\n",
      "Epoch 380/1000\n",
      "1500/1500 [==============================] - 0s 204us/step - loss: 0.4474 - val_loss: 198.5408\n",
      "Epoch 381/1000\n",
      "1500/1500 [==============================] - 0s 201us/step - loss: 0.3903 - val_loss: 200.6803\n",
      "Epoch 382/1000\n",
      "1500/1500 [==============================] - 0s 197us/step - loss: 0.7995 - val_loss: 197.7505\n",
      "Epoch 383/1000\n",
      "1500/1500 [==============================] - 0s 201us/step - loss: 3.4021 - val_loss: 195.5627\n",
      "Epoch 384/1000\n",
      "1500/1500 [==============================] - 0s 205us/step - loss: 3.8756 - val_loss: 201.6479\n",
      "Epoch 385/1000\n",
      "1500/1500 [==============================] - 0s 197us/step - loss: 1.7117 - val_loss: 200.6476\n",
      "Epoch 386/1000\n",
      "1500/1500 [==============================] - 0s 199us/step - loss: 1.1155 - val_loss: 203.8681\n",
      "Epoch 387/1000\n",
      "1500/1500 [==============================] - 0s 200us/step - loss: 1.1387 - val_loss: 198.4882\n",
      "Epoch 388/1000\n",
      "1500/1500 [==============================] - 0s 202us/step - loss: 0.7496 - val_loss: 197.0911\n",
      "Epoch 389/1000\n",
      "1500/1500 [==============================] - 0s 200us/step - loss: 0.3035 - val_loss: 198.1335\n",
      "Epoch 390/1000\n",
      "1500/1500 [==============================] - 0s 202us/step - loss: 0.3064 - val_loss: 198.0682\n",
      "Epoch 391/1000\n",
      "1500/1500 [==============================] - 0s 201us/step - loss: 0.2180 - val_loss: 197.8999\n",
      "Epoch 392/1000\n",
      "1500/1500 [==============================] - 0s 202us/step - loss: 0.1743 - val_loss: 197.3202\n",
      "Epoch 393/1000\n",
      "1500/1500 [==============================] - 0s 199us/step - loss: 0.3132 - val_loss: 197.7452\n",
      "Epoch 394/1000\n",
      "1500/1500 [==============================] - 0s 199us/step - loss: 1.6209 - val_loss: 196.4320\n",
      "Epoch 395/1000\n",
      "1500/1500 [==============================] - 0s 201us/step - loss: 0.8371 - val_loss: 198.5853\n",
      "Epoch 396/1000\n",
      "1500/1500 [==============================] - 0s 202us/step - loss: 0.9352 - val_loss: 198.3307\n",
      "Epoch 397/1000\n",
      "1500/1500 [==============================] - 0s 204us/step - loss: 2.7024 - val_loss: 196.0836\n",
      "Epoch 398/1000\n",
      "1500/1500 [==============================] - 0s 200us/step - loss: 5.7151 - val_loss: 205.3919\n",
      "Epoch 399/1000\n",
      "1500/1500 [==============================] - 0s 204us/step - loss: 2.1437 - val_loss: 196.9686\n",
      "Epoch 400/1000\n",
      "1500/1500 [==============================] - 0s 206us/step - loss: 1.0765 - val_loss: 197.4629\n",
      "Epoch 401/1000\n",
      "1500/1500 [==============================] - 0s 205us/step - loss: 0.7501 - val_loss: 196.3214\n",
      "Epoch 402/1000\n",
      "1500/1500 [==============================] - 0s 198us/step - loss: 0.6583 - val_loss: 197.7229\n",
      "Epoch 403/1000\n",
      "1500/1500 [==============================] - 0s 204us/step - loss: 0.3001 - val_loss: 196.8515\n",
      "Epoch 404/1000\n",
      "1500/1500 [==============================] - 0s 201us/step - loss: 0.2014 - val_loss: 197.1335\n",
      "Epoch 405/1000\n",
      "1500/1500 [==============================] - 0s 201us/step - loss: 0.2735 - val_loss: 196.5932\n",
      "Epoch 406/1000\n",
      "1500/1500 [==============================] - 0s 200us/step - loss: 0.2688 - val_loss: 197.4867\n",
      "Epoch 407/1000\n",
      "1500/1500 [==============================] - 0s 203us/step - loss: 0.5040 - val_loss: 197.4921\n",
      "Epoch 408/1000\n",
      "1500/1500 [==============================] - 0s 202us/step - loss: 0.9018 - val_loss: 200.4578\n",
      "Epoch 409/1000\n",
      "1500/1500 [==============================] - 0s 202us/step - loss: 1.6693 - val_loss: 198.2400\n",
      "Epoch 410/1000\n",
      "1500/1500 [==============================] - 0s 203us/step - loss: 0.8906 - val_loss: 195.8619\n",
      "Epoch 411/1000\n",
      "1500/1500 [==============================] - 0s 199us/step - loss: 0.4035 - val_loss: 197.7081\n",
      "Epoch 412/1000\n",
      "1500/1500 [==============================] - 0s 201us/step - loss: 0.8095 - val_loss: 196.7303\n",
      "Epoch 413/1000\n",
      "1500/1500 [==============================] - 0s 202us/step - loss: 0.4247 - val_loss: 196.9242\n",
      "Epoch 414/1000\n",
      "1500/1500 [==============================] - 0s 199us/step - loss: 0.2473 - val_loss: 197.3375\n",
      "Epoch 415/1000\n",
      "1500/1500 [==============================] - 0s 202us/step - loss: 0.2176 - val_loss: 196.7304\n",
      "Epoch 416/1000\n",
      "1500/1500 [==============================] - 0s 207us/step - loss: 0.3728 - val_loss: 197.1976\n",
      "Epoch 417/1000\n",
      "1500/1500 [==============================] - 0s 213us/step - loss: 0.5448 - val_loss: 202.5449\n",
      "Epoch 418/1000\n",
      "1500/1500 [==============================] - 0s 205us/step - loss: 0.8272 - val_loss: 199.7137\n",
      "Epoch 419/1000\n",
      "1500/1500 [==============================] - 0s 202us/step - loss: 4.2889 - val_loss: 208.1662\n",
      "Epoch 420/1000\n",
      "1500/1500 [==============================] - 0s 203us/step - loss: 6.3538 - val_loss: 197.5285\n",
      "Epoch 421/1000\n",
      "1500/1500 [==============================] - 0s 201us/step - loss: 2.1843 - val_loss: 197.1612\n",
      "Epoch 422/1000\n",
      "1500/1500 [==============================] - 0s 214us/step - loss: 0.6924 - val_loss: 198.5874\n",
      "Epoch 423/1000\n",
      "1500/1500 [==============================] - 0s 205us/step - loss: 0.6353 - val_loss: 196.6147\n",
      "Epoch 424/1000\n",
      "1500/1500 [==============================] - 0s 199us/step - loss: 0.3303 - val_loss: 197.0376\n",
      "Epoch 425/1000\n",
      "1500/1500 [==============================] - 0s 206us/step - loss: 0.3701 - val_loss: 197.0683\n",
      "Epoch 426/1000\n",
      "1500/1500 [==============================] - 0s 200us/step - loss: 0.2057 - val_loss: 196.8450\n",
      "Epoch 427/1000\n",
      "1500/1500 [==============================] - 0s 203us/step - loss: 0.2222 - val_loss: 197.3556\n",
      "Epoch 428/1000\n",
      "1500/1500 [==============================] - 0s 201us/step - loss: 0.1720 - val_loss: 197.2599\n",
      "Epoch 429/1000\n",
      "1500/1500 [==============================] - 0s 201us/step - loss: 0.3086 - val_loss: 196.6431\n",
      "Epoch 430/1000\n",
      "1500/1500 [==============================] - 0s 205us/step - loss: 0.2451 - val_loss: 197.7442\n",
      "Epoch 431/1000\n",
      "1500/1500 [==============================] - 0s 200us/step - loss: 0.3206 - val_loss: 198.0714\n",
      "Epoch 432/1000\n",
      "1500/1500 [==============================] - 0s 195us/step - loss: 0.2357 - val_loss: 196.9904\n",
      "Epoch 433/1000\n",
      "1500/1500 [==============================] - 0s 204us/step - loss: 0.1721 - val_loss: 198.0191\n",
      "Epoch 434/1000\n",
      "1500/1500 [==============================] - 0s 198us/step - loss: 0.1468 - val_loss: 197.2438\n",
      "Epoch 435/1000\n",
      "1500/1500 [==============================] - 0s 200us/step - loss: 0.1393 - val_loss: 196.7515\n",
      "Epoch 436/1000\n",
      "1500/1500 [==============================] - 0s 200us/step - loss: 0.1163 - val_loss: 197.1036\n",
      "Epoch 437/1000\n",
      "1500/1500 [==============================] - 0s 199us/step - loss: 0.1971 - val_loss: 196.4164\n",
      "Epoch 438/1000\n",
      "1500/1500 [==============================] - 0s 198us/step - loss: 0.3096 - val_loss: 196.5518\n",
      "Epoch 439/1000\n",
      "1500/1500 [==============================] - 0s 198us/step - loss: 2.0021 - val_loss: 197.9361\n",
      "Epoch 440/1000\n",
      "1500/1500 [==============================] - 0s 205us/step - loss: 0.8711 - val_loss: 196.4231\n",
      "Epoch 441/1000\n",
      "1500/1500 [==============================] - 0s 200us/step - loss: 0.3869 - val_loss: 197.5570\n",
      "Epoch 442/1000\n",
      "1500/1500 [==============================] - 0s 199us/step - loss: 0.4432 - val_loss: 199.6653\n",
      "Epoch 443/1000\n",
      "1500/1500 [==============================] - 0s 203us/step - loss: 1.5182 - val_loss: 198.8384\n",
      "Epoch 444/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1500/1500 [==============================] - 0s 203us/step - loss: 4.2529 - val_loss: 203.5573\n",
      "Epoch 445/1000\n",
      "1500/1500 [==============================] - 0s 201us/step - loss: 3.4906 - val_loss: 197.6482\n",
      "Epoch 446/1000\n",
      "1500/1500 [==============================] - 0s 196us/step - loss: 1.4908 - val_loss: 196.9185\n",
      "Epoch 447/1000\n",
      "1500/1500 [==============================] - 0s 197us/step - loss: 0.5933 - val_loss: 197.4724\n",
      "Epoch 448/1000\n",
      "1500/1500 [==============================] - 0s 200us/step - loss: 0.3377 - val_loss: 195.4991\n",
      "Epoch 449/1000\n",
      "1500/1500 [==============================] - 0s 200us/step - loss: 0.8198 - val_loss: 200.6958\n",
      "Epoch 450/1000\n",
      "1500/1500 [==============================] - 0s 203us/step - loss: 0.9115 - val_loss: 195.3624\n",
      "Epoch 451/1000\n",
      "1500/1500 [==============================] - 0s 200us/step - loss: 0.6819 - val_loss: 195.3093\n",
      "Epoch 452/1000\n",
      "1500/1500 [==============================] - 0s 208us/step - loss: 0.3306 - val_loss: 197.6647\n",
      "Epoch 453/1000\n",
      "1500/1500 [==============================] - 0s 201us/step - loss: 1.5168 - val_loss: 195.4567\n",
      "Epoch 454/1000\n",
      "1500/1500 [==============================] - 0s 199us/step - loss: 0.8123 - val_loss: 196.9016\n",
      "Epoch 455/1000\n",
      "1500/1500 [==============================] - 0s 200us/step - loss: 0.5607 - val_loss: 195.1640\n",
      "Epoch 456/1000\n",
      "1500/1500 [==============================] - 0s 203us/step - loss: 0.3127 - val_loss: 196.7415\n",
      "Epoch 457/1000\n",
      "1500/1500 [==============================] - 0s 206us/step - loss: 0.2138 - val_loss: 197.5700\n",
      "Epoch 458/1000\n",
      "1500/1500 [==============================] - 0s 200us/step - loss: 1.7422 - val_loss: 196.2415\n",
      "Epoch 459/1000\n",
      "1500/1500 [==============================] - 0s 200us/step - loss: 1.1979 - val_loss: 197.4554\n",
      "Epoch 460/1000\n",
      "1500/1500 [==============================] - 0s 203us/step - loss: 0.9781 - val_loss: 196.0858\n",
      "Epoch 461/1000\n",
      "1500/1500 [==============================] - 0s 203us/step - loss: 1.1903 - val_loss: 197.7971\n",
      "Epoch 462/1000\n",
      "1500/1500 [==============================] - 0s 199us/step - loss: 0.5829 - val_loss: 197.3592\n",
      "Epoch 463/1000\n",
      "1500/1500 [==============================] - 0s 198us/step - loss: 0.5596 - val_loss: 197.8974\n",
      "Epoch 464/1000\n",
      "1500/1500 [==============================] - 0s 201us/step - loss: 0.2885 - val_loss: 195.2718\n",
      "Epoch 465/1000\n",
      "1500/1500 [==============================] - 0s 200us/step - loss: 0.1796 - val_loss: 195.9851\n",
      "Epoch 466/1000\n",
      "1500/1500 [==============================] - 0s 202us/step - loss: 0.2880 - val_loss: 199.1350\n",
      "Epoch 467/1000\n",
      "1500/1500 [==============================] - 0s 201us/step - loss: 0.4948 - val_loss: 196.3788\n",
      "Epoch 468/1000\n",
      "1500/1500 [==============================] - 0s 203us/step - loss: 0.4644 - val_loss: 199.2407\n",
      "Epoch 469/1000\n",
      "1500/1500 [==============================] - 0s 200us/step - loss: 1.5558 - val_loss: 199.1782\n",
      "Epoch 470/1000\n",
      "1500/1500 [==============================] - 0s 199us/step - loss: 2.3663 - val_loss: 196.7734\n",
      "Epoch 471/1000\n",
      "1500/1500 [==============================] - 0s 200us/step - loss: 1.4078 - val_loss: 197.5500\n",
      "Epoch 472/1000\n",
      "1500/1500 [==============================] - 0s 199us/step - loss: 0.5582 - val_loss: 195.4303\n",
      "Epoch 473/1000\n",
      "1500/1500 [==============================] - 0s 205us/step - loss: 0.5301 - val_loss: 195.8306\n",
      "Epoch 474/1000\n",
      "1500/1500 [==============================] - 0s 201us/step - loss: 0.3556 - val_loss: 195.7143\n",
      "Epoch 475/1000\n",
      "1500/1500 [==============================] - 0s 203us/step - loss: 0.2228 - val_loss: 197.2962\n",
      "Epoch 476/1000\n",
      "1500/1500 [==============================] - 0s 198us/step - loss: 0.2305 - val_loss: 196.3929\n",
      "Epoch 477/1000\n",
      "1500/1500 [==============================] - 0s 200us/step - loss: 0.4535 - val_loss: 195.5702\n",
      "Epoch 478/1000\n",
      "1500/1500 [==============================] - 0s 203us/step - loss: 0.9996 - val_loss: 195.9148\n",
      "Epoch 479/1000\n",
      "1500/1500 [==============================] - 0s 199us/step - loss: 0.4444 - val_loss: 195.3189\n",
      "Epoch 480/1000\n",
      "1500/1500 [==============================] - 0s 202us/step - loss: 0.5689 - val_loss: 195.3964\n",
      "Epoch 481/1000\n",
      "1500/1500 [==============================] - 0s 204us/step - loss: 0.5582 - val_loss: 195.9207\n",
      "Epoch 482/1000\n",
      "1500/1500 [==============================] - 0s 198us/step - loss: 0.4933 - val_loss: 196.4933\n",
      "Epoch 483/1000\n",
      "1500/1500 [==============================] - 0s 200us/step - loss: 0.3285 - val_loss: 197.2404\n",
      "Epoch 484/1000\n",
      "1500/1500 [==============================] - 0s 200us/step - loss: 0.2717 - val_loss: 196.6110\n",
      "Epoch 485/1000\n",
      "1500/1500 [==============================] - 0s 199us/step - loss: 0.2756 - val_loss: 196.1273\n",
      "Epoch 486/1000\n",
      "1500/1500 [==============================] - 0s 205us/step - loss: 0.2366 - val_loss: 198.0748\n",
      "Epoch 487/1000\n",
      "1500/1500 [==============================] - 0s 198us/step - loss: 2.0140 - val_loss: 202.4252\n",
      "Epoch 488/1000\n",
      "1500/1500 [==============================] - 0s 201us/step - loss: 10.6032 - val_loss: 205.5042\n",
      "Epoch 489/1000\n",
      "1500/1500 [==============================] - 0s 201us/step - loss: 6.0376 - val_loss: 194.2439\n",
      "Epoch 490/1000\n",
      "1500/1500 [==============================] - 0s 208us/step - loss: 3.2571 - val_loss: 194.9081\n",
      "Epoch 491/1000\n",
      "1500/1500 [==============================] - 0s 202us/step - loss: 1.8120 - val_loss: 194.2839\n",
      "Epoch 492/1000\n",
      "1500/1500 [==============================] - 0s 199us/step - loss: 1.2993 - val_loss: 195.4765\n",
      "Epoch 493/1000\n",
      "1500/1500 [==============================] - 0s 200us/step - loss: 0.5228 - val_loss: 196.2291\n",
      "Epoch 494/1000\n",
      "1500/1500 [==============================] - 0s 202us/step - loss: 0.2598 - val_loss: 195.9931\n",
      "Epoch 495/1000\n",
      "1500/1500 [==============================] - 0s 200us/step - loss: 0.2076 - val_loss: 194.9222\n",
      "Epoch 496/1000\n",
      "1500/1500 [==============================] - 0s 200us/step - loss: 0.1672 - val_loss: 195.8923\n",
      "Epoch 497/1000\n",
      "1500/1500 [==============================] - 0s 197us/step - loss: 0.1976 - val_loss: 195.1245\n",
      "Epoch 498/1000\n",
      "1500/1500 [==============================] - 0s 202us/step - loss: 0.1156 - val_loss: 195.2154\n",
      "Epoch 499/1000\n",
      "1500/1500 [==============================] - 0s 205us/step - loss: 0.1430 - val_loss: 194.8924\n",
      "Epoch 500/1000\n",
      "1500/1500 [==============================] - 0s 201us/step - loss: 0.1126 - val_loss: 194.6011\n",
      "Epoch 501/1000\n",
      "1500/1500 [==============================] - 0s 199us/step - loss: 0.1355 - val_loss: 194.6499\n",
      "Epoch 502/1000\n",
      "1500/1500 [==============================] - 0s 205us/step - loss: 0.1249 - val_loss: 194.8976\n",
      "Epoch 503/1000\n",
      "1500/1500 [==============================] - 0s 203us/step - loss: 0.0701 - val_loss: 195.2302\n",
      "Epoch 504/1000\n",
      "1500/1500 [==============================] - 0s 199us/step - loss: 0.0540 - val_loss: 195.0316\n",
      "Epoch 505/1000\n",
      "1500/1500 [==============================] - 0s 202us/step - loss: 0.0827 - val_loss: 196.0646\n",
      "Epoch 506/1000\n",
      "1500/1500 [==============================] - 0s 199us/step - loss: 0.1804 - val_loss: 195.6800\n",
      "Epoch 507/1000\n",
      "1500/1500 [==============================] - 0s 203us/step - loss: 0.0988 - val_loss: 195.3164\n",
      "Epoch 508/1000\n",
      "1500/1500 [==============================] - 0s 203us/step - loss: 0.0647 - val_loss: 195.0768\n",
      "Epoch 509/1000\n",
      "1500/1500 [==============================] - 0s 203us/step - loss: 0.0562 - val_loss: 195.2173\n",
      "Epoch 510/1000\n",
      "1500/1500 [==============================] - 0s 200us/step - loss: 0.0901 - val_loss: 196.3404\n",
      "Epoch 511/1000\n",
      "1500/1500 [==============================] - 0s 200us/step - loss: 0.2059 - val_loss: 194.6531\n",
      "Epoch 512/1000\n",
      "1500/1500 [==============================] - 0s 206us/step - loss: 0.3433 - val_loss: 195.0924\n",
      "Epoch 513/1000\n",
      "1500/1500 [==============================] - 0s 201us/step - loss: 0.7483 - val_loss: 195.8521\n",
      "Epoch 514/1000\n",
      "1500/1500 [==============================] - 0s 200us/step - loss: 0.5061 - val_loss: 194.5697\n",
      "Epoch 515/1000\n",
      "1500/1500 [==============================] - 0s 203us/step - loss: 0.5724 - val_loss: 193.8871\n",
      "Epoch 516/1000\n",
      "1500/1500 [==============================] - 0s 204us/step - loss: 0.4233 - val_loss: 194.2155\n",
      "Epoch 517/1000\n",
      "1500/1500 [==============================] - 0s 199us/step - loss: 0.3774 - val_loss: 194.6924\n",
      "Epoch 518/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1500/1500 [==============================] - 0s 201us/step - loss: 0.3720 - val_loss: 193.5071\n",
      "Epoch 519/1000\n",
      "1500/1500 [==============================] - 0s 200us/step - loss: 0.4944 - val_loss: 195.0027\n",
      "Epoch 520/1000\n",
      "1500/1500 [==============================] - 0s 201us/step - loss: 0.4968 - val_loss: 195.5451\n",
      "Epoch 521/1000\n",
      "1500/1500 [==============================] - 0s 201us/step - loss: 0.3342 - val_loss: 196.8602\n",
      "Epoch 522/1000\n",
      "1500/1500 [==============================] - 0s 200us/step - loss: 1.1046 - val_loss: 199.9752\n",
      "Epoch 523/1000\n",
      "1500/1500 [==============================] - 0s 199us/step - loss: 5.3886 - val_loss: 193.8703\n",
      "Epoch 524/1000\n",
      "1500/1500 [==============================] - 0s 201us/step - loss: 4.2155 - val_loss: 195.4759\n",
      "Epoch 525/1000\n",
      "1500/1500 [==============================] - 0s 203us/step - loss: 2.9518 - val_loss: 192.5519\n",
      "Epoch 526/1000\n",
      "1500/1500 [==============================] - 0s 202us/step - loss: 0.8780 - val_loss: 195.7841\n",
      "Epoch 527/1000\n",
      "1500/1500 [==============================] - 0s 200us/step - loss: 0.4324 - val_loss: 194.9976\n",
      "Epoch 528/1000\n",
      "1500/1500 [==============================] - 0s 201us/step - loss: 0.5357 - val_loss: 193.8429\n",
      "Epoch 529/1000\n",
      "1500/1500 [==============================] - 0s 201us/step - loss: 0.8880 - val_loss: 194.4247\n",
      "Epoch 530/1000\n",
      "1500/1500 [==============================] - 0s 202us/step - loss: 1.2567 - val_loss: 191.9084\n",
      "Epoch 531/1000\n",
      "1500/1500 [==============================] - 0s 201us/step - loss: 0.8545 - val_loss: 193.6206\n",
      "Epoch 532/1000\n",
      "1500/1500 [==============================] - 0s 202us/step - loss: 0.5617 - val_loss: 194.4928\n",
      "Epoch 533/1000\n",
      "1500/1500 [==============================] - 0s 203us/step - loss: 0.2735 - val_loss: 194.4178\n",
      "Epoch 534/1000\n",
      "1500/1500 [==============================] - 0s 205us/step - loss: 0.6601 - val_loss: 193.1425\n",
      "Epoch 535/1000\n",
      "1500/1500 [==============================] - 0s 201us/step - loss: 0.5504 - val_loss: 193.3569\n",
      "Epoch 536/1000\n",
      "1500/1500 [==============================] - 0s 203us/step - loss: 1.1826 - val_loss: 197.9833\n",
      "Epoch 537/1000\n",
      "1500/1500 [==============================] - 0s 202us/step - loss: 2.2302 - val_loss: 197.7131\n",
      "Epoch 538/1000\n",
      "1500/1500 [==============================] - 0s 199us/step - loss: 3.6782 - val_loss: 200.0452\n",
      "Epoch 539/1000\n",
      "1500/1500 [==============================] - 0s 198us/step - loss: 1.2148 - val_loss: 193.8403\n",
      "Epoch 540/1000\n",
      "1500/1500 [==============================] - 0s 201us/step - loss: 0.9084 - val_loss: 194.9988\n",
      "Epoch 541/1000\n",
      "1500/1500 [==============================] - 0s 203us/step - loss: 1.5285 - val_loss: 193.9158\n",
      "Epoch 542/1000\n",
      "1500/1500 [==============================] - 0s 198us/step - loss: 1.7000 - val_loss: 194.7612\n",
      "Epoch 543/1000\n",
      "1500/1500 [==============================] - 0s 200us/step - loss: 0.8099 - val_loss: 195.2716\n",
      "Epoch 544/1000\n",
      "1500/1500 [==============================] - 0s 202us/step - loss: 0.5019 - val_loss: 196.4728\n",
      "Epoch 545/1000\n",
      "1500/1500 [==============================] - 0s 204us/step - loss: 0.3928 - val_loss: 193.6480\n",
      "Epoch 546/1000\n",
      "1500/1500 [==============================] - 0s 194us/step - loss: 0.1729 - val_loss: 194.8787\n",
      "Epoch 547/1000\n",
      "1500/1500 [==============================] - 0s 203us/step - loss: 0.1218 - val_loss: 194.6484\n",
      "Epoch 548/1000\n",
      "1500/1500 [==============================] - 0s 202us/step - loss: 0.1014 - val_loss: 194.8096\n",
      "Epoch 549/1000\n",
      "1500/1500 [==============================] - 0s 203us/step - loss: 0.1636 - val_loss: 194.1406\n",
      "Epoch 550/1000\n",
      "1500/1500 [==============================] - 0s 198us/step - loss: 0.1459 - val_loss: 193.9502\n",
      "Epoch 551/1000\n",
      "1500/1500 [==============================] - 0s 201us/step - loss: 0.0996 - val_loss: 194.7048\n",
      "Epoch 552/1000\n",
      "1500/1500 [==============================] - 0s 197us/step - loss: 0.1164 - val_loss: 194.4621\n",
      "Epoch 553/1000\n",
      "1500/1500 [==============================] - 0s 197us/step - loss: 0.1162 - val_loss: 194.1023\n",
      "Epoch 554/1000\n",
      "1500/1500 [==============================] - 0s 195us/step - loss: 0.1544 - val_loss: 195.4357\n",
      "Epoch 555/1000\n",
      "1500/1500 [==============================] - 0s 199us/step - loss: 0.1830 - val_loss: 194.8226\n",
      "Epoch 556/1000\n",
      "1500/1500 [==============================] - 0s 202us/step - loss: 0.1037 - val_loss: 193.9813\n",
      "Epoch 557/1000\n",
      "1500/1500 [==============================] - 0s 201us/step - loss: 0.3302 - val_loss: 194.0161\n",
      "Epoch 558/1000\n",
      "1500/1500 [==============================] - 0s 199us/step - loss: 0.5772 - val_loss: 194.5827\n",
      "Epoch 559/1000\n",
      "1500/1500 [==============================] - 0s 198us/step - loss: 0.3277 - val_loss: 193.4730\n",
      "Epoch 560/1000\n",
      "1500/1500 [==============================] - 0s 199us/step - loss: 0.5182 - val_loss: 199.6711\n",
      "Epoch 561/1000\n",
      "1500/1500 [==============================] - 0s 198us/step - loss: 4.9574 - val_loss: 192.7215\n",
      "Epoch 562/1000\n",
      "1500/1500 [==============================] - 0s 203us/step - loss: 4.4022 - val_loss: 195.3275\n",
      "Epoch 563/1000\n",
      "1500/1500 [==============================] - 0s 200us/step - loss: 2.6631 - val_loss: 193.6916\n",
      "Epoch 564/1000\n",
      "1500/1500 [==============================] - 0s 204us/step - loss: 2.8916 - val_loss: 195.9692\n",
      "Epoch 565/1000\n",
      "1500/1500 [==============================] - 0s 201us/step - loss: 2.2217 - val_loss: 193.6774\n",
      "Epoch 566/1000\n",
      "1500/1500 [==============================] - 0s 199us/step - loss: 0.7238 - val_loss: 192.2716\n",
      "Epoch 567/1000\n",
      "1500/1500 [==============================] - 0s 201us/step - loss: 0.5958 - val_loss: 191.9952\n",
      "Epoch 568/1000\n",
      "1500/1500 [==============================] - 0s 204us/step - loss: 0.2618 - val_loss: 192.6555\n",
      "Epoch 569/1000\n",
      "1500/1500 [==============================] - 0s 204us/step - loss: 0.3384 - val_loss: 195.1011\n",
      "Epoch 570/1000\n",
      "1500/1500 [==============================] - 0s 203us/step - loss: 0.2971 - val_loss: 192.1031\n",
      "Epoch 571/1000\n",
      "1500/1500 [==============================] - 0s 203us/step - loss: 0.2396 - val_loss: 193.3360\n",
      "Epoch 572/1000\n",
      "1500/1500 [==============================] - 0s 203us/step - loss: 0.1633 - val_loss: 193.1577\n",
      "Epoch 573/1000\n",
      "1500/1500 [==============================] - 0s 199us/step - loss: 0.1722 - val_loss: 192.7369\n",
      "Epoch 574/1000\n",
      "1500/1500 [==============================] - 0s 203us/step - loss: 0.1010 - val_loss: 192.6250\n",
      "Epoch 575/1000\n",
      "1500/1500 [==============================] - 0s 201us/step - loss: 0.1211 - val_loss: 192.9056\n",
      "Epoch 576/1000\n",
      "1500/1500 [==============================] - 0s 203us/step - loss: 0.1046 - val_loss: 193.1360\n",
      "Epoch 577/1000\n",
      "1500/1500 [==============================] - 0s 197us/step - loss: 0.1099 - val_loss: 192.8130\n",
      "Epoch 578/1000\n",
      "1500/1500 [==============================] - 0s 200us/step - loss: 0.0886 - val_loss: 193.7809\n",
      "Epoch 579/1000\n",
      "1500/1500 [==============================] - 0s 203us/step - loss: 0.0979 - val_loss: 192.6276\n",
      "Epoch 580/1000\n",
      "1500/1500 [==============================] - 0s 203us/step - loss: 0.1042 - val_loss: 193.3152\n",
      "Epoch 581/1000\n",
      "1500/1500 [==============================] - 0s 201us/step - loss: 0.4589 - val_loss: 193.6188\n",
      "Epoch 582/1000\n",
      "1500/1500 [==============================] - 0s 209us/step - loss: 0.3751 - val_loss: 193.0143\n",
      "Epoch 583/1000\n",
      "1500/1500 [==============================] - 0s 203us/step - loss: 0.5934 - val_loss: 196.8367\n",
      "Epoch 584/1000\n",
      "1500/1500 [==============================] - 0s 199us/step - loss: 0.7703 - val_loss: 192.4733\n",
      "Epoch 585/1000\n",
      "1500/1500 [==============================] - 0s 196us/step - loss: 3.4078 - val_loss: 197.1858\n",
      "Epoch 586/1000\n",
      "1500/1500 [==============================] - 0s 198us/step - loss: 2.8916 - val_loss: 191.3027\n",
      "Epoch 587/1000\n",
      "1500/1500 [==============================] - 0s 197us/step - loss: 1.1834 - val_loss: 192.6901\n",
      "Epoch 588/1000\n",
      "1500/1500 [==============================] - 0s 195us/step - loss: 2.2707 - val_loss: 190.4555\n",
      "Epoch 589/1000\n",
      "1500/1500 [==============================] - 0s 201us/step - loss: 1.9930 - val_loss: 192.0076\n",
      "Epoch 590/1000\n",
      "1500/1500 [==============================] - 0s 199us/step - loss: 1.2327 - val_loss: 192.2760\n",
      "Epoch 591/1000\n",
      "1500/1500 [==============================] - 0s 198us/step - loss: 0.4717 - val_loss: 191.9919\n",
      "Epoch 592/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1500/1500 [==============================] - 0s 202us/step - loss: 0.4102 - val_loss: 195.5204\n",
      "Epoch 593/1000\n",
      "1500/1500 [==============================] - 0s 203us/step - loss: 0.4418 - val_loss: 195.3510\n",
      "Epoch 594/1000\n",
      "1500/1500 [==============================] - 0s 199us/step - loss: 0.5624 - val_loss: 191.8958\n",
      "Epoch 595/1000\n",
      "1500/1500 [==============================] - 0s 199us/step - loss: 1.7501 - val_loss: 192.1942\n",
      "Epoch 596/1000\n",
      "1500/1500 [==============================] - 0s 200us/step - loss: 0.7343 - val_loss: 195.7117\n",
      "Epoch 597/1000\n",
      "1500/1500 [==============================] - 0s 199us/step - loss: 0.7588 - val_loss: 193.7151\n",
      "Epoch 598/1000\n",
      "1500/1500 [==============================] - 0s 201us/step - loss: 0.2830 - val_loss: 192.3866\n",
      "Epoch 599/1000\n",
      "1500/1500 [==============================] - 0s 201us/step - loss: 0.7017 - val_loss: 192.6037\n",
      "Epoch 600/1000\n",
      "1500/1500 [==============================] - 0s 201us/step - loss: 0.2769 - val_loss: 193.3736\n",
      "Epoch 601/1000\n",
      "1500/1500 [==============================] - 0s 205us/step - loss: 0.2210 - val_loss: 191.8298\n",
      "Epoch 602/1000\n",
      "1500/1500 [==============================] - 0s 201us/step - loss: 0.2602 - val_loss: 192.6613\n",
      "Epoch 603/1000\n",
      "1500/1500 [==============================] - 0s 203us/step - loss: 0.3932 - val_loss: 193.5856\n",
      "Epoch 604/1000\n",
      "1500/1500 [==============================] - 0s 199us/step - loss: 0.2456 - val_loss: 193.0419\n",
      "Epoch 605/1000\n",
      "1500/1500 [==============================] - 0s 205us/step - loss: 0.4778 - val_loss: 195.6601\n",
      "Epoch 606/1000\n",
      "1500/1500 [==============================] - 0s 200us/step - loss: 0.8437 - val_loss: 191.1536\n",
      "Epoch 607/1000\n",
      "1500/1500 [==============================] - 0s 197us/step - loss: 0.9002 - val_loss: 192.2735\n",
      "Epoch 608/1000\n",
      "1500/1500 [==============================] - 0s 200us/step - loss: 1.1277 - val_loss: 195.0357\n",
      "Epoch 609/1000\n",
      "1500/1500 [==============================] - 0s 196us/step - loss: 1.0849 - val_loss: 193.0059\n",
      "Epoch 610/1000\n",
      "1500/1500 [==============================] - 0s 204us/step - loss: 0.4559 - val_loss: 193.3397\n",
      "Epoch 611/1000\n",
      "1500/1500 [==============================] - 0s 199us/step - loss: 0.8475 - val_loss: 191.2659\n",
      "Epoch 612/1000\n",
      "1500/1500 [==============================] - 0s 199us/step - loss: 2.4309 - val_loss: 194.2565\n",
      "Epoch 613/1000\n",
      "1500/1500 [==============================] - 0s 203us/step - loss: 1.7474 - val_loss: 195.9053\n",
      "Epoch 614/1000\n",
      "1500/1500 [==============================] - 0s 203us/step - loss: 1.4311 - val_loss: 190.8237\n",
      "Epoch 615/1000\n",
      "1500/1500 [==============================] - 0s 204us/step - loss: 1.5144 - val_loss: 192.4280\n",
      "Epoch 616/1000\n",
      "1500/1500 [==============================] - 0s 201us/step - loss: 2.0869 - val_loss: 190.4532\n",
      "Epoch 617/1000\n",
      "1500/1500 [==============================] - 0s 207us/step - loss: 0.7855 - val_loss: 191.2421\n",
      "Epoch 618/1000\n",
      "1500/1500 [==============================] - 0s 199us/step - loss: 0.6645 - val_loss: 192.9180\n",
      "Epoch 619/1000\n",
      "1500/1500 [==============================] - 0s 207us/step - loss: 0.2421 - val_loss: 190.7950\n",
      "Epoch 620/1000\n",
      "1500/1500 [==============================] - 0s 204us/step - loss: 0.2184 - val_loss: 191.5551\n",
      "Epoch 621/1000\n",
      "1500/1500 [==============================] - 0s 202us/step - loss: 0.1490 - val_loss: 191.3145\n",
      "Epoch 622/1000\n",
      "1500/1500 [==============================] - 0s 199us/step - loss: 0.1372 - val_loss: 191.9779\n",
      "Epoch 623/1000\n",
      "1500/1500 [==============================] - 0s 202us/step - loss: 0.1383 - val_loss: 191.5254\n",
      "Epoch 624/1000\n",
      "1500/1500 [==============================] - 0s 201us/step - loss: 2.8049 - val_loss: 189.4224\n",
      "Epoch 625/1000\n",
      "1500/1500 [==============================] - 0s 199us/step - loss: 1.7296 - val_loss: 190.1168\n",
      "Epoch 626/1000\n",
      "1500/1500 [==============================] - 0s 202us/step - loss: 0.9055 - val_loss: 191.7575\n",
      "Epoch 627/1000\n",
      "1500/1500 [==============================] - 0s 199us/step - loss: 0.6992 - val_loss: 191.2273\n",
      "Epoch 628/1000\n",
      "1500/1500 [==============================] - 0s 202us/step - loss: 0.4808 - val_loss: 191.0749\n",
      "Epoch 629/1000\n",
      "1500/1500 [==============================] - 0s 201us/step - loss: 0.2737 - val_loss: 191.8850\n",
      "Epoch 630/1000\n",
      "1500/1500 [==============================] - 0s 199us/step - loss: 0.2029 - val_loss: 191.4786\n",
      "Epoch 631/1000\n",
      "1500/1500 [==============================] - 0s 202us/step - loss: 1.1815 - val_loss: 190.8003\n",
      "Epoch 632/1000\n",
      "1500/1500 [==============================] - 0s 206us/step - loss: 1.0582 - val_loss: 192.7570\n",
      "Epoch 633/1000\n",
      "1500/1500 [==============================] - 0s 199us/step - loss: 0.4711 - val_loss: 191.3945\n",
      "Epoch 634/1000\n",
      "1500/1500 [==============================] - 0s 203us/step - loss: 0.4878 - val_loss: 191.3352\n",
      "Epoch 635/1000\n",
      "1500/1500 [==============================] - 0s 202us/step - loss: 0.4011 - val_loss: 191.0960\n",
      "Epoch 636/1000\n",
      "1500/1500 [==============================] - 0s 202us/step - loss: 0.3241 - val_loss: 191.2577\n",
      "Epoch 637/1000\n",
      "1500/1500 [==============================] - 0s 202us/step - loss: 0.2440 - val_loss: 191.0493\n",
      "Epoch 638/1000\n",
      "1500/1500 [==============================] - 0s 205us/step - loss: 0.2876 - val_loss: 192.3509\n",
      "Epoch 639/1000\n",
      "1500/1500 [==============================] - 0s 203us/step - loss: 0.3046 - val_loss: 192.7478\n",
      "Epoch 640/1000\n",
      "1500/1500 [==============================] - 0s 201us/step - loss: 0.4527 - val_loss: 191.5441\n",
      "Epoch 641/1000\n",
      "1500/1500 [==============================] - 0s 202us/step - loss: 0.2925 - val_loss: 191.3398\n",
      "Epoch 642/1000\n",
      "1500/1500 [==============================] - 0s 199us/step - loss: 0.2569 - val_loss: 191.4103\n",
      "Epoch 643/1000\n",
      "1500/1500 [==============================] - 0s 200us/step - loss: 0.7119 - val_loss: 192.4608\n",
      "Epoch 644/1000\n",
      "1500/1500 [==============================] - 0s 206us/step - loss: 0.8182 - val_loss: 196.1999\n",
      "Epoch 645/1000\n",
      "1500/1500 [==============================] - 0s 201us/step - loss: 1.2093 - val_loss: 192.3847\n",
      "Epoch 646/1000\n",
      "1500/1500 [==============================] - 0s 204us/step - loss: 1.1322 - val_loss: 190.0264\n",
      "Epoch 647/1000\n",
      "1500/1500 [==============================] - 0s 203us/step - loss: 0.6062 - val_loss: 190.6822\n",
      "Epoch 648/1000\n",
      "1500/1500 [==============================] - 0s 203us/step - loss: 0.5611 - val_loss: 191.3965\n",
      "Epoch 649/1000\n",
      "1500/1500 [==============================] - 0s 205us/step - loss: 0.7183 - val_loss: 191.6786\n",
      "Epoch 650/1000\n",
      "1500/1500 [==============================] - 0s 201us/step - loss: 3.2945 - val_loss: 192.6191\n",
      "Epoch 651/1000\n",
      "1500/1500 [==============================] - 0s 197us/step - loss: 1.4145 - val_loss: 191.0143\n",
      "Epoch 652/1000\n",
      "1500/1500 [==============================] - 0s 203us/step - loss: 1.0570 - val_loss: 189.6986\n",
      "Epoch 653/1000\n",
      "1500/1500 [==============================] - 0s 210us/step - loss: 0.8184 - val_loss: 191.7667\n",
      "Epoch 654/1000\n",
      "1500/1500 [==============================] - 0s 201us/step - loss: 0.9217 - val_loss: 193.0142\n",
      "Epoch 655/1000\n",
      "1500/1500 [==============================] - 0s 200us/step - loss: 0.6509 - val_loss: 192.9903\n",
      "Epoch 656/1000\n",
      "1500/1500 [==============================] - 0s 201us/step - loss: 0.2978 - val_loss: 191.7240\n",
      "Epoch 657/1000\n",
      "1500/1500 [==============================] - 0s 197us/step - loss: 0.3252 - val_loss: 191.4039\n",
      "Epoch 658/1000\n",
      "1500/1500 [==============================] - 0s 202us/step - loss: 0.5360 - val_loss: 190.6915\n",
      "Epoch 659/1000\n",
      "1500/1500 [==============================] - 0s 205us/step - loss: 0.4364 - val_loss: 191.1541\n",
      "Epoch 660/1000\n",
      "1500/1500 [==============================] - 0s 206us/step - loss: 0.1808 - val_loss: 191.4922\n",
      "Epoch 661/1000\n",
      "1500/1500 [==============================] - 0s 203us/step - loss: 0.0967 - val_loss: 192.5999\n",
      "Epoch 662/1000\n",
      "1500/1500 [==============================] - 0s 199us/step - loss: 0.1612 - val_loss: 191.8246\n",
      "Epoch 663/1000\n",
      "1500/1500 [==============================] - 0s 197us/step - loss: 0.1152 - val_loss: 190.8667\n",
      "Epoch 664/1000\n",
      "1500/1500 [==============================] - 0s 203us/step - loss: 0.2565 - val_loss: 190.3536\n",
      "Epoch 665/1000\n",
      "1500/1500 [==============================] - 0s 201us/step - loss: 0.6671 - val_loss: 192.2469\n",
      "Epoch 666/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1500/1500 [==============================] - 0s 205us/step - loss: 1.5335 - val_loss: 189.9342\n",
      "Epoch 667/1000\n",
      "1500/1500 [==============================] - 0s 207us/step - loss: 4.1140 - val_loss: 193.0056\n",
      "Epoch 668/1000\n",
      "1500/1500 [==============================] - 0s 199us/step - loss: 1.6179 - val_loss: 193.2744\n",
      "Epoch 669/1000\n",
      "1500/1500 [==============================] - 0s 205us/step - loss: 0.9342 - val_loss: 192.3895\n",
      "Epoch 670/1000\n",
      "1500/1500 [==============================] - 0s 204us/step - loss: 0.6589 - val_loss: 191.7154\n",
      "Epoch 671/1000\n",
      "1500/1500 [==============================] - 0s 200us/step - loss: 0.5935 - val_loss: 192.8887\n",
      "Epoch 672/1000\n",
      "1500/1500 [==============================] - 0s 199us/step - loss: 0.3310 - val_loss: 191.2898\n",
      "Epoch 673/1000\n",
      "1500/1500 [==============================] - 0s 204us/step - loss: 0.3206 - val_loss: 191.9552\n",
      "Epoch 674/1000\n",
      "1500/1500 [==============================] - 0s 204us/step - loss: 0.4059 - val_loss: 193.1219\n",
      "Epoch 675/1000\n",
      "1500/1500 [==============================] - 0s 200us/step - loss: 0.7986 - val_loss: 189.3300\n",
      "Epoch 676/1000\n",
      "1500/1500 [==============================] - 0s 206us/step - loss: 0.5972 - val_loss: 192.6571\n",
      "Epoch 677/1000\n",
      "1500/1500 [==============================] - 0s 205us/step - loss: 0.3631 - val_loss: 190.8776\n",
      "Epoch 678/1000\n",
      "1500/1500 [==============================] - 0s 199us/step - loss: 0.2414 - val_loss: 190.4091\n",
      "Epoch 679/1000\n",
      "1500/1500 [==============================] - 0s 197us/step - loss: 0.3674 - val_loss: 189.9862\n",
      "Epoch 680/1000\n",
      "1500/1500 [==============================] - 0s 200us/step - loss: 0.5871 - val_loss: 192.8973\n",
      "Epoch 681/1000\n",
      "1500/1500 [==============================] - 0s 197us/step - loss: 0.7935 - val_loss: 190.0221\n",
      "Epoch 682/1000\n",
      "1500/1500 [==============================] - 0s 200us/step - loss: 1.0868 - val_loss: 188.4315\n",
      "Epoch 683/1000\n",
      "1500/1500 [==============================] - 0s 202us/step - loss: 1.6530 - val_loss: 189.3639\n",
      "Epoch 684/1000\n",
      "1500/1500 [==============================] - 0s 202us/step - loss: 1.4733 - val_loss: 188.6845\n",
      "Epoch 685/1000\n",
      "1500/1500 [==============================] - 0s 203us/step - loss: 0.9839 - val_loss: 191.8852\n",
      "Epoch 686/1000\n",
      "1500/1500 [==============================] - 0s 200us/step - loss: 0.8008 - val_loss: 192.7856\n",
      "Epoch 687/1000\n",
      "1500/1500 [==============================] - 0s 199us/step - loss: 1.1841 - val_loss: 192.4055\n",
      "Epoch 688/1000\n",
      "1500/1500 [==============================] - 0s 198us/step - loss: 0.9741 - val_loss: 190.7167\n",
      "Epoch 689/1000\n",
      "1500/1500 [==============================] - 0s 201us/step - loss: 0.6300 - val_loss: 191.3314\n",
      "Epoch 690/1000\n",
      "1500/1500 [==============================] - 0s 206us/step - loss: 0.4785 - val_loss: 192.4133\n",
      "Epoch 691/1000\n",
      "1500/1500 [==============================] - 0s 203us/step - loss: 0.2965 - val_loss: 191.0534\n",
      "Epoch 692/1000\n",
      "1500/1500 [==============================] - 0s 198us/step - loss: 0.3627 - val_loss: 191.1238\n",
      "Epoch 693/1000\n",
      "1500/1500 [==============================] - 0s 199us/step - loss: 0.6026 - val_loss: 191.2157\n",
      "Epoch 694/1000\n",
      "1500/1500 [==============================] - 0s 198us/step - loss: 0.3655 - val_loss: 190.2943\n",
      "Epoch 695/1000\n",
      "1500/1500 [==============================] - 0s 198us/step - loss: 0.2747 - val_loss: 190.7595\n",
      "Epoch 696/1000\n",
      "1500/1500 [==============================] - 0s 201us/step - loss: 0.2608 - val_loss: 190.3586\n",
      "Epoch 697/1000\n",
      "1500/1500 [==============================] - 0s 201us/step - loss: 0.2857 - val_loss: 189.5293\n",
      "Epoch 698/1000\n",
      "1500/1500 [==============================] - 0s 202us/step - loss: 0.2725 - val_loss: 190.4101\n",
      "Epoch 699/1000\n",
      "1500/1500 [==============================] - 0s 200us/step - loss: 0.1842 - val_loss: 189.1743\n",
      "Epoch 700/1000\n",
      "1500/1500 [==============================] - 0s 201us/step - loss: 0.2266 - val_loss: 189.7999\n",
      "Epoch 701/1000\n",
      "1500/1500 [==============================] - 0s 205us/step - loss: 0.6317 - val_loss: 190.6801\n",
      "Epoch 702/1000\n",
      "1500/1500 [==============================] - 0s 204us/step - loss: 0.9776 - val_loss: 192.5203\n",
      "Epoch 703/1000\n",
      "1500/1500 [==============================] - 0s 203us/step - loss: 0.7914 - val_loss: 190.2457\n",
      "Epoch 704/1000\n",
      "1500/1500 [==============================] - 0s 200us/step - loss: 1.1905 - val_loss: 191.0966\n",
      "Epoch 705/1000\n",
      "1500/1500 [==============================] - 0s 207us/step - loss: 2.6666 - val_loss: 188.7781\n",
      "Epoch 706/1000\n",
      "1500/1500 [==============================] - 0s 204us/step - loss: 1.2071 - val_loss: 190.0012\n",
      "Epoch 707/1000\n",
      "1500/1500 [==============================] - 0s 200us/step - loss: 1.2346 - val_loss: 188.4499\n",
      "Epoch 708/1000\n",
      "1500/1500 [==============================] - 0s 204us/step - loss: 0.9314 - val_loss: 188.1512\n",
      "Epoch 709/1000\n",
      "1500/1500 [==============================] - 0s 198us/step - loss: 0.6262 - val_loss: 188.3535\n",
      "Epoch 710/1000\n",
      "1500/1500 [==============================] - 0s 201us/step - loss: 0.7091 - val_loss: 192.0297\n",
      "Epoch 711/1000\n",
      "1500/1500 [==============================] - 0s 197us/step - loss: 1.0132 - val_loss: 188.4553\n",
      "Epoch 712/1000\n",
      "1500/1500 [==============================] - 0s 204us/step - loss: 0.8970 - val_loss: 189.5457\n",
      "Epoch 713/1000\n",
      "1500/1500 [==============================] - 0s 198us/step - loss: 0.4666 - val_loss: 190.8038\n",
      "Epoch 714/1000\n",
      "1500/1500 [==============================] - 0s 206us/step - loss: 0.3125 - val_loss: 189.5306\n",
      "Epoch 715/1000\n",
      "1500/1500 [==============================] - 0s 202us/step - loss: 0.2385 - val_loss: 189.8079\n",
      "Epoch 716/1000\n",
      "1500/1500 [==============================] - 0s 199us/step - loss: 0.1117 - val_loss: 189.6404\n",
      "Epoch 717/1000\n",
      "1500/1500 [==============================] - 0s 203us/step - loss: 0.2258 - val_loss: 188.8518\n",
      "Epoch 718/1000\n",
      "1500/1500 [==============================] - 0s 202us/step - loss: 0.2096 - val_loss: 190.3331\n",
      "Epoch 719/1000\n",
      "1500/1500 [==============================] - 0s 196us/step - loss: 0.1640 - val_loss: 189.7670\n",
      "Epoch 720/1000\n",
      "1500/1500 [==============================] - 0s 207us/step - loss: 0.2286 - val_loss: 189.6133\n",
      "Epoch 721/1000\n",
      "1500/1500 [==============================] - 0s 202us/step - loss: 0.1765 - val_loss: 189.2599\n",
      "Epoch 722/1000\n",
      "1500/1500 [==============================] - 0s 199us/step - loss: 0.8259 - val_loss: 189.5616\n",
      "Epoch 723/1000\n",
      "1500/1500 [==============================] - 0s 204us/step - loss: 2.7475 - val_loss: 189.3408\n",
      "Epoch 724/1000\n",
      "1500/1500 [==============================] - 0s 201us/step - loss: 1.5710 - val_loss: 189.5153\n",
      "Epoch 725/1000\n",
      "1500/1500 [==============================] - 0s 201us/step - loss: 1.4705 - val_loss: 188.6817\n",
      "Epoch 726/1000\n",
      "1500/1500 [==============================] - 0s 199us/step - loss: 0.7976 - val_loss: 188.5567\n",
      "Epoch 727/1000\n",
      "1500/1500 [==============================] - 0s 200us/step - loss: 0.5615 - val_loss: 190.0881\n",
      "Epoch 728/1000\n",
      "1500/1500 [==============================] - 0s 205us/step - loss: 0.5908 - val_loss: 192.2421\n",
      "Epoch 729/1000\n",
      "1500/1500 [==============================] - 0s 199us/step - loss: 0.7717 - val_loss: 188.1828\n",
      "Epoch 730/1000\n",
      "1500/1500 [==============================] - 0s 201us/step - loss: 0.7582 - val_loss: 190.7707\n",
      "Epoch 731/1000\n",
      "1500/1500 [==============================] - 0s 200us/step - loss: 0.5693 - val_loss: 190.7251\n",
      "Epoch 732/1000\n",
      "1500/1500 [==============================] - 0s 201us/step - loss: 0.7150 - val_loss: 190.0882\n",
      "Epoch 733/1000\n",
      "1500/1500 [==============================] - 0s 199us/step - loss: 0.8641 - val_loss: 188.7685\n",
      "Epoch 734/1000\n",
      "1500/1500 [==============================] - 0s 204us/step - loss: 0.6439 - val_loss: 189.6860\n",
      "Epoch 735/1000\n",
      "1500/1500 [==============================] - 0s 200us/step - loss: 0.5762 - val_loss: 189.5120\n",
      "Epoch 736/1000\n",
      "1500/1500 [==============================] - 0s 199us/step - loss: 2.0400 - val_loss: 191.4223\n",
      "Epoch 737/1000\n",
      "1500/1500 [==============================] - 0s 202us/step - loss: 1.7798 - val_loss: 186.8954\n",
      "Epoch 738/1000\n",
      "1500/1500 [==============================] - 0s 203us/step - loss: 1.1467 - val_loss: 191.5254\n",
      "Epoch 739/1000\n",
      "1500/1500 [==============================] - 0s 197us/step - loss: 0.6124 - val_loss: 188.2537\n",
      "Epoch 740/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1500/1500 [==============================] - 0s 197us/step - loss: 0.4260 - val_loss: 191.9060\n",
      "Epoch 741/1000\n",
      "1500/1500 [==============================] - 0s 201us/step - loss: 0.8323 - val_loss: 189.3607\n",
      "Epoch 742/1000\n",
      "1500/1500 [==============================] - 0s 200us/step - loss: 0.7097 - val_loss: 187.9674\n",
      "Epoch 743/1000\n",
      "1500/1500 [==============================] - 0s 198us/step - loss: 0.2748 - val_loss: 188.8167\n",
      "Epoch 744/1000\n",
      "1500/1500 [==============================] - 0s 204us/step - loss: 0.2286 - val_loss: 188.9397\n",
      "Epoch 745/1000\n",
      "1500/1500 [==============================] - 0s 199us/step - loss: 0.2094 - val_loss: 189.1445\n",
      "Epoch 746/1000\n",
      "1500/1500 [==============================] - 0s 203us/step - loss: 0.1361 - val_loss: 188.3941\n",
      "Epoch 747/1000\n",
      "1500/1500 [==============================] - 0s 205us/step - loss: 0.1445 - val_loss: 190.8837\n",
      "Epoch 748/1000\n",
      "1500/1500 [==============================] - 0s 208us/step - loss: 0.1678 - val_loss: 189.7785\n",
      "Epoch 749/1000\n",
      "1500/1500 [==============================] - 0s 199us/step - loss: 0.1633 - val_loss: 188.6154\n",
      "Epoch 750/1000\n",
      "1500/1500 [==============================] - 0s 201us/step - loss: 0.8401 - val_loss: 191.2503\n",
      "Epoch 751/1000\n",
      "1500/1500 [==============================] - 0s 197us/step - loss: 0.7607 - val_loss: 189.6610\n",
      "Epoch 752/1000\n",
      "1500/1500 [==============================] - 0s 198us/step - loss: 1.4131 - val_loss: 187.2612\n",
      "Epoch 753/1000\n",
      "1500/1500 [==============================] - 0s 203us/step - loss: 1.1259 - val_loss: 190.2366\n",
      "Epoch 754/1000\n",
      "1500/1500 [==============================] - 0s 200us/step - loss: 0.8875 - val_loss: 188.1686\n",
      "Epoch 755/1000\n",
      "1500/1500 [==============================] - 0s 201us/step - loss: 1.0310 - val_loss: 190.2000\n",
      "Epoch 756/1000\n",
      "1500/1500 [==============================] - 0s 199us/step - loss: 1.1406 - val_loss: 187.6635\n",
      "Epoch 757/1000\n",
      "1500/1500 [==============================] - 0s 201us/step - loss: 1.0422 - val_loss: 188.2701\n",
      "Epoch 758/1000\n",
      "1500/1500 [==============================] - 0s 200us/step - loss: 0.6197 - val_loss: 190.2159\n",
      "Epoch 759/1000\n",
      "1500/1500 [==============================] - 0s 202us/step - loss: 0.4874 - val_loss: 188.9294\n",
      "Epoch 760/1000\n",
      "1500/1500 [==============================] - 0s 200us/step - loss: 0.2461 - val_loss: 188.1027\n",
      "Epoch 761/1000\n",
      "1500/1500 [==============================] - 0s 200us/step - loss: 0.2394 - val_loss: 188.5845\n",
      "Epoch 762/1000\n",
      "1500/1500 [==============================] - 0s 204us/step - loss: 0.2230 - val_loss: 188.7332\n",
      "Epoch 763/1000\n",
      "1500/1500 [==============================] - 0s 203us/step - loss: 0.4603 - val_loss: 187.6253\n",
      "Epoch 764/1000\n",
      "1500/1500 [==============================] - 0s 200us/step - loss: 0.5191 - val_loss: 188.9450\n",
      "Epoch 765/1000\n",
      "1500/1500 [==============================] - 0s 200us/step - loss: 0.4266 - val_loss: 187.6385\n",
      "Epoch 766/1000\n",
      "1500/1500 [==============================] - 0s 202us/step - loss: 0.9280 - val_loss: 187.9831\n",
      "Epoch 767/1000\n",
      "1500/1500 [==============================] - 0s 207us/step - loss: 1.8523 - val_loss: 196.1219\n",
      "Epoch 768/1000\n",
      "1500/1500 [==============================] - 0s 202us/step - loss: 1.8592 - val_loss: 192.2506\n",
      "Epoch 769/1000\n",
      "1500/1500 [==============================] - 0s 195us/step - loss: 5.0809 - val_loss: 190.2708\n",
      "Epoch 770/1000\n",
      "1500/1500 [==============================] - 0s 201us/step - loss: 4.4427 - val_loss: 188.5564\n",
      "Epoch 771/1000\n",
      "1500/1500 [==============================] - 0s 204us/step - loss: 2.8066 - val_loss: 187.6547\n",
      "Epoch 772/1000\n",
      "1500/1500 [==============================] - 0s 204us/step - loss: 1.1497 - val_loss: 186.8907\n",
      "Epoch 773/1000\n",
      "1500/1500 [==============================] - 0s 202us/step - loss: 0.3962 - val_loss: 186.9960\n",
      "Epoch 774/1000\n",
      "1500/1500 [==============================] - 0s 202us/step - loss: 0.4794 - val_loss: 188.5410\n",
      "Epoch 775/1000\n",
      "1500/1500 [==============================] - 0s 200us/step - loss: 0.2833 - val_loss: 188.3026\n",
      "Epoch 776/1000\n",
      "1500/1500 [==============================] - 0s 204us/step - loss: 0.6814 - val_loss: 186.7039\n",
      "Epoch 777/1000\n",
      "1500/1500 [==============================] - 0s 201us/step - loss: 0.3495 - val_loss: 188.7551\n",
      "Epoch 778/1000\n",
      "1500/1500 [==============================] - 0s 206us/step - loss: 0.3081 - val_loss: 188.4282\n",
      "Epoch 779/1000\n",
      "1500/1500 [==============================] - 0s 205us/step - loss: 0.7476 - val_loss: 190.6022\n",
      "Epoch 780/1000\n",
      "1500/1500 [==============================] - 0s 205us/step - loss: 1.3072 - val_loss: 189.2540\n",
      "Epoch 781/1000\n",
      "1500/1500 [==============================] - 0s 203us/step - loss: 1.8511 - val_loss: 188.4004\n",
      "Epoch 782/1000\n",
      "1500/1500 [==============================] - 0s 194us/step - loss: 0.5881 - val_loss: 188.6714\n",
      "Epoch 783/1000\n",
      "1500/1500 [==============================] - 0s 201us/step - loss: 0.4182 - val_loss: 188.0799\n",
      "Epoch 784/1000\n",
      "1500/1500 [==============================] - 0s 201us/step - loss: 0.2221 - val_loss: 188.0813\n",
      "Epoch 785/1000\n",
      "1500/1500 [==============================] - 0s 196us/step - loss: 0.1256 - val_loss: 189.1455\n",
      "Epoch 786/1000\n",
      "1500/1500 [==============================] - 0s 202us/step - loss: 0.0940 - val_loss: 188.0043\n",
      "Epoch 787/1000\n",
      "1500/1500 [==============================] - 0s 198us/step - loss: 0.1485 - val_loss: 188.5410\n",
      "Epoch 788/1000\n",
      "1500/1500 [==============================] - 0s 199us/step - loss: 0.1229 - val_loss: 188.6103\n",
      "Epoch 789/1000\n",
      "1500/1500 [==============================] - 0s 203us/step - loss: 0.0734 - val_loss: 189.0912\n",
      "Epoch 790/1000\n",
      "1500/1500 [==============================] - 0s 195us/step - loss: 0.0538 - val_loss: 188.7402\n",
      "Epoch 791/1000\n",
      "1500/1500 [==============================] - 0s 197us/step - loss: 0.0453 - val_loss: 188.6071\n",
      "Epoch 792/1000\n",
      "1500/1500 [==============================] - 0s 199us/step - loss: 0.0565 - val_loss: 188.2541\n",
      "Epoch 793/1000\n",
      "1500/1500 [==============================] - 0s 197us/step - loss: 0.1032 - val_loss: 189.9225\n",
      "Epoch 794/1000\n",
      "1500/1500 [==============================] - 0s 202us/step - loss: 0.1151 - val_loss: 188.7197\n",
      "Epoch 795/1000\n",
      "1500/1500 [==============================] - 0s 201us/step - loss: 0.0933 - val_loss: 188.2066\n",
      "Epoch 796/1000\n",
      "1500/1500 [==============================] - 0s 203us/step - loss: 0.1411 - val_loss: 188.7966\n",
      "Epoch 797/1000\n",
      "1500/1500 [==============================] - 0s 201us/step - loss: 0.1086 - val_loss: 188.2157\n",
      "Epoch 798/1000\n",
      "1500/1500 [==============================] - 0s 202us/step - loss: 0.5577 - val_loss: 190.4264\n",
      "Epoch 799/1000\n",
      "1500/1500 [==============================] - 0s 206us/step - loss: 0.8117 - val_loss: 187.6770\n",
      "Epoch 800/1000\n",
      "1500/1500 [==============================] - 0s 198us/step - loss: 0.7026 - val_loss: 189.1926\n",
      "Epoch 801/1000\n",
      "1500/1500 [==============================] - 0s 195us/step - loss: 0.7214 - val_loss: 188.8715\n",
      "Epoch 802/1000\n",
      "1500/1500 [==============================] - 0s 197us/step - loss: 1.9522 - val_loss: 185.5078\n",
      "Epoch 803/1000\n",
      "1500/1500 [==============================] - 0s 202us/step - loss: 1.8151 - val_loss: 187.0675\n",
      "Epoch 804/1000\n",
      "1500/1500 [==============================] - 0s 199us/step - loss: 0.7453 - val_loss: 188.9791\n",
      "Epoch 805/1000\n",
      "1500/1500 [==============================] - 0s 201us/step - loss: 1.5175 - val_loss: 187.4399\n",
      "Epoch 806/1000\n",
      "1500/1500 [==============================] - 0s 201us/step - loss: 1.6089 - val_loss: 185.5792\n",
      "Epoch 807/1000\n",
      "1500/1500 [==============================] - 0s 198us/step - loss: 1.8861 - val_loss: 188.5502\n",
      "Epoch 808/1000\n",
      "1500/1500 [==============================] - 0s 199us/step - loss: 1.0472 - val_loss: 189.3892\n",
      "Epoch 809/1000\n",
      "1500/1500 [==============================] - 0s 202us/step - loss: 0.8370 - val_loss: 186.2192\n",
      "Epoch 810/1000\n",
      "1500/1500 [==============================] - 0s 201us/step - loss: 0.4382 - val_loss: 186.8799\n",
      "Epoch 811/1000\n",
      "1500/1500 [==============================] - 0s 203us/step - loss: 0.2291 - val_loss: 187.7704\n",
      "Epoch 812/1000\n",
      "1500/1500 [==============================] - 0s 204us/step - loss: 0.3898 - val_loss: 188.1925\n",
      "Epoch 813/1000\n",
      "1500/1500 [==============================] - 0s 201us/step - loss: 0.8048 - val_loss: 188.4884\n",
      "Epoch 814/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1500/1500 [==============================] - 0s 204us/step - loss: 1.4184 - val_loss: 187.2149\n",
      "Epoch 815/1000\n",
      "1500/1500 [==============================] - 0s 200us/step - loss: 1.7764 - val_loss: 187.9069\n",
      "Epoch 816/1000\n",
      "1500/1500 [==============================] - 0s 199us/step - loss: 0.6210 - val_loss: 187.9159\n",
      "Epoch 817/1000\n",
      "1500/1500 [==============================] - 0s 200us/step - loss: 0.3302 - val_loss: 186.5238\n",
      "Epoch 818/1000\n",
      "1500/1500 [==============================] - 0s 204us/step - loss: 0.1955 - val_loss: 187.1730\n",
      "Epoch 819/1000\n",
      "1500/1500 [==============================] - 0s 205us/step - loss: 0.2578 - val_loss: 188.4484\n",
      "Epoch 820/1000\n",
      "1500/1500 [==============================] - 0s 203us/step - loss: 0.2725 - val_loss: 188.7522\n",
      "Epoch 821/1000\n",
      "1500/1500 [==============================] - 0s 202us/step - loss: 0.1283 - val_loss: 188.1891\n",
      "Epoch 822/1000\n",
      "1500/1500 [==============================] - 0s 201us/step - loss: 0.0970 - val_loss: 188.3014\n",
      "Epoch 823/1000\n",
      "1500/1500 [==============================] - 0s 202us/step - loss: 0.0591 - val_loss: 188.3619\n",
      "Epoch 824/1000\n",
      "1500/1500 [==============================] - 0s 205us/step - loss: 0.0647 - val_loss: 188.2074\n",
      "Epoch 825/1000\n",
      "1500/1500 [==============================] - 0s 202us/step - loss: 0.0706 - val_loss: 187.5020\n",
      "Epoch 826/1000\n",
      "1500/1500 [==============================] - 0s 200us/step - loss: 0.2649 - val_loss: 188.2960\n",
      "Epoch 827/1000\n",
      "1500/1500 [==============================] - 0s 201us/step - loss: 0.6913 - val_loss: 188.0983\n",
      "Epoch 828/1000\n",
      "1500/1500 [==============================] - 0s 201us/step - loss: 4.2829 - val_loss: 188.1528\n",
      "Epoch 829/1000\n",
      "1500/1500 [==============================] - 0s 197us/step - loss: 1.9500 - val_loss: 187.6146\n",
      "Epoch 830/1000\n",
      "1500/1500 [==============================] - 0s 199us/step - loss: 1.9674 - val_loss: 188.8991\n",
      "Epoch 831/1000\n",
      "1500/1500 [==============================] - 0s 197us/step - loss: 0.6940 - val_loss: 189.4265\n",
      "Epoch 832/1000\n",
      "1500/1500 [==============================] - 0s 201us/step - loss: 0.6463 - val_loss: 189.1716\n",
      "Epoch 833/1000\n",
      "1500/1500 [==============================] - 0s 200us/step - loss: 0.5909 - val_loss: 192.2134\n",
      "Epoch 834/1000\n",
      "1500/1500 [==============================] - 0s 202us/step - loss: 0.3399 - val_loss: 189.0829\n",
      "Epoch 835/1000\n",
      "1500/1500 [==============================] - 0s 199us/step - loss: 0.2802 - val_loss: 188.3248\n",
      "Epoch 836/1000\n",
      "1500/1500 [==============================] - 0s 199us/step - loss: 0.2546 - val_loss: 187.7087\n",
      "Epoch 837/1000\n",
      "1500/1500 [==============================] - 0s 203us/step - loss: 0.6969 - val_loss: 189.7076\n",
      "Epoch 838/1000\n",
      "1500/1500 [==============================] - 0s 204us/step - loss: 0.4455 - val_loss: 187.8649\n",
      "Epoch 839/1000\n",
      "1500/1500 [==============================] - 0s 199us/step - loss: 0.1656 - val_loss: 188.1022\n",
      "Epoch 840/1000\n",
      "1500/1500 [==============================] - 0s 203us/step - loss: 0.1096 - val_loss: 188.0849\n",
      "Epoch 841/1000\n",
      "1500/1500 [==============================] - 0s 205us/step - loss: 0.1483 - val_loss: 189.0593\n",
      "Epoch 842/1000\n",
      "1500/1500 [==============================] - 0s 197us/step - loss: 0.1203 - val_loss: 188.1544\n",
      "Epoch 843/1000\n",
      "1500/1500 [==============================] - 0s 200us/step - loss: 0.4724 - val_loss: 186.7926\n",
      "Epoch 844/1000\n",
      "1500/1500 [==============================] - 0s 201us/step - loss: 0.6288 - val_loss: 192.2879\n",
      "Epoch 845/1000\n",
      "1500/1500 [==============================] - 0s 198us/step - loss: 1.2050 - val_loss: 187.5276\n",
      "Epoch 846/1000\n",
      "1500/1500 [==============================] - 0s 200us/step - loss: 0.8768 - val_loss: 188.8893\n",
      "Epoch 847/1000\n",
      "1500/1500 [==============================] - 0s 202us/step - loss: 0.5600 - val_loss: 189.3956\n",
      "Epoch 848/1000\n",
      "1500/1500 [==============================] - 0s 203us/step - loss: 0.4779 - val_loss: 188.1750\n",
      "Epoch 849/1000\n",
      "1500/1500 [==============================] - 0s 204us/step - loss: 0.2363 - val_loss: 188.6512\n",
      "Epoch 850/1000\n",
      "1500/1500 [==============================] - 0s 196us/step - loss: 0.2259 - val_loss: 187.5706\n",
      "Epoch 851/1000\n",
      "1500/1500 [==============================] - 0s 200us/step - loss: 0.7313 - val_loss: 188.4646\n",
      "Epoch 852/1000\n",
      "1500/1500 [==============================] - 0s 201us/step - loss: 0.5533 - val_loss: 190.0079\n",
      "Epoch 853/1000\n",
      "1500/1500 [==============================] - 0s 202us/step - loss: 2.8766 - val_loss: 187.5341\n",
      "Epoch 854/1000\n",
      "1500/1500 [==============================] - 0s 204us/step - loss: 2.9422 - val_loss: 188.4169\n",
      "Epoch 855/1000\n",
      "1500/1500 [==============================] - 0s 205us/step - loss: 1.4703 - val_loss: 186.4531\n",
      "Epoch 856/1000\n",
      "1500/1500 [==============================] - 0s 198us/step - loss: 0.5547 - val_loss: 188.3107\n",
      "Epoch 857/1000\n",
      "1500/1500 [==============================] - 0s 202us/step - loss: 0.3313 - val_loss: 186.5413\n",
      "Epoch 858/1000\n",
      "1500/1500 [==============================] - 0s 204us/step - loss: 0.3097 - val_loss: 186.7030\n",
      "Epoch 859/1000\n",
      "1500/1500 [==============================] - 0s 199us/step - loss: 1.9899 - val_loss: 188.0623\n",
      "Epoch 860/1000\n",
      "1500/1500 [==============================] - 0s 204us/step - loss: 0.7326 - val_loss: 186.0842\n",
      "Epoch 861/1000\n",
      "1500/1500 [==============================] - 0s 201us/step - loss: 0.5454 - val_loss: 190.3226\n",
      "Epoch 862/1000\n",
      "1500/1500 [==============================] - 0s 201us/step - loss: 0.8280 - val_loss: 186.4111\n",
      "Epoch 863/1000\n",
      "1500/1500 [==============================] - 0s 202us/step - loss: 0.9240 - val_loss: 187.5428\n",
      "Epoch 864/1000\n",
      "1500/1500 [==============================] - 0s 203us/step - loss: 0.8347 - val_loss: 189.6230\n",
      "Epoch 865/1000\n",
      "1500/1500 [==============================] - 0s 195us/step - loss: 0.7337 - val_loss: 189.8093\n",
      "Epoch 866/1000\n",
      "1500/1500 [==============================] - 0s 198us/step - loss: 2.2852 - val_loss: 187.0207\n",
      "Epoch 867/1000\n",
      "1500/1500 [==============================] - 0s 197us/step - loss: 0.8549 - val_loss: 187.9294\n",
      "Epoch 868/1000\n",
      "1500/1500 [==============================] - 0s 200us/step - loss: 0.5043 - val_loss: 187.5564\n",
      "Epoch 869/1000\n",
      "1500/1500 [==============================] - 0s 203us/step - loss: 0.4380 - val_loss: 187.9503\n",
      "Epoch 870/1000\n",
      "1500/1500 [==============================] - 0s 202us/step - loss: 0.2077 - val_loss: 188.2038\n",
      "Epoch 871/1000\n",
      "1500/1500 [==============================] - 0s 202us/step - loss: 0.1904 - val_loss: 187.4630\n",
      "Epoch 872/1000\n",
      "1500/1500 [==============================] - 0s 198us/step - loss: 0.1637 - val_loss: 187.9039\n",
      "Epoch 873/1000\n",
      "1500/1500 [==============================] - 0s 202us/step - loss: 0.2344 - val_loss: 186.6776\n",
      "Epoch 874/1000\n",
      "1500/1500 [==============================] - 0s 201us/step - loss: 0.1605 - val_loss: 187.5598\n",
      "Epoch 875/1000\n",
      "1500/1500 [==============================] - 0s 203us/step - loss: 0.0790 - val_loss: 187.9304\n",
      "Epoch 876/1000\n",
      "1500/1500 [==============================] - 0s 201us/step - loss: 0.2271 - val_loss: 188.2132\n",
      "Epoch 877/1000\n",
      "1500/1500 [==============================] - 0s 204us/step - loss: 0.8626 - val_loss: 185.2669\n",
      "Epoch 878/1000\n",
      "1500/1500 [==============================] - 0s 198us/step - loss: 0.5574 - val_loss: 189.8854\n",
      "Epoch 879/1000\n",
      "1500/1500 [==============================] - 0s 199us/step - loss: 0.6128 - val_loss: 188.0479\n",
      "Epoch 880/1000\n",
      "1500/1500 [==============================] - 0s 206us/step - loss: 0.3706 - val_loss: 186.4318\n",
      "Epoch 881/1000\n",
      "1500/1500 [==============================] - 0s 201us/step - loss: 1.6861 - val_loss: 187.0628\n",
      "Epoch 882/1000\n",
      "1500/1500 [==============================] - 0s 198us/step - loss: 0.5321 - val_loss: 188.9816\n",
      "Epoch 883/1000\n",
      "1500/1500 [==============================] - 0s 198us/step - loss: 0.2574 - val_loss: 188.0011\n",
      "Epoch 884/1000\n",
      "1500/1500 [==============================] - 0s 201us/step - loss: 0.3880 - val_loss: 186.3488\n",
      "Epoch 885/1000\n",
      "1500/1500 [==============================] - 0s 199us/step - loss: 0.3151 - val_loss: 187.5251\n",
      "Epoch 886/1000\n",
      "1500/1500 [==============================] - 0s 207us/step - loss: 0.2509 - val_loss: 187.6970\n",
      "Epoch 887/1000\n",
      "1500/1500 [==============================] - 0s 201us/step - loss: 4.5660 - val_loss: 203.5785\n",
      "Epoch 888/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1500/1500 [==============================] - 0s 200us/step - loss: 23.6530 - val_loss: 185.2000\n",
      "Epoch 889/1000\n",
      "1500/1500 [==============================] - 0s 197us/step - loss: 5.4173 - val_loss: 183.6118\n",
      "Epoch 890/1000\n",
      "1500/1500 [==============================] - 0s 203us/step - loss: 3.1564 - val_loss: 185.8005\n",
      "Epoch 891/1000\n",
      "1500/1500 [==============================] - 0s 197us/step - loss: 1.2910 - val_loss: 188.5201\n",
      "Epoch 892/1000\n",
      "1500/1500 [==============================] - 0s 199us/step - loss: 0.7773 - val_loss: 185.5124\n",
      "Epoch 893/1000\n",
      "1500/1500 [==============================] - 0s 196us/step - loss: 0.3770 - val_loss: 186.7916\n",
      "Epoch 894/1000\n",
      "1500/1500 [==============================] - 0s 204us/step - loss: 0.2556 - val_loss: 187.0368\n",
      "Epoch 895/1000\n",
      "1500/1500 [==============================] - 0s 203us/step - loss: 0.1817 - val_loss: 186.9650\n",
      "Epoch 896/1000\n",
      "1500/1500 [==============================] - 0s 201us/step - loss: 0.1274 - val_loss: 186.7809\n",
      "Epoch 897/1000\n",
      "1500/1500 [==============================] - 0s 200us/step - loss: 0.0950 - val_loss: 186.6688\n",
      "Epoch 898/1000\n",
      "1500/1500 [==============================] - 0s 206us/step - loss: 0.0740 - val_loss: 186.9421\n",
      "Epoch 899/1000\n",
      "1500/1500 [==============================] - 0s 202us/step - loss: 0.0617 - val_loss: 186.6772\n",
      "Epoch 900/1000\n",
      "1500/1500 [==============================] - 0s 201us/step - loss: 0.0639 - val_loss: 186.8627\n",
      "Epoch 901/1000\n",
      "1500/1500 [==============================] - 0s 205us/step - loss: 0.0517 - val_loss: 186.8577\n",
      "Epoch 902/1000\n",
      "1500/1500 [==============================] - 0s 203us/step - loss: 0.0368 - val_loss: 186.8498\n",
      "Epoch 903/1000\n",
      "1500/1500 [==============================] - 0s 201us/step - loss: 0.0303 - val_loss: 186.6724\n",
      "Epoch 904/1000\n",
      "1500/1500 [==============================] - 0s 203us/step - loss: 0.0441 - val_loss: 186.9580\n",
      "Epoch 905/1000\n",
      "1500/1500 [==============================] - 0s 201us/step - loss: 0.0369 - val_loss: 186.9379\n",
      "Epoch 906/1000\n",
      "1500/1500 [==============================] - 0s 201us/step - loss: 0.0335 - val_loss: 186.8211\n",
      "Epoch 907/1000\n",
      "1500/1500 [==============================] - 0s 193us/step - loss: 0.0322 - val_loss: 186.7690\n",
      "Epoch 908/1000\n",
      "1500/1500 [==============================] - 0s 205us/step - loss: 0.0267 - val_loss: 186.8963\n",
      "Epoch 909/1000\n",
      "1500/1500 [==============================] - 0s 202us/step - loss: 0.0232 - val_loss: 186.8438\n",
      "Epoch 910/1000\n",
      "1500/1500 [==============================] - 0s 203us/step - loss: 0.0217 - val_loss: 186.9872\n",
      "Epoch 911/1000\n",
      "1500/1500 [==============================] - 0s 206us/step - loss: 0.0228 - val_loss: 186.7798\n",
      "Epoch 912/1000\n",
      "1500/1500 [==============================] - 0s 204us/step - loss: 0.0174 - val_loss: 186.9341\n",
      "Epoch 913/1000\n",
      "1500/1500 [==============================] - 0s 198us/step - loss: 0.0177 - val_loss: 186.7699\n",
      "Epoch 914/1000\n",
      "1500/1500 [==============================] - 0s 201us/step - loss: 0.0259 - val_loss: 186.8439\n",
      "Epoch 915/1000\n",
      "1500/1500 [==============================] - 0s 201us/step - loss: 0.0186 - val_loss: 186.9837\n",
      "Epoch 916/1000\n",
      "1500/1500 [==============================] - 0s 201us/step - loss: 0.0170 - val_loss: 186.8260\n",
      "Epoch 917/1000\n",
      "1500/1500 [==============================] - 0s 199us/step - loss: 0.0187 - val_loss: 186.8331\n",
      "Epoch 918/1000\n",
      "1500/1500 [==============================] - 0s 202us/step - loss: 0.0171 - val_loss: 187.2122\n",
      "Epoch 919/1000\n",
      "1500/1500 [==============================] - 0s 201us/step - loss: 0.0164 - val_loss: 186.9640\n",
      "Epoch 920/1000\n",
      "1500/1500 [==============================] - 0s 199us/step - loss: 0.0161 - val_loss: 186.9563\n",
      "Epoch 921/1000\n",
      "1500/1500 [==============================] - 0s 200us/step - loss: 0.0144 - val_loss: 186.8950\n",
      "Epoch 922/1000\n",
      "1500/1500 [==============================] - 0s 202us/step - loss: 0.0151 - val_loss: 187.1114\n",
      "Epoch 923/1000\n",
      "1500/1500 [==============================] - 0s 203us/step - loss: 0.0203 - val_loss: 187.3774\n",
      "Epoch 924/1000\n",
      "1500/1500 [==============================] - 0s 199us/step - loss: 0.0264 - val_loss: 187.0955\n",
      "Epoch 925/1000\n",
      "1500/1500 [==============================] - 0s 200us/step - loss: 0.0356 - val_loss: 186.9918\n",
      "Epoch 926/1000\n",
      "1500/1500 [==============================] - 0s 198us/step - loss: 0.4545 - val_loss: 189.2412\n",
      "Epoch 927/1000\n",
      "1500/1500 [==============================] - 0s 203us/step - loss: 1.7359 - val_loss: 186.7064\n",
      "Epoch 928/1000\n",
      "1500/1500 [==============================] - 0s 204us/step - loss: 3.2005 - val_loss: 193.7368\n",
      "Epoch 929/1000\n",
      "1500/1500 [==============================] - 0s 200us/step - loss: 2.7070 - val_loss: 185.1778\n",
      "Epoch 930/1000\n",
      "1500/1500 [==============================] - 0s 200us/step - loss: 1.2334 - val_loss: 187.1126\n",
      "Epoch 931/1000\n",
      "1500/1500 [==============================] - 0s 203us/step - loss: 1.7417 - val_loss: 186.2577\n",
      "Epoch 932/1000\n",
      "1500/1500 [==============================] - 0s 200us/step - loss: 0.7684 - val_loss: 188.2154\n",
      "Epoch 933/1000\n",
      "1500/1500 [==============================] - 0s 198us/step - loss: 1.2270 - val_loss: 190.6445\n",
      "Epoch 934/1000\n",
      "1500/1500 [==============================] - 0s 200us/step - loss: 1.2622 - val_loss: 186.7501\n",
      "Epoch 935/1000\n",
      "1500/1500 [==============================] - 0s 205us/step - loss: 0.7566 - val_loss: 187.0408\n",
      "Epoch 936/1000\n",
      "1500/1500 [==============================] - 0s 196us/step - loss: 0.4484 - val_loss: 186.5977\n",
      "Epoch 937/1000\n",
      "1500/1500 [==============================] - 0s 202us/step - loss: 0.1878 - val_loss: 186.0893\n",
      "Epoch 938/1000\n",
      "1500/1500 [==============================] - 0s 202us/step - loss: 0.1289 - val_loss: 187.1164\n",
      "Epoch 939/1000\n",
      "1500/1500 [==============================] - 0s 204us/step - loss: 0.4767 - val_loss: 184.4789\n",
      "Epoch 940/1000\n",
      "1500/1500 [==============================] - 0s 200us/step - loss: 0.4053 - val_loss: 186.4016\n",
      "Epoch 941/1000\n",
      "1500/1500 [==============================] - 0s 198us/step - loss: 0.1709 - val_loss: 187.5412\n",
      "Epoch 942/1000\n",
      "1500/1500 [==============================] - 0s 201us/step - loss: 0.1023 - val_loss: 186.3447\n",
      "Epoch 943/1000\n",
      "1500/1500 [==============================] - 0s 199us/step - loss: 0.0757 - val_loss: 186.3166\n",
      "Epoch 944/1000\n",
      "1500/1500 [==============================] - 0s 200us/step - loss: 0.1490 - val_loss: 186.8626\n",
      "Epoch 945/1000\n",
      "1500/1500 [==============================] - 0s 205us/step - loss: 0.2142 - val_loss: 186.3574\n",
      "Epoch 946/1000\n",
      "1500/1500 [==============================] - 0s 201us/step - loss: 0.1673 - val_loss: 186.5234\n",
      "Epoch 947/1000\n",
      "1500/1500 [==============================] - 0s 202us/step - loss: 0.0935 - val_loss: 185.7367\n",
      "Epoch 948/1000\n",
      "1500/1500 [==============================] - 0s 204us/step - loss: 0.1013 - val_loss: 185.9625\n",
      "Epoch 949/1000\n",
      "1500/1500 [==============================] - 0s 202us/step - loss: 0.5323 - val_loss: 185.2558\n",
      "Epoch 950/1000\n",
      "1500/1500 [==============================] - 0s 202us/step - loss: 1.3363 - val_loss: 190.3007\n",
      "Epoch 951/1000\n",
      "1500/1500 [==============================] - 0s 200us/step - loss: 1.6105 - val_loss: 186.2484\n",
      "Epoch 952/1000\n",
      "1500/1500 [==============================] - 0s 201us/step - loss: 3.4499 - val_loss: 190.1438\n",
      "Epoch 953/1000\n",
      "1500/1500 [==============================] - 0s 200us/step - loss: 2.1066 - val_loss: 189.3350\n",
      "Epoch 954/1000\n",
      "1500/1500 [==============================] - 0s 203us/step - loss: 1.0265 - val_loss: 185.6588\n",
      "Epoch 955/1000\n",
      "1500/1500 [==============================] - 0s 203us/step - loss: 3.1312 - val_loss: 185.3813\n",
      "Epoch 956/1000\n",
      "1500/1500 [==============================] - 0s 204us/step - loss: 1.4094 - val_loss: 186.5655\n",
      "Epoch 957/1000\n",
      "1500/1500 [==============================] - 0s 201us/step - loss: 1.1767 - val_loss: 184.9420\n",
      "Epoch 958/1000\n",
      "1500/1500 [==============================] - 0s 201us/step - loss: 0.6005 - val_loss: 183.9531\n",
      "Epoch 959/1000\n",
      "1500/1500 [==============================] - 0s 196us/step - loss: 0.3206 - val_loss: 183.4491\n",
      "Epoch 960/1000\n",
      "1500/1500 [==============================] - 0s 205us/step - loss: 0.3233 - val_loss: 184.8800\n",
      "Epoch 961/1000\n",
      "1500/1500 [==============================] - 0s 198us/step - loss: 0.1659 - val_loss: 187.0422\n",
      "Epoch 962/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1500/1500 [==============================] - 0s 200us/step - loss: 0.3702 - val_loss: 185.9513\n",
      "Epoch 963/1000\n",
      "1500/1500 [==============================] - 0s 200us/step - loss: 0.1973 - val_loss: 185.6910\n",
      "Epoch 964/1000\n",
      "1500/1500 [==============================] - 0s 200us/step - loss: 0.1790 - val_loss: 185.7198\n",
      "Epoch 965/1000\n",
      "1500/1500 [==============================] - 0s 200us/step - loss: 0.2504 - val_loss: 185.0536\n",
      "Epoch 966/1000\n",
      "1500/1500 [==============================] - 0s 197us/step - loss: 0.1443 - val_loss: 185.2806\n",
      "Epoch 967/1000\n",
      "1500/1500 [==============================] - 0s 200us/step - loss: 0.1423 - val_loss: 186.1645\n",
      "Epoch 968/1000\n",
      "1500/1500 [==============================] - 0s 204us/step - loss: 0.1321 - val_loss: 185.8449\n",
      "Epoch 969/1000\n",
      "1500/1500 [==============================] - 0s 199us/step - loss: 0.1687 - val_loss: 185.9201\n",
      "Epoch 970/1000\n",
      "1500/1500 [==============================] - 0s 202us/step - loss: 0.0861 - val_loss: 185.9094\n",
      "Epoch 971/1000\n",
      "1500/1500 [==============================] - 0s 195us/step - loss: 0.0454 - val_loss: 185.5725\n",
      "Epoch 972/1000\n",
      "1500/1500 [==============================] - 0s 202us/step - loss: 0.0463 - val_loss: 185.4283\n",
      "Epoch 973/1000\n",
      "1500/1500 [==============================] - 0s 204us/step - loss: 0.1149 - val_loss: 185.7695\n",
      "Epoch 974/1000\n",
      "1500/1500 [==============================] - 0s 201us/step - loss: 0.1348 - val_loss: 185.8358\n",
      "Epoch 975/1000\n",
      "1500/1500 [==============================] - 0s 204us/step - loss: 0.5798 - val_loss: 187.9650\n",
      "Epoch 976/1000\n",
      "1500/1500 [==============================] - 0s 201us/step - loss: 0.4432 - val_loss: 185.5092\n",
      "Epoch 977/1000\n",
      "1500/1500 [==============================] - 0s 199us/step - loss: 0.7487 - val_loss: 188.4722\n",
      "Epoch 978/1000\n",
      "1500/1500 [==============================] - 0s 204us/step - loss: 0.7097 - val_loss: 184.3381\n",
      "Epoch 979/1000\n",
      "1500/1500 [==============================] - 0s 197us/step - loss: 2.2599 - val_loss: 186.0495\n",
      "Epoch 980/1000\n",
      "1500/1500 [==============================] - 0s 200us/step - loss: 2.0420 - val_loss: 186.1916\n",
      "Epoch 981/1000\n",
      "1500/1500 [==============================] - 0s 198us/step - loss: 3.1282 - val_loss: 184.8035\n",
      "Epoch 982/1000\n",
      "1500/1500 [==============================] - 0s 201us/step - loss: 2.4234 - val_loss: 186.6797\n",
      "Epoch 983/1000\n",
      "1500/1500 [==============================] - 0s 200us/step - loss: 1.1147 - val_loss: 185.8107\n",
      "Epoch 984/1000\n",
      "1500/1500 [==============================] - 0s 204us/step - loss: 0.7115 - val_loss: 189.7297\n",
      "Epoch 985/1000\n",
      "1500/1500 [==============================] - 0s 204us/step - loss: 0.6149 - val_loss: 186.2511\n",
      "Epoch 986/1000\n",
      "1500/1500 [==============================] - 0s 200us/step - loss: 0.3372 - val_loss: 186.6612\n",
      "Epoch 987/1000\n",
      "1500/1500 [==============================] - 0s 197us/step - loss: 0.2781 - val_loss: 185.6542\n",
      "Epoch 988/1000\n",
      "1500/1500 [==============================] - 0s 195us/step - loss: 0.1556 - val_loss: 186.1744\n",
      "Epoch 989/1000\n",
      "1500/1500 [==============================] - 0s 200us/step - loss: 0.1043 - val_loss: 186.9541\n",
      "Epoch 990/1000\n",
      "1500/1500 [==============================] - 0s 203us/step - loss: 0.0994 - val_loss: 185.6938\n",
      "Epoch 991/1000\n",
      "1500/1500 [==============================] - 0s 199us/step - loss: 0.1018 - val_loss: 185.8002\n",
      "Epoch 992/1000\n",
      "1500/1500 [==============================] - 0s 200us/step - loss: 0.0740 - val_loss: 185.5371\n",
      "Epoch 993/1000\n",
      "1500/1500 [==============================] - 0s 206us/step - loss: 0.1186 - val_loss: 185.6022\n",
      "Epoch 994/1000\n",
      "1500/1500 [==============================] - 0s 198us/step - loss: 0.1253 - val_loss: 186.7784\n",
      "Epoch 995/1000\n",
      "1500/1500 [==============================] - 0s 200us/step - loss: 0.0792 - val_loss: 185.7831\n",
      "Epoch 996/1000\n",
      "1500/1500 [==============================] - 0s 207us/step - loss: 0.1269 - val_loss: 185.2645\n",
      "Epoch 997/1000\n",
      "1500/1500 [==============================] - 0s 206us/step - loss: 0.1709 - val_loss: 185.4239\n",
      "Epoch 998/1000\n",
      "1500/1500 [==============================] - 0s 200us/step - loss: 0.1837 - val_loss: 186.5098\n",
      "Epoch 999/1000\n",
      "1500/1500 [==============================] - 0s 197us/step - loss: 0.4100 - val_loss: 186.6313\n",
      "Epoch 1000/1000\n",
      "1500/1500 [==============================] - 0s 200us/step - loss: 1.1018 - val_loss: 184.6488\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 0s 110us/step\n",
      "235.3449951171875\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 25 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "def generate_dataset(samples):\n",
    "\n",
    "    ds_x = []\n",
    "    ds_y = []\n",
    "    \n",
    "    for it in range(samples):\n",
    "        \n",
    "        num_pt = np.random.randint(0, width * height)\n",
    "        img = generate_image(num_pt)\n",
    "        \n",
    "        ds_y.append(num_pt)\n",
    "        ds_x.append(img)\n",
    "    \n",
    "    return np.array(ds_x), np.array(ds_y).reshape(samples, 1)\n",
    "    \n",
    "def generate_image(points):\n",
    "    \n",
    "    img = np.zeros((width, height))\n",
    "    pts = np.random.random((points, 2))\n",
    "    \n",
    "    for ipt in pts:\n",
    "        img[int(ipt[0] * width), int(ipt[1] * height)] = 1\n",
    "    \n",
    "    return img.reshape(width, height, 1)\n",
    "\n",
    "# 1. 데이터셋 생성하기\n",
    "x_train, y_train = generate_dataset(1500)\n",
    "x_val, y_val = generate_dataset(300)\n",
    "x_test, y_test = generate_dataset(100)\n",
    "\n",
    "# 2. 모델 구성하기\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(width, height, 1)))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(1))\n",
    "\n",
    "# 3. 모델 학습과정 설정하기\n",
    "model.compile(loss='mse', optimizer='adam')\n",
    "\n",
    "# 4. 모델 학습시키기\n",
    "hist = model.fit(x_train, y_train, batch_size=32, epochs=1000, validation_data=(x_val, y_val))\n",
    "\n",
    "# 5. 학습과정 살펴보기\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(hist.history['loss'])\n",
    "plt.plot(hist.history['val_loss'])\n",
    "plt.ylim(0.0, 300.0)\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# 6. 모델 평가하기\n",
    "score = model.evaluate(x_test, y_test, batch_size=32)\n",
    "\n",
    "print(score)\n",
    "\n",
    "# 7. 모델 사용하기\n",
    "yhat_test = model.predict(x_test, batch_size=32)\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt_row = 5\n",
    "plt_col = 5\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (10,10)\n",
    "\n",
    "f, axarr = plt.subplots(plt_row, plt_col)\n",
    "\n",
    "for i in range(plt_row*plt_col):\n",
    "    sub_plt = axarr[i//plt_row, i%plt_col]\n",
    "    sub_plt.axis('off')\n",
    "    sub_plt.imshow(x_test[i].reshape(width, height))\n",
    "    sub_plt.set_title('R %d P %.1f' % (y_test[i][0], yhat_test[i][0]))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
